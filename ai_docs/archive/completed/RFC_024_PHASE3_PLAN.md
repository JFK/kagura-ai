# RFC-024 Phase 3 Implementation Plan: Context Summarization

**Phase**: 3 of 4
**Duration**: Week 3-4 (10-14 days)
**Priority**: ğŸ”¥ğŸ”¥ğŸ”¥ Critical
**Depends on**: Phase 1 âœ…, Phase 2 âœ…

---

## ğŸ“‹ Overview

Phase 3ã§ã¯ã€LLMã‚’ä½¿ç”¨ã—ãŸä¼šè©±å±¥æ­´ã®è¦ç´„æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¾ã™ã€‚å˜ç´”ãªãƒˆãƒªãƒŸãƒ³ã‚°ã§ã¯æƒ…å ±ãŒå¤±ã‚ã‚Œã‚‹å ´åˆã«ã€é‡è¦ãªæƒ…å ±ã‚’ä¿æŒã—ãªãŒã‚‰ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å¤§å¹…ã«å‰Šæ¸›ã—ã¾ã™ã€‚

### Goals

1. **Recursive Summarization**: å†å¸°çš„ã«è¦ç´„ã‚’ç”Ÿæˆã—ã€ä»»æ„ã®é•·ã•ã®ä¼šè©±ã‚’åœ§ç¸®
2. **Hierarchical Summarization**: 3æ®µéšï¼ˆbrief/detailed/fullï¼‰ã®è¦ç´„ã‚’ç”Ÿæˆ
3. **Event-Preserving Compression**: é‡è¦ãªã‚¤ãƒ™ãƒ³ãƒˆï¼ˆæ±ºå®šäº‹é …ã€ã‚¨ãƒ©ãƒ¼ã€è¨­å®šç­‰ï¼‰ã‚’ä¿æŒã—ãªãŒã‚‰åœ§ç¸®

---

## ğŸ¯ Success Criteria

### Functional
- âœ… Recursive summarizationå‹•ä½œï¼ˆ10,000ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸â†’500ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
- âœ… Hierarchical summarizationç”Ÿæˆï¼ˆbrief: 10%, detailed: 30%, full: 70%ï¼‰
- âœ… Key event preservationï¼ˆ95%+ã®é‡è¦ã‚¤ãƒ™ãƒ³ãƒˆä¿æŒï¼‰
- âœ… éåŒæœŸå‡¦ç†å¯¾å¿œï¼ˆasync/awaitï¼‰

### Quality
- âœ… è¦ç´„å“è³ª: äººé–“è©•ä¾¡ã§4/5ä»¥ä¸Š
- âœ… æƒ…å ±ä¿æŒç‡: 90%+ï¼ˆé‡è¦æƒ…å ±ï¼‰
- âœ… ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ç‡: 80%+ï¼ˆsummarizationæ™‚ï¼‰
- âœ… 25+ testså…¨ãƒ‘ã‚¹

### Performance
- âœ… å‡¦ç†é€Ÿåº¦: <5s/1000ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆLLMå‘¼ã³å‡ºã—å«ã‚€ï¼‰
- âœ… LLMã‚³ã‚¹ãƒˆ: <$0.01/1000ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆgpt-4o-miniä½¿ç”¨æ™‚ï¼‰

### Code Quality
- âœ… Pyright: 0 errorsï¼ˆstrict modeï¼‰
- âœ… Ruff: All checks passed
- âœ… Coverage: 95%+

---

## ğŸ“¦ Implementation

### File Structure

```
src/kagura/core/compression/
â”œâ”€â”€ __init__.py              # Export ContextSummarizer
â”œâ”€â”€ summarizer.py            # NEW: ContextSummarizerå®Ÿè£…
â”œâ”€â”€ token_counter.py         # Existing (Phase 1)
â”œâ”€â”€ monitor.py              # Existing (Phase 1)
â””â”€â”€ trimmer.py              # Existing (Phase 2)

tests/core/compression/
â”œâ”€â”€ test_summarizer.py       # NEW: 25+ tests
â”œâ”€â”€ test_token_counter.py    # Existing
â”œâ”€â”€ test_monitor.py          # Existing
â””â”€â”€ test_trimmer.py          # Existing
```

---

## ğŸ“ Day-by-Day Plan

### Week 3: Core Summarization

#### Day 1-2: Recursive Summarization
**Goal**: å†å¸°çš„è¦ç´„ã®åŸºæœ¬å®Ÿè£…

**Tasks**:
1. `ContextSummarizer`ã‚¯ãƒ©ã‚¹ä½œæˆ
2. `summarize_recursive()`å®Ÿè£…
3. `_messages_to_text()`ãƒ˜ãƒ«ãƒ‘ãƒ¼å®Ÿè£…
4. `_split_into_chunks()`å®Ÿè£…
5. åŸºæœ¬ãƒ†ã‚¹ãƒˆï¼ˆ5 testsï¼‰

**Files**:
- `src/kagura/core/compression/summarizer.py`
- `tests/core/compression/test_summarizer.py`

**Code**:
```python
# src/kagura/core/compression/summarizer.py

from typing import Any, Optional
from kagura.core.llm import call_llm, LLMConfig
from .token_counter import TokenCounter

class ContextSummarizer:
    """Summarize conversation history to reduce tokens"""

    def __init__(
        self,
        token_counter: TokenCounter,
        llm_config: Optional[LLMConfig] = None
    ):
        self.counter = token_counter
        self.llm_config = llm_config or LLMConfig(
            model="gpt-4o-mini",
            temperature=0.3
        )

    async def summarize_recursive(
        self,
        messages: list[dict[str, Any]],
        target_tokens: int
    ) -> str:
        """Recursively summarize conversation history"""
        conversation = self._messages_to_text(messages)
        current_tokens = self.counter.count_tokens(conversation)

        if current_tokens <= target_tokens:
            return conversation

        # Summarize
        summary_prompt = f"""Summarize the following conversation concisely while preserving all important information, decisions, user preferences, and context:

{conversation}

Summary:"""

        summary = await call_llm(summary_prompt, self.llm_config)
        summary_tokens = self.counter.count_tokens(summary)

        if summary_tokens <= target_tokens:
            return summary

        # Recursively summarize if still too large
        chunks = self._split_into_chunks(conversation, target_tokens)
        chunk_summaries = []

        for chunk in chunks:
            chunk_summary = await self._summarize_chunk(chunk)
            chunk_summaries.append(chunk_summary)

        combined = "\n\n".join(chunk_summaries)

        return await self.summarize_recursive(
            [{"role": "user", "content": combined}],
            target_tokens
        )

    def _messages_to_text(self, messages: list[dict[str, Any]]) -> str:
        """Convert message list to readable text"""
        lines = []
        for msg in messages:
            role = msg.get("role", "unknown")
            content = msg.get("content", "")
            lines.append(f"{role.upper()}: {content}")
        return "\n\n".join(lines)

    async def _summarize_chunk(self, chunk: str) -> str:
        """Summarize a single chunk"""
        prompt = f"""Summarize this conversation segment concisely:

{chunk}

Summary:"""
        return await call_llm(prompt, self.llm_config)

    def _split_into_chunks(self, text: str, target_tokens: int) -> list[str]:
        """Split text into chunks of target size"""
        sentences = text.split(". ")
        chunks = []
        current_chunk = []
        current_tokens = 0

        for sentence in sentences:
            sentence_tokens = self.counter.count_tokens(sentence)

            if current_tokens + sentence_tokens > target_tokens and current_chunk:
                chunks.append(". ".join(current_chunk) + ".")
                current_chunk = [sentence]
                current_tokens = sentence_tokens
            else:
                current_chunk.append(sentence)
                current_tokens += sentence_tokens

        if current_chunk:
            chunks.append(". ".join(current_chunk) + ".")

        return chunks
```

**Tests**:
```python
# tests/core/compression/test_summarizer.py

import pytest
from unittest.mock import AsyncMock, patch
from kagura.core.compression import TokenCounter, ContextSummarizer

@pytest.fixture
def summarizer():
    counter = TokenCounter(model="gpt-4o-mini")
    return ContextSummarizer(counter)

@pytest.mark.asyncio
@patch("kagura.core.compression.summarizer.call_llm", new_callable=AsyncMock)
async def test_summarize_recursive_basic(mock_call_llm, summarizer):
    """Test basic recursive summarization"""
    mock_call_llm.return_value = "This is a brief summary."

    messages = [
        {"role": "user", "content": "Long message " * 100},
        {"role": "assistant", "content": "Long response " * 100},
    ]

    summary = await summarizer.summarize_recursive(messages, target_tokens=50)

    assert "summary" in summary.lower()
    assert len(summary) < 200

@pytest.mark.asyncio
@patch("kagura.core.compression.summarizer.call_llm", new_callable=AsyncMock)
async def test_summarize_recursive_already_short(mock_call_llm, summarizer):
    """Test when content is already under target"""
    messages = [{"role": "user", "content": "Short message"}]

    summary = await summarizer.summarize_recursive(messages, target_tokens=1000)

    # Should not call LLM
    mock_call_llm.assert_not_called()
    assert "Short message" in summary
```

---

#### Day 3-4: Hierarchical Summarization
**Goal**: 3æ®µéšã®è¦ç´„ç”Ÿæˆ

**Tasks**:
1. `summarize_hierarchical()`å®Ÿè£…
2. briefï¼ˆ10%ï¼‰ã€detailedï¼ˆ30%ï¼‰ã€fullï¼ˆ70%ï¼‰ã®è¦ç´„ç”Ÿæˆ
3. ãƒ†ã‚¹ãƒˆè¿½åŠ ï¼ˆ5 testsï¼‰

**Code**:
```python
async def summarize_hierarchical(
    self,
    messages: list[dict[str, Any]],
    levels: int = 3
) -> dict[str, str]:
    """Create hierarchical summary at multiple levels

    Returns:
        Dict with keys: "brief", "detailed", "full"
    """
    conversation = self._messages_to_text(messages)
    current_tokens = self.counter.count_tokens(conversation)

    summaries = {}

    # Level 1: Brief (10% of original)
    target_brief = max(int(current_tokens * 0.1), 100)
    summaries["brief"] = await self.summarize_recursive(messages, target_brief)

    # Level 2: Detailed (30% of original)
    target_detailed = max(int(current_tokens * 0.3), 300)
    summaries["detailed"] = await self.summarize_recursive(messages, target_detailed)

    # Level 3: Full (original or 70% if too long)
    if current_tokens > 5000:
        target_full = int(current_tokens * 0.7)
        summaries["full"] = await self.summarize_recursive(messages, target_full)
    else:
        summaries["full"] = conversation

    return summaries
```

**Tests**:
```python
@pytest.mark.asyncio
@patch("kagura.core.compression.summarizer.call_llm", new_callable=AsyncMock)
async def test_summarize_hierarchical(mock_call_llm, summarizer):
    """Test hierarchical summarization"""
    mock_call_llm.return_value = "Summary text"

    messages = [
        {"role": "user", "content": "Message " * 100}
    ] * 10

    summaries = await summarizer.summarize_hierarchical(messages, levels=3)

    assert "brief" in summaries
    assert "detailed" in summaries
    assert "full" in summaries

    # Brief should be shortest
    assert len(summaries["brief"]) < len(summaries["detailed"])
```

---

#### Day 5-7: Event-Preserving Compression
**Goal**: é‡è¦ã‚¤ãƒ™ãƒ³ãƒˆä¿æŒå‹åœ§ç¸®

**Tasks**:
1. `compress_preserve_events()`å®Ÿè£…
2. `_is_key_event()`ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºå®Ÿè£…
3. ã‚¤ãƒ™ãƒ³ãƒˆä¿æŒãƒ†ã‚¹ãƒˆï¼ˆ8 testsï¼‰

**Code**:
```python
async def compress_preserve_events(
    self,
    messages: list[dict[str, Any]],
    target_tokens: int
) -> list[dict[str, Any]]:
    """Compress while preserving key events

    Strategy:
    1. Identify key events (decisions, errors, preferences)
    2. Summarize routine messages
    3. Keep key events verbatim
    """
    # Separate key events from routine messages
    key_events = []
    routine = []

    for msg in messages:
        if self._is_key_event(msg):
            key_events.append(msg)
        else:
            routine.append(msg)

    # Calculate token budget
    key_event_tokens = self.counter.count_tokens_messages(key_events)
    remaining_tokens = target_tokens - key_event_tokens

    if remaining_tokens < 100:
        # Not enough space, must summarize everything
        summary = await self.summarize_recursive(messages, target_tokens)
        return [{"role": "system", "content": f"[Summary] {summary}"}]

    # Summarize routine messages
    if routine:
        routine_summary = await self.summarize_recursive(routine, remaining_tokens)
        summary_msg = {
            "role": "system",
            "content": f"[Previous conversation summary] {routine_summary}"
        }
    else:
        summary_msg = None

    # Reconstruct message list
    compressed = []
    if summary_msg:
        compressed.append(summary_msg)
    compressed.extend(key_events)

    return compressed

def _is_key_event(self, msg: dict[str, Any]) -> bool:
    """Check if message is a key event"""
    content = msg.get("content", "").lower()

    key_indicators = [
        "error", "exception", "failed",
        "important", "critical", "urgent",
        "decided", "agreed", "confirmed",
        "preference", "setting", "config",
        "remember", "note", "save"
    ]

    return any(indicator in content for indicator in key_indicators)
```

**Tests**:
```python
@pytest.mark.asyncio
@patch("kagura.core.compression.summarizer.call_llm", new_callable=AsyncMock)
async def test_compress_preserve_events(mock_call_llm, summarizer):
    """Test event-preserving compression"""
    mock_call_llm.return_value = "Routine summary"

    messages = [
        {"role": "user", "content": "Normal message 1"},
        {"role": "user", "content": "IMPORTANT: User decided to use dark mode"},
        {"role": "user", "content": "Normal message 2"},
        {"role": "user", "content": "ERROR: Connection failed"},
        {"role": "user", "content": "Normal message 3"},
    ]

    compressed = await summarizer.compress_preserve_events(messages, target_tokens=200)

    # Should preserve key events
    contents = [m["content"] for m in compressed]
    assert any("IMPORTANT" in c for c in contents)
    assert any("ERROR" in c for c in contents)

def test_is_key_event(summarizer):
    """Test key event detection"""
    # Key events
    assert summarizer._is_key_event({"content": "IMPORTANT: user preference"})
    assert summarizer._is_key_event({"content": "ERROR: failed to connect"})
    assert summarizer._is_key_event({"content": "Decided to use API key auth"})

    # Not key events
    assert not summarizer._is_key_event({"content": "Hello, how are you?"})
    assert not summarizer._is_key_event({"content": "Thanks for the help"})
```

---

### Week 4: Testing & Documentation

#### Day 1-3: Comprehensive Testing
**Goal**: 25+ testså…¨ãƒ‘ã‚¹

**Test Categories**:
1. **Basic Functionality** (5 tests)
   - Recursive summarization
   - Hierarchical summarization
   - Event-preserving compression

2. **Edge Cases** (8 tests)
   - Empty messages
   - Single message
   - Very long messages
   - No key events
   - All key events
   - Target tokens < actual tokens

3. **Integration** (7 tests)
   - With TokenCounter
   - With different LLM models
   - With async processing
   - Mock LLM responses

4. **Performance** (5 tests)
   - Large message lists (1000+)
   - Token reduction verification
   - LLM call count optimization

**Additional Tests**:
```python
@pytest.mark.asyncio
async def test_summarize_empty_messages(summarizer):
    """Test with empty message list"""
    messages = []
    summary = await summarizer.summarize_recursive(messages, target_tokens=100)
    assert summary == ""

@pytest.mark.asyncio
@patch("kagura.core.compression.summarizer.call_llm", new_callable=AsyncMock)
async def test_summarize_large_conversation(mock_call_llm, summarizer):
    """Test with large conversation (1000+ messages)"""
    mock_call_llm.return_value = "Summary"

    messages = [{"role": "user", "content": f"Message {i}"} for i in range(1000)]

    summary = await summarizer.summarize_recursive(messages, target_tokens=500)

    # Should significantly reduce tokens
    original_tokens = summarizer.counter.count_tokens_messages(messages)
    summary_tokens = summarizer.counter.count_tokens(summary)

    assert summary_tokens < original_tokens * 0.1  # 90%+ reduction

@pytest.mark.asyncio
@patch("kagura.core.compression.summarizer.call_llm", new_callable=AsyncMock)
async def test_compress_no_routine_messages(mock_call_llm, summarizer):
    """Test when all messages are key events"""
    messages = [
        {"role": "user", "content": "IMPORTANT: Event 1"},
        {"role": "user", "content": "ERROR: Event 2"},
        {"role": "user", "content": "CRITICAL: Event 3"},
    ]

    compressed = await summarizer.compress_preserve_events(messages, target_tokens=500)

    # Should not call LLM (no routine to summarize)
    mock_call_llm.assert_not_called()

    # Should keep all key events
    assert len(compressed) == len(messages)
```

---

#### Day 4-7: Documentation & PR

**Tasks**:
1. Update `__init__.py` exports
2. Update `ai_docs/NEXT_STEPS.md`
3. Create comprehensive docstrings
4. Write usage examples
5. Create Draft PR
6. CI verification

**Documentation**:
```markdown
## Usage Example

```python
from kagura.core.compression import TokenCounter, ContextSummarizer

counter = TokenCounter(model="gpt-4o-mini")
summarizer = ContextSummarizer(counter)

# Recursive summarization
messages = [
    {"role": "user", "content": "Long conversation..."},
    # ... many messages
]

summary = await summarizer.summarize_recursive(messages, target_tokens=500)
print(summary)

# Hierarchical summarization
summaries = await summarizer.summarize_hierarchical(messages)
print(summaries["brief"])     # 10% of original
print(summaries["detailed"])  # 30% of original
print(summaries["full"])      # 70% of original

# Event-preserving compression
compressed = await summarizer.compress_preserve_events(messages, target_tokens=1000)
# Key events are preserved verbatim, routine messages are summarized
```
```

---

## ğŸ¯ Deliverables

### Code
- âœ… `src/kagura/core/compression/summarizer.py` (~250 lines)
- âœ… `tests/core/compression/test_summarizer.py` (~400 lines, 25+ tests)
- âœ… Updated `__init__.py` exports

### Tests
- âœ… 25+ testså…¨ãƒ‘ã‚¹
- âœ… Pyright: 0 errors
- âœ… Ruff: All checks passed
- âœ… Coverage: 95%+

### Documentation
- âœ… Comprehensive docstrings
- âœ… Usage examples
- âœ… `ai_docs/NEXT_STEPS.md` updated

### PR
- âœ… Draft PRä½œæˆ
- âœ… CIé€šé
- âœ… Ready for review

---

## ğŸ“Š Quality Metrics

### Functional
- Token reduction: 80%+ (summarization)
- Key event preservation: 95%+
- Async processing: Full support

### Performance
- Processing speed: <5s/1000 messages
- LLM cost: <$0.01/1000 messages

### Code Quality
- Pyright: 0 errors (strict mode)
- Ruff: All checks passed
- Test coverage: 95%+

---

## ğŸ”— Next Steps

After Phase 3:
- **Phase 4**: Integration & Policy
  - CompressionPolicy implementation
  - ContextManagerçµ±åˆ
  - MemoryManagerçµ±åˆ
  - @agentãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿çµ±åˆ

---

**Phase 3å®Œäº†ã«ã‚ˆã‚Šã€Kagura AIã¯é«˜åº¦ãªContext Compressionæ©Ÿèƒ½ã‚’ç²å¾—ã—ã¾ã™ï¼**
