# Kagura AI v4.0 - Strategic Pivot: Universal AI Memory Platform

**日付**: 2025-10-25（更新: マルチモーダル対応追加）
**作成**: Claude Code + ChatGPT 5 Pro アイデア統合
**ステータス**: 戦略提案（Community Feedback Welcome）

---

## 📋 エグゼクティブ・サマリ

### PIVOTの核心

**v3.0（現在）**: Python-First AI Agent SDK + Chat
**v4.0（提案）**: **Universal AI Memory & Context Platform (MCP-native + Multimodal)**

```
従来: 各AIプラットフォームが個別に記憶を保持
      ↓
課題: ChatGPT、Claude、Gemini間で記憶が分断
      プラットフォーム変更＝記憶リセット
      ↓
解決: Kagura = 横断的なメモリー層
      すべてのAIが同じ「あなた」を参照
```

**キーメッセージ**:
> **Own your memory. Bring it to every AI.**
> Kagura: A portable, privacy-first **Context & Memory Hub** for all your agents.

**v4.0+の拡張**: 🆕 **Multimodal Memory**
- テキストだけでなく、**画像・音声・動画・PDF・コード**も統一的に記憶・検索
- 「去年の設計図のスクショ」「このコードに関する議事録」など、**クロスモーダル検索**
- 開発者の**全交流経験**（Vibe Coding）を記録: コード + スクショ + 音声メモ + 動画

---

## 🎯 戦略の4本柱

### 1. Memory-First Architecture

**Core Value**: メモリー・コンテキスト管理に特化

```
┌─────────────────────────────────────────┐
│  AI Platforms (via MCP)                 │
│  Claude, ChatGPT, Gemini, Cursor, ...   │
└─────────────────────────────────────────┘
         ↕ MCP Protocol
┌─────────────────────────────────────────┐
│  Kagura Memory Hub (Core)               │
│  - Memory Manager (3-tier + Graph)      │
│  - RAG (Knowledge Base)                 │
│  - History Tracker (Vibe Coding)        │
│  - API Server (REST/GraphQL)            │
└─────────────────────────────────────────┘
         ↕ Storage
┌─────────────────────────────────────────┐
│  SQLite + ChromaDB + NetworkX           │
│  pgvector (Cloud/Self-hosted)           │
└─────────────────────────────────────────┘
```

**機能の優先順位**:
- 🎯 **Core (v4.0)**: Text Memory API (MCP + REST) + Graph
- 🔧 **v4.1 MVP**: **Multimodal Attachments** (画像/音声/PDF) + 派生テキスト検索
- 🚀 **v4.2 Full**: **Cross-modal Search** (Image/Audio Embedding)
- 🔧 **Optional**: MCP Tools (Web search, YouTube, Files)
- 🧪 **Minimal**: Chat CLI (MCP testing only)
- ❌ **Remove**: Personal tools (news, weather, recipes), SDK-focused examples

### 2. MCP-Native Design

**MCPツール（最小契約 v1）**:
```python
# Memory Management
memory.store(text, kind, source, meta)
memory.recall(cue_text, k, include_graph_hops)
memory.search(query, filter)
memory.feedback(node_id, label, weight)
memory.delete(node_id)

# Graph Operations (#345)
memory.link(src_id, dst_id, rel, weight)
memory.query_graph(seed_ids, hops, rel_filters)
memory.record_interaction(...)

# System
memory.metrics()
memory.export()
memory.import()
```

**既存Issueとの整合**:
- **#331**: MCP Enhancement Roadmap - ツール管理、Claude Desktop統合自動化
- **#345**: GraphDB Memory - user/topic/memory/interaction nodes + edges

### 3. Multimodal Memory（段階的導入）

**v4.0（Text Foundation）**:
- Text memory + Graph
- MCP tools（text only）
- Export/Import（text）

**v4.1（Multimodal MVP）**:
- **Attachments**: 画像、音声、PDF、コード
- **派生テキスト**: Caption/OCR/ASR → Text化
- **Text-based検索**: 派生テキスト経由で画像・音声も検索可能
- **Consumer App**: Quick Capture（camera, mic, files）

**v4.2（Full Multimodal）**:
- **Image/Audio Embedding**: CLIP、Whisper等
- **Cross-modal Search**: text→image, image→text
- **Video Support**: Keyframe extraction, transcription
- **Advanced Analytics**: Per-modality insights

### 4. 3層デプロイメント戦略

| デプロイ形態 | タイミング | ターゲット | 特徴 |
|------------|----------|-----------|------|
| **Local** | v4.0 (Now) | 個人開発者 | Docker Compose, 完全プライバシー |
| **Self-hosted API** | v4.1 (3-4M) | 小規模チーム | API Server, デバイス間同期, **Multimodal** |
| **Kagura Cloud** | v4.2+ (6-12M) | エンタープライズ | SaaS, BYOK, RLS, 監査ログ, **Full Multimodal** |

---

## 🎨 マルチモーダル戦略（詳細）

### なぜマルチモーダルか

**開発者の典型的な1日**:
```
朝: 設計図をスクショ → Claudeに質問
昼: 会議を音声録音 → 議事録として保存
午後: エラー画面キャプチャ → 解決策を検索
夕: チュートリアル動画視聴 → メモとして記録
夜: コード + PRレビュー → GitHubと連携
```

**現状の問題**:
- これらは**別々のツール**で管理
- **横断検索不可**: 「あのスクショに関連する議事録は？」
- **AIが参照できない**: 各AIは画像・音声を記憶に活用できない

**Kaguraの解決**:
- すべてを**統一メモリー**に保存
- **クロスモーダル検索**: テキストで画像を、画像でテキストを
- **AI横断参照**: どのAIも同じ画像・音声にアクセス可能

### アーキテクチャ（拡張版）

```
┌─────────────────────────────────────────┐
│  AI Platforms + Consumer Apps           │
│  Claude, ChatGPT, Gemini, Mobile App    │
└─────────────────────────────────────────┘
         ↕ MCP + REST API
┌─────────────────────────────────────────┐
│  Kagura Memory Hub                      │
│  ┌─────────────────────────────────┐   │
│  │ Memory Manager                  │   │
│  │  - Text nodes                   │   │
│  │  - Attachment nodes (v4.1+) 🆕  │   │
│  │  - Derived text nodes 🆕        │   │
│  └─────────────────────────────────┘   │
│  ┌─────────────────────────────────┐   │
│  │ Search Engine                   │   │
│  │  - Text embedding (ChromaDB)    │   │
│  │  - Image embedding (v4.2+) 🆕   │   │
│  │  - Audio embedding (v4.2+) 🆕   │   │
│  │  - Cross-modal fusion 🆕        │   │
│  └─────────────────────────────────┘   │
│  ┌─────────────────────────────────┐   │
│  │ Worker Pipeline (v4.1+) 🆕      │   │
│  │  - Caption generation           │   │
│  │  - OCR (Tesseract/Cloud)        │   │
│  │  - ASR (Whisper/Cloud)          │   │
│  │  - Thumbnail generation         │   │
│  └─────────────────────────────────┘   │
└─────────────────────────────────────────┘
         ↕ Storage
┌─────────────────────────────────────────┐
│  Database (Postgres/SQLite)             │
│  - nodes (memory本体)                   │
│  - attachments (v4.1+) 🆕               │
│    - id, modality, mime, bytes, url     │
│  - derived_texts (v4.1+) 🆕             │
│    - id, source (caption/ocr/asr), text │
│  - embeddings (Multi-Vector) 🆕         │
│    - id, modality, vector, weight       │
│  - edges (graph relationships)          │
└─────────────────────────────────────────┘
```

### MCPツール拡張（v4.1+）

```python
# v4.1: Multimodal MVP
memory.attach(node_id, file, modality, meta)
  # modality: image/audio/video/pdf/code
  # Auto-triggers: caption/ocr/asr worker

memory.derive(node_id, ops: ["caption", "ocr", "asr"])
  # On-demand派生テキスト生成

memory.recall(query, modalities: ["text", "image", "audio"])
  # Multi-modal recall
  # Returns: nodes with attachments + derived texts

# v4.2: Full Multimodal
memory.recall_multimodal(cue: {text, image_ref, audio_ref}, k)
  # Cross-modal search
  # text→image, image→text, etc.

memory.search_by_image(image_ref, k)
  # Image similarity search

memory.search_by_audio(audio_ref, k)
  # Audio similarity search
```

### データフロー（v4.1 MVP）

```
1. Upload Image
   ↓
2. Store in attachments table
   ↓
3. Queue worker job
   ↓
4. Worker generates:
   - Caption (BLIP/GPT-4V)
   - OCR (Tesseract/Cloud Vision)
   - Thumbnail
   ↓
5. Store in derived_texts
   ↓
6. Generate text embedding
   ↓
7. Update search index
   ↓
8. Text検索で画像も見つかる！
```

**Example**:
```
User uploads: error_screen.png
↓
Caption: "Web application error page showing 500 Internal Server Error with stack trace"
OCR: "Error 500\nInternal Server Error\nTraceback (most recent call last):\n  File api.py, line 42..."
↓
Later:
User searches: "500 error last week"
→ error_screen.png が検索結果に！
```

### データフロー（v4.2 Full）

```
1. Upload Image
   ↓
2. Worker generates:
   - Caption → Text embedding
   - Image embedding (CLIP) 🆕
   ↓
3. Store両方のembedding
   ↓
4. Cross-modal search可能:
   - Text query → Image embedding空間も検索
   - Image query → Text embedding空間も検索
```

### 技術スタック

**v4.1（MVP）**:
- **Caption**: BLIP-2 or GPT-4V API
- **OCR**: Tesseract (local) or Google Cloud Vision API
- **ASR**: Whisper (local) or Cloud Speech-to-Text
- **Storage**: S3-compatible (MinIO/S3/R2)
- **Queue**: Redis + RQ
- **Text Embedding**: 既存（ChromaDB）

**v4.2（Full）**:
- **Image Embedding**: CLIP / SigLIP
- **Audio Embedding**: Wav2Vec2 or Audio-CLIP
- **Cross-modal Fusion**: Late fusion with learned weights
- **Vector DB**: pgvector (multi-modal support)

### 競合優位性（更新）

| Feature | Mem0 | Rewind AI | **Kagura v4.2** |
|---------|------|-----------|-----------------|
| **Text** | ✅ | ❌ | ✅ |
| **Image** | ❌ | ✅ Screen | ✅ Any image |
| **Audio** | ❌ | ✅ Record | ✅ Any audio |
| **Video** | ❌ | ❌ | ✅ v4.2 |
| **PDF/Code** | ❌ | ❌ | ✅ |
| **Cross-modal** | ❌ | ❌ | ✅ text↔image |
| **MCP** | ✅ | ❌ | ✅ |
| **Local** | ❌ | ✅ Mac | ✅ All platforms |
| **Price** | Custom | $19/month | Free/Premium |

**Kaguraの独自価値（更新）**:
1. ✅ **Universal Memory** + **Multimodal**
2. ✅ **Vibe Coding特化**: コード + スクショ + 音声 + 動画
3. ✅ **Cross-modal Search**: Rewind AIを超える
4. ✅ **MCP-native**: 全AIプラットフォーム対応
5. ✅ **Open Source + All platforms**: Linux/Windows/Mac/iOS/Android

---

## 💡 統合アイデア: ChatGPT 5 Pro提案

### 提案された新アーキテクチャ

```
                 ┌──────────────────────┐
                 │   MCP Clients        │  Claude Desktop / ChatGPT Plugins /
                 │  (Agents & IDEs)     │  Cline / Custom Agents / Apps
                 └─────────┬────────────┘
                           │  (MCP)
                   ┌───────▼──────────────────────────┐
                   │   Kagura Memory Hub (MCP Server) │
                   │   - memory.* tools               │
                   │   - auth / quota / audit         │
                   └───────┬─────────────┬────────────┘
                           │             │
                   (REST/OpenAPI)   (SDK: Python/TS)
                           │             │
         ┌─────────────────▼─────────────▼──────────────────┐
         │        Memory Services (Microservices)            │
         │  • Vector Recall (pgvector / FAISS)               │
         │  • GraphMemory (relations & interactions)         │
         │  • Consolidation / Summarization Jobs             │
         │  • Feedback / Trust & Importance                  │
         └─────────────┬───────────────────┬─────────────────┘
                       │                   │
              ┌────────▼──────┐    ┌──────▼────────┐
              │  Storage       │    │  Connectors   │ GitHub/Calendar/Files/
              │  • Postgres+   │    │  • Ingest     │ Slack/Notion/etc.
              │    pgvector    │    │  • Schedulers │
              │  • Graph (SQL  │    └───────────────┘
              │    or GDB)     │
              └────────────────┘
```

**Key Points**:
- REST/OpenAPI + MCP + SDK の3層API
- Microservices構成（Vector/Graph/Consolidation/Connectors）
- Local/Cloud/Hybridの統一インターフェース

### 提案されたMCPツール詳細

```python
# Storage
memory.store(text, kind, source, meta)
  # kind: note/code/conversation/document
  # source: github/slack/manual/claude
  # meta: {tags, timestamp, importance}

# Retrieval
memory.recall(cue_text|embedding, k, include_graph_hops)
  # Hybrid: Vector similarity + Graph traversal
  # Returns: nodes + relations + confidence

memory.search(query, filter)
  # Full-text + Semantic search
  # filter: {kind, source, date_range, tags}

# Feedback Loop
memory.feedback(node_id, label, weight)
  # label: useful/irrelevant/outdated
  # weight: -1.0 to 1.0
  # → Hebbian learning, importance scoring

# Graph Operations
memory.link(src_id, dst_id, rel, weight)
  # rel: related_to/depends_on/learned_from/influences

memory.query_graph(seed_ids, hops, rel_filters)
  # Multi-hop graph traversal
  # Returns: subgraph with paths

memory.record_interaction(user_id, ai_platform, query, response, meta)
  # Track "Vibe Coding" history
  # Build interaction graph over time

# Maintenance
memory.consolidate()
  # Short-term → Long-term
  # Summarization, deduplication
  # Hebbian weight updates

memory.metrics()
  # Storage usage, recall metrics, graph stats

memory.export() / memory.import()
  # JSONL + attachments format
  # Complete data portability
```

### 提案されたREADME骨子

```markdown
# Kagura Memory Hub — Own your memory. Bring it to every AI.

**Kagura** は、あなたの**コンテキストと記憶**を、Claude/ChatGPT/Gemini/各種エージェントから**横断参照**できるようにする、オープンな **MCP対応メモリ基盤**です。

## ✨ What is Kagura?
- **Portable memory:** AI横断で使える個人・組織の「知識・文脈・交流経験」のハブ
- **MCP-first:** Claude Desktop等のMCPクライアントに**そのまま**接続
- **Privacy-first:** ローカル/セルフホスト/クラウド（BYOK, RLS, 監査）を選択可能

## 🧩 Key Features
- **memory.store / recall / search / feedback / delete**（MCP tools）
- **Vector + Graph**：意味検索＋関係グラフ（交流履歴/依存/関連）
- **Consolidation**：短期→長期の統合、要約・重複排除
- **Connectors**：GitHub/Calendar/Files/...（選択的インポート・同期）
- **Export/Import**：人質化しない可搬フォーマット（JSONL + attachments）

## 🚀 Quickstart

### A. Local (Docker)
```bash
docker compose up -d --build
docker compose exec api python -m nmn.scripts.migrate
open http://localhost:8080/docs
```

### B. MCP (Claude Desktop)
```jsonc
// ~/.config/claude/claude_desktop_config.json
{
  "mcpServers": {
    "kagura-memory": {
      "command": "python",
      "args": ["mcp_server.py"],
      "env": { "NMN_API_BASE": "http://localhost:8080" }
    }
  }
}
```

> Kagura CLIで**自動生成**も可能（`kagura mcp install`） — see Roadmap v3.1.0.

## 🧠 Architecture

* Vector: pgvector / FAISS
* Graph: GraphMemory（関係・交流履歴）
* Jobs: RQ/Celery（遅延ヘブ更新、夜間統合）
* Security: API keys / OAuth2, RLS, BYOK, audit, deletion logs

## 🔌 Connectors (opt-in)

* GitHub, Google Calendar, Files, Slack, Notion, ...
* 取得範囲/保持ルールを**明示設定**。いつでも**エクスポート＆削除**。

## 🗺 Roadmap

* v4.0 MCPツール管理 & Claude統合自動化
* v4.1 Self-hosted API / GraphMemory強化
* v4.2+ Cloud SaaS / Team collaboration
```

---

## 🆕 補足アイデア: Consumer App戦略

### なぜコンシューマーアプリが重要か

**MCPの制約**:
- 主に開発者ツール（Claude Desktop、Cursor等）
- 一般ユーザーにはアクセス困難

**アプリの価値**:
- App Store/Google Playで発見可能
- 非開発者でもメモリー管理可能
- 新市場創造: "AI Memory Management"

### 3層プラットフォーム構成

```
┌─────────────────────────────────────────┐
│  Consumer Apps (iOS/Android/Desktop)    │
│  - メモリー管理UI                        │
│  - 検索・ブラウジング                    │
│  - グラフビュー（関連性可視化）           │
│  - 統計・インサイト                      │
└─────────────────────────────────────────┘
         ↕ Kagura Memory API (REST)
┌─────────────────────────────────────────┐
│  Kagura Core Engine                     │
│  - Memory Manager (3-tier + Graph)      │
│  - RAG (Knowledge Base)                 │
│  - API Server                           │
└─────────────────────────────────────────┘
         ↕ MCP Protocol
┌─────────────────────────────────────────┐
│  AI Platforms (via MCP)                 │
│  Claude, ChatGPT, Gemini, Cursor, ...   │
└─────────────────────────────────────────┘
```

### アプリ機能イメージ（マルチモーダル対応）

**Core Features**:
- 📱 **Memory Browser** - カード形式でメモリー表示
  - Text + **Attachments preview** 🆕
  - **Image thumbnails**, **audio waveforms**, **PDF pages** 🆕
- 🔍 **Search & Discovery** - セマンティック検索
  - Text検索で**画像・音声も発見**（v4.1 MVP） 🆕
  - **Image similarity search**（v4.2） 🆕
  - **Audio similarity search**（v4.2） 🆕
- 📸 **Quick Capture** 🆕
  - **Camera**: スクショ、ホワイトボード
  - **Mic**: 音声メモ、会議録音
  - **Files**: PDF、コード、動画
  - **Share extension**（iOS/Android）
- 🕸️ **Graph View** - 関連性の可視化（NetworkX）
  - Multimodal nodes表示 🆕
- 📊 **Insights & Stats** - 学習パターン、トピック分析
  - **Per-modality analytics**（画像・音声・動画の統計） 🆕
- ✏️ **Manual Management** - 手動追加/編集/タグ付け
  - **Attachment editing**（crop, rotate, trim） 🆕
- ⚙️ **Settings** - プライバシー、同期、API接続
  - **Modality filters**（検索対象の選択） 🆕

**Pro Features** (マネタイズ):
- 💎 無制限メモリー（Free: 1,000 memories）
- 📦 無制限ストレージ（Free: 1GB, Pro: 100GB） 🆕
- ☁️ Cloud sync（複数デバイス間）
- 🎬 **Video support**（Free: 5 videos, Pro: unlimited） 🆕
- 🤖 **Advanced AI**（CLIP image search, audio search） 🆕（v4.2）
- 📈 Advanced analytics
- 👥 Team sharing

### 技術スタック（Flutter推奨）

**理由**:
- iOS/Android/macOS/Windows/Linux 全対応
- 単一コードベース
- 高速、ネイティブ並みパフォーマンス

**構成**:
```
kagura-app/  (新リポジトリ or サブディレクトリ)
├── lib/
│   ├── models/       # Memory, Context等
│   ├── services/     # Kagura API client
│   ├── screens/      # UI screens
│   ├── widgets/      # Reusable components
│   └── providers/    # State management (Riverpod)
├── ios/
├── android/
├── macos/
├── windows/
└── linux/
```

### Memory API設計（REST）

```python
# src/kagura/api/server.py (新規)
from fastapi import FastAPI

app = FastAPI()

# Memory CRUD
@app.post("/api/v1/memory")
async def create_memory(key: str, value: str, scope: str): ...

@app.get("/api/v1/memory/{key}")
async def get_memory(key: str, scope: str = "working"): ...

@app.put("/api/v1/memory/{key}")
async def update_memory(key: str, value: str): ...

@app.delete("/api/v1/memory/{key}")
async def delete_memory(key: str): ...

# Search
@app.get("/api/v1/memory/search")
async def search_memory(query: str, scope: str = "all"): ...

# Graph
@app.get("/api/v1/memory/{key}/related")
async def get_related(key: str, depth: int = 2): ...

@app.get("/api/v1/graph")
async def get_full_graph(): ...

# History
@app.get("/api/v1/history")
async def get_history(limit: int = 50): ...

@app.get("/api/v1/insights")
async def get_insights(): ...

# Knowledge (RAG)
@app.post("/api/v1/knowledge/index")
async def index_content(content: str, metadata: dict): ...

@app.get("/api/v1/knowledge/query")
async def query_knowledge(query: str, top_k: int = 5): ...
```

---

## 📊 更新されたロードマップ（マルチモーダル統合版）

### v4.0.0 - Memory Platform Foundation (2-3 months)
**Focus**: **Text Memory + Graph** 基盤
**Target**: 開発者 + テクニカルユーザー

**Phase A: MCPファースト化**
- [ ] Core refactoring（Memory特化）
- [ ] MCPツール管理 (#331)
- [ ] Claude Desktop自動設定
- [ ] REST API実装（FastAPI）
- [ ] Documentation rewrite

**Phase B: GraphMemory統合 (#345)**
- [ ] NetworkX integration
- [ ] Node types: user/topic/memory/interaction
- [ ] Edge types: related/depends/learned_from/influences
- [ ] MCP tools: memory.link/query_graph/record_interaction

**Phase C: Consolidation & Export**
- [ ] Short-term → Long-term migration
- [ ] Summarization, deduplication
- [ ] Export/Import (JSONL format)
- [ ] Deletion audit logs

**マルチモーダル準備**:
- [ ] Attachments/derived_texts table設計
- [ ] Worker infrastructure（Redis + RQ）
- [ ] S3-compatible storage設定

**Launch**:
- [ ] v4.0.0 tag
- [ ] HN/Reddit/Product Hunt announcement
- [ ] Blog post / tutorial

---

### v4.1.0 - Self-hosted API + **Multimodal MVP** (4-6 months)
**Focus**: **Attachments + 派生テキスト検索** 🆕
**Target**: 一般ユーザー + 小規模チーム

**Phase D: Self-hosted API**
- [ ] Docker Compose production setup
- [ ] API authentication (API Key/OAuth2)
- [ ] Multi-device sync
- [ ] Connectors: GitHub, Calendar, Files

**Phase E: Multimodal MVP** 🆕
- [ ] **Attachments support**（画像、音声、PDF、コード）
  - S3-compatible storage integration
  - Attachment CRUD API
  - MCP tool: `memory.attach`
- [ ] **Worker pipeline**
  - Caption generation（BLIP-2/GPT-4V API）
  - OCR（Tesseract local + Cloud Vision fallback）
  - ASR（Whisper local + Cloud Speech-to-Text fallback）
  - Thumbnail generation
- [ ] **Derived texts storage**
  - derived_texts table
  - Link to original attachments
- [ ] **Text-based multimodal search**
  - 派生テキストのembedding生成
  - Text検索で画像・音声も発見可能
- [ ] **MCP tools拡張**
  - `memory.derive` - On-demand派生生成
  - `memory.recall` - Multimodal結果を含む

**Phase F: Consumer App (Flutter)**
- [ ] iOS/Android/Desktop app開発
- [ ] **Quick Capture**（camera, mic, files） 🆕
- [ ] **Attachment preview**（images, audio player, PDF viewer） 🆕
- [ ] Memory Browser UI
- [ ] Graph Viewer
- [ ] Insights dashboard
- [ ] App Store/Google Play公開

**Launch**:
- [ ] v4.1.0 tag
- [ ] Product Hunt (Multimodal Memory App)
- [ ] Demo video（クロスモーダル検索）
- [ ] Blog post（"Beyond Text: Multimodal AI Memory"）

---

### v4.2.0 - Cloud + **Full Multimodal** (6-12 months)
**Focus**: **Cross-modal Search + Enterprise** 🆕
**Target**: エンタープライズ + チーム

**Phase G: Full Multimodal** 🆕
- [ ] **Image Embedding**
  - CLIP / SigLIP integration
  - Image embedding generation worker
  - Image similarity search API
- [ ] **Audio Embedding**
  - Wav2Vec2 or Audio-CLIP
  - Audio embedding generation worker
  - Audio similarity search API
- [ ] **Cross-modal Search**
  - Late fusion scoring
  - MCP tool: `memory.recall_multimodal`
  - `memory.search_by_image` / `memory.search_by_audio`
- [ ] **Video Support**
  - Keyframe extraction
  - Transcription
  - Timeline-based search
- [ ] **Multimodal Analytics**
  - Per-modality insights（画像・音声・動画の統計）
  - Cross-modal relationship visualization

**Phase H: Kagura Cloud (SaaS)**
- [ ] Multi-tenant architecture
- [ ] Row-Level Security (RLS)
- [ ] BYOK (Bring Your Own Key)
- [ ] Audit logs & compliance
- [ ] Team collaboration features
- [ ] Enterprise SSO
- [ ] **Multimodal at scale**（高速embedding生成、CDN）

**Launch**:
- [ ] v4.2.0 tag
- [ ] Beta program
- [ ] Pricing tiers（Free/Premium/Enterprise）
- [ ] Case studies（"How Company X uses Kagura for Multimodal Knowledge"）
- [ ] Conference talks

---

## 🎯 成功指標（KPI）

### v4.0（Technical - Text Foundation）
- [ ] MCP初期設定時間: 80%短縮（60分 → 10分）
- [ ] Recall@k: 0.9+（Top-5 accuracy, text only）
- [ ] API p95 latency: < 100ms
- [ ] Export/Import成功率: 99%+
- [ ] `kagura mcp doctor`で90%の問題自動診断
- [ ] Test coverage: > 90%

### v4.1（User Adoption + Multimodal MVP）
- [ ] 月間アクティブユーザー: 1,000+
- [ ] App Store評価: 4.5+
- [ ] GitHub stars: 5,000+
- [ ] カスタムコネクタ: 10+（コミュニティ貢献）
- [ ] **Multimodal KPI** 🆕:
  - **Attachment upload成功率**: 99%+
  - **Caption/OCR/ASR生成成功率**: 95%+
  - **派生テキスト経由の発見率**: 60%+（画像・音声がtext検索で見つかる割合）
  - **Multimodal検索満足度**: NPS 50+

### v4.2（Business + Full Multimodal）
- [ ] Paying customers: 100+
- [ ] MRR: $10,000+
- [ ] Enterprise pilots: 5+
- [ ] Retention rate: 90%+
- [ ] **Multimodal KPI** 🆕:
  - **Cross-modal Recall@k**: 0.85+（text→image, image→text）
  - **Image embedding生成時間**: < 500ms/image
  - **Audio embedding生成時間**: < 1s/minute of audio
  - **Video処理成功率**: 90%+
  - **Multimodal storage efficiency**: 3,000x+ compression（Rewind AI並み）

---

## 🔗 関連ドキュメント

- [V4.0_COMPETITIVE_ANALYSIS.md](./V4.0_COMPETITIVE_ANALYSIS.md) - 競合分析
- [V4.0_IMPLEMENTATION_ROADMAP.md](./V4.0_IMPLEMENTATION_ROADMAP.md) - 実装計画
- [V4.0_README_DRAFT.md](./V4.0_README_DRAFT.md) - 新README草案
- [V4.0_GITHUB_ISSUE_TEMPLATE.md](./V4.0_GITHUB_ISSUE_TEMPLATE.md) - Issue作成用テンプレート

**既存Issue参照**:
- [#331: MCP Enhancement Roadmap](https://github.com/JFK/kagura-ai/issues/331)
- [#345: GraphDB Memory Integration](https://github.com/JFK/kagura-ai/issues/345)
- [#348: Neural Memory Research](https://github.com/JFK/kagura-ai/issues/348)

---

## 💬 オープンディスカッション

### 決定事項

**アーキテクチャ**:
- [x] **リポジトリ構成**: **モノレポ継続**（`kagura-ai`）✅
- [ ] **デフォルト接続先**: Local優先 vs Cloud優先
- [ ] **MCPツール契約v1**: 凍結タイミング
- [ ] **Exportフォーマット**: JSONL + attachments スキーマ
- [ ] **削除ポリシー**: GDPR準拠、SLO設定

**機能優先順位**:
- [ ] **初回コネクタ**: GitHub/Calendar/Files で確定
- [ ] **アプリ開発タイミング**: v4.1で分離（v4.0はcore focus）
- [x] **マルチモーダル戦略**: **段階的導入** ✅
  - v4.0: Text + Graph基盤
  - v4.1: Multimodal MVP（Attachments + 派生テキスト）
  - v4.2: Full Multimodal（Cross-modal search）

**マルチモーダル詳細**:
- [ ] **v4.1 Attachments storage**: S3-compatible（MinIO local / S3 cloud / R2）
- [ ] **Caption provider**: BLIP-2 local vs GPT-4V API
- [ ] **OCR provider**: Tesseract local + Cloud Vision fallback
- [ ] **ASR provider**: Whisper local + Cloud Speech-to-Text fallback
- [ ] **v4.2 Image Embedding**: CLIP vs SigLIP
- [ ] **v4.2 Audio Embedding**: Wav2Vec2 vs Audio-CLIP

### リスク

| リスク | 対策 |
|--------|------|
| Mem0との直接競合 | 差別化: **Multimodal + Vibe Coding**、日本語、完全OSS |
| Rewind AIとの競合 🆕 | 差別化: **MCP対応 + 全プラットフォーム** + AI横断 |
| MCP仕様変更 | バージョン明記、後方互換性保証 |
| データプライバシー懸念 | BYOK、完全削除、Export保証、**画像・音声の暗号化** 🆕 |
| Multimodal実装の複雑性 🆕 | **段階的導入**（MVP → Full）、既存実装活用 |
| ストレージコスト増大 🆕 | 圧縮（3,000x目標）、S3/R2低コストストレージ、ユーザー選択（local/cloud） |
| 開発リソース不足 | コミュニティ貢献、段階的リリース |

### Next Actions

1. ~~**GitHub Issue作成**~~（スキップ）
2. **ドキュメント更新** - 全5ファイルにマルチモーダル戦略を反映 ✅ IN PROGRESS
3. **技術検証** 🆕
   - GPT 5 Pro提供のzipファイル確認・活用
   - Caption/OCR/ASR workerのPoC
   - Attachment storage設計（S3-compatible）
4. **コミュニティフィードバック** - HN/Reddit/Discordで検証（オプション）
5. **v4.0.0 Alpha実装開始** - Text + Graph基盤

---

**Created**: 2025-10-25
**Updated**: 2025-10-25（マルチモーダル戦略追加）
**Contributors**: Claude Code, ChatGPT 5 Pro, @jfk
**Status**: 📋 Strategic Proposal（マルチモーダル統合版）
