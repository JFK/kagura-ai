# RFC-034: Hippocampus Memory System - Personal AI with Local SLM

**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: Draft
**ä½œæˆæ—¥**: 2025-10-15
**å„ªå…ˆåº¦**: â­ï¸â­ï¸ High
**å¯¾è±¡ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: v2.6.0
**é–¢é€£Issue**: TBD
**ç½®ãæ›ãˆå¯¾è±¡**: RFC-003 (Personal Assistant with Auto Fine-tuning)

---

## ğŸ“‹ Executive Summary

**ã€Œä½¿ãˆã°ä½¿ã†ã»ã©è³¢ããªã‚‹ã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«AIã‚’ã€ãƒ­ãƒ¼ã‚«ãƒ«SLMï¼ˆSmall Language Modelï¼‰ã‚’æ´»ç”¨ã—ã¦å®Ÿç¾ã—ã¾ã™ã€‚**

äººé–“ã®è„³ã®ã€Œæµ·é¦¬ã€ã®ã‚ˆã†ã«ã€çŸ­æœŸè¨˜æ†¶ã‚’ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ã«å¤‰æ›ã—ã€ã•ã‚‰ã«ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯è¨˜æ†¶ï¼ˆçŸ¥è­˜ï¼‰ã¸ã¨çµ±åˆã™ã‚‹ã€æ®µéšçš„ãªè¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

### æ ¸å¿ƒçš„ãªç›®çš„

**æœ€çµ‚ç›®æ¨™**: ã“ã®è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ è‡ªä½“ãŒã€Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€ã¨ãªã‚Šã€Main LLMãŒã‚ˆã‚Šè‰¯ã„å›ç­”ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚

```
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
    â†“
Hippocampus Memory ãŒã€Œé–¢é€£ã™ã‚‹éå»ã®çŸ¥è­˜ã€ã‚’æä¾›
    â†“
Main LLM ãŒã€Œè±Šå¯Œãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€ã‚’å…ƒã«å›ç­”ç”Ÿæˆ
    â†“
ã‚ˆã‚Šè‰¯ã„å›ç­”ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®æ–‡è„ˆã‚’ç†è§£ï¼‰
```

---

## ğŸ¯ å•é¡Œå®šç¾©

### ç¾çŠ¶ã®èª²é¡Œ

1. **RAGã®é™ç•Œ**
   - ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¯ã€Œè¿‘ã„ã€æƒ…å ±ã‚’è¦‹ã¤ã‘ã‚‹ãŒã€ã€Œæ„å‘³çš„ãªç¹‹ãŒã‚Šã€ã‚’ç†è§£ã—ãªã„
   - æ™‚ç³»åˆ—çš„ãªå› æœé–¢ä¿‚ãŒå¤±ã‚ã‚Œã‚‹
   - é‡è¦åº¦ã®åˆ¤å®šãŒã§ããªã„

2. **Context Window ã®é™ç•Œ**
   - 10,000ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¦ç´„ã—ã¦ã‚‚ã€çµå±€ã¯ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã•ã‚ŒãŸæƒ…å ±
   - RFC-024ï¼ˆContext Compressionï¼‰ã§å¯¾å‡¦ä¸­ã ãŒã€æœ¬è³ªçš„ãªè§£æ±ºã§ã¯ãªã„
   - ã€Œè¨˜æ†¶ã€ã§ã¯ãªãã€Œãƒ­ã‚°ã®åœ§ç¸®ã€

3. **Fine-tuning ã®èª²é¡Œ**ï¼ˆRFC-003ã®å•é¡Œï¼‰
   - é«˜ã‚³ã‚¹ãƒˆï¼ˆ$5-20/å›ï¼‰
   - ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼æ‡¸å¿µï¼ˆå¤–éƒ¨é€ä¿¡ï¼‰
   - 100ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã§åŠ¹æœãŒã‚ã‚‹ã‹ä¸æ˜

### äººé–“ã®è„³ã¨ã®æ¯”è¼ƒ

| äººé–“ã®è„³ | ç¾çŠ¶ã®LLM | ç†æƒ³ã®Kagura AI |
|---------|----------|----------------|
| **çŸ­æœŸè¨˜æ†¶ï¼ˆæµ·é¦¬ï¼‰** | Context Window | WorkingMemory + ContextMemory |
| **ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶** | ãªã—ï¼ˆRAGã§æ¨¡å€£ï¼‰ | Episodic Consolidationï¼ˆSLMã§æŠ½å‡ºï¼‰ |
| **ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯è¨˜æ†¶** | äº‹å‰å­¦ç¿’æ¸ˆã¿çŸ¥è­˜ | Semantic Integrationï¼ˆçµ±åˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ |
| **å›ºç€ï¼ˆæ–°çš®è³ªï¼‰** | Fine-tuningï¼ˆé«˜ã‚³ã‚¹ãƒˆï¼‰ | (Optional) LoRAï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰ |
| **å¿˜å´** | ãªã— | TTLã€é‡è¦åº¦ãƒ™ãƒ¼ã‚¹å‰Šé™¤ |

---

## ğŸ’¡ è§£æ±ºç­–ï¼šæµ·é¦¬å‹è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ 

### ã‚³ãƒ³ã‚»ãƒ—ãƒˆ

```
äººé–“ã®è„³              Kagura AI
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
çŸ­æœŸè¨˜æ†¶ (STM)   â†’  WorkingMemory + ContextMemory
  â†“ æµ·é¦¬çš„å‡¦ç†          â†“ Personal Memory Agent (Local SLM)
ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶   â†’  MemoryRAG (episodic layer)
  â†“ ç¡çœ ä¸­ã®çµ±åˆ        â†“ Nightly consolidation (Local SLM)
ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯è¨˜æ†¶ â†’ PersistentMemory (semantic profile)
  â†“ å›ºç€                â†“ (Optional) LoRA fine-tuning
é•·æœŸè¨˜æ†¶ï¼ˆæ–°çš®è³ªï¼‰â†’  Fine-tuned model
```

### ã‚­ãƒ¼ã‚¢ã‚¤ãƒ‡ã‚¢

1. **ãƒ­ãƒ¼ã‚«ãƒ«SLMã‚’ã€Œæµ·é¦¬ã€ã¨ã—ã¦ä½¿ç”¨**
   - Qwen2.5 0.5B-3Bã€Phi-3 Miniã€Gemma-2 2Bãªã©
   - å½¹å‰²: äº‹å®ŸæŠ½å‡ºã€é‡è¦åº¦åˆ¤å®šã€è¦ç´„ãƒ»çµ±åˆ
   - VRAM: 0.4GB-2GBï¼ˆRTX 3060ã§ã‚‚å‹•ä½œï¼‰

2. **æ®µéšçš„ãªè¨˜æ†¶çµ±åˆ**
   - Phase 1: Episodic Consolidationï¼ˆä¼šè©±çµ‚äº†æ™‚ï¼‰
   - Phase 2: Semantic Integrationï¼ˆå¤œé–“ãƒãƒƒãƒï¼‰
   - Phase 3: Knowledge Graphï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
   - Phase 4: LoRA Learningï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

3. **ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ç¬¬ä¸€**
   - å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆå¤–éƒ¨é€ä¿¡ãªã—ï¼‰
   - ã‚³ã‚¹ãƒˆ: $0ï¼ˆSLMå®Ÿè¡Œã‚³ã‚¹ãƒˆã®ã¿ï¼‰

---

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### å…¨ä½“åƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              User Query: "ç”»é¢ã®è¨­å®šã¯ï¼Ÿ"        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Hippocampus Memory  â”‚ â† ãƒ­ãƒ¼ã‚«ãƒ«SLMï¼ˆæµ·é¦¬ï¼‰
         â”‚  ãŒé–¢é€£è¨˜æ†¶ã‚’æ¤œç´¢     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰ã‚’å¥½ã‚€ã€â† éå»ã®è¨˜æ†¶
         ã€Œæœ€çµ‚æ›´æ–°: 2025-10-10ã€
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Main LLM (GPT-4o)   â”‚
         â”‚  + è±Šå¯Œãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ "ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š   â”‚ â† ã‚ˆã‚Šè‰¯ã„å›ç­”
         â”‚  ã—ã¾ã—ã‚‡ã†ã‹ï¼Ÿ"       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è©³ç´°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Interaction                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Main LLM Agent      â”‚ (GPT-4o/Claude/Gemini)
            â”‚   @agent(...)         â”‚
            â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
                â”‚               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”       â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Hippocampus   â”‚       â”‚ MemoryManager â”‚
    â”‚ Memory Agent  â”‚â—„â”€â”€â”€â”€â”€â”€â”¤ (æ—¢å­˜)        â”‚
    â”‚ (Local SLM)   â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚               â”‚
    â”‚ Ultra-Light:  â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 0.5B (0.4GB)  â”‚       â”‚ 4å±¤ãƒ¡ãƒ¢ãƒª     â”‚
    â”‚ Light: 2B     â”‚       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Standard: 3B  â”‚       â”‚ Working       â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ Context       â”‚
        â”‚                   â”‚ Episodic (RAG)â”‚
        â”‚                   â”‚ Semantic (DB) â”‚
        â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Consolidation Layer (NEW)         â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
    â”‚  â”œâ”€ Episodic Consolidation         â”‚
    â”‚  â”‚   - ä¼šè©±çµ‚äº†æ™‚ã«äº‹å®ŸæŠ½å‡º        â”‚
    â”‚  â”‚   - é‡è¦åº¦åˆ¤å®šï¼ˆã‚²ãƒ¼ãƒˆï¼‰        â”‚
    â”‚  â”‚   - RAGä¿å­˜ï¼ˆepisodic layerï¼‰   â”‚
    â”‚  â”‚                                 â”‚
    â”‚  â”œâ”€ Semantic Integration           â”‚
    â”‚  â”‚   - å¤œé–“ãƒãƒƒãƒã§çµ±åˆ            â”‚
    â”‚  â”‚   - é‡è¤‡å‰Šé™¤ãƒ»çŸ›ç›¾è§£æ¶ˆ          â”‚
    â”‚  â”‚   - ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆDBä¿å­˜ï¼‰  â”‚
    â”‚  â”‚                                 â”‚
    â”‚  â”œâ”€ Knowledge Graph (Optional)     â”‚
    â”‚  â”‚   - ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡º            â”‚
    â”‚  â”‚   - é–¢ä¿‚æ€§ã‚°ãƒ©ãƒ•æ§‹ç¯‰            â”‚
    â”‚  â”‚                                 â”‚
    â”‚  â””â”€ LoRA Learning (Optional)       â”‚
    â”‚      - é€±1å›ã®å¾®èª¿æ•´               â”‚
    â”‚      - PEFTçµ±åˆ                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è¦ä»¶ï¼ˆUltra-Light Modeï¼‰

**æœ€å°ç’°å¢ƒ**: RTX 3060 (8GB) ã§ã‚‚ä½™è£•ã§å‹•ä½œ âœ…

| Component | VRAM | RAM | å‚™è€ƒ |
|-----------|------|-----|------|
| **Main LLM** | 0GB | - | ã‚¯ãƒ©ã‚¦ãƒ‰API |
| **Hippocampus SLM** | **0.4GB** | 2GB | Qwen2.5-0.5B (INT4) |
| **ChromaDB** | 0GB | 1GB | ãƒ™ã‚¯ãƒˆãƒ«DB |
| **åˆè¨ˆ** | **< 0.5GB** | **3GB** | ä¸€èˆ¬çš„ãªPCã§å‹•ä½œ |

---

## ğŸ“¦ Phase 1: Episodic Consolidationï¼ˆ2é€±é–“ï¼‰â­ï¸ æœ€å„ªå…ˆ

### ç›®æ¨™

**ä¼šè©±çµ‚äº†æ™‚ã«è‡ªå‹•çš„ã«é‡è¦äº‹å®Ÿã‚’æŠ½å‡ºã—ã€RAGã«ä¿å­˜ã™ã‚‹**

### å®Ÿè£…

#### 1.1 HippocampusConfig

```python
# src/kagura/memory/hippocampus/config.py

from enum import Enum
from dataclasses import dataclass

class HippocampusMode(Enum):
    """å‹•ä½œãƒ¢ãƒ¼ãƒ‰"""
    ULTRA_LIGHT = "ultra_light"  # 0.5B ãƒ¢ãƒ‡ãƒ«, æœ€å°VRAM (< 0.5GB)
    LIGHT = "light"              # 2B ãƒ¢ãƒ‡ãƒ«, ãƒãƒ©ãƒ³ã‚¹ (< 1.5GB)
    STANDARD = "standard"        # 3B ãƒ¢ãƒ‡ãƒ«, é«˜ç²¾åº¦ (< 2.5GB)
    CLOUD = "cloud"              # ã‚¯ãƒ©ã‚¦ãƒ‰APIï¼ˆGemini Flash 8Bï¼‰

@dataclass
class HippocampusConfig:
    """æµ·é¦¬ãƒ¡ãƒ¢ãƒªè¨­å®š"""

    mode: HippocampusMode = HippocampusMode.ULTRA_LIGHT

    # ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆãƒ¢ãƒ¼ãƒ‰åˆ¥ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    model_map: dict = None

    # é‡å­åŒ–
    quantization: str = "int4"  # "int4" | "int8" | "fp16"

    # ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™
    max_vram_mb: int = 500  # 0.5GB ã¾ã§ï¼ˆUltra-Lightï¼‰

    # é‡è¦åº¦é–¾å€¤
    importance_threshold: int = 6  # 0-10ã‚¹ã‚±ãƒ¼ãƒ«

    def __post_init__(self):
        if self.model_map is None:
            self.model_map = {
                HippocampusMode.ULTRA_LIGHT: "qwen2.5:0.5b-instruct-q4_K_M",
                HippocampusMode.LIGHT: "gemma-2:2b-instruct-q4_K_M",
                HippocampusMode.STANDARD: "qwen2.5:3b-instruct-q4_K_M",
                HippocampusMode.CLOUD: "gemini-1.5-flash-8b",
            }

    def get_model(self) -> str:
        """ç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰ã«å¯¾å¿œã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        return self.model_map[self.mode]
```

#### 1.2 EpisodicConsolidator

```python
# src/kagura/memory/hippocampus/episodic.py

from kagura import agent
from kagura.core.memory import MemoryManager
from kagura.memory.hippocampus.config import HippocampusConfig, HippocampusMode
from datetime import datetime
from typing import Any
import asyncio

class EpisodicConsolidator:
    """
    æµ·é¦¬ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶çµ±åˆ
    - ä¼šè©±çµ‚äº†æ™‚ã«ã€Œé‡è¦äº‹å®Ÿã€ã‚’æŠ½å‡º
    - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãã§RAGã«ä¿å­˜
    """

    def __init__(self, config: HippocampusConfig = None):
        self.config = config or HippocampusConfig(
            mode=HippocampusMode.ULTRA_LIGHT
        )
        self.model = self.config.get_model()

    @agent(
        model="ollama/{model}",  # å‹•çš„ãƒ¢ãƒ‡ãƒ«é¸æŠ
        temperature=0.0,  # æ±ºå®šçš„å‡ºåŠ›
        max_tokens=200    # çŸ­ã„å‡ºåŠ›
    )
    async def extract_facts(self, conversation: str) -> str:
        """
        ä¼šè©±ã‹ã‚‰é‡è¦äº‹å®Ÿã‚’ç®‡æ¡æ›¸ãã§æŠ½å‡ºï¼ˆæœ€å°ã‚¿ã‚¹ã‚¯ï¼‰

        Conversation:
        {{ conversation }}

        Task: Extract important facts (user preferences, settings, decisions, names, dates).
        Format: One fact per line, starting with "-".

        Example:
        - User prefers dark mode
        - User's name is John
        - Meeting scheduled for 2025-10-20

        Output (max 5 facts):
        """
        pass

    @agent(
        model="ollama/{model}",
        temperature=0.0,
        max_tokens=10
    )
    async def classify_importance(self, fact: str) -> str:
        """
        é‡è¦åº¦ã‚’0-10ã§åˆ¤å®šï¼ˆå˜ç´”åˆ†é¡ï¼‰

        Fact: {{ fact }}

        Rate importance (0-10):
        - 0-3: Not important (chitchat, temporary info)
        - 4-6: Somewhat important
        - 7-10: Very important (user info, preferences, decisions)

        Output only a number (0-10):
        """
        pass

    async def consolidate_episode(
        self,
        memory: MemoryManager,
        session_id: str,
        importance_threshold: int = None
    ) -> dict[str, Any]:
        """
        ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ±åˆï¼ˆè¶…è»½é‡ç‰ˆï¼‰

        Args:
            memory: MemoryManager instance
            session_id: Session identifier
            importance_threshold: Importance threshold (0-10)

        Returns:
            Consolidation statistics
        """
        if importance_threshold is None:
            importance_threshold = self.config.importance_threshold

        # 1. ä¼šè©±å–å¾—
        context = memory.get_context()
        conversation_text = "\n".join([
            f"{msg.role}: {msg.content}" for msg in context
        ])

        # 2. SLMã§äº‹å®ŸæŠ½å‡ºï¼ˆ1å›ã®LLMå‘¼ã³å‡ºã—ï¼‰
        facts_text = await self.extract_facts(conversation_text)
        facts = [f.strip("- ").strip() for f in facts_text.split("\n") if f.strip()]

        # 3. é‡è¦åº¦åˆ¤å®šï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰
        importance_scores = await asyncio.gather(*[
            self.classify_importance(fact) for fact in facts
        ])

        # 4. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° + RAGä¿å­˜
        saved_facts = []
        for fact, score_text in zip(facts, importance_scores):
            try:
                score = int(score_text.strip())
                if score >= importance_threshold:
                    memory.store_semantic(
                        content=fact,
                        metadata={
                            "importance": score,
                            "session_id": session_id,
                            "layer": "episodic",
                            "timestamp": datetime.now().isoformat()
                        }
                    )
                    saved_facts.append({"fact": fact, "score": score})
            except ValueError:
                continue  # ã‚¹ã‚³ã‚¢è§£æå¤±æ•—ã¯ã‚¹ã‚­ãƒƒãƒ—

        return {
            "total_facts": len(facts),
            "saved_facts": len(saved_facts),
            "model": self.model,
            "vram_estimate": "< 0.5 GB",
            "session_id": session_id
        }
```

#### 1.3 @agent ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿çµ±åˆ

```python
# src/kagura/core/decorators.pyï¼ˆæ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‹¡å¼µï¼‰

from kagura.memory.hippocampus import HippocampusConfig, EpisodicConsolidator

def agent(
    model: str = "gpt-4o-mini",
    # ... æ—¢å­˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ...
    enable_hippocampus: bool = False,  # â† NEW
    hippocampus_config: HippocampusConfig = None,  # â† NEW
):
    """
    Agent decorator with hippocampus memory

    Args:
        enable_hippocampus: Enable hippocampus memory system
        hippocampus_config: Hippocampus configuration
    """
    def decorator(func):
        # ... æ—¢å­˜ã‚³ãƒ¼ãƒ‰ ...

        if enable_hippocampus and enable_memory:
            # HippocampusåˆæœŸåŒ–
            config = hippocampus_config or HippocampusConfig()
            consolidator = EpisodicConsolidator(config)

            # ä¼šè©±çµ‚äº†æ™‚ã«consolidate
            async def cleanup():
                session_id = agent_instance.memory.get_session_id()
                if session_id:
                    await consolidator.consolidate_episode(
                        memory=agent_instance.memory,
                        session_id=session_id
                    )

            # Register cleanup hook
            agent_instance._cleanup_hooks.append(cleanup)

        return wrapper
    return decorator
```

### ä½¿ç”¨ä¾‹

```python
from kagura import agent
from kagura.memory.hippocampus import HippocampusConfig, HippocampusMode

# æœ€å°æ§‹æˆï¼ˆRTX 3060 8GB ã§ã‚‚å‹•ä½œï¼‰
@agent(
    model="gpt-4o-mini",  # ã‚¯ãƒ©ã‚¦ãƒ‰ API
    enable_memory=True,
    enable_hippocampus=True,  # â† æµ·é¦¬æ©Ÿèƒ½ON
    hippocampus_config=HippocampusConfig(
        mode=HippocampusMode.ULTRA_LIGHT  # 0.5B, VRAM < 0.5GB
    )
)
async def my_assistant(query: str) -> str:
    """
    ã‚ãªãŸã®ç§˜æ›¸ã§ã™ã€‚

    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {{ query }}
    """
    pass

# ä½¿ç”¨ä¾‹
await my_assistant("ç§ã¯ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰ãŒå¥½ãã§ã™")
# â†’ çµ‚äº†æ™‚ã«è‡ªå‹•çš„ã«ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰ã‚’å¥½ã‚€ã€ã‚’è¨˜æ†¶

# æ¬¡å›
await my_assistant("ç”»é¢ã®è¨­å®šã‚’æ•™ãˆã¦")
# â†’ RAGã‹ã‚‰ã€Œãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰å¥½ãã€ã‚’æ¤œç´¢ â†’ Main LLMã«æ¸¡ã™
# â†’ "ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®šã—ã¾ã—ã‚‡ã†ã‹ï¼Ÿ" â† ã‚ˆã‚Šè‰¯ã„å›ç­”
```

### æˆåŠŸæŒ‡æ¨™ï¼ˆPhase 1ï¼‰

- âœ… ä¼šè©±çµ‚äº†æ™‚ã«è‡ªå‹•è¦ç´„ï¼ˆSLMã§äº‹å®ŸæŠ½å‡ºï¼‰
- âœ… é‡è¦äº‹å®Ÿã‚’RAGä¿å­˜ï¼ˆimportance >= 6ï¼‰
- âœ… VRAMä½¿ç”¨é‡ < 0.5GBï¼ˆUltra-Lightï¼‰
- âœ… ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· < 50msï¼ˆäº‹å®ŸæŠ½å‡ºï¼‰
- âœ… RTX 3060 (8GB) ã§å‹•ä½œç¢ºèª

---

## ğŸ“¦ Phase 2: Semantic Integrationï¼ˆ2é€±é–“ï¼‰

### ç›®æ¨™

**å¤œé–“ãƒãƒƒãƒã§ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ã‚’çµ±åˆã—ã€ã€Œæ’ä¹…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã€ã‚’ç”Ÿæˆ**

### å®Ÿè£…

#### 2.1 SemanticIntegrator

```python
# src/kagura/memory/hippocampus/semantic.py

from kagura import agent
from kagura.core.memory import MemoryManager
from datetime import datetime
from typing import Any

class SemanticIntegrator:
    """
    æµ·é¦¬ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯è¨˜æ†¶çµ±åˆ
    - å¤œé–“ãƒãƒƒãƒã§ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’çµ±åˆ
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
    """

    @agent(
        model="gemini-1.5-flash-8b",  # è¶…å®‰ä¾¡ï¼ˆ$0.0375 / 1M tokensï¼‰
        temperature=0.2
    )
    async def integrate_profile(self, episodes: list[str]) -> dict:
        """
        ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’çµ±åˆã—ã¦ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ

        Recent episodes (last 7 days):
        {% for ep in episodes %}
        - {{ ep }}
        {% endfor %}

        Generate a unified user profile JSON:
        {
          "preferences": {
            "ui_theme": "dark",
            "programming_language": "Python"
          },
          "personal_info": {
            "name": "...",
            "role": "..."
          },
          "recurring_topics": [
            "Project X",
            "Team meeting"
          ],
          "decisions": [
            "2025-10-10: Decided to use PostgreSQL"
          ],
          "updated_at": "2025-10-15T00:00:00"
        }

        Rules:
        - Remove duplicates
        - Resolve contradictions (prefer newer info)
        - Merge related items
        """
        pass

    async def nightly_consolidation(
        self,
        memory: MemoryManager,
        use_cloud: bool = True  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚¯ãƒ©ã‚¦ãƒ‰
    ) -> dict[str, Any]:
        """
        å¤œé–“çµ±åˆï¼ˆãƒãƒƒãƒå‡¦ç†ã€VRAMä½¿ç”¨ã‚¼ãƒ­ï¼‰

        Args:
            memory: MemoryManager instance
            use_cloud: Use cloud API (Gemini Flash 8B)

        Returns:
            Consolidated profile
        """
        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å–å¾—
        episodes = memory.recall_semantic(query="", top_k=100)
        episode_texts = [
            ep["content"] for ep in episodes
            if ep.get("metadata", {}).get("layer") == "episodic"
        ]

        if not episode_texts:
            return {"message": "No episodes to consolidate"}

        # çµ±åˆï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰æ¨å¥¨ï¼‰
        profile = await self.integrate_profile(episode_texts)

        # ä¿å­˜
        memory.remember(
            "semantic_profile",
            profile,
            metadata={
                "layer": "semantic",
                "updated_at": datetime.now().isoformat()
            }
        )

        return profile
```

#### 2.2 CLIçµ±åˆ

```python
# src/kagura/cli/memory_cli.py

import click
import asyncio
from kagura.core.memory import MemoryManager
from kagura.memory.hippocampus import SemanticIntegrator

@click.group()
def memory():
    """Memory management commands"""
    pass

@memory.command()
@click.option('--agent-name', '-a', required=True, help='Agent name')
def consolidate(agent_name: str):
    """Run nightly consolidation"""

    # MemoryManageråˆæœŸåŒ–
    memory = MemoryManager(
        agent_name=agent_name,
        enable_rag=True
    )

    # çµ±åˆå®Ÿè¡Œ
    integrator = SemanticIntegrator()
    profile = asyncio.run(integrator.nightly_consolidation(memory))

    print(f"""
âœ… Consolidation completed!

Profile:
{json.dumps(profile, indent=2, ensure_ascii=False)}
    """)

@memory.command()
@click.option('--interval', '-i', default='24h', help='Consolidation interval')
def daemon(interval: str):
    """Run consolidation daemon"""
    print(f"Starting consolidation daemon (interval: {interval})")
    # ãƒ‡ãƒ¼ãƒ¢ãƒ³å®Ÿè£…...
```

### ä½¿ç”¨ä¾‹

```bash
# å¤œé–“ãƒãƒƒãƒï¼ˆcronã§å®Ÿè¡Œï¼‰
$ kagura memory consolidate --agent-name my_assistant

# ã¾ãŸã¯è‡ªå‹•ãƒ‡ãƒ¼ãƒ¢ãƒ³
$ kagura memory daemon --interval 24h
```

### æˆåŠŸæŒ‡æ¨™ï¼ˆPhase 2ï¼‰

- âœ… å¤œé–“çµ±åˆã§é‡è¤‡å‰Šé™¤ãƒ»çŸ›ç›¾è§£æ¶ˆ
- âœ… æ’ä¹…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆJSONï¼‰
- âœ… ã‚³ã‚¹ãƒˆ < $0.0001/runï¼ˆGemini Flash 8Bï¼‰
- âœ… æ¬¡å›ä¼šè©±ã§ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•æ³¨å…¥

---

## ğŸ“¦ Phase 3: Knowledge Graphï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ»2é€±é–“ï¼‰

### ç›®æ¨™

**ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–¢ä¿‚ã®ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ã—ã€é–¢é€£æ€§ãƒ™ãƒ¼ã‚¹ã®æ¤œç´¢ã‚’å¯èƒ½ã«ã™ã‚‹**

### å®Ÿè£…æ¦‚è¦

```python
# src/kagura/memory/hippocampus/graph.py

import networkx as nx

class KnowledgeGraphBuilder:
    """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–¢ä¿‚ã®ã‚°ãƒ©ãƒ•æ§‹ç¯‰"""

    def __init__(self):
        self.graph = nx.DiGraph()

    @agent(model="ollama/qwen2.5:3b-instruct")
    async def extract_entities_relations(self, text: str) -> dict:
        """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨é–¢ä¿‚ã‚’æŠ½å‡º"""
        pass

    def query_relations(self, entity: str, depth: int = 2) -> dict:
        """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®é–¢ä¿‚ã‚’å–å¾—ï¼ˆdepth-hopï¼‰"""
        pass
```

### æˆåŠŸæŒ‡æ¨™ï¼ˆPhase 3ï¼‰

- âœ… NetworkXçµ±åˆ
- âœ… ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ»é–¢ä¿‚æŠ½å‡º
- âœ… ã‚°ãƒ©ãƒ•ã‚¯ã‚¨ãƒªAPI

---

## ğŸ“¦ Phase 4: LoRA Fine-tuningï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ»3é€±é–“ï¼‰

### ç›®æ¨™

**é€±1å›ã®è»½é‡Fine-tuningï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰ã§ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯çµ±åˆ**

### å®Ÿè£…æ¦‚è¦

```python
# src/kagura/memory/hippocampus/learning.py

from transformers import AutoModelForCausalLM
from peft import get_peft_model, LoraConfig

class IncrementalLearner:
    """é€±1å›ã®LoRAå¾®èª¿æ•´"""

    async def finetune_lora(self, dataset: list[dict]):
        """LoRAå¾®èª¿æ•´ï¼ˆè»½é‡ï¼‰"""
        model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-3B-Instruct")
        lora_config = LoraConfig(r=8, lora_alpha=16)
        model = get_peft_model(model, lora_config)
        # å­¦ç¿’...
```

### æˆåŠŸæŒ‡æ¨™ï¼ˆPhase 4ï¼‰

- âœ… PEFTï¼ˆLoRAï¼‰çµ±åˆ
- âœ… é€±æ¬¡å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
- âœ… CPUå¯èƒ½ï¼ˆGPUä¸è¦ï¼‰

---

## ğŸ“Š RFC-003ã¨ã®æ¯”è¼ƒ

| é …ç›® | RFC-003ï¼ˆæ—§ï¼‰| RFC-034ï¼ˆæ–°ï¼‰|
|------|-------------|-------------|
| **æ ¸å¿ƒç›®çš„** | Fine-tuningä¸­å¿ƒ | **è¨˜æ†¶â†’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¼·åŒ–** |
| **ã‚³ã‚¹ãƒˆ** | $5-20/å›ï¼ˆFTï¼‰ | **$0ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«SLMï¼‰** |
| **ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼** | âš ï¸ å¤–éƒ¨é€ä¿¡ | âœ… **å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«** |
| **VRAM** | ä¸æ˜ | **< 0.5GBï¼ˆUltra-Lightï¼‰** |
| **åŠ¹æœ** | â­â­â­â­ | â­â­â­â­â­ |
| **æ®µéšæ€§** | FTä¸­å¿ƒ | **æ®µéšçš„ï¼ˆPhase 1-4ï¼‰** |
| **è¨˜æ†¶ãƒ¢ãƒ‡ãƒ«** | ãƒ‡ãƒ¼ã‚¿åé›†â†’FT | **æµ·é¦¬å‹ï¼ˆçµ±åˆãƒ»è¦ç´„ï¼‰** |
| **Knowledge Graph** | ãªã— | **ã‚ã‚Šï¼ˆPhase 3ï¼‰** |
| **æœ€å°å®Ÿè£…** | 4é€±é–“ | **2é€±é–“ï¼ˆPhase 1ï¼‰** |
| **Hardware** | ä¸æ˜ | **RTX 3060 OK** |

---

## ğŸ“… å®Ÿè£…ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

### v2.6.0: Hippocampus Memory Systemï¼ˆ8é€±é–“ï¼‰

**Week 1-2: Phase 1 - Episodic Consolidation** â­ï¸ æœ€å„ªå…ˆ
- [ ] `HippocampusConfig` å®Ÿè£…
- [ ] `EpisodicConsolidator` å®Ÿè£…
- [ ] `@agent(enable_hippocampus=True)` çµ±åˆ
- [ ] Qwen2.5-0.5Bçµ±åˆï¼ˆOllamaï¼‰
- [ ] 20+ tests
- [ ] **æˆæœ**: ä¼šè©±çµ‚äº†æ™‚ã«è‡ªå‹•è¦ç´„ã€VRAM < 0.5GB

**Week 3-4: Phase 2 - Semantic Integration**
- [ ] `SemanticIntegrator` å®Ÿè£…
- [ ] å¤œé–“çµ±åˆãƒãƒƒãƒï¼ˆGemini Flash 8Bï¼‰
- [ ] CLI: `kagura memory consolidate`
- [ ] 15+ tests
- [ ] **æˆæœ**: æ’ä¹…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã€ã‚³ã‚¹ãƒˆ < $0.0001/run

**Week 5-6: Phase 3 - Knowledge Graph (Optional)**
- [ ] `KnowledgeGraphBuilder` å®Ÿè£…
- [ ] NetworkXçµ±åˆ
- [ ] ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ»é–¢ä¿‚æŠ½å‡º
- [ ] 10+ tests

**Week 7-8: Phase 4 - LoRA Learning (Optional)**
- [ ] `IncrementalLearner` å®Ÿè£…
- [ ] PEFTï¼ˆLoRAï¼‰çµ±åˆ
- [ ] é€±æ¬¡å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
- [ ] 5+ tests

---

## ğŸ¯ æˆåŠŸæŒ‡æ¨™ï¼ˆå…¨ä½“ï¼‰

### Phase 1-2å®Œäº†æ™‚ï¼ˆå¿…é ˆï¼‰

**æŠ€è¡“æŒ‡æ¨™**:
- âœ… VRAMä½¿ç”¨é‡ < 0.5GBï¼ˆUltra-Lightï¼‰
- âœ… ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· < 50msï¼ˆäº‹å®ŸæŠ½å‡ºï¼‰
- âœ… ã‚³ã‚¹ãƒˆ < $0.01/æ—¥ï¼ˆå¤œé–“çµ±åˆï¼‰
- âœ… RTX 3060 (8GB) ã§å‹•ä½œ

**ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¾¡å€¤**:
- âœ… **å³åº§ã®è¨˜æ†¶**: ä¼šè©±ã”ã¨ã«é‡è¦äº‹å®Ÿã‚’è‡ªå‹•ä¿å­˜
- âœ… **çµ±åˆçŸ¥è­˜**: å¤œé–“ãƒãƒƒãƒã§ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
- âœ… **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¼·åŒ–**: Main LLMãŒã‚ˆã‚Šè‰¯ã„å›ç­”ã‚’ç”Ÿæˆ
- âœ… **ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼**: å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆå¤–éƒ¨é€ä¿¡ãªã—ï¼‰

### Phase 3-4å®Œäº†æ™‚ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

- âœ… **é–¢ä¿‚æ€§ç†è§£**: Knowledge Graphã§ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–¢ä¿‚ç®¡ç†
- âœ… **æ·±ã„å­¦ç¿’**: LoRAã§ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯çµ±åˆ
- âœ… **è‡ªå·±æ”¹å–„**: ä½¿ã†ã»ã©è³¢ããªã‚‹

---

## âš ï¸ ãƒªã‚¹ã‚¯ã¨å¯¾ç­–

### ãƒªã‚¹ã‚¯1: SLMå“è³ª

**å•é¡Œ**: 0.5B-3Bãƒ¢ãƒ‡ãƒ«ã§ååˆ†ãªç²¾åº¦ãŒå‡ºã‚‹ã‹ï¼Ÿ
**å¯¾ç­–**:
- Ultra-Lightï¼ˆ0.5Bï¼‰ã¯æœ€å°ã‚¿ã‚¹ã‚¯ã®ã¿ï¼ˆäº‹å®ŸæŠ½å‡ºãƒ»åˆ†é¡ï¼‰
- çµ±åˆå‡¦ç†ã¯ã‚¯ãƒ©ã‚¦ãƒ‰ï¼ˆGemini Flash 8Bï¼‰æ¨å¥¨
- ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿å¯èƒ½ï¼ˆUltra-Light / Light / Standard / Cloudï¼‰

### ãƒªã‚¹ã‚¯2: ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“

**å•é¡Œ**: ã€Œè¦šãˆã¦ã„ã‚‹ã€æ„Ÿè¦šãŒè–„ã„ã‹ã‚‚
**å¯¾ç­–**:
- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¡¨ç¤ºï¼ˆ"ğŸ’¾ è¨˜æ†¶ã—ã¾ã—ãŸ: ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰å¥½ã"ï¼‰
- `kagura memory show` ã‚³ãƒãƒ³ãƒ‰ã§è¨˜æ†¶ç¢ºèª
- Main LLMã®å›ç­”ã«è¨˜æ†¶ã‚½ãƒ¼ã‚¹è¡¨ç¤º

### ãƒªã‚¹ã‚¯3: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸è‚¥å¤§åŒ–

**å•é¡Œ**: RAGãŒè‚¥å¤§åŒ–ã™ã‚‹å¯èƒ½æ€§
**å¯¾ç­–**:
- TTLè¨­å®šï¼ˆ90æ—¥å¾Œã«è‡ªå‹•å‰Šé™¤ï¼‰
- é‡è¦åº¦ãƒ™ãƒ¼ã‚¹ã®å‰Šé™¤
- `kagura memory prune` ã‚³ãƒãƒ³ãƒ‰

---

## ğŸ”— é–¢é€£RFCãƒ»Issue

- **RFC-018**: Memory Management Systemï¼ˆæ—¢å­˜ãƒ»åŸºç›¤ï¼‰
- **RFC-024**: Context Compressionï¼ˆæ—¢å­˜ãƒ»è£œå®Œé–¢ä¿‚ï¼‰
- **RFC-025**: Knowledge Graph Integrationï¼ˆæœªå®Ÿè£…ãƒ»Phase 3ã§çµ±åˆï¼‰
- **Issue #63**: RFC-003 Personal Assistantï¼ˆ**ç½®ãæ›ãˆå¯¾è±¡**ï¼‰

---

## ğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **Issueä½œæˆ**ï¼ˆä»Šæ—¥ï¼‰
   - GitHub Issue: RFC-034 Hippocampus Memory System
   - Issue #63ã«ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆRFC-034ã¸ã®ç§»è¡Œèª¬æ˜ï¼‰

2. **ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**ï¼ˆ1é€±é–“ï¼‰
   - ãƒ­ãƒ¼ã‚«ãƒ«SLMã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¸ã®æ„è¦‹
   - ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è¦ä»¶ã®ç¢ºèª
   - å„ªå…ˆåº¦ã®èª¿æ•´

3. **Phase 1ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—**ï¼ˆ1é€±é–“ï¼‰
   - `EpisodicConsolidator` æœ€å°å®Ÿè£…
   - Qwen2.5-0.5Bçµ±åˆï¼ˆOllamaï¼‰
   - å®Ÿä½¿ç”¨ãƒ†ã‚¹ãƒˆï¼ˆRTX 3060ï¼‰

4. **è©•ä¾¡ â†’ Phase 2ä»¥é™ã®åˆ¤æ–­**

---

## ğŸ’¬ è­°è«–ãƒã‚¤ãƒ³ãƒˆ

1. **Ultra-Lightï¼ˆ0.5Bï¼‰ã§ååˆ†ã‹ï¼Ÿ**
   - äº‹å®ŸæŠ½å‡ºãƒ»åˆ†é¡ã¯å˜ç´”ã‚¿ã‚¹ã‚¯ â†’ 0.5Bã§ååˆ†
   - çµ±åˆå‡¦ç†ã¯ã‚¯ãƒ©ã‚¦ãƒ‰ï¼ˆGemini Flashï¼‰æ¨å¥¨

2. **çµ±åˆé »åº¦: å¤œé–“ãƒãƒƒãƒ vs ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼Ÿ**
   - Phase 1: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼ˆä¼šè©±çµ‚äº†æ™‚ï¼‰
   - Phase 2: å¤œé–“ãƒãƒƒãƒï¼ˆã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼‰

3. **Knowledge Graph: å¿…é ˆ or ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼Ÿ**
   - Phase 3: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆåŠ¹æœæ¤œè¨¼å¾Œã«åˆ¤æ–­ï¼‰

4. **LoRA Fine-tuning: æœ¬å½“ã«å¿…è¦ï¼Ÿ**
   - Phase 4: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆPhase 1-2ã§ååˆ†ã‹ã‚‚ï¼‰

---

## ğŸ“ ã¾ã¨ã‚

ã“ã®RFCã¯ã€Kagura AIã‚’ã€Œå˜ãªã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ã‹ã‚‰**ã€Œç¶™ç¶šçš„ã«è¨˜æ†¶ãƒ»å­¦ç¿’ã™ã‚‹ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«AIã€**ã¸ã¨é€²åŒ–ã•ã›ã¾ã™ã€‚

### æ ¸å¿ƒçš„ãªä¾¡å€¤

**ã€Œã“ã®è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ è‡ªä½“ãŒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ãªã‚Šã€Main LLMãŒã‚ˆã‚Šè‰¯ã„å›ç­”ã‚’ç”Ÿæˆã§ãã‚‹ã€**

### ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ

1. âœ… **æ®µéšçš„å®Ÿè£…**ï¼ˆPhase 1-4ã€Phase 1ã®ã¿ã§ä¾¡å€¤ã‚ã‚Šï¼‰
2. âœ… **ãƒ­ãƒ¼ã‚«ãƒ«å„ªå…ˆ**ï¼ˆãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ç¬¬ä¸€ã€ã‚³ã‚¹ãƒˆ$0ï¼‰
3. âœ… **è»½é‡**ï¼ˆVRAM < 0.5GBã€RTX 3060 OKï¼‰
4. âœ… **æµ·é¦¬å‹**ï¼ˆäººé–“ã®è¨˜æ†¶ãƒ¢ãƒ‡ãƒ«ã‚’æ¨¡å€£ï¼‰
5. âœ… **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¼·åŒ–**ï¼ˆè¨˜æ†¶â†’ã‚ˆã‚Šè‰¯ã„å›ç­”ï¼‰

### RFC-003ã‹ã‚‰ã®é€²åŒ–

- âŒ Fine-tuningä¸­å¿ƒ â†’ âœ… è¨˜æ†¶çµ±åˆä¸­å¿ƒ
- âŒ é«˜ã‚³ã‚¹ãƒˆï¼ˆ$5-20/å›ï¼‰â†’ âœ… ä½ã‚³ã‚¹ãƒˆï¼ˆ$0ï¼‰
- âŒ å¤–éƒ¨é€ä¿¡ â†’ âœ… å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«
- âŒ 4é€±é–“ â†’ âœ… 2é€±é–“ï¼ˆPhase 1ï¼‰

**ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ­“è¿ã—ã¾ã™ï¼**
