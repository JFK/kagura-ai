# RFC-003: Personal AI Assistant with Auto Fine-tuning

**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: ææ¡ˆä¸­
**ä½œæˆæ—¥**: 2025-10-03
**å¯¾è±¡ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: v2.3.0 - v2.4.0
**é–¢é€£Issue**: #63

---

## ğŸ“‹ æ¦‚è¦

**ä½¿ãˆã°ä½¿ã†ã»ã©è³¢ããªã‚‹ã€ã‚ãªãŸå°‚å±ã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ**

ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•åé›†ã—ã€å®šæœŸçš„ã«LLMã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆFTï¼‰ã™ã‚‹ã“ã¨ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®çŸ¥è­˜ãƒ»è©±ã—æ–¹ãƒ»å¥½ã¿ã‚’ç¶™ç¶šçš„ã«å­¦ç¿’ã—ã¾ã™ã€‚

---

## ğŸ¯ ç›®æ¨™

### ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦–ç‚¹

- âœ… è‡ªåˆ†ã®å¥½ã¿ã‚’ç†è§£ã—ãŸã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
- âœ… éå»ã®ä¼šè©±ã‚’è¨˜æ†¶
- âœ… ä½¿ã†ã»ã©ç²¾åº¦ãŒå‘ä¸Š
- âœ… ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- âœ… ã‚·ãƒ³ãƒ—ãƒ«ãªæ“ä½œï¼ˆè‡ªå‹•åŒ–ï¼‰

### æŠ€è¡“çš„ç›®æ¨™

- âœ… RAG + Few-shot + Fine-tuningã®3æ®µéšå­¦ç¿’
- âœ… OpenAI/Gemini FT APIçµ±åˆ
- âœ… ãƒ­ãƒ¼ã‚«ãƒ«LoRA FTå¯¾å¿œï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- âœ… ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
- âœ… ã‚³ã‚¹ãƒˆç®¡ç†æ©Ÿèƒ½

---

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 3æ®µéšãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³

```
Level 1: RAG (å³åº§ã®è¨˜æ†¶)
  â†“
  ã™ã¹ã¦ã®ä¼šè©±ã‚’ãƒ™ã‚¯ãƒˆãƒ«DBã«ä¿å­˜
  é–¢é€£ã™ã‚‹éå»ã®ä¼šè©±ã‚’å³åº§ã«å‚ç…§
  åŠ¹æœ: å³åº§ã«åæ˜ 

Level 2: Few-shot Learning (çŸ­æœŸå­¦ç¿’)
  â†“
  é«˜è©•ä¾¡ã®ä¼šè©±ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸ‹ã‚è¾¼ã¿
  æœ€æ–°10-20ä»¶ã‚’å‹•çš„ã«few-shot examplesã¨ã—ã¦ä½¿ç”¨
  åŠ¹æœ: æ•°å›ã®ä¼šè©±ã§åæ˜ 

Level 3: Fine-tuning (é•·æœŸå­¦ç¿’)
  â†“
  100ä»¶ä»¥ä¸Šã®é«˜è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã§FT
  ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ãƒ¢ãƒ‡ãƒ«ä½œæˆ
  åŠ¹æœ: æ ¹æœ¬çš„ãªçŸ¥è­˜ãƒ»è©±ã—æ–¹ã‚’å­¦ç¿’
```

### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

```mermaid
graph TB
    A[User Input] --> B[Agent Execution]
    B --> C[Generate Response]
    C --> D[User Feedback]

    D --> E{Rating >= 4?}
    E -->|Yes| F[Add to Training Data]
    E -->|No| G[Discard]

    F --> H{Count >= Threshold?}
    H -->|Yes| I[Trigger Fine-tuning]
    H -->|No| J[Store for Later]

    I --> K[Create FT Job]
    K --> L[Wait for Completion]
    L --> M[Deploy New Model]
    M --> N[Use in Next Conversation]

    D --> O[Add to Vector DB]
    O --> P[RAG Retrieval]
    P --> B

    F --> Q[Update Few-shot Cache]
    Q --> R[Inject in Prompt]
    R --> B
```

---

## ğŸ’» å®Ÿè£…è©³ç´°

### 1. ã‚³ã‚¢ã‚·ã‚¹ãƒ†ãƒ 

#### ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼

```python
# src/kagura/personalize/collector.py
import aiosqlite
import json
from datetime import datetime
from pathlib import Path

class ConversationCollector:
    """ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•åé›†"""

    def __init__(self, user_id: str, storage_dir: str = ".kagura/data"):
        self.user_id = user_id
        self.storage_dir = Path(storage_dir) / user_id
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        self.db_path = self.storage_dir / "conversations.db"

    async def initialize(self):
        """DBåˆæœŸåŒ–"""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute("""
                CREATE TABLE IF NOT EXISTS conversations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    messages TEXT NOT NULL,
                    response TEXT NOT NULL,
                    model TEXT,
                    rating INTEGER,
                    feedback TEXT,
                    metadata TEXT,
                    used_for_ft BOOLEAN DEFAULT 0
                )
            """)
            await db.commit()

    async def collect(
        self,
        messages: list[dict],
        response: str,
        model: str,
        metadata: dict = None
    ) -> int:
        """ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’åé›†

        Args:
            messages: ä¼šè©±å±¥æ­´
            response: AIã®å¿œç­”
            model: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«
            metadata: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿

        Returns:
            conversation_id
        """
        async with aiosqlite.connect(self.db_path) as db:
            cursor = await db.execute(
                """INSERT INTO conversations
                   (timestamp, messages, response, model, metadata)
                   VALUES (?, ?, ?, ?, ?)""",
                (
                    datetime.now().isoformat(),
                    json.dumps(messages, ensure_ascii=False),
                    response,
                    model,
                    json.dumps(metadata or {}, ensure_ascii=False)
                )
            )
            await db.commit()
            return cursor.lastrowid

    async def add_feedback(
        self,
        conversation_id: int,
        rating: int,
        comment: str = None
    ):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¿½åŠ 

        Args:
            conversation_id: ä¼šè©±ID
            rating: è©•ä¾¡ (1-5)
            comment: ã‚³ãƒ¡ãƒ³ãƒˆ
        """
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute(
                """UPDATE conversations
                   SET rating = ?, feedback = ?
                   WHERE id = ?""",
                (rating, comment, conversation_id)
            )
            await db.commit()

    async def get_training_data(
        self,
        min_rating: int = 4,
        limit: int = None
    ) -> list[dict]:
        """FTç”¨ãƒ‡ãƒ¼ã‚¿å–å¾—

        Args:
            min_rating: æœ€ä½è©•ä¾¡
            limit: ä»¶æ•°åˆ¶é™

        Returns:
            å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
        """
        query = """
            SELECT messages, response, rating
            FROM conversations
            WHERE rating >= ? AND used_for_ft = 0
            ORDER BY timestamp DESC
        """

        if limit:
            query += f" LIMIT {limit}"

        async with aiosqlite.connect(self.db_path) as db:
            async with db.execute(query, (min_rating,)) as cursor:
                rows = await cursor.fetchall()

        return [
            {
                "messages": json.loads(row[0]),
                "response": row[1],
                "rating": row[2]
            }
            for row in rows
        ]

    async def get_stats(self) -> dict:
        """çµ±è¨ˆæƒ…å ±å–å¾—"""
        async with aiosqlite.connect(self.db_path) as db:
            total = await db.execute_fetchall(
                "SELECT COUNT(*) FROM conversations"
            )
            rated = await db.execute_fetchall(
                "SELECT COUNT(*) FROM conversations WHERE rating IS NOT NULL"
            )
            high_rated = await db.execute_fetchall(
                "SELECT COUNT(*) FROM conversations WHERE rating >= 4"
            )
            used_for_ft = await db.execute_fetchall(
                "SELECT COUNT(*) FROM conversations WHERE used_for_ft = 1"
            )

        return {
            "total": total[0][0],
            "rated": rated[0][0],
            "high_rated": high_rated[0][0],
            "ready_for_ft": high_rated[0][0] - used_for_ft[0][0]
        }
```

#### ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼

```python
# src/kagura/personalize/privacy.py
import re
from typing import Any

class PrivacyFilter:
    """å€‹äººæƒ…å ±æ¤œå‡ºãƒ»é™¤å¤–"""

    # æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
    PATTERNS = {
        "email": r"\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}\b",
        "phone_jp": r"\d{2,4}-\d{2,4}-\d{4}",
        "phone_intl": r"\+\d{1,3}[-\s]?\d{1,4}[-\s]?\d{1,4}[-\s]?\d{1,4}",
        "credit_card": r"\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}",
        "ssn": r"\d{3}-\d{2}-\d{4}",
    }

    def __init__(
        self,
        detect_pii: bool = True,
        anonymize: bool = True,
        custom_patterns: dict[str, str] = None
    ):
        self.detect_pii = detect_pii
        self.anonymize = anonymize

        if custom_patterns:
            self.PATTERNS.update(custom_patterns)

    def scan(self, text: str) -> dict[str, list[str]]:
        """å€‹äººæƒ…å ±ã‚’ã‚¹ã‚­ãƒ£ãƒ³

        Args:
            text: ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            æ¤œå‡ºã•ã‚ŒãŸå€‹äººæƒ…å ±ã®è¾æ›¸
        """
        found = {}

        for name, pattern in self.PATTERNS.items():
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                found[name] = matches

        return found

    def filter(self, text: str) -> tuple[str, bool]:
        """å€‹äººæƒ…å ±ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

        Args:
            text: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¯¾è±¡

        Returns:
            (ãƒ•ã‚£ãƒ«ã‚¿å¾Œãƒ†ã‚­ã‚¹ãƒˆ, å€‹äººæƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ãŸã‹)
        """
        found = self.scan(text)

        if not found:
            return text, False

        if self.anonymize:
            # åŒ¿ååŒ–
            filtered = text
            for pii_type, matches in found.items():
                for match in matches:
                    filtered = filtered.replace(match, f"[REDACTED_{pii_type.upper()}]")
            return filtered, True
        else:
            # é™¤å¤–ï¼ˆç©ºæ–‡å­—åˆ—ï¼‰
            return "", True

    def is_safe(self, data: dict) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãŒå®‰å…¨ã‹åˆ¤å®š

        Args:
            data: ãƒã‚§ãƒƒã‚¯å¯¾è±¡ãƒ‡ãƒ¼ã‚¿

        Returns:
            å®‰å…¨ãªã‚‰True
        """
        # messagesã¨responseã‚’ãƒã‚§ãƒƒã‚¯
        for msg in data.get("messages", []):
            content = msg.get("content", "")
            if self.scan(content):
                return False

        response = data.get("response", "")
        if self.scan(response):
            return False

        return True
```

#### Fine-tuning Manager

```python
# src/kagura/personalize/finetune.py
from openai import OpenAI
import asyncio
import json

class OpenAIFinetune:
    """OpenAI Fine-tuningç®¡ç†"""

    def __init__(
        self,
        user_id: str,
        base_model: str = "gpt-4o-mini-2024-07-18",
        api_key: str = None
    ):
        self.user_id = user_id
        self.base_model = base_model
        self.client = OpenAI(api_key=api_key)
        self.jobs_file = f".kagura/data/{user_id}/ft_jobs.json"

    async def prepare_training_data(
        self,
        conversations: list[dict],
        output_path: str = None
    ) -> str:
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’OpenAIå½¢å¼ã«å¤‰æ›

        Args:
            conversations: ä¼šè©±ãƒ‡ãƒ¼ã‚¿
            output_path: å‡ºåŠ›å…ˆ

        Returns:
            ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        if not output_path:
            output_path = f".kagura/data/{self.user_id}/training_data.jsonl"

        with open(output_path, 'w', encoding='utf-8') as f:
            for conv in conversations:
                training_example = {
                    "messages": conv["messages"] + [
                        {"role": "assistant", "content": conv["response"]}
                    ]
                }
                f.write(json.dumps(training_example, ensure_ascii=False) + '\n')

        return output_path

    async def estimate_cost(self, training_file: str) -> dict:
        """ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š

        Args:
            training_file: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«

        Returns:
            ã‚³ã‚¹ãƒˆæƒ…å ±
        """
        # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚«ã‚¦ãƒ³ãƒˆ
        total_tokens = 0
        with open(training_file, 'r') as f:
            for line in f:
                data = json.loads(line)
                # ç°¡æ˜“çš„ãªãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šï¼ˆå®Ÿéš›ã¯tiktokenã‚’ä½¿ç”¨ï¼‰
                for msg in data['messages']:
                    total_tokens += len(msg['content'].split()) * 1.3

        # ã‚³ã‚¹ãƒˆè¨ˆç®—ï¼ˆ2024å¹´10æœˆæ™‚ç‚¹ã®ä¾¡æ ¼ï¼‰
        # gpt-4o-mini: $0.30/1M tokens (training)
        training_cost = (total_tokens / 1_000_000) * 0.30

        return {
            "total_tokens": int(total_tokens),
            "estimated_cost_usd": round(training_cost, 2),
            "estimated_time_minutes": 15  # å›ºå®šå€¤ï¼ˆå®Ÿéš›ã¯å¯å¤‰ï¼‰
        }

    async def start_finetuning(
        self,
        training_file: str,
        validation_file: str = None,
        hyperparameters: dict = None
    ) -> str:
        """Fine-tuningé–‹å§‹

        Args:
            training_file: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
            validation_file: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿
            hyperparameters: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

        Returns:
            Job ID
        """
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        with open(training_file, 'rb') as f:
            train_file = self.client.files.create(
                file=f,
                purpose='fine-tune'
            )

        # FTé–‹å§‹
        job = self.client.fine_tuning.jobs.create(
            training_file=train_file.id,
            model=self.base_model,
            suffix=f"{self.user_id}-v{self._get_next_version()}",
            hyperparameters=hyperparameters or {}
        )

        # Jobè¨˜éŒ²
        self._save_job(job.id, {
            "started_at": datetime.now().isoformat(),
            "status": "running",
            "model": self.base_model,
            "training_file": train_file.id
        })

        return job.id

    async def check_status(self, job_id: str) -> dict:
        """FTçŠ¶æ³ç¢ºèª

        Args:
            job_id: Job ID

        Returns:
            ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±
        """
        job = self.client.fine_tuning.jobs.retrieve(job_id)

        return {
            "status": job.status,
            "created_at": job.created_at,
            "finished_at": job.finished_at,
            "fine_tuned_model": job.fine_tuned_model,
            "error": job.error if job.status == "failed" else None
        }

    async def wait_for_completion(
        self,
        job_id: str,
        polling_interval: int = 60
    ) -> str:
        """FTå®Œäº†ã‚’å¾…ã¤

        Args:
            job_id: Job ID
            polling_interval: ãƒãƒ¼ãƒªãƒ³ã‚°é–“éš”ï¼ˆç§’ï¼‰

        Returns:
            Fine-tuned model ID
        """
        while True:
            status = await self.check_status(job_id)

            if status["status"] == "succeeded":
                model_id = status["fine_tuned_model"]

                # Jobè¨˜éŒ²æ›´æ–°
                self._update_job(job_id, {
                    "status": "succeeded",
                    "finished_at": status["finished_at"],
                    "model_id": model_id
                })

                return model_id

            elif status["status"] == "failed":
                raise Exception(f"Fine-tuning failed: {status['error']}")

            # å¾…æ©Ÿ
            await asyncio.sleep(polling_interval)

    def _get_next_version(self) -> int:
        """æ¬¡ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·å–å¾—"""
        jobs = self._load_jobs()
        if not jobs:
            return 1
        return max(job.get("version", 0) for job in jobs.values()) + 1

    def _save_job(self, job_id: str, data: dict):
        """Jobæƒ…å ±ä¿å­˜"""
        jobs = self._load_jobs()
        jobs[job_id] = data

        with open(self.jobs_file, 'w') as f:
            json.dump(jobs, f, indent=2)

    def _update_job(self, job_id: str, updates: dict):
        """Jobæƒ…å ±æ›´æ–°"""
        jobs = self._load_jobs()
        if job_id in jobs:
            jobs[job_id].update(updates)

            with open(self.jobs_file, 'w') as f:
                json.dump(jobs, f, indent=2)

    def _load_jobs(self) -> dict:
        """Jobæƒ…å ±èª­ã¿è¾¼ã¿"""
        if not os.path.exists(self.jobs_file):
            return {}

        with open(self.jobs_file, 'r') as f:
            return json.load(f)
```

### 2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµ±åˆ

```python
# src/kagura/personalize/decorators.py
from functools import wraps
from typing import Callable, TypeVar, ParamSpec

P = ParamSpec('P')
T = TypeVar('T')

def auto_finetune(
    user_id: str,
    threshold: int = 100,
    min_rating: int = 4,
    auto_approve: bool = False,
    privacy_filter: PrivacyFilter = None
):
    """Auto fine-tuning decorator

    Args:
        user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        threshold: FTé–‹å§‹é–¾å€¤
        min_rating: æœ€ä½è©•ä¾¡
        auto_approve: è‡ªå‹•æ‰¿èª
        privacy_filter: ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    """
    def decorator(func: Callable[P, T]) -> Callable[P, T]:
        # ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼åˆæœŸåŒ–
        collector = ConversationCollector(user_id)
        asyncio.create_task(collector.initialize())

        # FTãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
        ft_manager = OpenAIFinetune(user_id)

        @wraps(func)
        async def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œ
            result = await func(*args, **kwargs)

            # ãƒ‡ãƒ¼ã‚¿åé›†
            messages = kwargs.get('_messages', [])
            conv_id = await collector.collect(
                messages=messages,
                response=str(result),
                model=kwargs.get('_model', 'unknown')
            )

            # conversation_idã‚’ä¿å­˜ï¼ˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”¨ï¼‰
            wrapper._last_conversation_id = conv_id

            # FTé–¾å€¤ãƒã‚§ãƒƒã‚¯
            stats = await collector.get_stats()
            if stats['ready_for_ft'] >= threshold:
                await _trigger_finetuning(
                    collector, ft_manager, auto_approve, privacy_filter
                )

            return result

        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ 
        async def feedback(rating: int, comment: str = None):
            """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¿½åŠ """
            conv_id = getattr(wrapper, '_last_conversation_id', None)
            if conv_id:
                await collector.add_feedback(conv_id, rating, comment)

        wrapper.feedback = feedback

        return wrapper

    return decorator

async def _trigger_finetuning(
    collector: ConversationCollector,
    ft_manager: OpenAIFinetune,
    auto_approve: bool,
    privacy_filter: PrivacyFilter
):
    """Fine-tuningã‚’é–‹å§‹"""
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å–å¾—
    training_data = await collector.get_training_data()

    # ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if privacy_filter:
        filtered_data = []
        for data in training_data:
            if privacy_filter.is_safe(data):
                filtered_data.append(data)
            else:
                print(f"âš ï¸ Skipped 1 conversation (contains PII)")
        training_data = filtered_data

    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    training_file = await ft_manager.prepare_training_data(training_data)

    # ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š
    cost_info = await ft_manager.estimate_cost(training_file)

    print(f"""
ğŸ“ Fine-tuning Ready!
ğŸ“Š Training samples: {len(training_data)}
ğŸ’° Estimated cost: ${cost_info['estimated_cost_usd']}
â±ï¸ Estimated time: {cost_info['estimated_time_minutes']} minutes
    """)

    # æ‰¿èªç¢ºèª
    if not auto_approve:
        response = input("Proceed? (y/n): ")
        if response.lower() != 'y':
            print("Fine-tuning cancelled.")
            return

    # FTé–‹å§‹
    print("ğŸš€ Starting fine-tuning...")
    job_id = await ft_manager.start_finetuning(training_file)

    print(f"Job ID: {job_id}")
    print("You can check status with: kagura assistant status")
```

### 3. CLIã‚³ãƒãƒ³ãƒ‰

```python
# src/kagura/cli/assistant.py
import click
import asyncio

@click.group()
def assistant():
    """Personal AI assistant commands"""
    pass

@assistant.command()
@click.option('--user-id', '-u', required=True, help='User ID')
def start(user_id: str):
    """Start interactive personal assistant"""
    from kagura import agent, memory, personalize

    @agent(model="gpt-4o-mini")
    @memory.vector(collection=f"{user_id}_memory")
    @personalize.auto_finetune(user_id=user_id, threshold=100)
    async def my_assistant(task: str) -> str:
        """{{ task }}"""
        pass

    # REPLèµ·å‹•
    print(f"Kagura Personal Assistant ({user_id})")
    print("Type 'exit' to quit\n")

    while True:
        task = input("You: ")
        if task.lower() in ['exit', 'quit']:
            break

        result = await my_assistant(task)
        print(f"\nAI: {result}\n")

        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
        rating = input("Rating (1-5, or press Enter to skip): ")
        if rating:
            await my_assistant.feedback(int(rating))

@assistant.command()
@click.option('--user-id', '-u', required=True)
def status(user_id: str):
    """Show assistant status"""
    collector = ConversationCollector(user_id)
    stats = asyncio.run(collector.get_stats())

    print(f"""
Personal Assistant Status
User: {user_id}

ğŸ“Š Data Collection:
  Total conversations: {stats['total']}
  Rated conversations: {stats['rated']}
  High-rated (4-5â˜…): {stats['high_rated']}
  Ready for FT: {stats['ready_for_ft']}
    """)

@assistant.command()
@click.option('--user-id', '-u', required=True)
@click.option('--approve/--no-approve', default=False)
def train(user_id: str, approve: bool):
    """Start fine-tuning"""
    # FTå®Ÿè¡Œ
    pass
```

---

## ğŸ“Š æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ

### å®šé‡çš„åŠ¹æœ

| æŒ‡æ¨™ | Before | After (100 samples FT) | æ”¹å–„ç‡ |
|------|--------|----------------------|--------|
| **å¿œç­”ç²¾åº¦** | 85% | 92% | +8% |
| **ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦** | 3.8/5 | 4.5/5 | +18% |
| **ã‚¿ã‚¹ã‚¯å®Œäº†ç‡** | 70% | 88% | +26% |

### å®šæ€§çš„åŠ¹æœ

- âœ… **ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚º**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã‚’ç†è§£
- âœ… **ä¸€è²«æ€§**: è©±ã—æ–¹ãƒ»ç”¨èªãŒçµ±ä¸€
- âœ… **ç¶™ç¶šå­¦ç¿’**: ä½¿ã†ã»ã©æ”¹å–„
- âœ… **å·®åˆ¥åŒ–**: ä»–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ãªã„æ©Ÿèƒ½

---

## âš ï¸ ãƒªã‚¹ã‚¯ã¨å¯¾ç­–

### ãƒªã‚¹ã‚¯1: ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼

**å•é¡Œ**: ãƒ‡ãƒ¼ã‚¿ã‚’å¤–éƒ¨APIã«é€ä¿¡
**å¯¾ç­–**:
- ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å®Ÿè£…
- ãƒ­ãƒ¼ã‚«ãƒ«LoRAã‚ªãƒ—ã‚·ãƒ§ãƒ³
- æ˜ç¤ºçš„ãªåŒæ„å–å¾—

### ãƒªã‚¹ã‚¯2: ã‚³ã‚¹ãƒˆ

**å•é¡Œ**: FTã‚³ã‚¹ãƒˆï¼ˆ$5-20/å›ï¼‰
**å¯¾ç­–**:
- ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Šè¡¨ç¤º
- æ‰‹å‹•æ‰¿èªåˆ¶ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
- é–¾å€¤èª¿æ•´å¯èƒ½

### ãƒªã‚¹ã‚¯3: å“è³ª

**å•é¡Œ**: å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã¯åŠ¹æœè–„ã„
**å¯¾ç­–**:
- é–¾å€¤100ä»¶æ¨å¥¨
- RAG/Few-shotã§è£œå®Œ
- A/Bãƒ†ã‚¹ãƒˆå®Ÿæ–½

---

## ğŸ“… å®Ÿè£…ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

### Phase 2.3: ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³åŸºç›¤ï¼ˆv2.3.0ï¼‰

**Week 1-2** (2025-12-02 ã€œ 2025-12-15):
- [ ] ConversationCollectorå®Ÿè£…
- [ ] PrivacyFilterå®Ÿè£…
- [ ] SQLiteã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
- [ ] ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯API

**Week 3-4** (2025-12-16 ã€œ 2025-12-29):
- [ ] RAGçµ±åˆï¼ˆLevel 1ï¼‰
- [ ] Few-shotçµ±åˆï¼ˆLevel 2ï¼‰
- [ ] ãƒ™ã‚¯ãƒˆãƒ«DBæœ€é©åŒ–
- [ ] CLIã‚³ãƒãƒ³ãƒ‰åŸºæœ¬

### Phase 2.4: Fine-tuningçµ±åˆï¼ˆv2.4.0ï¼‰

**Week 5-6** (2026-01-06 ã€œ 2026-01-19):
- [ ] OpenAIFinetuneå®Ÿè£…
- [ ] GeminiFinetuneå®Ÿè£…
- [ ] è‡ªå‹•FTç®¡ç†
- [ ] ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š

**Week 7-8** (2026-01-20 ã€œ 2026-02-02):
- [ ] ãƒ­ãƒ¼ã‚«ãƒ«LoRAå®Ÿè£…ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- [ ] CLIã‚³ãƒãƒ³ãƒ‰æ‹¡å……
- [ ] ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆWeb UIï¼‰
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«

---

## ğŸ“ å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹

### ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘

- ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«: ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å§‹ã‚æ–¹
- ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹: åŠ¹æœçš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ–¹æ³•
- FAQ: ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã€ã‚³ã‚¹ãƒˆã€ãƒ‡ãƒ¼ã‚¿ç®¡ç†

### é–‹ç™ºè€…å‘ã‘

- ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å®Ÿè£…
- ãƒ­ãƒ¼ã‚«ãƒ«LoRA Fine-tuning ã‚¬ã‚¤ãƒ‰
- Fine-tuning ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´

---

## ğŸ“ ã¾ã¨ã‚

ã“ã®RFCã¯ã€Kagura AIã‚’ã€Œå˜ãªã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ã‹ã‚‰ã€Œç¶™ç¶šçš„ã«å­¦ç¿’ã™ã‚‹ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ã¸ã¨é€²åŒ–ã•ã›ã¾ã™ã€‚

**ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ**:
1. âœ… **3æ®µéšå­¦ç¿’**ï¼ˆRAG + Few-shot + FTï¼‰
2. âœ… **ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·**ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ + ãƒ­ãƒ¼ã‚«ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
3. âœ… **ã‚³ã‚¹ãƒˆç®¡ç†**ï¼ˆè¦‹ç©ã‚‚ã‚Š + æ‰‹å‹•æ‰¿èªï¼‰
4. âœ… **ã‚·ãƒ³ãƒ—ãƒ«ãªUX**ï¼ˆè‡ªå‹•åŒ– + CLIï¼‰
5. âœ… **å·®åˆ¥åŒ–**ï¼ˆæ¥­ç•Œåˆã®FTçµ±åˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼‰

ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ­“è¿ã—ã¾ã™ï¼
