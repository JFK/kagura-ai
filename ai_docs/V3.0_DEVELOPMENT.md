# Kagura AI v3.0 Development Guide

**Date**: 2025-10-19
**Purpose**: v3.0開発の実践的ガイド

---

## 🎯 v3.0コンセプト

### SDK軸、Chatはボーナス

**メインターゲット**: Python開発者（アプリへのSDK統合）
**ボーナス**: Chatで手軽に試せる（実験・プロトタイピング）

**理由**: GitHubはエンジニア向けプラットフォーム

---

## 📐 アーキテクチャ

### 3層構造（簡略版）

```
┌─────────────────────────────────────┐
│  Layer 1: Developer SDK             │
│  - from kagura import agent         │
│  - Type-safe, Production-ready      │
└─────────────────────────────────────┘
           ↓ also provides
┌─────────────────────────────────────┐
│  Layer 2: Built-in Tools & Agents   │
│  - Web search, File ops, Code exec  │
│  - Personal tools (news, weather)   │
└─────────────────────────────────────┘
           ↓ showcased in
┌─────────────────────────────────────┐
│  Layer 3: Interactive Chat (Bonus)  │
│  - kagura chat (試す・実験用)      │
│  - Claude Code-like UX              │
└─────────────────────────────────────┘
```

---

## 📋 開発優先度

### 🔥 Critical

1. **ドキュメント刷新** (Issue #315)
   - README: SDK-first
   - CLAUDE.md: 簡素化
   - Examples: v2.6.0対応 + SDK統合例

2. **SDK化推進**
   - `__init__.py` exports拡張
   - Personal tools直接import
   - Built-in tools直接import

### ⭐️ High

3. **Chat機能強化** (v3.0完成へ)
   - `/create` command（Meta Agent）
   - `/stats` command（コスト可視化）
   - `/reload` command（エージェント再読込）

4. **Examples拡充**
   - SDK統合例（FastAPI, Streamlit）
   - Personal tools使用例
   - Real-world use cases

### 📚 Medium

5. **RFC-033 Phase 1** - Auto-Discovery
6. **Pre-installed Agents** - エージェントコレクション

---

## 🛠️ 開発フロー

### 標準フロー

```bash
# 1. Issue作成
gh issue create --title "feat(scope): description" --body "..."

# 2. Branchを作成
gh issue develop [番号] --checkout

# 3. 実装（TDD）
# テスト → 実装 → 型チェック・lint

# 4. コミット
git add .
git commit -m "feat(scope): ... (#XX)

🤖 Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>"

# 5. Draft PR
gh pr create --draft --title "..." --body "..."

# 6. CI通過 → Merge
gh pr ready [番号]
gh pr merge [番号] --squash
```

---

## 📝 実装ガイドライン

### @agent デコレータ

```python
from kagura import agent

@agent(
    model="gpt-5-mini",           # デフォルトモデル
    temperature=0.7,              # 温度設定
    enable_memory=True,           # メモリ有効化
    tools=["web_search"],         # Built-in tools
    stream=True,                  # ストリーミング
)
async def my_agent(query: str) -> str:
    '''プロンプトテンプレート: {{ query }}'''
```

### Custom Tools

```python
from kagura import tool

@tool
async def custom_tool(input: str) -> str:
    '''ツール説明'''
    # 実装
    return result
```

### Memory活用

```python
@agent(enable_memory=True)
async def assistant(message: str, memory: MemoryManager) -> str:
    '''{{ message }}'''

    # Memory APIは自動注入
    # await memory.recall(key)
    # await memory.store(key, value)
```

---

## 🧪 テスト戦略

### ユニットテスト

```python
import pytest
from kagura import agent

@pytest.mark.asyncio
async def test_agent_basic():
    @agent
    async def test_agent(query: str) -> str:
        '''Process: {{ query }}'''

    result = await test_agent("hello")
    assert isinstance(result, str)
    assert len(result) > 0
```

### LLM Mocking

```python
from kagura.testing.mocking import LLMMock

@pytest.mark.asyncio
async def test_with_mock():
    with LLMMock("Mocked response"):
        result = await my_agent("test")
        assert "Mocked response" in result
```

---

## 📊 v3.0進捗

### 完了済み (v2.7.x)
- ✅ Streaming support
- ✅ User config (`kagura init`)
- ✅ Personal tools (4個)
- ✅ Context compression
- ✅ MCP integration

### 進行中 (v3.0)
- 🔄 Documentation refresh (Issue #315)
- 🔄 SDK exports拡張
- 🔄 Examples更新

### 未実装 (v3.0リリース前)
- ⏳ Chat `/create` command
- ⏳ Chat `/stats` command
- ⏳ Chat `/reload` command完成

---

## 🔗 関連ドキュメント

- `ROADMAP_v3.md` - v3.0ロードマップ
- `V3.0_PIVOT.md` - v3.0方針転換の背景
- `V3.0_WORK_LOG.md` - 作業ログ
- `CODING_STANDARDS.md` - コーディング規約
- `VISION.md` - プロジェクトビジョン

---

## 🎓 ベストプラクティス

### @agentデコレータの型の一貫性

**重要**: `@agent`デコレータは関数の返り値型アノテーションを尊重します。

```python
# ✅ Good: 型アノテーションと実際の返り値が一致
@agent
async def get_summary(text: str) -> str:
    """Summarize: {{ text }}"""
    ...

result = await get_summary("...")
assert isinstance(result, str)  # ✅ Passes

# ✅ Good: Pydantic modelを返す
@agent
async def extract_data(text: str) -> Person:
    """Extract person info from: {{ text }}"""
    ...

result = await extract_data("...")
assert isinstance(result, Person)  # ✅ Passes

# ❌ Bad: 型アノテーション無しでLLMResponseが返る
@agent
async def get_news(topic: str):  # No return type annotation
    """Get news about: {{ topic }}"""
    ...

result = await get_news("AI")
# result is LLMResponse object, not str! ❌
```

**内部実装**:
- `-> str`の場合: `LLMResponse.content`を返す
- Pydanticモデルの場合: JSONパースして検証済みモデルを返す
- 型アノテーション無しの場合: `LLMResponse`オブジェクトを返す

### テスト作成時のLLMMock使用

```python
from kagura.testing.mocking import LLMMock

@pytest.mark.asyncio
async def test_my_agent():
    """Test with mocked LLM response"""
    with LLMMock("Mocked response content"):
        result = await my_agent("test input")
        assert isinstance(result, str)
        assert "Mocked response" in result
```

**LLMMockの動作**:
- OpenAI SDK, LiteLLM, Gemini SDKをすべてモック
- テスト実行時に実際のAPI呼び出しを回避
- 決定的なテスト結果を保証

### hasattrを使ったDuck Typing

循環インポートや型チェック遅延を避けるため、`isinstance`の代わりに`hasattr`を使用：

```python
# ❌ Avoid: isinstance with import
from kagura.core.llm import LLMResponse
if isinstance(response, LLMResponse):
    return response.content

# ✅ Prefer: hasattr for duck typing
if hasattr(response, "content"):
    return response.content  # type: ignore
```

---

**v3.0でKagura AIを最高のPython AI SDKにしましょう！** 🚀
