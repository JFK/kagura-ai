{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Kagura AI v2.5.0","text":"<p>Python-First AI Agent Framework with Memory, Routing, and Multimodal RAG</p> <p>Kagura AI v2.5.0 is a modern framework that makes building AI agents as simple as writing a Python function. With a single <code>@agent</code> decorator, you can transform any async function into a powerful AI agent with memory, routing, multimodal understanding, and web search capabilities.</p>"},{"location":"#what-is-kagura-ai","title":"What is Kagura AI?","text":"<p>Kagura AI v2.5.0 is a production-ready framework focused on developer experience and simplicity. You write agents in pure Python with familiar async/await patterns.</p> <pre><code>from kagura import agent\n\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\nresult = await hello(\"World\")\n# \"Hello, World!\"\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#core-features","title":"Core Features","text":"<ul> <li>One-Line Agent Creation: <code>@agent</code> decorator converts functions to AI agents</li> <li>Jinja2 Templates: Dynamic prompts using template syntax in docstrings</li> <li>Type-Based Parsing: Automatic response conversion using Python type hints</li> <li>Pydantic Support: First-class structured output with Pydantic models</li> <li>Code Execution: Built-in safe Python code generation and execution</li> <li>Multi-LLM Support: Works with OpenAI, Anthropic, Google, and more</li> </ul>"},{"location":"#v250-advanced-features","title":"v2.5.0 Advanced Features","text":"<ul> <li>Memory Management: Context, persistent, and RAG-based memory</li> <li>Agent Routing: Intelligent agent selection with intent and semantic matching</li> <li>Multimodal RAG: Index and search images, audio, video, and PDFs</li> <li>Web Integration: Real-time web search and content scraping</li> <li>Context Compression: Efficient token management for long conversations</li> <li>Interactive Chat: Full-featured chat REPL with memory and web search</li> <li>Testing Framework: Built-in testing utilities with semantic assertions</li> <li>Observability: Telemetry, cost tracking, and performance monitoring</li> </ul>"},{"location":"#core-concepts","title":"Core Concepts","text":""},{"location":"#1-agent-decorator","title":"1. Agent Decorator","text":"<p>Transform any async function into an AI agent:</p> <pre><code>@agent\nasync def my_agent(input: str) -&gt; str:\n    '''Process {{ input }}'''\n    pass\n</code></pre> <p>The decorator: - Extracts the function signature - Uses the docstring as a Jinja2 template - Calls the LLM with rendered prompt - Parses the response based on return type</p>"},{"location":"#2-template-engine","title":"2. Template Engine","text":"<p>Use Jinja2 templates in docstrings for dynamic prompts:</p> <pre><code>@agent\nasync def translator(text: str, lang: str = \"ja\") -&gt; str:\n    '''Translate to {{ lang }}: {{ text }}'''\n    pass\n</code></pre>"},{"location":"#3-type-based-parser","title":"3. Type-Based Parser","text":"<p>Automatic response parsing based on return type hints:</p> <pre><code>from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    '''Extract person info from: {{ text }}'''\n    pass\n</code></pre> <p>Returns a fully validated Pydantic model instance.</p>"},{"location":"#4-code-execution","title":"4. Code Execution","text":"<p>Safe Python code generation and execution:</p> <pre><code>from kagura.agents import execute_code\n\nresult = await execute_code(\"Calculate the factorial of 10\")\n# Generates code, executes safely, returns result\n</code></pre>"},{"location":"#architecture","title":"Architecture","text":"<p>Kagura AI v2.5.0 follows a clean, layered architecture:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         @agent Decorator            \u2502\n\u2502  (Function \u2192 Agent transformation)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       Template Engine (Jinja2)      \u2502\n\u2502    (Docstring \u2192 Rendered prompt)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         LLM Layer (LiteLLM)         \u2502\n\u2502   (Prompt \u2192 LLM \u2192 Raw response)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Parser (Type-based parsing)      \u2502\n\u2502  (Raw response \u2192 Typed Python obj)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#design-philosophy","title":"Design Philosophy","text":"<p>Kagura AI v2.5.0 is built on these principles:</p> <ul> <li>Python-First: No external configuration files</li> <li>Type Safety: Leverages Python's type system</li> <li>Developer Experience: Simple API, fast iteration</li> <li>Composability: Agents are just async functions</li> <li>Explicitness: Clear data flow, no magic</li> <li>Production-Ready: Built-in testing, monitoring, and optimization tools</li> </ul>"},{"location":"#get-started","title":"Get Started","text":"<p>Ready to build your first agent?</p> <ul> <li>Installation Guide - Install Kagura AI</li> <li>Quick Start Tutorial - Build your first agent in 5 minutes</li> <li>API Reference - Detailed API documentation</li> <li>Examples - More examples and patterns</li> </ul> <p>Get Started \u2192</p>"},{"location":"en/installation/","title":"Installation","text":""},{"location":"en/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.11 or higher</li> <li>pip or uv package manager</li> </ul>"},{"location":"en/installation/#install-from-pypi","title":"Install from PyPI","text":""},{"location":"en/installation/#using-pip","title":"Using pip","text":"<pre><code>pip install kagura-ai\n</code></pre>"},{"location":"en/installation/#using-uv-recommended","title":"Using uv (recommended)","text":"<pre><code>uv add kagura-ai\n</code></pre>"},{"location":"en/installation/#verify-installation","title":"Verify Installation","text":"<p>Check that Kagura AI is installed correctly:</p> <pre><code>kagura version\n</code></pre> <p>You should see output like:</p> <pre><code>Kagura AI v2.5.0\n</code></pre>"},{"location":"en/installation/#set-api-key","title":"Set API Key","text":"<p>Kagura AI uses LiteLLM, which supports multiple LLM providers. You need to set the appropriate API key for your chosen provider.</p> <p>\ud83d\udca1 Quick Start Tip</p> <p>The fastest way to get started with Gemini: 1. Visit Google AI Studio 2. Click \"Create API Key\" 3. Copy the key and set: <code>export GOOGLE_API_KEY=\"your-key\"</code></p> <p>No Google Cloud Console setup needed! OAuth2 is an advanced feature for specific use cases. See OAuth2 Authentication Guide for details.</p>"},{"location":"en/installation/#openai","title":"OpenAI","text":"<pre><code>export OPENAI_API_KEY=\"your-key-here\"\n</code></pre> <p>Or in Python: <pre><code>import os\nos.environ[\"OPENAI_API_KEY\"] = \"your-key-here\"\n</code></pre></p>"},{"location":"en/installation/#anthropic-claude","title":"Anthropic (Claude)","text":"<pre><code>export ANTHROPIC_API_KEY=\"your-key-here\"\n</code></pre>"},{"location":"en/installation/#google-gemini","title":"Google (Gemini)","text":"<pre><code>export GOOGLE_API_KEY=\"your-key-here\"\n</code></pre>"},{"location":"en/installation/#azure-openai","title":"Azure OpenAI","text":"<pre><code>export AZURE_API_KEY=\"your-key-here\"\nexport AZURE_API_BASE=\"https://your-endpoint.openai.azure.com/\"\nexport AZURE_API_VERSION=\"2023-05-15\"\n</code></pre>"},{"location":"en/installation/#test-your-installation","title":"Test Your Installation","text":"<p>Create a simple test file:</p> <pre><code># test_kagura.py\nfrom kagura import agent\n\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    async def main():\n        result = await hello(\"Kagura AI\")\n        print(result)\n\n    asyncio.run(main())\n</code></pre> <p>Run it:</p> <pre><code>python test_kagura.py\n</code></pre> <p>If successful, you should see a greeting message.</p>"},{"location":"en/installation/#development-installation","title":"Development Installation","text":"<p>For contributing to Kagura AI or running from source:</p>"},{"location":"en/installation/#clone-repository","title":"Clone Repository","text":"<pre><code>git clone https://github.com/JFK/kagura-ai.git\ncd kagura-ai\n</code></pre>"},{"location":"en/installation/#install-dependencies","title":"Install Dependencies","text":"<p>Using uv (recommended):</p> <pre><code>uv sync --dev\n</code></pre> <p>This will install: - All runtime dependencies - Development dependencies (pytest, pyright, ruff, etc.)</p>"},{"location":"en/installation/#run-tests","title":"Run Tests","text":"<pre><code>pytest\n</code></pre>"},{"location":"en/installation/#type-checking","title":"Type Checking","text":"<pre><code>pyright\n</code></pre>"},{"location":"en/installation/#code-formatting","title":"Code Formatting","text":"<pre><code>ruff check src/\n</code></pre>"},{"location":"en/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>Kagura AI provides several optional feature presets to install only what you need.</p>"},{"location":"en/installation/#user-facing-presets","title":"\ud83d\udce6 User-Facing Presets","text":""},{"location":"en/installation/#ai-features-kagura-aiai","title":"AI Features (<code>kagura-ai[ai]</code>)","text":"<p>Core AI capabilities: Memory, Routing, Context Compression</p> <pre><code>pip install kagura-ai[ai]\n# or\nuv add \"kagura-ai[ai]\"\n</code></pre> <p>Includes: - <code>chromadb</code> - Vector storage for memory &amp; RAG - <code>semantic-router</code> - Semantic routing - <code>tiktoken</code> - Token counting for context compression</p> <p>Use cases: - Agents with long-term memory - Semantic routing between agents - Context-aware conversation management</p>"},{"location":"en/installation/#web-multimodal-kagura-aiweb","title":"Web &amp; Multimodal (<code>kagura-ai[web]</code>)","text":"<p>Web search, scraping, and multimodal (image/audio/video) processing</p> <pre><code>pip install kagura-ai[web]\n# or\nuv add \"kagura-ai[web]\"\n</code></pre> <p>Includes: - <code>google-generativeai</code> - Gemini API for multimodal - <code>pillow</code> - Image processing - <code>httpx</code> - HTTP client - <code>duckduckgo-search</code> - Web search - <code>beautifulsoup4</code> - HTML parsing</p> <p>Use cases: - Web search agents - Image/audio/video analysis - Web scraping and data extraction</p>"},{"location":"en/installation/#oauth2-authentication-kagura-aiauth","title":"OAuth2 Authentication (<code>kagura-ai[auth]</code>)","text":"<p>OAuth2 authentication with Google/Gemini (advanced feature)</p> <pre><code>pip install kagura-ai[auth]\n# or\nuv add \"kagura-ai[auth]\"\n</code></pre> <p>Includes: - <code>google-auth</code> - Google authentication library - <code>google-auth-oauthlib</code> - OAuth2 flow - <code>google-auth-httplib2</code> - HTTP library - <code>cryptography</code> - Credential encryption</p> <p>Note: OAuth2 is an advanced feature. For most users, using API Keys is recommended as it's simpler. See OAuth2 Authentication Guide for when to use OAuth2.</p>"},{"location":"en/installation/#mcp-integration-kagura-aimcp","title":"MCP Integration (<code>kagura-ai[mcp]</code>)","text":"<p>Use Kagura agents with Claude Desktop, Claude Code, and other MCP clients</p> <pre><code>pip install kagura-ai[mcp]\n# or\nuv add \"kagura-ai[mcp]\"\n</code></pre> <p>Includes: - <code>mcp</code> - Model Context Protocol SDK - <code>jsonschema</code> - JSON Schema validation</p> <p>See MCP Integration Tutorial for setup guide.</p>"},{"location":"en/installation/#combined-presets-recommended","title":"\ud83c\udf81 Combined Presets (Recommended)","text":""},{"location":"en/installation/#full-features-kagura-aifull","title":"Full Features (<code>kagura-ai[full]</code>)","text":"<p>All user-facing features in one install</p> <pre><code>pip install kagura-ai[full]\n# or\nuv add \"kagura-ai[full]\"\n</code></pre> <p>Includes: <code>ai</code> + <code>web</code> + <code>auth</code> + <code>mcp</code></p> <p>Recommended for: Most users who want to explore all Kagura AI capabilities</p>"},{"location":"en/installation/#everything-kagura-aiall","title":"Everything (<code>kagura-ai[all]</code>)","text":"<p>All features including development tools</p> <pre><code>pip install kagura-ai[all]\n# or\nuv add \"kagura-ai[all]\"\n</code></pre> <p>Includes: <code>full</code> + <code>dev</code> + <code>docs</code></p> <p>Recommended for: Contributors and advanced users</p>"},{"location":"en/installation/#development-presets","title":"\ud83d\udee0\ufe0f Development Presets","text":""},{"location":"en/installation/#development-tools-kagura-aidev","title":"Development Tools (<code>kagura-ai[dev]</code>)","text":"<p>Testing and linting tools (included with <code>uv sync --dev</code>)</p> <pre><code>pip install kagura-ai[dev]\n# or\nuv add \"kagura-ai[dev]\"\n</code></pre> <p>Includes: - <code>pytest</code> - Testing framework - <code>pytest-asyncio</code> - Async test support - <code>pytest-cov</code> - Code coverage - <code>pytest-timeout</code> - Test timeout - <code>langdetect</code> - For agent testing - <code>pyright</code> - Type checker - <code>ruff</code> - Linter and formatter</p>"},{"location":"en/installation/#documentation-tools-kagura-aidocs","title":"Documentation Tools (<code>kagura-ai[docs]</code>)","text":"<p>Build documentation locally</p> <pre><code>pip install kagura-ai[docs]\n# or\nuv add \"kagura-ai[docs]\"\n</code></pre> <p>Includes: - <code>mkdocs</code> - Documentation generator - <code>mkdocs-material</code> - Material theme - <code>pymdown-extensions</code> - Markdown extensions</p> <p>Then run: <pre><code>mkdocs serve\n</code></pre></p> <p>Visit <code>http://localhost:8000</code> to view docs.</p>"},{"location":"en/installation/#installation-size-comparison","title":"\ud83d\udcca Installation Size Comparison","text":"Preset Dependencies Approximate Size Use Case <code>base</code> 8 packages ~50 MB Basic agents only <code>ai</code> +3 packages +150 MB AI features <code>web</code> +7 packages +200 MB Web &amp; Multimodal <code>auth</code> +4 packages +20 MB OAuth2 <code>mcp</code> +2 packages +10 MB MCP integration <code>full</code> +16 packages +380 MB All features <code>all</code> +23 packages +420 MB Everything"},{"location":"en/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/installation/#import-error","title":"Import Error","text":"<p>If you get import errors:</p> <pre><code>ImportError: cannot import name 'agent' from 'kagura'\n</code></pre> <p>Make sure you're using Python 3.11+:</p> <pre><code>python --version\n</code></pre>"},{"location":"en/installation/#api-key-not-found","title":"API Key Not Found","text":"<p>If you see authentication errors:</p> <pre><code>AuthenticationError: The api_key client option must be set\n</code></pre> <p>Set your API key as described above. The key must be set before importing kagura.</p>"},{"location":"en/installation/#type-errors","title":"Type Errors","text":"<p>If pyright shows errors in your IDE:</p> <ol> <li>Make sure your Python interpreter is set to 3.11+</li> <li>Ensure kagura-ai is installed in your environment</li> <li>Restart your IDE/language server</li> </ol>"},{"location":"en/installation/#upgrading","title":"Upgrading","text":""},{"location":"en/installation/#from-pypi","title":"From PyPI","text":"<pre><code>pip install --upgrade kagura-ai\n</code></pre> <p>or with uv:</p> <pre><code>uv add kagura-ai --upgrade\n</code></pre>"},{"location":"en/installation/#from-git","title":"From Git","text":"<pre><code>cd kagura-ai\ngit pull\nuv sync --dev\n</code></pre>"},{"location":"en/installation/#uninstalling","title":"Uninstalling","text":"<pre><code>pip uninstall kagura-ai\n</code></pre> <p>or with uv:</p> <pre><code>uv remove kagura-ai\n</code></pre>"},{"location":"en/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start - Build your first agent</li> <li>API Reference - Detailed API documentation</li> <li>Examples - Example code</li> </ul>"},{"location":"en/quickstart/","title":"Quick Start","text":"<p>Get started with Kagura AI 2.0 in 5 minutes.</p>"},{"location":"en/quickstart/#installation","title":"Installation","text":"<pre><code>pip install kagura-ai\n</code></pre> <p>or with uv:</p> <pre><code>uv add kagura-ai\n</code></pre>"},{"location":"en/quickstart/#set-api-key","title":"Set API Key","text":"<p>Kagura AI uses LiteLLM, which supports multiple LLM providers. Set your API key:</p> <pre><code>export OPENAI_API_KEY=\"your-key-here\"\n</code></pre>"},{"location":"en/quickstart/#your-first-agent","title":"Your First Agent","text":"<p>Create a simple conversational agent:</p> <pre><code># chat.py\nfrom kagura import agent\n\n@agent\nasync def chat(message: str) -&gt; str:\n    '''You are a friendly AI assistant. Respond to: {{ message }}'''\n    pass\n\n# Run\nif __name__ == \"__main__\":\n    import asyncio\n\n    async def main():\n        response = await chat(\"Hello! How are you?\")\n        print(response)\n\n    asyncio.run(main())\n</code></pre> <p>Run it: <pre><code>python chat.py\n</code></pre></p> <p>Output: <pre><code>Hello! I'm doing well, thank you for asking! How can I help you today?\n</code></pre></p>"},{"location":"en/quickstart/#structured-output-with-pydantic","title":"Structured Output with Pydantic","text":"<p>Extract structured data using Pydantic models:</p> <pre><code># extract.py\nfrom kagura import agent\nfrom pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    '''Extract person information from: {{ text }}'''\n    pass\n\n# Use it\nif __name__ == \"__main__\":\n    import asyncio\n\n    async def main():\n        result = await extract_person(\n            \"Alice is 30 years old and works as a software engineer\"\n        )\n        print(f\"Name: {result.name}\")\n        print(f\"Age: {result.age}\")\n        print(f\"Occupation: {result.occupation}\")\n\n    asyncio.run(main())\n</code></pre> <p>Output: <pre><code>Name: Alice\nAge: 30\nOccupation: software engineer\n</code></pre></p>"},{"location":"en/quickstart/#multiple-parameters","title":"Multiple Parameters","text":"<p>Use multiple parameters in your templates:</p> <pre><code>from kagura import agent\n\n@agent\nasync def translator(text: str, target_lang: str = \"ja\") -&gt; str:\n    '''Translate to {{ target_lang }}: {{ text }}'''\n    pass\n\n# Use with default\nresult = await translator(\"Hello, world!\")\n# Output: \"\u3053\u3093\u306b\u3061\u306f\u3001\u4e16\u754c\uff01\"\n\n# Use with custom language\nresult = await translator(\"Hello, world!\", target_lang=\"fr\")\n# Output: \"Bonjour, le monde!\"\n</code></pre>"},{"location":"en/quickstart/#code-execution","title":"Code Execution","text":"<p>Generate and execute Python code:</p> <pre><code>from kagura.agents import execute_code\n\nresult = await execute_code(\"Calculate the factorial of 10\")\n\nif result[\"success\"]:\n    print(f\"Code:\\n{result['code']}\\n\")\n    print(f\"Result: {result['result']}\")\nelse:\n    print(f\"Error: {result['error']}\")\n</code></pre> <p>Output: <pre><code>Code:\nimport math\nresult = math.factorial(10)\n\nResult: 3628800\n</code></pre></p>"},{"location":"en/quickstart/#interactive-repl","title":"Interactive REPL","text":"<p>Try the interactive REPL for rapid prototyping:</p> <pre><code>kagura repl\n</code></pre> <p>Available commands: - <code>/help</code> - Show available commands - <code>/agents</code> - List defined agents - <code>/exit</code> - Exit REPL - <code>/clear</code> - Clear screen</p> <p>Example REPL session:</p> <pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Kagura AI REPL                       \u2502\n\u2502 Python-First AI Agent Framework      \u2502\n\u2502                                      \u2502\n\u2502 Type /help for commands, /exit to    \u2502\n\u2502 quit                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n&gt;&gt;&gt; @agent\n... async def hello(name: str) -&gt; str:\n...     '''Say hello to {{ name }}'''\n...     pass\n...\n\n&gt;&gt;&gt; await hello(\"World\")\nHello, World!\n\n&gt;&gt;&gt; /exit\nGoodbye!\n</code></pre>"},{"location":"en/quickstart/#list-operations","title":"List Operations","text":"<p>Return lists from agents:</p> <pre><code>@agent\nasync def extract_keywords(text: str) -&gt; list[str]:\n    '''Extract keywords from: {{ text }}'''\n    pass\n\nkeywords = await extract_keywords(\n    \"Python is a programming language used for AI and web development\"\n)\nprint(keywords)\n# ['Python', 'programming language', 'AI', 'web development']\n</code></pre>"},{"location":"en/quickstart/#complex-data-structures","title":"Complex Data Structures","text":"<p>Work with nested Pydantic models:</p> <pre><code>from pydantic import BaseModel\nfrom typing import List\n\nclass Task(BaseModel):\n    title: str\n    priority: int\n    completed: bool\n\nclass Project(BaseModel):\n    name: str\n    tasks: List[Task]\n\n@agent\nasync def plan_project(goal: str) -&gt; Project:\n    '''Create a project plan for: {{ goal }}'''\n    pass\n\nproject = await plan_project(\"Build a web application\")\nprint(f\"Project: {project.name}\")\nfor task in project.tasks:\n    status = \"\u2713\" if task.completed else \"\u25cb\"\n    print(f\"{status} [{task.priority}] {task.title}\")\n</code></pre>"},{"location":"en/quickstart/#use-in-claude-desktop","title":"Use in Claude Desktop","text":"<p>Integrate your Kagura agents with Claude Desktop!</p>"},{"location":"en/quickstart/#1-install-mcp-support","title":"1. Install MCP Support","text":"<pre><code>pip install kagura-ai[mcp]\n</code></pre>"},{"location":"en/quickstart/#2-create-an-agent","title":"2. Create an Agent","text":"<pre><code># my_agents.py\nfrom kagura import agent\n\n@agent\nasync def analyze_code(code: str) -&gt; str:\n    \"\"\"Analyze code quality and suggest improvements\"\"\"\n    pass\n</code></pre>"},{"location":"en/quickstart/#3-configure-claude-desktop","title":"3. Configure Claude Desktop","text":"<p>Add to Claude Desktop config file:</p> <p>macOS: <code>~/Library/Application Support/Claude/claude_desktop_config.json</code></p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"en/quickstart/#4-use-in-claude-desktop","title":"4. Use in Claude Desktop","text":"<p>Restart Claude Desktop, and your agents are available as tools!</p> <pre><code>You: Can you analyze this Python code?\n\ndef calc(x):\n    return x * 2 + 3\n\nClaude: [Uses kagura_analyze_code tool]\n</code></pre> <p>See MCP Integration Tutorial for details.</p>"},{"location":"en/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>MCP Integration - Use agents in Claude Desktop</li> <li>API Reference - Detailed API documentation</li> <li>Examples - More examples and patterns</li> <li>Code Executor - Deep dive into code execution</li> <li>REPL Guide - Advanced REPL usage</li> </ul>"},{"location":"en/api/","title":"API Reference","text":"<p>Complete API documentation for Kagura AI 2.0.</p>"},{"location":"en/api/#core-components","title":"Core Components","text":""},{"location":"en/api/#agent-decorator","title":"@agent Decorator","text":"<p>Convert async functions into AI agents with automatic LLM integration.</p> <pre><code>from kagura import agent\n\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n</code></pre> <p>Key Features: - One-line agent creation - Type-based response parsing - Jinja2 template support - Multi-LLM support via LiteLLM</p> <p>Read more \u2192</p>"},{"location":"en/api/#code-executor","title":"Code Executor","text":"<p>Safe Python code generation and execution.</p> <pre><code>from kagura.agents import execute_code\n\nresult = await execute_code(\"Calculate factorial of 10\")\nprint(result[\"result\"])  # 3628800\n</code></pre> <p>Key Features: - Natural language \u2192 Python code - AST-based security validation - Resource limits (timeout, memory) - Safe module whitelist</p> <p>Read more \u2192</p>"},{"location":"en/api/#cli-commands","title":"CLI Commands","text":"<p>Command-line interface for Kagura AI.</p> <pre><code># Start interactive REPL\nkagura repl\n\n# Check version\nkagura version\n</code></pre> <p>Key Features: - Interactive REPL for rapid prototyping - Multi-line input support - Syntax highlighting - Command history</p> <p>Read more \u2192</p>"},{"location":"en/api/#quick-links","title":"Quick Links","text":"<ul> <li>Getting Started - Build your first agent</li> <li>Tutorials - Step-by-step guides</li> <li>Examples - Code examples</li> <li>FAQ - Frequently asked questions</li> </ul>"},{"location":"en/api/#api-overview","title":"API Overview","text":""},{"location":"en/api/#core-functions","title":"Core Functions","text":"Function Description <code>@agent</code> Convert function to AI agent <code>execute_code()</code> Generate and execute Python code"},{"location":"en/api/#configuration","title":"Configuration","text":"<p>Agents can be configured with: - <code>model</code>: LLM model to use - <code>temperature</code>: Sampling temperature - <code>max_tokens</code>: Maximum response tokens</p> <p>Example:</p> <pre><code>@agent(model=\"gpt-4o\", temperature=0.5)\nasync def my_agent(query: str) -&gt; str:\n    '''Answer: {{ query }}'''\n    pass\n</code></pre>"},{"location":"en/api/#type-support","title":"Type Support","text":"<p>Supported return types:</p> Type Example Description <code>str</code> <code>-&gt; str</code> Plain text response <code>int</code> <code>-&gt; int</code> Integer value <code>float</code> <code>-&gt; float</code> Floating point number <code>bool</code> <code>-&gt; bool</code> Boolean value <code>list[T]</code> <code>-&gt; list[str]</code> List of items <code>dict</code> <code>-&gt; dict</code> Dictionary <code>BaseModel</code> <code>-&gt; Person</code> Pydantic model <code>Optional[T]</code> <code>-&gt; Optional[str]</code> Optional value"},{"location":"en/api/#template-syntax","title":"Template Syntax","text":"<p>Agent docstrings use Jinja2 syntax:</p> <pre><code>@agent\nasync def greet(name: str, time: str = \"morning\") -&gt; str:\n    '''\n    Good {{ time }}, {{ name }}!\n    {% if time == \"evening\" %}\n    Hope you had a great day.\n    {% endif %}\n    '''\n    pass\n</code></pre> <p>Supported Jinja2 features: - Variable interpolation: <code>{{ variable }}</code> - Conditionals: <code>{% if condition %}</code> - Loops: <code>{% for item in items %}</code> - Filters: <code>{{ text|upper }}</code></p>"},{"location":"en/api/#error-handling","title":"Error Handling","text":"<p>All agents can raise these exceptions:</p> <pre><code>from litellm import APIError\nfrom pydantic import ValidationError\n\ntry:\n    result = await my_agent(\"input\")\nexcept APIError as e:\n    # LLM API error (auth, rate limit, etc.)\n    print(f\"API error: {e}\")\nexcept ValidationError as e:\n    # Pydantic parsing error\n    print(f\"Validation error: {e}\")\nexcept Exception as e:\n    # Other errors\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"en/api/#environment-variables","title":"Environment Variables","text":"<p>Kagura AI respects these environment variables:</p> Variable Description <code>OPENAI_API_KEY</code> OpenAI API key <code>ANTHROPIC_API_KEY</code> Anthropic (Claude) API key <code>GOOGLE_API_KEY</code> Google (Gemini) API key <code>AZURE_API_KEY</code> Azure OpenAI API key <p>Set them before running your agents:</p> <pre><code>export OPENAI_API_KEY=\"your-key-here\"\npython my_agent.py\n</code></pre>"},{"location":"en/api/#best-practices","title":"Best Practices","text":""},{"location":"en/api/#1-use-type-hints","title":"1. Use Type Hints","text":"<p>Always specify return types for automatic parsing:</p> <pre><code># Good\n@agent\nasync def extract_keywords(text: str) -&gt; list[str]:\n    '''Extract keywords from: {{ text }}'''\n    pass\n\n# Less good\n@agent\nasync def extract_keywords(text: str):  # No return type\n    '''Extract keywords from: {{ text }}'''\n    pass\n</code></pre>"},{"location":"en/api/#2-clear-instructions","title":"2. Clear Instructions","text":"<p>Write explicit docstrings:</p> <pre><code># Good\n@agent\nasync def summarize(text: str, max_words: int) -&gt; str:\n    '''Summarize the following text in {{ max_words }} words or less.\n\n    Text: {{ text }}\n    '''\n    pass\n\n# Less clear\n@agent\nasync def summarize(text: str, max_words: int) -&gt; str:\n    '''Summarize {{ text }} in {{ max_words }} words'''\n    pass\n</code></pre>"},{"location":"en/api/#3-pydantic-models","title":"3. Pydantic Models","text":"<p>Use Pydantic for structured data:</p> <pre><code>from pydantic import BaseModel, Field\n\nclass Person(BaseModel):\n    name: str = Field(description=\"Full name\")\n    age: int = Field(ge=0, le=150, description=\"Age in years\")\n    email: str = Field(pattern=r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\")\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    '''Extract person information from: {{ text }}'''\n    pass\n</code></pre>"},{"location":"en/api/#4-error-handling","title":"4. Error Handling","text":"<p>Always handle errors in production:</p> <pre><code>async def safe_agent_call():\n    try:\n        result = await my_agent(\"input\")\n        return {\"success\": True, \"data\": result}\n    except Exception as e:\n        logger.error(f\"Agent failed: {e}\")\n        return {\"success\": False, \"error\": str(e)}\n</code></pre>"},{"location":"en/api/#version-information","title":"Version Information","text":"<p>Check Kagura AI version:</p> <pre><code>import kagura\nprint(kagura.__version__)  # \"2.5.0\"\n</code></pre> <p>Or via CLI:</p> <pre><code>kagura version\n</code></pre>"},{"location":"en/api/#support","title":"Support","text":"<ul> <li>GitHub Issues</li> <li>Discussion Forum</li> <li>Documentation</li> </ul>"},{"location":"en/api/#related","title":"Related","text":"<ul> <li>Quick Start Guide</li> <li>Tutorials</li> <li>Examples</li> <li>FAQ</li> </ul>"},{"location":"en/api/agent/","title":"@agent Decorator","text":"<p>The <code>@agent</code> decorator is the core of Kagura AI 2.0, converting any async function into an AI agent with automatic LLM integration.</p>"},{"location":"en/api/agent/#overview","title":"Overview","text":"<p>The decorator: 1. Extracts function signature and parameters 2. Uses the docstring as a Jinja2 template 3. Calls the LLM with the rendered prompt 4. Parses the response based on return type hints 5. Returns a properly typed result</p>"},{"location":"en/api/agent/#signature","title":"Signature","text":"<pre><code>def agent(\n    fn: Callable = None,\n    *,\n    model: str = \"gpt-4o-mini\",\n    temperature: float = 0.7,\n    max_tokens: int | None = None,\n    **kwargs\n) -&gt; Callable\n</code></pre>"},{"location":"en/api/agent/#parameters","title":"Parameters","text":""},{"location":"en/api/agent/#required-parameters","title":"Required Parameters","text":"<ul> <li>fn (<code>Callable</code>): The async function to convert into an agent. When using <code>@agent</code> without parentheses, this is automatically passed.</li> </ul>"},{"location":"en/api/agent/#optional-parameters","title":"Optional Parameters","text":"<ul> <li>model (<code>str</code>, default: <code>\"gpt-4o-mini\"</code>): The LLM model to use. Supports any model from LiteLLM:</li> <li>OpenAI: <code>\"gpt-4o\"</code>, <code>\"gpt-4o-mini\"</code>, <code>\"gpt-3.5-turbo\"</code></li> <li>Anthropic: <code>\"claude-3-5-sonnet-20241022\"</code>, <code>\"claude-3-haiku-20240307\"</code></li> <li>Google: <code>\"gemini/gemini-pro\"</code>, <code>\"gemini/gemini-1.5-flash\"</code></li> <li> <p>Ollama: <code>\"ollama/llama3.2\"</code>, <code>\"ollama/gemma2\"</code></p> </li> <li> <p>temperature (<code>float</code>, default: <code>0.7</code>): Sampling temperature (0.0 to 2.0). Lower values make output more focused and deterministic.</p> </li> <li> <p>max_tokens (<code>int | None</code>, default: <code>None</code>): Maximum tokens in the response. If not specified, uses the model's default.</p> </li> <li> <p>kwargs: Additional parameters passed to LiteLLM's <code>completion()</code> function.</p> </li> </ul>"},{"location":"en/api/agent/#return-value","title":"Return Value","text":"<p>Returns a wrapped async function with the same signature as the original, but with AI-powered behavior.</p>"},{"location":"en/api/agent/#usage","title":"Usage","text":""},{"location":"en/api/agent/#basic-usage","title":"Basic Usage","text":"<pre><code>from kagura import agent\n\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\nresult = await hello(\"World\")\nprint(result)  # \"Hello, World! How can I help you today?\"\n</code></pre>"},{"location":"en/api/agent/#with-custom-model","title":"With Custom Model","text":"<pre><code>@agent(model=\"gpt-4o\")\nasync def analyze(text: str) -&gt; str:\n    '''Analyze the sentiment of: {{ text }}'''\n    pass\n\nresult = await analyze(\"I love this product!\")\nprint(result)  # \"Positive sentiment...\"\n</code></pre>"},{"location":"en/api/agent/#with-temperature-control","title":"With Temperature Control","text":"<pre><code># More deterministic (lower temperature)\n@agent(temperature=0.2)\nasync def translate(text: str, lang: str) -&gt; str:\n    '''Translate to {{ lang }}: {{ text }}'''\n    pass\n\n# More creative (higher temperature)\n@agent(temperature=1.5)\nasync def creative_story(topic: str) -&gt; str:\n    '''Write a creative story about: {{ topic }}'''\n    pass\n</code></pre>"},{"location":"en/api/agent/#with-pydantic-models","title":"With Pydantic Models","text":"<pre><code>from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    '''Extract person information from: {{ text }}'''\n    pass\n\nperson = await extract_person(\"Alice is 30 years old and works as a software engineer\")\nprint(f\"{person.name}, {person.age}, {person.occupation}\")\n# Output: Alice, 30, software engineer\n</code></pre>"},{"location":"en/api/agent/#with-list-return-types","title":"With List Return Types","text":"<pre><code>@agent\nasync def extract_keywords(text: str) -&gt; list[str]:\n    '''Extract keywords from: {{ text }}'''\n    pass\n\nkeywords = await extract_keywords(\"Python is a programming language for AI\")\nprint(keywords)\n# Output: ['Python', 'programming language', 'AI']\n</code></pre>"},{"location":"en/api/agent/#multiple-parameters","title":"Multiple Parameters","text":"<pre><code>@agent\nasync def summarize(text: str, max_words: int = 50) -&gt; str:\n    '''Summarize in {{ max_words }} words or less: {{ text }}'''\n    pass\n\nsummary = await summarize(\"Long text here...\", max_words=30)\n</code></pre>"},{"location":"en/api/agent/#docstring-templates","title":"Docstring Templates","text":"<p>The docstring is treated as a Jinja2 template. All function parameters are available as template variables.</p>"},{"location":"en/api/agent/#simple-variable-interpolation","title":"Simple Variable Interpolation","text":"<pre><code>@agent\nasync def greet(name: str, greeting: str = \"Hello\") -&gt; str:\n    '''{{ greeting }}, {{ name }}! How are you?'''\n    pass\n</code></pre>"},{"location":"en/api/agent/#conditional-logic","title":"Conditional Logic","text":"<pre><code>@agent\nasync def format_response(query: str, formal: bool = False) -&gt; str:\n    '''\n    {% if formal %}\n    Respond formally to: {{ query }}\n    {% else %}\n    Respond casually to: {{ query }}\n    {% endif %}\n    '''\n    pass\n</code></pre>"},{"location":"en/api/agent/#loops","title":"Loops","text":"<pre><code>@agent\nasync def process_items(items: list[str]) -&gt; str:\n    '''\n    Process the following items:\n    {% for item in items %}\n    - {{ item }}\n    {% endfor %}\n    '''\n    pass\n</code></pre>"},{"location":"en/api/agent/#type-based-response-parsing","title":"Type-Based Response Parsing","text":"<p>The decorator automatically parses LLM responses based on the return type annotation:</p> Return Type Parsing Behavior <code>str</code> Returns raw response <code>int</code> Parses as integer <code>float</code> Parses as float <code>bool</code> Parses as boolean <code>list[T]</code> Parses as list of type T <code>dict[K, V]</code> Parses as dictionary <code>Pydantic Model</code> Validates and returns model instance <code>Optional[T]</code> Allows None values"},{"location":"en/api/agent/#error-handling","title":"Error Handling","text":""},{"location":"en/api/agent/#llm-api-errors","title":"LLM API Errors","text":"<pre><code>from litellm import APIError\n\n@agent\nasync def my_agent(query: str) -&gt; str:\n    '''Process: {{ query }}'''\n    pass\n\ntry:\n    result = await my_agent(\"test\")\nexcept APIError as e:\n    print(f\"LLM API error: {e}\")\n</code></pre>"},{"location":"en/api/agent/#parsing-errors","title":"Parsing Errors","text":"<pre><code>from pydantic import ValidationError\n\n@agent\nasync def extract_data(text: str) -&gt; Person:\n    '''Extract person from: {{ text }}'''\n    pass\n\ntry:\n    result = await extract_data(\"invalid text\")\nexcept ValidationError as e:\n    print(f\"Failed to parse response: {e}\")\n</code></pre>"},{"location":"en/api/agent/#advanced-features","title":"Advanced Features","text":""},{"location":"en/api/agent/#accessing-agent-metadata","title":"Accessing Agent Metadata","text":"<pre><code>@agent(model=\"gpt-4o\", temperature=0.5)\nasync def my_agent(query: str) -&gt; str:\n    '''Answer: {{ query }}'''\n    pass\n\n# Check if function is an agent\nprint(hasattr(my_agent, '_is_agent'))  # True\n\n# Access configuration\nprint(my_agent._model)  # \"gpt-4o\"\n</code></pre>"},{"location":"en/api/agent/#agent-composition","title":"Agent Composition","text":"<p>Agents can call other agents:</p> <pre><code>@agent\nasync def extract_topic(text: str) -&gt; str:\n    '''Extract the main topic from: {{ text }}'''\n    pass\n\n@agent\nasync def elaborate(topic: str) -&gt; str:\n    '''Elaborate on: {{ topic }}'''\n    pass\n\n# Compose agents\ntext = \"Quantum computing is revolutionary\"\ntopic = await extract_topic(text)\nelaboration = await elaborate(topic)\n</code></pre>"},{"location":"en/api/agent/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Clear Docstrings: Write explicit instructions in the docstring    <pre><code># Good\n'''Extract the person's name, age, and occupation from: {{ text }}'''\n\n# Less clear\n'''Process {{ text }}'''\n</code></pre></p> </li> <li> <p>Appropriate Return Types: Use the most specific type possible    <pre><code># Good\nasync def extract_person(text: str) -&gt; Person:\n\n# Less good\nasync def extract_person(text: str) -&gt; dict:\n</code></pre></p> </li> <li> <p>Temperature Selection:</p> </li> <li>Use low temperature (0.0-0.3) for factual, deterministic tasks</li> <li>Use medium temperature (0.7-1.0) for balanced responses</li> <li> <p>Use high temperature (1.0-2.0) for creative tasks</p> </li> <li> <p>Model Selection:</p> </li> <li>Use <code>gpt-4o-mini</code> for simple tasks (faster, cheaper)</li> <li>Use <code>gpt-4o</code> or <code>claude-3-5-sonnet</code> for complex reasoning</li> <li>Use <code>claude-3-haiku</code> for fast, cost-effective responses</li> </ol>"},{"location":"en/api/agent/#related","title":"Related","text":"<ul> <li>Template Engine - Jinja2 templating details</li> <li>Type Parser - Response parsing details</li> <li>Quick Start - Getting started guide</li> </ul>"},{"location":"en/api/auth/","title":"Authentication API Reference","text":"<p>API reference for Kagura AI's OAuth2 authentication system.</p> <p>\ud83d\udccc Important Note</p> <p>OAuth2 is an advanced feature for Google/Gemini only.</p> <p>For most use cases, API Keys are recommended: - Simpler setup (no Google Cloud Console required) - Works with all LLMs (OpenAI, Claude, Gemini) - Faster to get started</p> <p>OAuth2 is designed for: - Multi-user applications - Production environments with strict access controls - Per-user quota management</p> <p>See OAuth2 Authentication Guide for when to use each method.</p>"},{"location":"en/api/auth/#oauth2manager","title":"OAuth2Manager","text":"<p>Main class for managing OAuth2 authentication with Google services.</p>"},{"location":"en/api/auth/#class-definition","title":"Class Definition","text":"<pre><code>from kagura.auth import OAuth2Manager\n\nclass OAuth2Manager:\n    \"\"\"OAuth2 authentication manager for Google services\n\n    Handles OAuth2 authentication flow, token management, and secure credential storage.\n\n    Args:\n        provider: OAuth2 provider name (default: \"google\")\n        config: Optional AuthConfig instance\n\n    Example:\n        &gt;&gt;&gt; auth = OAuth2Manager(provider=\"google\")\n        &gt;&gt;&gt; auth.login()  # Opens browser for authentication\n        &gt;&gt;&gt; creds = auth.get_credentials()  # Returns valid credentials\n        &gt;&gt;&gt; token = auth.get_token()  # Returns access token\n\n    Security:\n        - Credentials are encrypted using Fernet (AES-128)\n        - Encryption key stored separately with 0o600 permissions\n        - Credentials file has 0o600 permissions\n        - Automatic token refresh when expired\n    \"\"\"\n</code></pre>"},{"location":"en/api/auth/#methods","title":"Methods","text":""},{"location":"en/api/auth/#__init__providergoogle-confignone","title":"<code>__init__(provider=\"google\", config=None)</code>","text":"<p>Initialize OAuth2 manager.</p> <p>Parameters: - <code>provider</code> (str): OAuth2 provider name (default: \"google\") - <code>config</code> (AuthConfig | None): Optional authentication configuration</p> <p>Example: <pre><code>auth = OAuth2Manager(provider=\"google\")\n</code></pre></p>"},{"location":"en/api/auth/#login","title":"<code>login()</code>","text":"<p>Launch browser for OAuth2 authentication.</p> <p>Raises: - <code>FileNotFoundError</code>: If client_secrets.json not found - <code>InvalidCredentialsError</code>: If authentication fails</p> <p>Example: <pre><code>auth = OAuth2Manager()\nauth.login()  # Opens browser, saves credentials\n</code></pre></p>"},{"location":"en/api/auth/#logout","title":"<code>logout()</code>","text":"<p>Remove stored credentials.</p> <p>Raises: - <code>NotAuthenticatedError</code>: If not authenticated</p> <p>Example: <pre><code>auth = OAuth2Manager()\nauth.logout()  # Removes ~/.kagura/credentials.json.enc\n</code></pre></p>"},{"location":"en/api/auth/#is_authenticated-bool","title":"<code>is_authenticated() -&gt; bool</code>","text":"<p>Check if user is authenticated.</p> <p>Returns: - <code>bool</code>: True if valid credentials exist</p> <p>Example: <pre><code>auth = OAuth2Manager()\nif auth.is_authenticated():\n    print(\"Already logged in\")\nelse:\n    auth.login()\n</code></pre></p>"},{"location":"en/api/auth/#get_credentials-credentials","title":"<code>get_credentials() -&gt; Credentials</code>","text":"<p>Get valid credentials with automatic refresh.</p> <p>Returns: - <code>google.oauth2.credentials.Credentials</code>: Valid Google OAuth2 credentials</p> <p>Raises: - <code>NotAuthenticatedError</code>: If not authenticated - <code>TokenRefreshError</code>: If token refresh fails</p> <p>Example: <pre><code>auth = OAuth2Manager()\ncreds = auth.get_credentials()\nprint(creds.token)  # Access token\n</code></pre></p>"},{"location":"en/api/auth/#get_token-str","title":"<code>get_token() -&gt; str</code>","text":"<p>Get access token for API calls.</p> <p>Returns: - <code>str</code>: Access token string</p> <p>Raises: - <code>NotAuthenticatedError</code>: If not authenticated - <code>TokenRefreshError</code>: If token refresh fails</p> <p>Example: <pre><code>auth = OAuth2Manager()\ntoken = auth.get_token()\n# Use token in API calls\n</code></pre></p>"},{"location":"en/api/auth/#attributes","title":"Attributes","text":""},{"location":"en/api/auth/#scopes","title":"<code>SCOPES</code>","text":"<p>Default OAuth2 scopes for each provider.</p> <pre><code>SCOPES = {\n    \"google\": [\n        \"https://www.googleapis.com/auth/generative-language\",\n        \"openid\",\n    ]\n}\n</code></pre>"},{"location":"en/api/auth/#authconfig","title":"AuthConfig","text":"<p>Configuration for OAuth2 authentication.</p>"},{"location":"en/api/auth/#class-definition_1","title":"Class Definition","text":"<pre><code>from kagura.auth import AuthConfig\nfrom pathlib import Path\n\nclass AuthConfig(BaseModel):\n    \"\"\"OAuth2 authentication configuration\n\n    Configuration for OAuth2 authentication manager.\n\n    Args:\n        provider: OAuth2 provider name (e.g., \"google\")\n        scopes: Optional list of OAuth2 scopes\n        client_secrets_path: Optional path to client_secrets.json\n\n    Example:\n        &gt;&gt;&gt; config = AuthConfig(\n        ...     provider=\"google\",\n        ...     client_secrets_path=Path(\"/custom/path/client_secrets.json\")\n        ... )\n        &gt;&gt;&gt; auth = OAuth2Manager(config=config)\n    \"\"\"\n</code></pre>"},{"location":"en/api/auth/#fields","title":"Fields","text":""},{"location":"en/api/auth/#provider-str-google","title":"<code>provider: str = \"google\"</code>","text":"<p>OAuth2 provider name.</p> <p>Default: <code>\"google\"</code></p> <p>Example: <pre><code>config = AuthConfig(provider=\"google\")\n</code></pre></p>"},{"location":"en/api/auth/#scopes-liststr-none-none","title":"<code>scopes: list[str] | None = None</code>","text":"<p>Custom OAuth2 scopes. If None, uses default scopes from <code>OAuth2Manager.SCOPES</code>.</p> <p>Default: <code>None</code></p> <p>Example: <pre><code>config = AuthConfig(\n    provider=\"google\",\n    scopes=[\n        \"https://www.googleapis.com/auth/generative-language\",\n        \"openid\",\n        \"https://www.googleapis.com/auth/userinfo.email\"\n    ]\n)\n</code></pre></p>"},{"location":"en/api/auth/#client_secrets_path-path-none-none","title":"<code>client_secrets_path: Path | None = None</code>","text":"<p>Custom path to <code>client_secrets.json</code>. If None, uses <code>~/.kagura/client_secrets.json</code>.</p> <p>Default: <code>None</code></p> <p>Example: <pre><code>from pathlib import Path\n\nconfig = AuthConfig(\n    provider=\"google\",\n    client_secrets_path=Path(\"/custom/path/client_secrets.json\")\n)\n</code></pre></p>"},{"location":"en/api/auth/#exceptions","title":"Exceptions","text":""},{"location":"en/api/auth/#authenticationerror","title":"AuthenticationError","text":"<p>Base exception for authentication errors.</p> <pre><code>from kagura.auth.exceptions import AuthenticationError\n\nclass AuthenticationError(Exception):\n    \"\"\"Base exception for authentication errors\"\"\"\n</code></pre> <p>Example: <pre><code>try:\n    auth.login()\nexcept AuthenticationError as e:\n    print(f\"Authentication failed: {e}\")\n</code></pre></p>"},{"location":"en/api/auth/#notauthenticatederror","title":"NotAuthenticatedError","text":"<p>Raised when user is not authenticated.</p> <pre><code>from kagura.auth.exceptions import NotAuthenticatedError\n\nclass NotAuthenticatedError(AuthenticationError):\n    \"\"\"Raised when user is not authenticated with OAuth2 provider\"\"\"\n</code></pre> <p>Message Format: <pre><code>Not authenticated with {provider}. Please run: kagura auth login --provider {provider}\n</code></pre></p> <p>Example: <pre><code>try:\n    token = auth.get_token()\nexcept NotAuthenticatedError as e:\n    print(f\"Please login first: {e}\")\n    auth.login()\n</code></pre></p>"},{"location":"en/api/auth/#invalidcredentialserror","title":"InvalidCredentialsError","text":"<p>Raised when credentials are invalid or corrupted.</p> <pre><code>from kagura.auth.exceptions import InvalidCredentialsError\n\nclass InvalidCredentialsError(AuthenticationError):\n    \"\"\"Raised when credentials are invalid or fail validation\"\"\"\n</code></pre> <p>Example: <pre><code>try:\n    creds = auth.get_credentials()\nexcept InvalidCredentialsError as e:\n    print(f\"Credentials invalid: {e}\")\n    auth.logout()  # Remove corrupted credentials\n    auth.login()   # Re-authenticate\n</code></pre></p>"},{"location":"en/api/auth/#tokenrefresherror","title":"TokenRefreshError","text":"<p>Raised when token refresh fails.</p> <pre><code>from kagura.auth.exceptions import TokenRefreshError\n\nclass TokenRefreshError(AuthenticationError):\n    \"\"\"Raised when OAuth2 token refresh fails\"\"\"\n</code></pre> <p>Example: <pre><code>try:\n    creds = auth.get_credentials()\nexcept TokenRefreshError as e:\n    print(f\"Token refresh failed: {e}\")\n    auth.logout()\n    auth.login()\n</code></pre></p>"},{"location":"en/api/auth/#llmconfig-oauth2-integration","title":"LLMConfig OAuth2 Integration","text":"<p>OAuth2 authentication is integrated into <code>LLMConfig</code> for seamless use with LLM calls.</p>"},{"location":"en/api/auth/#oauth2-fields","title":"OAuth2 Fields","text":""},{"location":"en/api/auth/#auth_type-literalapi_key-oauth2-api_key","title":"<code>auth_type: Literal[\"api_key\", \"oauth2\"] = \"api_key\"</code>","text":"<p>Authentication type for LLM calls.</p> <p>Options: - <code>\"api_key\"</code>: Use environment variables (default) - <code>\"oauth2\"</code>: Use OAuth2 token from OAuth2Manager</p> <p>Example: <pre><code>from kagura.core.llm import LLMConfig\n\n# OAuth2 authentication\nconfig = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\"\n)\n\n# API key authentication (default)\nconfig = LLMConfig(\n    model=\"gpt-4o-mini\",\n    auth_type=\"api_key\"  # Uses OPENAI_API_KEY env var\n)\n</code></pre></p>"},{"location":"en/api/auth/#oauth_provider-str-none-none","title":"<code>oauth_provider: str | None = None</code>","text":"<p>OAuth2 provider name when <code>auth_type=\"oauth2\"</code>.</p> <p>Required when: <code>auth_type=\"oauth2\"</code></p> <p>Example: <pre><code>config = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\"  # Required for OAuth2\n)\n</code></pre></p>"},{"location":"en/api/auth/#methods_1","title":"Methods","text":""},{"location":"en/api/auth/#get_api_key-str-none","title":"<code>get_api_key() -&gt; str | None</code>","text":"<p>Get API key or OAuth2 token based on <code>auth_type</code>.</p> <p>Returns: - <code>str | None</code>: API key or OAuth2 access token</p> <p>Raises: - <code>ValueError</code>: If OAuth2 is requested but auth module not installed - <code>NotAuthenticatedError</code>: If OAuth2 auth required but not logged in</p> <p>Example: <pre><code>config = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\"\n)\n\n# Get OAuth2 token automatically\ntoken = config.get_api_key()  # Returns OAuth2 access token\n</code></pre></p>"},{"location":"en/api/auth/#cli-commands","title":"CLI Commands","text":""},{"location":"en/api/auth/#kagura-auth-login","title":"kagura auth login","text":"<p>Authenticate with OAuth2 provider.</p> <p>Usage: <pre><code>kagura auth login [OPTIONS]\n</code></pre></p> <p>Options: - <code>--provider TEXT</code>: OAuth2 provider name (default: <code>google</code>)</p> <p>Example: <pre><code>kagura auth login --provider google\n</code></pre></p> <p>Output: <pre><code>\u2713 Authentication successful!\n\u2713 Credentials saved to: /home/user/.kagura/credentials.json.enc\n</code></pre></p>"},{"location":"en/api/auth/#kagura-auth-logout","title":"kagura auth logout","text":"<p>Remove stored OAuth2 credentials.</p> <p>Usage: <pre><code>kagura auth logout [OPTIONS]\n</code></pre></p> <p>Options: - <code>--provider TEXT</code>: OAuth2 provider name (default: <code>google</code>)</p> <p>Example: <pre><code>kagura auth logout --provider google\n</code></pre></p> <p>Output: <pre><code>\u2713 Logged out from google\n</code></pre></p>"},{"location":"en/api/auth/#kagura-auth-status","title":"kagura auth status","text":"<p>Check OAuth2 authentication status.</p> <p>Usage: <pre><code>kagura auth status [OPTIONS]\n</code></pre></p> <p>Options: - <code>--provider TEXT</code>: OAuth2 provider name (default: <code>google</code>)</p> <p>Example: <pre><code>kagura auth status --provider google\n</code></pre></p> <p>Output (authenticated): <pre><code>\u2713 Authenticated with google\nToken expires: 2025-10-13 15:30:00 UTC\n</code></pre></p> <p>Output (not authenticated): <pre><code>\u2717 Not authenticated with google\nRun: kagura auth login --provider google\n</code></pre></p>"},{"location":"en/api/auth/#complete-example","title":"Complete Example","text":"<p>Here's a complete example using OAuth2 authentication:</p> <pre><code>from kagura import agent\nfrom kagura.core.llm import LLMConfig\nfrom kagura.auth import OAuth2Manager\nfrom kagura.auth.exceptions import NotAuthenticatedError\n\n# Check if authenticated\nauth = OAuth2Manager(provider=\"google\")\nif not auth.is_authenticated():\n    print(\"Not authenticated. Please run: kagura auth login --provider google\")\n    exit(1)\n\n# Create OAuth2 LLM config\ngemini_config = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\",\n    temperature=0.7,\n    max_tokens=1000\n)\n\n# Define agent with OAuth2\n@agent(\n    name=\"gemini_assistant\",\n    template=\"Answer the question: {{ question }}\",\n    llm_config=gemini_config\n)\ndef ask_gemini(question: str) -&gt; str:\n    pass\n\n# Use the agent\ntry:\n    response = ask_gemini(\"What is the capital of France?\")\n    print(response)  # \"The capital of France is Paris.\"\nexcept NotAuthenticatedError:\n    print(\"Please authenticate: kagura auth login --provider google\")\n</code></pre>"},{"location":"en/api/auth/#see-also","title":"See Also","text":"<ul> <li>OAuth2 Authentication Guide</li> <li>LLM API Reference</li> <li>Installation Guide</li> </ul>"},{"location":"en/api/builder/","title":"AgentBuilder API","text":"<p>Fluent API for building agents with integrated features like memory, tools, and hooks.</p>"},{"location":"en/api/builder/#overview","title":"Overview","text":"<p><code>AgentBuilder</code> provides a declarative, method-chaining interface for creating complex agents. Instead of manually wiring together components, you specify what features you want, and the builder handles the integration.</p> <p>Key Features: - Fluent API with method chaining - Memory configuration (working, persistent, RAG) - Tool integration - Pre/post execution hooks - LLM parameter configuration - Agent routing</p>"},{"location":"en/api/builder/#class-agentbuilder","title":"Class: AgentBuilder","text":"<pre><code>from kagura import AgentBuilder\n\nbuilder = AgentBuilder(name=\"my_agent\")\n</code></pre>"},{"location":"en/api/builder/#constructor","title":"Constructor","text":"<pre><code>def __init__(self, name: str) -&gt; None\n</code></pre> <p>Parameters: - name (<code>str</code>, required): Agent name used for identification and logging</p> <p>Returns: <code>AgentBuilder</code> instance</p> <p>Example: <pre><code>builder = AgentBuilder(\"customer_support_bot\")\n</code></pre></p>"},{"location":"en/api/builder/#methods","title":"Methods","text":""},{"location":"en/api/builder/#with_model","title":"with_model()","text":"<p>Set the LLM model to use.</p> <pre><code>def with_model(self, model: str) -&gt; AgentBuilder\n</code></pre> <p>Parameters: - model (<code>str</code>): Model identifier (e.g., <code>\"gpt-4o-mini\"</code>, <code>\"claude-3-5-sonnet-20241022\"</code>)</p> <p>Returns: Self for method chaining</p> <p>Supported Models: - OpenAI: <code>\"gpt-4o\"</code>, <code>\"gpt-4o-mini\"</code>, <code>\"gpt-3.5-turbo\"</code> - Anthropic: <code>\"claude-3-5-sonnet-20241022\"</code>, <code>\"claude-3-haiku-20240307\"</code> - Google: <code>\"gemini/gemini-pro\"</code>, <code>\"gemini/gemini-1.5-flash\"</code> - Ollama: <code>\"ollama/llama3.2\"</code>, <code>\"ollama/gemma2\"</code></p> <p>Example: <pre><code>agent = (\n    AgentBuilder(\"translator\")\n    .with_model(\"gpt-4o-mini\")\n    .build()\n)\n</code></pre></p>"},{"location":"en/api/builder/#with_memory","title":"with_memory()","text":"<p>Configure the memory system.</p> <pre><code>def with_memory(\n    self,\n    type: str = \"working\",\n    persist_dir: Optional[Path] = None,\n    max_messages: int = 100,\n    enable_rag: bool = False,\n) -&gt; AgentBuilder\n</code></pre> <p>Parameters: - type (<code>str</code>, default: <code>\"working\"</code>): Memory type   - <code>\"working\"</code>: In-memory storage (fast, temporary)   - <code>\"context\"</code>: Conversation context for LLM   - <code>\"persistent\"</code>: SQLite storage (survives restarts)   - <code>\"rag\"</code>: Vector-based semantic search - persist_dir (<code>Optional[Path]</code>, default: <code>None</code>): Directory for persistent storage - max_messages (<code>int</code>, default: <code>100</code>): Maximum messages to store - enable_rag (<code>bool</code>, default: <code>False</code>): Enable RAG (requires ChromaDB)</p> <p>Returns: Self for method chaining</p> <p>Example: <pre><code># In-memory working memory\nagent = (\n    AgentBuilder(\"chatbot\")\n    .with_memory(type=\"working\", max_messages=50)\n    .build()\n)\n\n# Persistent memory with RAG\nagent = (\n    AgentBuilder(\"knowledge_bot\")\n    .with_memory(\n        type=\"persistent\",\n        persist_dir=Path.home() / \".kagura\" / \"memory\",\n        enable_rag=True,\n        max_messages=200\n    )\n    .build()\n)\n</code></pre></p>"},{"location":"en/api/builder/#with_routing","title":"with_routing()","text":"<p>Configure agent routing strategies.</p> <pre><code>def with_routing(\n    self,\n    strategy: str = \"semantic\",\n    routes: Optional[dict] = None,\n) -&gt; AgentBuilder\n</code></pre> <p>Parameters: - strategy (<code>str</code>, default: <code>\"semantic\"</code>): Routing strategy   - <code>\"keyword\"</code>: Keyword-based routing   - <code>\"llm\"</code>: LLM-powered routing   - <code>\"semantic\"</code>: Semantic similarity routing - routes (<code>Optional[dict]</code>, default: <code>None</code>): Route definitions mapping route names to agents</p> <p>Returns: Self for method chaining</p> <p>Example: <pre><code>routes = {\n    \"translate\": translator_agent,\n    \"summarize\": summarizer_agent,\n}\n\nagent = (\n    AgentBuilder(\"router\")\n    .with_routing(strategy=\"semantic\", routes=routes)\n    .build()\n)\n</code></pre></p>"},{"location":"en/api/builder/#with_tools","title":"with_tools()","text":"<p>Add tools to the agent.</p> <pre><code>def with_tools(self, tools: list[Callable]) -&gt; AgentBuilder\n</code></pre> <p>Parameters: - tools (<code>list[Callable]</code>): List of tool functions</p> <p>Returns: Self for method chaining</p> <p>Example: <pre><code>def search_web(query: str) -&gt; str:\n    \"\"\"Search the web.\"\"\"\n    return f\"Results for: {query}\"\n\ndef calculate(expression: str) -&gt; float:\n    \"\"\"Calculate math expression.\"\"\"\n    return eval(expression)\n\nagent = (\n    AgentBuilder(\"assistant\")\n    .with_tools([search_web, calculate])\n    .build()\n)\n</code></pre></p>"},{"location":"en/api/builder/#with_hooks","title":"with_hooks()","text":"<p>Add pre and post execution hooks.</p> <pre><code>def with_hooks(\n    self,\n    pre: Optional[list[Callable]] = None,\n    post: Optional[list[Callable]] = None,\n) -&gt; AgentBuilder\n</code></pre> <p>Parameters: - pre (<code>Optional[list[Callable]]</code>, default: <code>None</code>): Pre-execution hooks - post (<code>Optional[list[Callable]]</code>, default: <code>None</code>): Post-execution hooks</p> <p>Returns: Self for method chaining</p> <p>Hook Signatures: - Pre-hook: <code>def pre_hook(*args, **kwargs) -&gt; None</code> - Post-hook: <code>def post_hook(result: Any) -&gt; None</code></p> <p>Example: <pre><code>def log_input(*args, **kwargs):\n    print(f\"Input: {args}, {kwargs}\")\n\ndef log_output(result):\n    print(f\"Output: {result}\")\n\nagent = (\n    AgentBuilder(\"monitored_agent\")\n    .with_hooks(\n        pre=[log_input],\n        post=[log_output]\n    )\n    .build()\n)\n</code></pre></p>"},{"location":"en/api/builder/#with_context","title":"with_context()","text":"<p>Set LLM generation parameters.</p> <pre><code>def with_context(self, **kwargs: Any) -&gt; AgentBuilder\n</code></pre> <p>Parameters: - kwargs: LLM generation parameters   - <code>temperature</code> (<code>float</code>): Sampling temperature (0.0-2.0)   - <code>max_tokens</code> (<code>int</code>): Maximum response tokens   - <code>top_p</code> (<code>float</code>): Nucleus sampling threshold   - <code>frequency_penalty</code> (<code>float</code>): Repetition penalty   - <code>presence_penalty</code> (<code>float</code>): Topic diversity penalty   - Other LiteLLM-supported parameters</p> <p>Returns: Self for method chaining</p> <p>Example: <pre><code># Deterministic agent (factual tasks)\nfactual = (\n    AgentBuilder(\"fact_checker\")\n    .with_context(\n        temperature=0.2,\n        max_tokens=500\n    )\n    .build()\n)\n\n# Creative agent (story generation)\ncreative = (\n    AgentBuilder(\"storyteller\")\n    .with_context(\n        temperature=1.5,\n        max_tokens=2000,\n        top_p=0.9\n    )\n    .build()\n)\n</code></pre></p>"},{"location":"en/api/builder/#build","title":"build()","text":"<p>Build and return the final agent.</p> <pre><code>def build(self) -&gt; Callable\n</code></pre> <p>Returns: Callable agent function</p> <p>Raises: - <code>ValueError</code>: If configuration is invalid</p> <p>Example: <pre><code>agent = (\n    AgentBuilder(\"my_agent\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(type=\"working\")\n    .build()\n)\n\n# Use the agent\nresult = await agent(\"Hello!\")\n</code></pre></p>"},{"location":"en/api/builder/#complete-example","title":"Complete Example","text":"<pre><code>import asyncio\nfrom pathlib import Path\nfrom kagura import AgentBuilder\n\n\ndef search_web(query: str) -&gt; str:\n    \"\"\"Search the web.\"\"\"\n    return f\"Search results for: {query}\"\n\n\ndef log_execution(result):\n    \"\"\"Log agent executions.\"\"\"\n    print(f\"[LOG] Result: {result}\")\n\n\nasync def main():\n    # Build a complex agent\n    agent = (\n        AgentBuilder(\"advanced_assistant\")\n        .with_model(\"gpt-4o-mini\")\n        .with_memory(\n            type=\"persistent\",\n            persist_dir=Path.home() / \".kagura\" / \"agents\",\n            max_messages=100,\n            enable_rag=True\n        )\n        .with_tools([search_web])\n        .with_hooks(post=[log_execution])\n        .with_context(\n            temperature=0.7,\n            max_tokens=800\n        )\n        .build()\n    )\n\n    # Use the agent\n    result = await agent(\"Search for Python tutorials\")\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/api/builder/#configuration-classes","title":"Configuration Classes","text":""},{"location":"en/api/builder/#agentconfiguration","title":"AgentConfiguration","text":"<pre><code>from kagura.builder import AgentConfiguration\n\nconfig = AgentConfiguration(\n    name=\"my_agent\",\n    model=\"gpt-4o-mini\"\n)\n</code></pre> <p>Fields: - name (<code>str</code>): Agent name - model (<code>str</code>): LLM model - memory (<code>Optional[MemoryConfig]</code>): Memory configuration - routing (<code>Optional[RoutingConfig]</code>): Routing configuration - tools (<code>list[Callable]</code>): Tool functions - hooks (<code>Optional[HooksConfig]</code>): Hook configuration - context (<code>dict[str, Any]</code>): LLM parameters</p>"},{"location":"en/api/builder/#memoryconfig","title":"MemoryConfig","text":"<pre><code>from kagura.builder import MemoryConfig\n\nmemory = MemoryConfig(\n    type=\"persistent\",\n    persist_dir=Path(\".kagura\"),\n    max_messages=100,\n    enable_rag=True\n)\n</code></pre> <p>Fields: - type (<code>str</code>): Memory type - persist_dir (<code>Optional[Path]</code>): Storage directory - max_messages (<code>int</code>): Message limit - enable_rag (<code>bool</code>): Enable RAG</p>"},{"location":"en/api/builder/#routingconfig","title":"RoutingConfig","text":"<pre><code>from kagura.builder import RoutingConfig\n\nrouting = RoutingConfig(\n    strategy=\"semantic\",\n    routes={\"translate\": translator_agent}\n)\n</code></pre> <p>Fields: - strategy (<code>str</code>): Routing strategy - routes (<code>dict</code>): Route mappings</p>"},{"location":"en/api/builder/#hooksconfig","title":"HooksConfig","text":"<pre><code>from kagura.builder import HooksConfig\n\nhooks = HooksConfig(\n    pre=[pre_hook1, pre_hook2],\n    post=[post_hook1, post_hook2]\n)\n</code></pre> <p>Fields: - pre (<code>list[Callable]</code>): Pre-execution hooks - post (<code>list[Callable]</code>): Post-execution hooks</p>"},{"location":"en/api/builder/#best-practices","title":"Best Practices","text":""},{"location":"en/api/builder/#1-use-descriptive-names","title":"1. Use Descriptive Names","text":"<pre><code># Good\nAgentBuilder(\"customer_support_chatbot\")\n\n# Less clear\nAgentBuilder(\"agent1\")\n</code></pre>"},{"location":"en/api/builder/#2-chain-methods-vertically","title":"2. Chain Methods Vertically","text":"<pre><code># Good - readable\nagent = (\n    AgentBuilder(\"name\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(type=\"rag\")\n    .build()\n)\n\n# Less readable\nagent = AgentBuilder(\"name\").with_model(\"gpt-4o-mini\").with_memory(type=\"rag\").build()\n</code></pre>"},{"location":"en/api/builder/#3-choose-appropriate-memory-type","title":"3. Choose Appropriate Memory Type","text":"<pre><code># Short conversations\n.with_memory(type=\"working\")\n\n# Long-term knowledge\n.with_memory(type=\"persistent\", enable_rag=True)\n\n# Context-aware\n.with_memory(type=\"context\", max_messages=20)\n</code></pre>"},{"location":"en/api/builder/#4-temperature-selection","title":"4. Temperature Selection","text":"<pre><code># Factual tasks (low temperature)\n.with_context(temperature=0.2)\n\n# Balanced (medium temperature)\n.with_context(temperature=0.7)\n\n# Creative tasks (high temperature)\n.with_context(temperature=1.5)\n</code></pre>"},{"location":"en/api/builder/#error-handling","title":"Error Handling","text":"<pre><code>from kagura import AgentBuilder\n\ntry:\n    agent = (\n        AgentBuilder(\"my_agent\")\n        .with_model(\"invalid-model\")\n        .build()\n    )\nexcept ValueError as e:\n    print(f\"Configuration error: {e}\")\n\ntry:\n    agent = (\n        AgentBuilder(\"my_agent\")\n        .with_memory(enable_rag=True)  # Without ChromaDB\n        .build()\n    )\nexcept ImportError as e:\n    print(f\"Missing dependency: {e}\")\n</code></pre>"},{"location":"en/api/builder/#related","title":"Related","text":"<ul> <li>Tutorial: Agent Builder - Step-by-step guide</li> <li>@agent Decorator - Core agent decorator</li> <li>Memory Management - Memory system details</li> <li>Agent Routing - Routing strategies</li> </ul>"},{"location":"en/api/builder/#see-also","title":"See Also","text":"<ul> <li>Quick Start - Getting started guide</li> <li>Tutorial: Testing - Testing agents</li> <li>Tutorial: Observability - Monitoring agents</li> </ul>"},{"location":"en/api/chat/","title":"Chat API Reference","text":"<p>API documentation for the Kagura Chat REPL system.</p>"},{"location":"en/api/chat/#chatsession","title":"ChatSession","text":"<p>The main class for managing interactive chat sessions.</p>"},{"location":"en/api/chat/#constructor","title":"Constructor","text":"<pre><code>from kagura.chat import ChatSession\n\nsession = ChatSession(\n    model=\"gpt-4o-mini\",\n    session_dir=None\n)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>model</code> <code>str</code> <code>\"gpt-4o-mini\"</code> LLM model to use for chat <code>session_dir</code> <code>Path \\| None</code> <code>~/.kagura/sessions</code> Directory for session storage"},{"location":"en/api/chat/#methods","title":"Methods","text":""},{"location":"en/api/chat/#run","title":"<code>run()</code>","text":"<p>Start the interactive chat loop.</p> <pre><code>async def run() -&gt; None\n</code></pre> <p>Example:</p> <pre><code>session = ChatSession()\nawait session.run()\n</code></pre>"},{"location":"en/api/chat/#chatuser_input","title":"<code>chat(user_input)</code>","text":"<p>Handle a single chat interaction.</p> <pre><code>async def chat(user_input: str) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>user_input</code> (<code>str</code>): User message</li> </ul> <p>Example:</p> <pre><code>await session.chat(\"What is Python?\")\n</code></pre>"},{"location":"en/api/chat/#save_sessionname","title":"<code>save_session(name)</code>","text":"<p>Save the current conversation session.</p> <pre><code>async def save_session(name: str = \"\") -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>name</code> (<code>str</code>, optional): Session name. If empty, uses timestamp.</li> </ul> <p>Example:</p> <pre><code># Save with custom name\nawait session.save_session(\"my_session\")\n\n# Save with auto-generated name\nawait session.save_session()\n</code></pre>"},{"location":"en/api/chat/#load_sessionname","title":"<code>load_session(name)</code>","text":"<p>Load a previously saved session.</p> <pre><code>async def load_session(name: str) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>name</code> (<code>str</code>): Session name to load</li> </ul> <p>Example:</p> <pre><code>await session.load_session(\"my_session\")\n</code></pre>"},{"location":"en/api/chat/#clear_history","title":"<code>clear_history()</code>","text":"<p>Clear the conversation history.</p> <pre><code>def clear_history() -&gt; None\n</code></pre> <p>Example:</p> <pre><code>session.clear_history()\n</code></pre>"},{"location":"en/api/chat/#show_welcome","title":"<code>show_welcome()</code>","text":"<p>Display the welcome message.</p> <pre><code>def show_welcome() -&gt; None\n</code></pre>"},{"location":"en/api/chat/#show_help","title":"<code>show_help()</code>","text":"<p>Display the help message.</p> <pre><code>def show_help() -&gt; None\n</code></pre>"},{"location":"en/api/chat/#preset-commands","title":"Preset Commands","text":""},{"location":"en/api/chat/#preset_translateargs","title":"<code>preset_translate(args)</code>","text":"<p>Translate text using the built-in translation agent.</p> <pre><code>async def preset_translate(args: str) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>args</code> (<code>str</code>): Translation arguments in format: <code>\"text [to language]\"</code></li> </ul> <p>Example:</p> <pre><code>await session.preset_translate(\"Hello to ja\")\nawait session.preset_translate(\"Bonjour to en\")\n</code></pre>"},{"location":"en/api/chat/#preset_summarizeargs","title":"<code>preset_summarize(args)</code>","text":"<p>Summarize text using the built-in summarization agent.</p> <pre><code>async def preset_summarize(args: str) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>args</code> (<code>str</code>): Text to summarize</li> </ul> <p>Example:</p> <pre><code>await session.preset_summarize(\"Long text here...\")\n</code></pre>"},{"location":"en/api/chat/#preset_reviewargs","title":"<code>preset_review(args)</code>","text":"<p>Review code using the built-in code review agent.</p> <pre><code>async def preset_review(args: str) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>args</code> (<code>str</code>): Code to review (or empty to prompt for input)</li> </ul> <p>Example:</p> <pre><code>code = \"\"\"\ndef divide(a, b):\n    return a / b\n\"\"\"\nawait session.preset_review(code)\n</code></pre>"},{"location":"en/api/chat/#preset-agents","title":"Preset Agents","text":""},{"location":"en/api/chat/#translateagent","title":"TranslateAgent","text":"<p>Translate text to a target language.</p> <pre><code>from kagura.chat import TranslateAgent\n\nresult = await TranslateAgent(\n    text=\"Hello World\",\n    target_language=\"ja\"\n)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>text</code> <code>str</code> - Text to translate <code>target_language</code> <code>str</code> <code>\"ja\"</code> Target language code <p>Returns: <code>str</code> - Translated text</p> <p>Example:</p> <pre><code># Translate to Japanese (default)\nresult = await TranslateAgent(\"Good morning\")\n# Output: \"\u304a\u306f\u3088\u3046\u3054\u3056\u3044\u307e\u3059\"\n\n# Translate to Spanish\nresult = await TranslateAgent(\"Hello\", target_language=\"es\")\n# Output: \"Hola\"\n\n# Translate to French\nresult = await TranslateAgent(\"Thank you\", target_language=\"fr\")\n# Output: \"Merci\"\n</code></pre>"},{"location":"en/api/chat/#summarizeagent","title":"SummarizeAgent","text":"<p>Summarize long text into a concise summary.</p> <pre><code>from kagura.chat import SummarizeAgent\n\nresult = await SummarizeAgent(\n    text=\"Long text here...\",\n    max_sentences=3\n)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>text</code> <code>str</code> - Text to summarize <code>max_sentences</code> <code>int</code> <code>3</code> Maximum sentences in summary <p>Returns: <code>str</code> - Summarized text</p> <p>Example:</p> <pre><code>long_text = \"\"\"\nArtificial intelligence (AI) is intelligence demonstrated by machines,\nas opposed to natural intelligence displayed by animals including humans.\nAI research has been defined as the field of study of intelligent agents,\nwhich refers to any system that perceives its environment and takes actions\nthat maximize its chance of achieving its goals.\n\"\"\"\n\nsummary = await SummarizeAgent(long_text, max_sentences=2)\n# Output: \"AI is machine intelligence. It studies intelligent\n#          agents that perceive and act to achieve goals.\"\n</code></pre>"},{"location":"en/api/chat/#codereviewagent","title":"CodeReviewAgent","text":"<p>Review code and provide feedback on issues, improvements, and best practices.</p> <pre><code>from kagura.chat import CodeReviewAgent\n\nresult = await CodeReviewAgent(\n    code=\"def add(a, b): return a + b\",\n    language=\"python\"\n)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>code</code> <code>str</code> - Code to review <code>language</code> <code>str</code> <code>\"python\"</code> Programming language <p>Returns: <code>str</code> - Code review in markdown format</p> <p>Example:</p> <pre><code>code = \"\"\"\ndef divide(a, b):\n    return a / b\n\"\"\"\n\nreview = await CodeReviewAgent(code)\n# Output: Detailed markdown review with:\n# - Issues found (division by zero, missing type hints)\n# - Improvement suggestions\n# - Best practices recommendations\n</code></pre>"},{"location":"en/api/chat/#cli-command","title":"CLI Command","text":""},{"location":"en/api/chat/#kagura-chat","title":"<code>kagura chat</code>","text":"<p>Start an interactive chat session.</p> <pre><code>kagura chat [OPTIONS]\n</code></pre> <p>Options:</p> Option Short Type Default Description <code>--model</code> <code>-m</code> <code>str</code> <code>gpt-4o-mini</code> LLM model to use <p>Examples:</p> <pre><code># Start with default model\nkagura chat\n\n# Use GPT-4o\nkagura chat --model gpt-4o\n\n# Use Claude\nkagura chat -m claude-3-5-sonnet-20241022\n\n# Use Gemini\nkagura chat -m gemini/gemini-2.0-flash-exp\n</code></pre>"},{"location":"en/api/chat/#session-file-format","title":"Session File Format","text":"<p>Session files are stored as JSON in <code>~/.kagura/sessions/</code>.</p> <p>Format:</p> <pre><code>{\n  \"name\": \"my_session\",\n  \"created_at\": \"2025-10-10T14:30:15.123456\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"What is Python?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"Python is a high-level programming language...\"\n    }\n  ]\n}\n</code></pre> <p>Fields:</p> Field Type Description <code>name</code> <code>str</code> Session name <code>created_at</code> <code>str</code> ISO 8601 timestamp <code>messages</code> <code>list[dict]</code> List of messages <p>Message format:</p> Field Type Description <code>role</code> <code>str</code> Message role (<code>user</code>, <code>assistant</code>, <code>system</code>) <code>content</code> <code>str</code> Message content"},{"location":"en/api/chat/#configuration","title":"Configuration","text":""},{"location":"en/api/chat/#environment-variables","title":"Environment Variables","text":"Variable Description Default <code>OPENAI_API_KEY</code> OpenAI API key Required for OpenAI models <code>ANTHROPIC_API_KEY</code> Anthropic API key Required for Claude models <code>GOOGLE_API_KEY</code> Google API key Required for Gemini models"},{"location":"en/api/chat/#session-directory","title":"Session Directory","text":"<p>Default: <code>~/.kagura/sessions/</code></p> <p>Override with <code>ChatSession(session_dir=Path(\"/custom/path\"))</code></p>"},{"location":"en/api/chat/#history-file","title":"History File","text":"<p>Chat history is stored in: <code>~/.kagura/sessions/chat_history.txt</code></p> <p>Accessible via up/down arrows in the chat interface.</p>"},{"location":"en/api/chat/#integration-examples","title":"Integration Examples","text":""},{"location":"en/api/chat/#programmatic-chat","title":"Programmatic Chat","text":"<pre><code>from kagura.chat import ChatSession\n\nasync def automated_chat():\n    session = ChatSession(model=\"gpt-4o-mini\")\n\n    # Simulate chat interactions\n    await session.chat(\"Explain recursion\")\n    await session.chat(\"Give me an example in Python\")\n\n    # Save session\n    await session.save_session(\"recursion_tutorial\")\n\n# Run\nimport asyncio\nasyncio.run(automated_chat())\n</code></pre>"},{"location":"en/api/chat/#custom-preset-agent","title":"Custom Preset Agent","text":"<pre><code>from kagura import agent\n\n@agent(model=\"gpt-4o-mini\", temperature=0.3)\nasync def CustomPresetAgent(text: str, task: str) -&gt; str:\n    \"\"\"\n    Perform {{ task }} on the following text:\n\n    {{ text }}\n\n    Provide a concise result.\n    \"\"\"\n    pass\n\n# Use in Chat Session\nsession = ChatSession()\nresult = await CustomPresetAgent(\n    text=\"Sample text\",\n    task=\"sentiment analysis\"\n)\n</code></pre>"},{"location":"en/api/chat/#session-management","title":"Session Management","text":"<pre><code>from pathlib import Path\nfrom kagura.chat import ChatSession\n\n# Use custom session directory\nsession_dir = Path(\"./my_sessions\")\nsession = ChatSession(session_dir=session_dir)\n\n# Save multiple sessions\nawait session.chat(\"Python tutorial\")\nawait session.save_session(\"python_basics\")\n\nsession.clear_history()\n\nawait session.chat(\"JavaScript tutorial\")\nawait session.save_session(\"js_basics\")\n\n# List all sessions\nsessions = list(session_dir.glob(\"*.json\"))\nprint(f\"Available sessions: {[s.stem for s in sessions]}\")\n</code></pre>"},{"location":"en/api/chat/#error-handling","title":"Error Handling","text":""},{"location":"en/api/chat/#api-key-missing","title":"API Key Missing","text":"<pre><code># Raises: openai.error.AuthenticationError\nsession = ChatSession()\nawait session.run()\n</code></pre> <p>Solution: Set environment variable</p> <pre><code>export OPENAI_API_KEY=your_key_here\n</code></pre>"},{"location":"en/api/chat/#session-not-found","title":"Session Not Found","text":"<pre><code>await session.load_session(\"nonexistent\")\n# Prints: \"Session not found: nonexistent\"\n</code></pre>"},{"location":"en/api/chat/#invalid-model","title":"Invalid Model","text":"<pre><code>session = ChatSession(model=\"invalid-model\")\n# Raises: litellm.exceptions.BadRequestError\n</code></pre>"},{"location":"en/api/chat/#best-practices","title":"Best Practices","text":""},{"location":"en/api/chat/#1-save-important-conversations","title":"1. Save Important Conversations","text":"<pre><code># Before exiting, save valuable sessions\nawait session.save_session(\"important_discussion\")\n</code></pre>"},{"location":"en/api/chat/#2-use-appropriate-models","title":"2. Use Appropriate Models","text":"<pre><code># Fast responses for simple tasks\nsession = ChatSession(model=\"gpt-4o-mini\")\n\n# Higher quality for complex tasks\nsession = ChatSession(model=\"gpt-4o\")\n</code></pre>"},{"location":"en/api/chat/#3-clear-history-for-new-topics","title":"3. Clear History for New Topics","text":"<pre><code># Start fresh conversation\nsession.clear_history()\nawait session.chat(\"New topic...\")\n</code></pre>"},{"location":"en/api/chat/#4-organize-sessions","title":"4. Organize Sessions","text":"<pre><code># Use descriptive names\nawait session.save_session(\"python_debugging_2025-10-10\")\nawait session.save_session(\"code_review_auth_module\")\n</code></pre>"},{"location":"en/api/chat/#see-also","title":"See Also","text":"<ul> <li>Chat REPL Tutorial</li> <li>Memory Management API</li> <li>Agent Decorator</li> <li>CLI Reference</li> </ul>"},{"location":"en/api/cli/","title":"CLI Commands","text":"<p>Kagura AI 2.0 provides a command-line interface for version checking, running agents, and interactive development.</p>"},{"location":"en/api/cli/#overview","title":"Overview","text":"<p>The CLI is built with Click and provides: - Version information - Interactive REPL for rapid prototyping - Agent file execution (future)</p>"},{"location":"en/api/cli/#installation","title":"Installation","text":"<p>The CLI is automatically installed with Kagura AI:</p> <pre><code>pip install kagura-ai\n</code></pre> <p>Verify installation:</p> <pre><code>kagura --version\n</code></pre>"},{"location":"en/api/cli/#commands","title":"Commands","text":""},{"location":"en/api/cli/#kagura","title":"kagura","text":"<p>Main command group.</p> <pre><code>kagura [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options: - <code>--help</code>: Show help message - <code>--version</code>: Show version information</p>"},{"location":"en/api/cli/#kagura-version","title":"kagura version","text":"<p>Display Kagura AI version information.</p> <pre><code>kagura version\n</code></pre> <p>Output: <pre><code>Kagura AI v2.5.0\n</code></pre></p>"},{"location":"en/api/cli/#kagura-repl","title":"kagura repl","text":"<p>Start an interactive REPL (Read-Eval-Print Loop) for rapid agent prototyping.</p> <pre><code>kagura repl [OPTIONS]\n</code></pre> <p>Options: - <code>--model TEXT</code>: Default LLM model to use (default: <code>gpt-4o-mini</code>) - <code>--temperature FLOAT</code>: Default temperature (default: <code>0.7</code>) - <code>--help</code>: Show help message</p> <p>Example: <pre><code># Start REPL with default settings\nkagura repl\n\n# Start with custom model\nkagura repl --model gpt-4o\n\n# Start with higher temperature\nkagura repl --temperature 1.0\n</code></pre></p>"},{"location":"en/api/cli/#interactive-repl","title":"Interactive REPL","text":"<p>The REPL provides an interactive Python environment optimized for AI agent development.</p>"},{"location":"en/api/cli/#starting-the-repl","title":"Starting the REPL","text":"<pre><code>kagura repl\n</code></pre> <p>Welcome screen: <pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Kagura AI REPL                       \u2502\n\u2502 Python-First AI Agent Framework      \u2502\n\u2502                                      \u2502\n\u2502 Type /help for commands, /exit to    \u2502\n\u2502 quit                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n&gt;&gt;&gt;\n</code></pre></p>"},{"location":"en/api/cli/#repl-commands","title":"REPL Commands","text":"<p>Commands start with <code>/</code> and provide special functionality:</p>"},{"location":"en/api/cli/#help","title":"/help","text":"<p>Show available commands and usage information.</p> <pre><code>&gt;&gt;&gt; /help\n</code></pre> <p>Output: <pre><code>Available Commands:\n  /help      - Show this help message\n  /agents    - List all defined agents\n  /exit      - Exit REPL\n  /clear     - Clear screen\n  /model     - Show or set default model\n  /temp      - Show or set default temperature\n</code></pre></p>"},{"location":"en/api/cli/#agents","title":"/agents","text":"<p>List all agents defined in the current session.</p> <pre><code>&gt;&gt;&gt; /agents\n</code></pre> <p>Output: <pre><code>Defined Agents:\n  hello(name: str) -&gt; str\n  translate(text: str, lang: str) -&gt; str\n  extract_person(text: str) -&gt; Person\n</code></pre></p>"},{"location":"en/api/cli/#exit","title":"/exit","text":"<p>Exit the REPL.</p> <pre><code>&gt;&gt;&gt; /exit\n</code></pre> <p>Output: <pre><code>Goodbye!\n</code></pre></p>"},{"location":"en/api/cli/#clear","title":"/clear","text":"<p>Clear the terminal screen.</p> <pre><code>&gt;&gt;&gt; /clear\n</code></pre>"},{"location":"en/api/cli/#model","title":"/model","text":"<p>Show or set the default model for new agents.</p> <pre><code>&gt;&gt;&gt; /model\nCurrent model: gpt-4o-mini\n\n&gt;&gt;&gt; /model gpt-4o\nModel changed to: gpt-4o\n</code></pre>"},{"location":"en/api/cli/#temp","title":"/temp","text":"<p>Show or set the default temperature.</p> <pre><code>&gt;&gt;&gt; /temp\nCurrent temperature: 0.7\n\n&gt;&gt;&gt; /temp 1.0\nTemperature changed to: 1.0\n</code></pre>"},{"location":"en/api/cli/#defining-agents-in-repl","title":"Defining Agents in REPL","text":"<p>Use Python syntax to define agents:</p> <pre><code>&gt;&gt;&gt; from kagura import agent\n&gt;&gt;&gt;\n&gt;&gt;&gt; @agent\n... async def hello(name: str) -&gt; str:\n...     '''Say hello to {{ name }}'''\n...     pass\n...\nAgent 'hello' defined\n\n&gt;&gt;&gt; await hello(\"World\")\nHello, World! How can I help you today?\n</code></pre>"},{"location":"en/api/cli/#multi-line-input","title":"Multi-line Input","text":"<p>The REPL supports multi-line input for complex definitions:</p> <pre><code>&gt;&gt;&gt; from pydantic import BaseModel\n&gt;&gt;&gt;\n&gt;&gt;&gt; class Person(BaseModel):\n...     name: str\n...     age: int\n...\n&gt;&gt;&gt;\n&gt;&gt;&gt; @agent\n... async def extract_person(text: str) -&gt; Person:\n...     '''Extract person info from: {{ text }}'''\n...     pass\n...\nAgent 'extract_person' defined\n\n&gt;&gt;&gt; result = await extract_person(\"Alice is 30 years old\")\n&gt;&gt;&gt; result.name\nAlice\n&gt;&gt;&gt; result.age\n30\n</code></pre>"},{"location":"en/api/cli/#importing-modules","title":"Importing Modules","text":"<p>Import any Python module as usual:</p> <pre><code>&gt;&gt;&gt; from kagura import agent\n&gt;&gt;&gt; from pydantic import BaseModel\n&gt;&gt;&gt; from typing import List\n&gt;&gt;&gt; import json\n</code></pre>"},{"location":"en/api/cli/#executing-code","title":"Executing Code","text":"<p>Execute arbitrary Python code:</p> <pre><code>&gt;&gt;&gt; x = 10\n&gt;&gt;&gt; y = 20\n&gt;&gt;&gt; x + y\n30\n\n&gt;&gt;&gt; [i**2 for i in range(5)]\n[0, 1, 4, 9, 16]\n</code></pre>"},{"location":"en/api/cli/#using-code-execution","title":"Using Code Execution","text":"<pre><code>&gt;&gt;&gt; from kagura.agents import execute_code\n&gt;&gt;&gt;\n&gt;&gt;&gt; result = await execute_code(\"Calculate fibonacci(10)\")\n&gt;&gt;&gt; result[\"result\"]\n55\n</code></pre>"},{"location":"en/api/cli/#repl-features","title":"REPL Features","text":""},{"location":"en/api/cli/#syntax-highlighting","title":"Syntax Highlighting","text":"<p>Code is syntax-highlighted using Pygments for better readability.</p>"},{"location":"en/api/cli/#command-history","title":"Command History","text":"<p>Use arrow keys to navigate command history: - \u2191 (Up): Previous command - \u2193 (Down): Next command</p>"},{"location":"en/api/cli/#auto-completion","title":"Auto-completion","text":"<p>Tab completion for: - Python keywords - Variable names - Function names - Module names</p>"},{"location":"en/api/cli/#error-handling","title":"Error Handling","text":"<p>Errors are displayed with helpful messages:</p> <pre><code>&gt;&gt;&gt; await hello()\nError: hello() missing 1 required positional argument: 'name'\n\n&gt;&gt;&gt; result = await extract_person(\"invalid\")\nError: Validation error - could not parse response\n</code></pre>"},{"location":"en/api/cli/#examples","title":"Examples","text":""},{"location":"en/api/cli/#example-1-simple-agent","title":"Example 1: Simple Agent","text":"<pre><code>$ kagura repl\n&gt;&gt;&gt; from kagura import agent\n&gt;&gt;&gt;\n&gt;&gt;&gt; @agent\n... async def sentiment(text: str) -&gt; str:\n...     '''Analyze sentiment of: {{ text }}'''\n...     pass\n...\n&gt;&gt;&gt; await sentiment(\"I love this product!\")\nThe sentiment is overwhelmingly positive...\n</code></pre>"},{"location":"en/api/cli/#example-2-data-extraction","title":"Example 2: Data Extraction","text":"<pre><code>$ kagura repl\n&gt;&gt;&gt; from kagura import agent\n&gt;&gt;&gt; from pydantic import BaseModel\n&gt;&gt;&gt; from typing import List\n&gt;&gt;&gt;\n&gt;&gt;&gt; class Task(BaseModel):\n...     title: str\n...     priority: int\n...\n&gt;&gt;&gt; @agent\n... async def extract_tasks(text: str) -&gt; List[Task]:\n...     '''Extract tasks from: {{ text }}'''\n...     pass\n...\n&gt;&gt;&gt; tasks = await extract_tasks(\"1. Fix bug (high), 2. Write docs (low)\")\n&gt;&gt;&gt; for task in tasks:\n...     print(f\"{task.title}: Priority {task.priority}\")\n...\nFix bug: Priority 3\nWrite docs: Priority 1\n</code></pre>"},{"location":"en/api/cli/#example-3-code-generation","title":"Example 3: Code Generation","text":"<pre><code>$ kagura repl --model gpt-4o\n&gt;&gt;&gt; from kagura.agents import execute_code\n&gt;&gt;&gt;\n&gt;&gt;&gt; result = await execute_code(\"Calculate prime numbers up to 20\")\n&gt;&gt;&gt; result[\"result\"]\n[2, 3, 5, 7, 11, 13, 17, 19]\n</code></pre>"},{"location":"en/api/cli/#example-4-agent-composition","title":"Example 4: Agent Composition","text":"<pre><code>$ kagura repl\n&gt;&gt;&gt; from kagura import agent\n&gt;&gt;&gt;\n&gt;&gt;&gt; @agent\n... async def summarize(text: str) -&gt; str:\n...     '''Summarize in one sentence: {{ text }}'''\n...     pass\n...\n&gt;&gt;&gt; @agent\n... async def translate(text: str, lang: str) -&gt; str:\n...     '''Translate to {{ lang }}: {{ text }}'''\n...     pass\n...\n&gt;&gt;&gt; text = \"Long article text here...\"\n&gt;&gt;&gt; summary = await summarize(text)\n&gt;&gt;&gt; japanese = await translate(summary, \"Japanese\")\n&gt;&gt;&gt; print(japanese)\n</code></pre>"},{"location":"en/api/cli/#configuration","title":"Configuration","text":""},{"location":"en/api/cli/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>OPENAI_API_KEY</code>: OpenAI API key</li> <li><code>ANTHROPIC_API_KEY</code>: Anthropic API key</li> <li><code>GOOGLE_API_KEY</code>: Google API key</li> </ul> <p>Set before starting REPL:</p> <pre><code>export OPENAI_API_KEY=\"your-key-here\"\nkagura repl\n</code></pre>"},{"location":"en/api/cli/#model-selection","title":"Model Selection","text":"<p>Use different models for different tasks:</p> <pre><code># Fast, cheap model for simple tasks\nkagura repl --model gpt-4o-mini\n\n# Powerful model for complex reasoning\nkagura repl --model gpt-4o\n\n# Claude for long context\nkagura repl --model claude-3-5-sonnet-20241022\n\n# Local model with Ollama\nkagura repl --model ollama/llama3.2\n</code></pre>"},{"location":"en/api/cli/#tips-and-tricks","title":"Tips and Tricks","text":""},{"location":"en/api/cli/#1-quick-testing","title":"1. Quick Testing","text":"<p>Use REPL for quick agent testing:</p> <pre><code>&gt;&gt;&gt; @agent\n... async def test(x: str) -&gt; str:\n...     '''{{ x }}'''\n...     pass\n...\n&gt;&gt;&gt; await test(\"Is this working?\")\n</code></pre>"},{"location":"en/api/cli/#2-iterative-development","title":"2. Iterative Development","text":"<p>Refine prompts interactively:</p> <pre><code>&gt;&gt;&gt; @agent\n... async def v1(text: str) -&gt; str:\n...     '''Summarize: {{ text }}'''\n...     pass\n...\n&gt;&gt;&gt; @agent\n... async def v2(text: str) -&gt; str:\n...     '''Summarize in technical terms: {{ text }}'''\n...     pass\n...\n&gt;&gt;&gt; await v1(text)  # Try first version\n&gt;&gt;&gt; await v2(text)  # Try improved version\n</code></pre>"},{"location":"en/api/cli/#3-debugging","title":"3. Debugging","text":"<p>Print intermediate results:</p> <pre><code>&gt;&gt;&gt; result = await my_agent(\"test\")\n&gt;&gt;&gt; print(result)\n&gt;&gt;&gt; print(type(result))\n&gt;&gt;&gt; print(result.model_dump())  # For Pydantic models\n</code></pre>"},{"location":"en/api/cli/#4-saving-work","title":"4. Saving Work","text":"<p>Copy working code from REPL to a <code>.py</code> file:</p> <pre><code># In REPL - test and refine\n&gt;&gt;&gt; @agent\n... async def my_agent(x: str) -&gt; str:\n...     '''Process {{ x }}'''\n...     pass\n\n# Then save to agent.py:\n# from kagura import agent\n#\n# @agent\n# async def my_agent(x: str) -&gt; str:\n#     '''Process {{ x }}'''\n#     pass\n</code></pre>"},{"location":"en/api/cli/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/api/cli/#repl-wont-start","title":"REPL Won't Start","text":"<pre><code>$ kagura repl\nError: 'kagura' command not found\n</code></pre> <p>Solution: Ensure Kagura AI is installed and in your PATH: <pre><code>pip install kagura-ai\nwhich kagura  # Should show path to kagura command\n</code></pre></p>"},{"location":"en/api/cli/#import-errors","title":"Import Errors","text":"<pre><code>&gt;&gt;&gt; from kagura import agent\nModuleNotFoundError: No module named 'kagura'\n</code></pre> <p>Solution: Check your Python environment: <pre><code>python --version  # Should be 3.11+\npip list | grep kagura\n</code></pre></p>"},{"location":"en/api/cli/#api-key-errors","title":"API Key Errors","text":"<pre><code>&gt;&gt;&gt; await hello(\"test\")\nAuthenticationError: API key not found\n</code></pre> <p>Solution: Set your API key: <pre><code>export OPENAI_API_KEY=\"your-key-here\"\n</code></pre></p>"},{"location":"en/api/cli/#memory-issues","title":"Memory Issues","text":"<p>If REPL becomes slow or unresponsive:</p> <ol> <li>Exit and restart: <code>/exit</code></li> <li>Clear variables: <code>del large_variable</code></li> <li>Use <code>/clear</code> to clear screen</li> </ol>"},{"location":"en/api/cli/#custom-commands","title":"Custom Commands","text":"<p>Run custom commands defined in Markdown files.</p>"},{"location":"en/api/cli/#kagura-run","title":"kagura run","text":"<p>Execute a custom command defined in a Markdown file.</p> <pre><code>kagura run COMMAND_NAME [OPTIONS]\n</code></pre> <p>Arguments: - <code>COMMAND_NAME</code>: Name of the command to execute (required)</p> <p>Options: - <code>--param, -p KEY=VALUE</code>: Command parameter in key=value format (can be used multiple times) - <code>--commands-dir PATH</code>: Custom commands directory (default: <code>~/.kagura/commands</code>) - <code>--no-inline</code>: Disable inline command execution - <code>--help</code>: Show help message</p> <p>Examples:</p> <pre><code># Run a simple command\nkagura run git-workflow\n\n# Run with parameters\nkagura run analyze-data --param file=data.csv --param verbose=true\n\n# Use custom commands directory\nkagura run my-cmd --commands-dir ./my-commands\n\n# Disable inline command execution\nkagura run my-cmd --no-inline\n\n# Use global flags for quiet output\nkagura --quiet run my-cmd\n</code></pre>"},{"location":"en/api/cli/#command-files","title":"Command Files","text":"<p>Commands are Markdown files with YAML frontmatter stored in <code>~/.kagura/commands/</code>.</p> <p>Example command file (<code>~/.kagura/commands/git-status.md</code>):</p> <pre><code>---\nname: git-status\ndescription: Show git status with user context\nparameters:\n  username: string\n---\n\n# Git Status Report\n\n**User**: {{ username }}\n**Branch**: !`git branch --show-current`\n**Working Directory**: !`pwd`\n\n## Changes\n\n!`git status --short`\n\n## Task\n\nReview the changes and provide a commit message.\n</code></pre> <p>Run it:</p> <pre><code>kagura run git-status --param username=Alice\n</code></pre>"},{"location":"en/api/cli/#inline-commands","title":"Inline Commands","text":"<p>Commands can include inline shell commands using the <code>!</code>command`` syntax:</p> <pre><code>Current directory: !`pwd`\nCurrent user: !`whoami`\nGit branch: !`git branch --show-current`\nFile count: !`ls | wc -l`\n</code></pre> <p>Inline commands are executed before the template is rendered.</p>"},{"location":"en/api/cli/#parameter-passing","title":"Parameter Passing","text":"<p>Pass parameters via the <code>--param</code> flag:</p> <pre><code># Single parameter\nkagura run my-cmd --param name=Alice\n\n# Multiple parameters\nkagura run analyze-file \\\n  --param file=data.csv \\\n  --param lines=10 \\\n  --param verbose=true\n</code></pre> <p>Parameters are validated against the command's <code>parameters</code> definition in frontmatter.</p>"},{"location":"en/api/cli/#output-modes","title":"Output Modes","text":"<p>Normal mode (default):</p> <pre><code>kagura run my-cmd\n</code></pre> <p>Shows command information and rendered output in formatted panels.</p> <p>Quiet mode:</p> <pre><code>kagura --quiet run my-cmd\n</code></pre> <p>Shows only the rendered result without decorations.</p> <p>Verbose mode:</p> <pre><code>kagura --verbose run my-cmd\n</code></pre> <p>Shows additional debugging information and tracebacks on errors.</p>"},{"location":"en/api/cli/#error-handling_1","title":"Error Handling","text":"<p>Command not found:</p> <pre><code>$ kagura run nonexistent\nError: Command not found: nonexistent\n\nAvailable commands:\n  \u2022 git-workflow: Complete git workflow (commit, push, PR)\n  \u2022 code-review: Review code changes\n  \u2022 analyze-data: Analyze CSV data file\n</code></pre> <p>Missing required parameter:</p> <pre><code>$ kagura run analyze-data\nError: Required parameter 'file' is missing\n\nRequired parameters:\n  \u2022 file: string (required)\n</code></pre> <p>Invalid parameter format:</p> <pre><code>$ kagura run my-cmd --param invalid\nError: Invalid parameter format: invalid\nUse format: key=value\n</code></pre> <p>Commands directory not found:</p> <pre><code>$ kagura run my-cmd\nError: Commands directory not found: /home/user/.kagura/commands\n\nTip: Create the directory with:\n  mkdir -p /home/user/.kagura/commands\n</code></pre>"},{"location":"en/api/cli/#see-also","title":"See Also","text":"<ul> <li>Custom Commands API - API reference for commands</li> <li>Custom Commands Quick Start - Tutorial and examples</li> <li>@agent Decorator - Creating AI agents</li> </ul>"},{"location":"en/api/cli/#mcp-commands","title":"MCP Commands","text":"<p>MCP (Model Context Protocol) commands for Claude Desktop integration.</p>"},{"location":"en/api/cli/#kagura-mcp","title":"kagura mcp","text":"<p>MCP command group for managing Model Context Protocol integration.</p> <pre><code>kagura mcp [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Commands: - <code>serve</code> - Start MCP server - <code>list</code> - List registered agents</p>"},{"location":"en/api/cli/#kagura-mcp-serve","title":"kagura mcp serve","text":"<p>Start MCP server using stdio transport for Claude Desktop, Claude Code, Cline, etc.</p> <pre><code>kagura mcp serve [OPTIONS]\n</code></pre> <p>Options: - <code>--name TEXT</code>: Server name (default: \"kagura-ai\") - <code>--help</code>: Show help message</p> <p>Examples:</p> <pre><code># Start MCP server (called by Claude Desktop)\nkagura mcp serve\n\n# Custom server name\nkagura mcp serve --name my-custom-server\n\n# Verbose logging (stderr)\nkagura -v mcp serve\n</code></pre> <p>Usage in Claude Desktop:</p> <p>Add to Claude Desktop config file:</p> <p>macOS: <code>~/Library/Application Support/Claude/claude_desktop_config.json</code> Windows: <code>%APPDATA%\\Claude\\claude_desktop_config.json</code> Linux: <code>~/.config/Claude/claude_desktop_config.json</code></p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n</code></pre> <p>How it works:</p> <ol> <li>Claude Desktop starts <code>kagura mcp serve</code> as a subprocess</li> <li>Communication happens via stdio (stdin/stdout)</li> <li>Kagura agents are exposed as MCP tools</li> <li>Claude can call agents using the MCP protocol</li> </ol>"},{"location":"en/api/cli/#kagura-mcp-list","title":"kagura mcp list","text":"<p>List all registered Kagura agents available via MCP.</p> <pre><code>kagura mcp list\n</code></pre> <p>Example:</p> <pre><code>$ kagura mcp list\nRegistered agents (3):\n\n  \u2022 analyze_code\n    Analyze code quality and suggest improvements\n\n  \u2022 review_code\n    Review code and provide detailed feedback\n\n  \u2022 generate_tests\n    Generate unit tests for the provided code\n</code></pre> <p>Output:</p> <p>Shows agent names and descriptions extracted from docstrings.</p>"},{"location":"en/api/cli/#mcp-integration-examples","title":"MCP Integration Examples","text":""},{"location":"en/api/cli/#example-1-basic-setup","title":"Example 1: Basic Setup","text":"<pre><code># 1. Install MCP support\npip install kagura-ai[mcp]\n\n# 2. Create agent\ncat &gt; my_agents.py &lt;&lt; 'EOF'\nfrom kagura import agent\n\n@agent\nasync def analyze_code(code: str) -&gt; str:\n    \"\"\"Analyze code quality\"\"\"\n    pass\nEOF\n\n# 3. Test locally\nkagura mcp list\n\n# 4. Configure Claude Desktop (edit config file)\n# See configuration above\n\n# 5. Restart Claude Desktop\n</code></pre>"},{"location":"en/api/cli/#example-2-multiple-agents","title":"Example 2: Multiple Agents","text":"<pre><code># agents.py\nfrom kagura import agent\n\n@agent\nasync def code_review(code: str) -&gt; str:\n    \"\"\"Review code and suggest improvements\"\"\"\n    pass\n\n@agent\nasync def generate_tests(code: str, framework: str = \"pytest\") -&gt; str:\n    \"\"\"Generate unit tests\"\"\"\n    pass\n\n@agent\nasync def explain_code(code: str, audience: str = \"beginner\") -&gt; str:\n    \"\"\"Explain code for different audiences\"\"\"\n    pass\n</code></pre> <p>All three agents are automatically available in Claude Desktop.</p>"},{"location":"en/api/cli/#example-3-debugging","title":"Example 3: Debugging","text":"<pre><code># Check agents are registered\nkagura mcp list\n\n# Start server with verbose logging\nkagura -v mcp serve 2&gt; mcp_debug.log\n\n# In another terminal, check logs\ntail -f mcp_debug.log\n</code></pre>"},{"location":"en/api/cli/#mcp-troubleshooting","title":"MCP Troubleshooting","text":""},{"location":"en/api/cli/#agent-not-appearing","title":"Agent Not Appearing","text":"<ol> <li> <p>Verify agent is registered: <pre><code>kagura mcp list\n</code></pre></p> </li> <li> <p>Check import errors: <pre><code>python -c \"import my_agents\"\n</code></pre></p> </li> <li> <p>Restart Claude Desktop completely:</p> </li> <li>Quit application</li> <li>Start again</li> <li>Check MCP indicator</li> </ol>"},{"location":"en/api/cli/#configuration-issues","title":"Configuration Issues","text":"<ol> <li> <p>Verify config file location: <pre><code># macOS\ncat ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n\n# Linux\ncat ~/.config/Claude/claude_desktop_config.json\n</code></pre></p> </li> <li> <p>Validate JSON syntax: <pre><code>python -m json.tool &lt; claude_desktop_config.json\n</code></pre></p> </li> <li> <p>Check environment variables: <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"env\": {\n        \"OPENAI_API_KEY\": \"${OPENAI_API_KEY}\"\n      }\n    }\n  }\n}\n</code></pre></p> </li> </ol>"},{"location":"en/api/cli/#permission-errors","title":"Permission Errors","text":"<p>On Unix systems: <pre><code>which kagura\nchmod +x $(which kagura)\n</code></pre></p>"},{"location":"en/api/cli/#related","title":"Related","text":"<ul> <li>@agent Decorator - Creating agents</li> <li>MCP Integration Tutorial - Complete MCP guide</li> <li>MCP API Reference - MCP API documentation</li> <li>Quick Start - Getting started</li> <li>REPL Tutorial - Detailed REPL guide</li> </ul>"},{"location":"en/api/commands/","title":"Commands API","text":"<p>Custom commands allow you to define reusable AI tasks in Markdown files with YAML frontmatter.</p>"},{"location":"en/api/commands/#overview","title":"Overview","text":"<p>Commands are Markdown files with two parts: 1. Frontmatter (YAML metadata): Command configuration 2. Body (Markdown content): Command template</p>"},{"location":"en/api/commands/#command-class","title":"Command Class","text":"<p>Represents a custom command loaded from a Markdown file.</p>"},{"location":"en/api/commands/#constructor","title":"Constructor","text":"<pre><code>Command(\n    name: str,\n    description: str,\n    template: str,\n    allowed_tools: list[str] = [],\n    model: str = \"gpt-4o-mini\",\n    parameters: dict[str, Any] = {},\n    metadata: dict[str, Any] = {}\n)\n</code></pre> <p>Parameters:</p> <ul> <li><code>name</code>: Command name (used to invoke the command)</li> <li><code>description</code>: Human-readable description</li> <li><code>template</code>: Markdown template body</li> <li><code>allowed_tools</code>: List of allowed tool names (empty = all allowed)</li> <li><code>model</code>: LLM model to use (default: <code>gpt-4o-mini</code>)</li> <li><code>parameters</code>: Parameter definitions</li> <li><code>metadata</code>: Additional metadata from frontmatter</li> </ul>"},{"location":"en/api/commands/#methods","title":"Methods","text":""},{"location":"en/api/commands/#validate_parameters","title":"validate_parameters","text":"<pre><code>command.validate_parameters(provided: dict[str, Any]) -&gt; None\n</code></pre> <p>Validate provided parameters against parameter definitions.</p> <p>Raises: <code>ValueError</code> if required parameters are missing.</p> <p>Example:</p> <pre><code>command = Command(\n    name=\"test\",\n    description=\"Test\",\n    template=\"Content\",\n    parameters={\"file\": \"string\", \"count\": \"int\"}\n)\n\n# Valid\ncommand.validate_parameters({\"file\": \"test.txt\", \"count\": 5})\n\n# Invalid - raises ValueError\ncommand.validate_parameters({\"file\": \"test.txt\"})  # Missing 'count'\n</code></pre>"},{"location":"en/api/commands/#commandloader-class","title":"CommandLoader Class","text":"<p>Loads custom commands from Markdown files.</p> <p>By default, searches both project-local (<code>./.kagura/commands</code>) and global (<code>~/.kagura/commands</code>) directories. Local commands take priority over global commands with the same name.</p>"},{"location":"en/api/commands/#constructor_1","title":"Constructor","text":"<pre><code>CommandLoader(commands_dir: Optional[Path] = None)\n</code></pre> <p>Parameters:</p> <ul> <li><code>commands_dir</code>: Directory containing command files. If <code>None</code>, searches both:</li> <li><code>~/.kagura/commands</code> (global commands)</li> <li><code>./.kagura/commands</code> (project-local commands, takes priority)</li> </ul>"},{"location":"en/api/commands/#methods_1","title":"Methods","text":""},{"location":"en/api/commands/#load_command","title":"load_command","text":"<pre><code>loader.load_command(path: Path) -&gt; Command\n</code></pre> <p>Load a single command from a Markdown file.</p> <p>Returns: <code>Command</code> object</p> <p>Raises: - <code>FileNotFoundError</code>: If file doesn't exist - <code>ValueError</code>: If frontmatter is invalid</p> <p>Example:</p> <pre><code>from pathlib import Path\nfrom kagura.commands import CommandLoader\n\nloader = CommandLoader()\ncommand = loader.load_command(Path(\"~/.kagura/commands/example.md\"))\nprint(command.name)  # \"example\"\n</code></pre>"},{"location":"en/api/commands/#load_all","title":"load_all","text":"<pre><code>loader.load_all() -&gt; dict[str, Command]\n</code></pre> <p>Load all commands from configured directories.</p> <p>Searches all directories in priority order. When multiple directories contain commands with the same name, later directories take priority (local overrides global).</p> <p>Returns: Dictionary mapping command names to <code>Command</code> objects</p> <p>Raises: <code>FileNotFoundError</code> if no commands directory exists</p> <p>Example:</p> <pre><code># Default: searches both global and local directories\nloader = CommandLoader()\ncommands = loader.load_all()\n\nfor name, command in commands.items():\n    print(f\"{name}: {command.description}\")\n\n# Custom single directory\nloader = CommandLoader(Path(\"./my-commands\"))\ncommands = loader.load_all()\n</code></pre>"},{"location":"en/api/commands/#get_command","title":"get_command","text":"<pre><code>loader.get_command(name: str) -&gt; Optional[Command]\n</code></pre> <p>Get a loaded command by name.</p> <p>Returns: <code>Command</code> object if found, <code>None</code> otherwise</p> <p>Example:</p> <pre><code>loader = CommandLoader()\nloader.load_all()\n\ncommand = loader.get_command(\"example\")\nif command:\n    print(command.description)\n</code></pre>"},{"location":"en/api/commands/#list_commands","title":"list_commands","text":"<pre><code>loader.list_commands() -&gt; list[str]\n</code></pre> <p>List all loaded command names.</p> <p>Returns: List of command names</p> <p>Example:</p> <pre><code>loader = CommandLoader()\nloader.load_all()\n\ncommands = loader.list_commands()\nprint(f\"Available commands: {', '.join(commands)}\")\n</code></pre>"},{"location":"en/api/commands/#command-file-format","title":"Command File Format","text":"<p>Commands are defined in Markdown files with YAML frontmatter.</p>"},{"location":"en/api/commands/#basic-example","title":"Basic Example","text":"<p><code>~/.kagura/commands/example.md</code>:</p> <pre><code>---\nname: example\ndescription: Example command\n---\n\n# Task\n\nExecute an example task.\n</code></pre>"},{"location":"en/api/commands/#full-example","title":"Full Example","text":"<p><code>~/.kagura/commands/full-example.md</code>:</p> <pre><code>---\nname: full-example\ndescription: Full example with all fields\nallowed_tools: [git, gh, bash]\nmodel: gpt-4o\nparameters:\n  file: string\n  count: int\nauthor: Your Name\nversion: 1.0\n---\n\n# Context\n\nProcessing file: {{ file }}\n\n# Task\n\nExecute task {{ count }} times.\n</code></pre>"},{"location":"en/api/commands/#frontmatter-fields","title":"Frontmatter Fields","text":"<p>Required: - None (all fields are optional)</p> <p>Standard Fields: - <code>name</code>: Command name (defaults to filename if not specified) - <code>description</code>: Command description - <code>allowed_tools</code>: List of allowed tools (e.g., <code>[git, bash]</code>) - <code>model</code>: LLM model name (default: <code>gpt-4o-mini</code>) - <code>parameters</code>: Parameter definitions</p> <p>Custom Fields: - Any additional YAML fields are stored in <code>command.metadata</code></p>"},{"location":"en/api/commands/#parameter-definitions","title":"Parameter Definitions","text":""},{"location":"en/api/commands/#simple-type","title":"Simple Type","text":"<pre><code>parameters:\n  file: string\n  count: int\n  enabled: bool\n</code></pre>"},{"location":"en/api/commands/#with-required-flag","title":"With Required Flag","text":"<pre><code>parameters:\n  file:\n    type: string\n    required: true\n  count:\n    type: int\n    required: false\n</code></pre>"},{"location":"en/api/commands/#usage-examples","title":"Usage Examples","text":""},{"location":"en/api/commands/#loading-commands","title":"Loading Commands","text":"<pre><code>from pathlib import Path\nfrom kagura.commands import CommandLoader\n\n# Default: searches both global and local directories\nloader = CommandLoader()\n# Searches:\n#   1. ~/.kagura/commands (global)\n#   2. ./.kagura/commands (local, takes priority)\n\n# Custom single directory\nloader = CommandLoader(Path(\"./my-commands\"))\n\n# Load all commands\ncommands = loader.load_all()\nprint(f\"Loaded {len(commands)} commands\")\n\n# Get specific command\nexample = loader.get_command(\"example\")\nif example:\n    print(f\"Template: {example.template}\")\n</code></pre>"},{"location":"en/api/commands/#multi-directory-search","title":"Multi-Directory Search","text":"<p>By default, <code>CommandLoader</code> searches both global and local directories:</p> <pre><code>loader = CommandLoader()  # No argument\n\n# Equivalent to:\n# loader.commands_dirs = [\n#     Path.home() / \".kagura\" / \"commands\",  # Global\n#     Path.cwd() / \".kagura\" / \"commands\",   # Local (priority)\n# ]\n\ncommands = loader.load_all()\n</code></pre> <p>Priority: Local commands override global commands with the same name.</p> <p>Example:</p> <pre><code>~/.kagura/commands/deploy.md       \u2190 Global version\n./.kagura/commands/deploy.md       \u2190 Local version (used)\n</code></pre> <p>When both exist, the local version is used.</p>"},{"location":"en/api/commands/#creating-commands-programmatically","title":"Creating Commands Programmatically","text":"<pre><code>from kagura.commands import Command\n\ncommand = Command(\n    name=\"my-command\",\n    description=\"My custom command\",\n    template=\"# Task\\nDo something\",\n    allowed_tools=[\"bash\"],\n    model=\"gpt-4o-mini\"\n)\n\n# Validate parameters\ncommand.validate_parameters({})  # OK if no required params\n</code></pre>"},{"location":"en/api/commands/#command-with-parameters","title":"Command with Parameters","text":"<p>Create <code>~/.kagura/commands/greet.md</code>:</p> <pre><code>---\nname: greet\ndescription: Greet a person\nparameters:\n  name: string\n  formal: bool\n---\n\n# Task\n\nGreet {{ name }} in a {% if formal %}formal{% else %}casual{% endif %} manner.\n</code></pre> <p>Load and use:</p> <pre><code>loader = CommandLoader()\nloader.load_all()\n\ngreet = loader.get_command(\"greet\")\n\n# Validate parameters\ngreet.validate_parameters({\"name\": \"Alice\", \"formal\": True})  # OK\ngreet.validate_parameters({\"name\": \"Bob\"})  # Error: missing 'formal'\n</code></pre>"},{"location":"en/api/commands/#error-handling","title":"Error Handling","text":""},{"location":"en/api/commands/#missing-command-file","title":"Missing Command File","text":"<pre><code>from pathlib import Path\nfrom kagura.commands import CommandLoader\n\nloader = CommandLoader()\n\ntry:\n    cmd = loader.load_command(Path(\"nonexistent.md\"))\nexcept FileNotFoundError as e:\n    print(f\"Command file not found: {e}\")\n</code></pre>"},{"location":"en/api/commands/#invalid-frontmatter","title":"Invalid Frontmatter","text":"<p>If a command file has invalid YAML frontmatter, <code>load_command</code> will raise a <code>ValueError</code>.</p>"},{"location":"en/api/commands/#missing-directory","title":"Missing Directory","text":"<pre><code>from pathlib import Path\nfrom kagura.commands import CommandLoader\n\nloader = CommandLoader(Path(\"/nonexistent\"))\n\ntry:\n    loader.load_all()\nexcept FileNotFoundError as e:\n    print(f\"Commands directory not found: {e}\")\n</code></pre>"},{"location":"en/api/commands/#skipping-invalid-files","title":"Skipping Invalid Files","text":"<p><code>load_all()</code> skips invalid files and prints warnings:</p> <pre><code>loader = CommandLoader()\ncommands = loader.load_all()\n# Prints: \"Warning: Failed to load invalid.md: ...\"\n# But continues loading other commands\n</code></pre>"},{"location":"en/api/commands/#best-practices","title":"Best Practices","text":""},{"location":"en/api/commands/#1-use-descriptive-names","title":"1. Use Descriptive Names","text":"<pre><code>---\nname: git-commit-push-pr\ndescription: Create commit, push, and open PR\n---\n</code></pre>"},{"location":"en/api/commands/#2-specify-allowed-tools","title":"2. Specify Allowed Tools","text":"<pre><code>---\nallowed_tools: [git, gh]  # Only allow git and GitHub CLI\n---\n</code></pre>"},{"location":"en/api/commands/#3-add-metadata","title":"3. Add Metadata","text":"<pre><code>---\nauthor: Your Name\nversion: 1.0\ntags: [git, workflow]\n---\n</code></pre>"},{"location":"en/api/commands/#4-organize-by-purpose","title":"4. Organize by Purpose","text":"<pre><code>~/.kagura/commands/\n\u251c\u2500\u2500 git/\n\u2502   \u251c\u2500\u2500 commit-pr.md\n\u2502   \u2514\u2500\u2500 sync-fork.md\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 generate-readme.md\n\u2502   \u2514\u2500\u2500 update-changelog.md\n\u2514\u2500\u2500 analysis/\n    \u251c\u2500\u2500 analyze-logs.md\n    \u2514\u2500\u2500 report-metrics.md\n</code></pre>"},{"location":"en/api/commands/#inlinecommandexecutor-class","title":"InlineCommandExecutor Class","text":"<p>Executes inline shell commands in templates using the <code>!</code>command`` syntax.</p>"},{"location":"en/api/commands/#constructor_2","title":"Constructor","text":"<pre><code>InlineCommandExecutor(timeout: int = 10)\n</code></pre> <p>Parameters:</p> <ul> <li><code>timeout</code>: Timeout in seconds for command execution (default: 10)</li> </ul>"},{"location":"en/api/commands/#methods_2","title":"Methods","text":""},{"location":"en/api/commands/#execute","title":"execute","text":"<pre><code>executor.execute(template: str) -&gt; str\n</code></pre> <p>Execute all inline commands in a template string.</p> <p>Parameters:</p> <ul> <li><code>template</code>: Template string containing inline commands in <code>!</code>command`` format</li> </ul> <p>Returns: Template with inline commands replaced by their output</p> <p>Example:</p> <pre><code>from kagura.commands import InlineCommandExecutor\n\nexecutor = InlineCommandExecutor()\n\n# Simple command\nresult = executor.execute(\"Current user: !`whoami`\")\nprint(result)  # \"Current user: alice\"\n\n# Multiple commands\nresult = executor.execute(\"User: !`whoami`, PWD: !`pwd`\")\nprint(result)  # \"User: alice, PWD: /home/alice/project\"\n\n# Command with pipes\nresult = executor.execute(\"Files: !`ls | wc -l`\")\nprint(result)  # \"Files: 5\"\n</code></pre>"},{"location":"en/api/commands/#inline-command-syntax","title":"Inline Command Syntax","text":"<p>Inline commands use the format: <code>!</code>command``</p> <p>Examples:</p> <pre><code>Current directory: !`pwd`\nCurrent user: !`whoami`\nGit branch: !`git branch --show-current`\nFile count: !`ls | wc -l`\nDate: !`date +%Y-%m-%d`\n</code></pre>"},{"location":"en/api/commands/#error-handling_1","title":"Error Handling","text":"<p>Failed commands are replaced with error messages:</p> <pre><code>executor = InlineCommandExecutor()\n\n# Nonexistent command\nresult = executor.execute(\"Result: !`nonexistent_cmd`\")\nprint(result)  # \"Result: [Error: command not found]\"\n\n# Failed command\nresult = executor.execute(\"Result: !`false`\")\nprint(result)  # \"Result: [Error: ...]\"\n</code></pre>"},{"location":"en/api/commands/#timeout","title":"Timeout","text":"<p>Commands that exceed the timeout are terminated:</p> <pre><code>executor = InlineCommandExecutor(timeout=1)\n\n# This will timeout\nresult = executor.execute(\"Result: !`sleep 5`\")\nprint(result)  # \"Result: [Error: Command timed out after 1s]\"\n</code></pre>"},{"location":"en/api/commands/#commandexecutor-class","title":"CommandExecutor Class","text":"<p>Executes custom commands with template rendering and inline command execution.</p> <p>Combines two rendering steps: 1. Execute inline commands (<code>!</code>command``) 2. Render Jinja2 template with parameters</p>"},{"location":"en/api/commands/#constructor_3","title":"Constructor","text":"<pre><code>CommandExecutor(\n    inline_timeout: int = 10,\n    enable_inline: bool = True\n)\n</code></pre> <p>Parameters:</p> <ul> <li><code>inline_timeout</code>: Timeout for inline command execution (default: 10)</li> <li><code>enable_inline</code>: Enable inline command execution (default: True)</li> </ul>"},{"location":"en/api/commands/#methods_3","title":"Methods","text":""},{"location":"en/api/commands/#render","title":"render","text":"<pre><code>executor.render(\n    command: Command,\n    parameters: Optional[dict[str, Any]] = None\n) -&gt; str\n</code></pre> <p>Render command template with parameters and inline commands.</p> <p>Parameters:</p> <ul> <li><code>command</code>: Command to render</li> <li><code>parameters</code>: Template parameters (default: {})</li> </ul> <p>Returns: Rendered template string</p> <p>Raises: <code>ValueError</code> if required parameters are missing</p> <p>Example:</p> <pre><code>from kagura.commands import Command, CommandExecutor\n\n# Command with inline commands\ncommand = Command(\n    name=\"status\",\n    description=\"Show status\",\n    template=\"User: {{ user }}, PWD: !`pwd`\",\n    parameters={\"user\": \"string\"}\n)\n\nexecutor = CommandExecutor()\nresult = executor.render(command, {\"user\": \"Alice\"})\nprint(result)  # \"User: Alice, PWD: /home/alice\"\n</code></pre>"},{"location":"en/api/commands/#execute_1","title":"execute","text":"<pre><code>executor.execute(\n    command: Command,\n    parameters: Optional[dict[str, Any]] = None\n) -&gt; str\n</code></pre> <p>Alias for <code>render()</code> for consistency with executor pattern.</p>"},{"location":"en/api/commands/#rendering-order","title":"Rendering Order","text":"<ol> <li>Inline commands first: <code>!</code>pwd<code>` \u2192</code>/home/user`</li> <li>Jinja2 second: <code>{{ user }}</code> \u2192 <code>Alice</code></li> </ol> <p>Example:</p> <pre><code># Template\ntemplate = \"{{ name }} is in !`pwd`\"\n\n# Step 1: Inline execution\n# \u2192 \"{{ name }} is in /home/alice\"\n\n# Step 2: Jinja2 rendering with {\"name\": \"Alice\"}\n# \u2192 \"Alice is in /home/alice\"\n</code></pre>"},{"location":"en/api/commands/#disabling-inline-commands","title":"Disabling Inline Commands","text":"<pre><code>executor = CommandExecutor(enable_inline=False)\nresult = executor.render(command)\n# Inline commands like !`pwd` are NOT executed\n</code></pre>"},{"location":"en/api/commands/#full-example_1","title":"Full Example","text":"<pre><code>from kagura.commands import Command, CommandExecutor\n\n# Create command\ncommand = Command(\n    name=\"git-status\",\n    description=\"Show git status for user\",\n    template=\"\"\"# Git Status Report\n\n**User**: {{ username }}\n**Branch**: !`git branch --show-current`\n**Working Directory**: !`pwd`\n\n## Changes\n\n!`git status --short`\n\n## Summary\n\nYou are currently on branch !`git branch --show-current` in directory !`pwd`.\n\"\"\",\n    parameters={\"username\": \"string\"}\n)\n\n# Execute\nexecutor = CommandExecutor()\nresult = executor.render(command, {\"username\": \"Alice\"})\n\nprint(result)\n# Output:\n# # Git Status Report\n#\n# **User**: Alice\n# **Branch**: main\n# **Working Directory**: /home/alice/project\n#\n# ## Changes\n#\n# M src/main.py\n# ?? new_file.py\n#\n# ## Summary\n#\n# You are currently on branch main in directory /home/alice/project.\n</code></pre>"},{"location":"en/api/commands/#hook-integration","title":"Hook Integration","text":"<p>CommandExecutor automatically applies hooks during execution. See Hooks API for details.</p>"},{"location":"en/api/commands/#using-hooks-with-commandexecutor","title":"Using Hooks with CommandExecutor","text":"<pre><code>from kagura.commands import Command, CommandExecutor, hook, HookResult\n\n# Define hook\n@hook.pre_tool_use(\"bash\")\ndef block_dangerous(tool_input):\n    if \"rm -rf /\" in tool_input.get(\"command\", \"\"):\n        return HookResult.block(\"Dangerous command!\")\n    return HookResult.ok()\n\n# Hooks automatically applied\ncommand = Command(\n    name=\"check\",\n    description=\"Check system\",\n    template=\"Files: !`ls`\"\n)\n\nexecutor = CommandExecutor()\nresult = executor.render(command)  # Hook applied\n</code></pre>"},{"location":"en/api/commands/#custom-hook-registry","title":"Custom Hook Registry","text":"<pre><code>from kagura.commands import CommandExecutor, HookRegistry\n\n# Create custom registry\nregistry = HookRegistry()\n\n# Register hooks to custom registry\n# ... (register hooks)\n\n# Use custom registry\nexecutor = CommandExecutor(hook_registry=registry)\n</code></pre>"},{"location":"en/api/commands/#see-also","title":"See Also","text":"<ul> <li>Custom Commands Quick Start</li> <li>Hooks Guide - Hook system guide</li> <li>Hooks API - Hooks API reference</li> <li>CLI Commands Reference</li> <li>@agent Decorator API</li> <li>Memory Management API</li> </ul>"},{"location":"en/api/compression/","title":"Context Compression API","text":"<p>RFC-024 Phase 1: Token Management</p> <p>Status: Phase 1 Implemented Since: v2.5.0</p>"},{"location":"en/api/compression/#overview","title":"Overview","text":"<p>The compression module provides token counting and context window management for efficient long-form conversations.</p> <p>Key Components: - <code>TokenCounter</code>: Accurate token counting for all major LLM models - <code>ContextMonitor</code>: Real-time context window usage monitoring - <code>ContextUsage</code>: Usage statistics dataclass</p>"},{"location":"en/api/compression/#tokencounter","title":"TokenCounter","text":"<p>Count tokens for various LLM models using tiktoken.</p>"},{"location":"en/api/compression/#constructor","title":"Constructor","text":"<pre><code>TokenCounter(model: str = \"gpt-4o-mini\")\n</code></pre> <p>Parameters: - <code>model</code> (str): LLM model name. Supported models:   - OpenAI: <code>gpt-4o-mini</code>, <code>gpt-4o</code>, <code>gpt-4-turbo</code>, <code>gpt-3.5-turbo</code>   - Anthropic: <code>claude-3-5-sonnet</code>, <code>claude-3-opus</code>, <code>claude-3-sonnet</code>   - Google: <code>gemini-1.5-pro</code>, <code>gemini-1.5-flash</code></p> <p>Example: <pre><code>from kagura.core.compression import TokenCounter\n\ncounter = TokenCounter(model=\"gpt-4o-mini\")\n</code></pre></p>"},{"location":"en/api/compression/#methods","title":"Methods","text":""},{"location":"en/api/compression/#count_tokens","title":"count_tokens","text":"<p>Count tokens in text.</p> <pre><code>def count_tokens(text: str) -&gt; int\n</code></pre> <p>Parameters: - <code>text</code> (str): Text to count</p> <p>Returns: - <code>int</code>: Number of tokens</p> <p>Example: <pre><code>counter = TokenCounter()\ntokens = counter.count_tokens(\"Hello, world!\")\nprint(f\"Tokens: {tokens}\")  # Tokens: 4\n</code></pre></p>"},{"location":"en/api/compression/#count_tokens_messages","title":"count_tokens_messages","text":"<p>Count tokens in message list (OpenAI format).</p> <p>Includes overhead for message formatting (3 tokens per message + 3 tokens reply priming).</p> <pre><code>def count_tokens_messages(messages: list[dict[str, Any]]) -&gt; int\n</code></pre> <p>Parameters: - <code>messages</code> (list[dict]): List of messages with <code>role</code> and <code>content</code> fields</p> <p>Returns: - <code>int</code>: Total token count including overhead</p> <p>Example: <pre><code>messages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Hello!\"},\n    {\"role\": \"assistant\", \"content\": \"Hi there!\"}\n]\n\ntokens = counter.count_tokens_messages(messages)\nprint(f\"Total tokens: {tokens}\")\n</code></pre></p>"},{"location":"en/api/compression/#estimate_context_size","title":"estimate_context_size","text":"<p>Estimate total context window usage.</p> <pre><code>def estimate_context_size(\n    messages: list[dict[str, Any]],\n    system_prompt: str = \"\",\n    max_tokens: int = 1000\n) -&gt; dict[str, int]\n</code></pre> <p>Parameters: - <code>messages</code>: Conversation history - <code>system_prompt</code>: System prompt (default: \"\") - <code>max_tokens</code>: Max completion tokens (default: 1000)</p> <p>Returns: - Dictionary with keys:   - <code>prompt_tokens</code> (int): Tokens in prompts   - <code>completion_tokens</code> (int): Reserved for completion   - <code>total_tokens</code> (int): Total tokens</p> <p>Example: <pre><code>estimate = counter.estimate_context_size(\n    messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n    system_prompt=\"Be helpful.\",\n    max_tokens=1000\n)\n\nprint(f\"Prompt tokens: {estimate['prompt_tokens']}\")\nprint(f\"Total tokens: {estimate['total_tokens']}\")\n</code></pre></p>"},{"location":"en/api/compression/#should_compress","title":"should_compress","text":"<p>Decide if compression is needed.</p> <pre><code>def should_compress(\n    current_tokens: int,\n    max_tokens: int,\n    threshold: float = 0.8\n) -&gt; bool\n</code></pre> <p>Parameters: - <code>current_tokens</code>: Current token count - <code>max_tokens</code>: Maximum allowed tokens - <code>threshold</code>: Trigger compression at this ratio (default: 0.8 = 80%)</p> <p>Returns: - <code>bool</code>: True if compression should be triggered</p> <p>Example: <pre><code># Check if compression needed\nif counter.should_compress(current_tokens=9000, max_tokens=10000):\n    print(\"Time to compress!\")\n</code></pre></p>"},{"location":"en/api/compression/#get_model_limits","title":"get_model_limits","text":"<p>Get token limits for specific model.</p> <pre><code>def get_model_limits(model: str) -&gt; dict[str, int]\n</code></pre> <p>Parameters: - <code>model</code> (str): Model name</p> <p>Returns: - Dictionary with keys:   - <code>context_window</code> (int): Maximum context window size   - <code>max_completion</code> (int): Maximum completion tokens</p> <p>Example: <pre><code>limits = counter.get_model_limits(\"gpt-4o-mini\")\nprint(f\"Context window: {limits['context_window']:,}\")  # 128,000\nprint(f\"Max completion: {limits['max_completion']:,}\")  # 16,384\n</code></pre></p> <p>Supported Models:</p> Model Context Window Max Completion gpt-4o-mini 128,000 16,384 gpt-4o 128,000 16,384 gpt-4-turbo 128,000 4,096 gpt-3.5-turbo 16,385 4,096 claude-3-5-sonnet 200,000 8,192 claude-3-opus 200,000 4,096 gemini-1.5-pro 2,000,000 8,192 gemini-1.5-flash 1,000,000 8,192 unknown 8,000 2,000"},{"location":"en/api/compression/#contextmonitor","title":"ContextMonitor","text":"<p>Monitor context window usage and recommend compression.</p>"},{"location":"en/api/compression/#constructor_1","title":"Constructor","text":"<pre><code>ContextMonitor(\n    token_counter: TokenCounter,\n    max_tokens: Optional[int] = None\n)\n</code></pre> <p>Parameters: - <code>token_counter</code>: TokenCounter instance - <code>max_tokens</code>: Max context window (if None, auto-detect from model)</p> <p>Auto-detection: When <code>max_tokens=None</code>, the monitor automatically calculates the safe limit as: <pre><code>max_tokens = model_context_window - 4000\n</code></pre></p> <p>This reserves 4000 tokens for completion.</p> <p>Example: <pre><code>from kagura.core.compression import TokenCounter, ContextMonitor\n\ncounter = TokenCounter(model=\"gpt-4o-mini\")\n\n# Explicit limit\nmonitor = ContextMonitor(counter, max_tokens=10000)\n\n# Auto-detect (128k - 4k = 124k for gpt-4o-mini)\nmonitor_auto = ContextMonitor(counter, max_tokens=None)\n</code></pre></p>"},{"location":"en/api/compression/#methods_1","title":"Methods","text":""},{"location":"en/api/compression/#check_usage","title":"check_usage","text":"<p>Check current context usage.</p> <pre><code>def check_usage(\n    messages: list[dict[str, Any]],\n    system_prompt: str = \"\"\n) -&gt; ContextUsage\n</code></pre> <p>Parameters: - <code>messages</code>: Message history - <code>system_prompt</code>: System prompt (default: \"\")</p> <p>Returns: - <code>ContextUsage</code>: Usage statistics</p> <p>Example: <pre><code>messages = [\n    {\"role\": \"user\", \"content\": \"Hello\"},\n    {\"role\": \"assistant\", \"content\": \"Hi!\"}\n]\n\nusage = monitor.check_usage(messages, system_prompt=\"Be helpful.\")\n\nprint(f\"Usage: {usage.usage_ratio:.1%}\")  # e.g., 5.2%\nprint(f\"Tokens: {usage.total_tokens} / {usage.max_tokens}\")\n\nif usage.should_compress:\n    print(\"\u26a0\ufe0f Context is getting full. Compression recommended!\")\n</code></pre></p>"},{"location":"en/api/compression/#contextusage","title":"ContextUsage","text":"<p>Context usage statistics (dataclass).</p>"},{"location":"en/api/compression/#attributes","title":"Attributes","text":"<ul> <li><code>prompt_tokens</code> (int): Tokens in prompts (messages + system prompt)</li> <li><code>completion_tokens</code> (int): Reserved for completion</li> <li><code>total_tokens</code> (int): Total tokens (prompt + completion)</li> <li><code>max_tokens</code> (int): Maximum allowed tokens</li> <li><code>usage_ratio</code> (float): Usage ratio (0.0 - 1.0)</li> <li><code>should_compress</code> (bool): Whether compression is recommended</li> </ul> <p>Example: <pre><code>&gt;&gt;&gt; usage = monitor.check_usage(messages)\n&gt;&gt;&gt; usage\nContextUsage(\n    prompt_tokens=500,\n    completion_tokens=4000,\n    total_tokens=4500,\n    max_tokens=10000,\n    usage_ratio=0.45,\n    should_compress=False\n)\n</code></pre></p>"},{"location":"en/api/compression/#exceptions","title":"Exceptions","text":""},{"location":"en/api/compression/#compressionerror","title":"CompressionError","text":"<p>Base exception for compression errors.</p> <pre><code>class CompressionError(Exception)\n</code></pre>"},{"location":"en/api/compression/#tokencounterror","title":"TokenCountError","text":"<p>Error during token counting.</p> <pre><code>class TokenCountError(CompressionError)\n</code></pre> <p>Example: <pre><code>from kagura.core.compression import TokenCountError\n\ntry:\n    tokens = counter.count_tokens(text)\nexcept TokenCountError as e:\n    print(f\"Failed to count tokens: {e}\")\n</code></pre></p>"},{"location":"en/api/compression/#modelnotsupportederror","title":"ModelNotSupportedError","text":"<p>Model is not supported.</p> <pre><code>class ModelNotSupportedError(CompressionError)\n</code></pre>"},{"location":"en/api/compression/#installation","title":"Installation","text":"<p>Install with compression support:</p> <pre><code>pip install kagura-ai[ai]\n\n# Or install all features\npip install kagura-ai[all]\n</code></pre>"},{"location":"en/api/compression/#see-also","title":"See Also","text":"<ul> <li>Context Compression Guide - User guide with examples</li> <li>RFC-024 - Full specification</li> <li>Memory Management API - Memory system (will integrate in Phase 4)</li> </ul> <p>Phase 1 provides token counting and monitoring. Phases 2-4 will add trimming, summarization, and automatic compression.</p>"},{"location":"en/api/executor/","title":"Code Executor","text":"<p>The Code Executor provides safe Python code generation and execution capabilities in Kagura AI 2.0.</p>"},{"location":"en/api/executor/#overview","title":"Overview","text":"<p>The code execution system consists of: 1. CodeExecutor: Low-level code execution with security constraints 2. execute_code(): High-level agent that generates and executes code from natural language</p>"},{"location":"en/api/executor/#execute_code-function","title":"execute_code() Function","text":"<p>The simplest way to use code execution is through the <code>execute_code()</code> convenience function.</p>"},{"location":"en/api/executor/#signature","title":"Signature","text":"<pre><code>async def execute_code(task: str, *, model: str = \"gpt-4o-mini\") -&gt; dict\n</code></pre>"},{"location":"en/api/executor/#parameters","title":"Parameters","text":"<ul> <li>task (<code>str</code>): Natural language description of what to calculate or compute</li> <li>model (<code>str</code>, optional): LLM model to use for code generation</li> </ul>"},{"location":"en/api/executor/#return-value","title":"Return Value","text":"<p>Returns a dictionary with the following keys:</p> <pre><code>{\n    \"success\": bool,          # True if execution succeeded\n    \"code\": str,              # Generated Python code\n    \"result\": Any,            # Value of the 'result' variable\n    \"error\": str | None,      # Error message if failed\n}\n</code></pre>"},{"location":"en/api/executor/#examples","title":"Examples","text":""},{"location":"en/api/executor/#basic-calculation","title":"Basic Calculation","text":"<pre><code>from kagura.agents import execute_code\n\nresult = await execute_code(\"Calculate the factorial of 10\")\n\nif result[\"success\"]:\n    print(f\"Code:\\n{result['code']}\\n\")\n    print(f\"Result: {result['result']}\")\n    # Code:\n    # import math\n    # result = math.factorial(10)\n    #\n    # Result: 3628800\nelse:\n    print(f\"Error: {result['error']}\")\n</code></pre>"},{"location":"en/api/executor/#string-processing","title":"String Processing","text":"<pre><code>result = await execute_code(\"Reverse the string 'Hello, World!' and make it uppercase\")\n\nif result[\"success\"]:\n    print(result['result'])  # \"!DLROW ,OLLEH\"\n</code></pre>"},{"location":"en/api/executor/#list-operations","title":"List Operations","text":"<pre><code>result = await execute_code(\"Create a list of squares of numbers from 1 to 10\")\n\nif result[\"success\"]:\n    print(result['result'])  # [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n</code></pre>"},{"location":"en/api/executor/#statistical-analysis","title":"Statistical Analysis","text":"<pre><code>result = await execute_code(\n    \"Calculate the mean and standard deviation of [10, 20, 30, 40, 50]\"\n)\n\nif result[\"success\"]:\n    print(result['result'])\n    # {'mean': 30.0, 'stdev': 15.811388300841896}\n</code></pre>"},{"location":"en/api/executor/#error-handling","title":"Error Handling","text":"<pre><code>result = await execute_code(\"Divide 100 by 0\")\n\nif not result[\"success\"]:\n    print(f\"Error: {result['error']}\")\n    # Error: division by zero\n</code></pre>"},{"location":"en/api/executor/#codeexecutor-class","title":"CodeExecutor Class","text":"<p>For more control, use the <code>CodeExecutor</code> class directly.</p>"},{"location":"en/api/executor/#signature_1","title":"Signature","text":"<pre><code>class CodeExecutor:\n    def __init__(\n        self,\n        timeout: float = 30.0,\n        max_memory: int = 512 * 1024 * 1024,  # 512MB\n        allowed_imports: set[str] | None = None\n    )\n</code></pre>"},{"location":"en/api/executor/#parameters_1","title":"Parameters","text":"<ul> <li>timeout (<code>float</code>, default: <code>30.0</code>): Maximum execution time in seconds</li> <li>max_memory (<code>int</code>, default: <code>512MB</code>): Maximum memory usage in bytes</li> <li>allowed_imports (<code>set[str] | None</code>): Set of allowed import modules. If <code>None</code>, uses default safe list.</li> </ul>"},{"location":"en/api/executor/#methods","title":"Methods","text":""},{"location":"en/api/executor/#execute","title":"execute()","text":"<pre><code>async def execute(self, code: str) -&gt; ExecutionResult\n</code></pre> <p>Executes Python code and returns the result.</p> <p>Parameters: - code (<code>str</code>): Python code to execute. Must set a variable named <code>result</code>.</p> <p>Returns: - <code>ExecutionResult</code> object with fields:   - <code>success</code> (<code>bool</code>): Whether execution succeeded   - <code>result</code> (<code>Any</code>): Value of the <code>result</code> variable   - <code>error</code> (<code>str | None</code>): Error message if failed   - <code>stdout</code> (<code>str</code>): Captured stdout output   - <code>stderr</code> (<code>str</code>): Captured stderr output</p>"},{"location":"en/api/executor/#examples_1","title":"Examples","text":""},{"location":"en/api/executor/#basic-usage","title":"Basic Usage","text":"<pre><code>from kagura.core.executor import CodeExecutor\n\nexecutor = CodeExecutor()\n\nresult = await executor.execute(\"\"\"\nimport math\nresult = math.sqrt(16)\n\"\"\")\n\nprint(result.success)  # True\nprint(result.result)   # 4.0\n</code></pre>"},{"location":"en/api/executor/#custom-timeout","title":"Custom Timeout","text":"<pre><code>executor = CodeExecutor(timeout=60.0)\n\nresult = await executor.execute(\"\"\"\nimport time\ntime.sleep(2)\nresult = \"completed\"\n\"\"\")\n</code></pre>"},{"location":"en/api/executor/#capturing-output","title":"Capturing Output","text":"<pre><code>result = await executor.execute(\"\"\"\nprint(\"Debug message\")\nresult = 42\n\"\"\")\n\nprint(result.stdout)  # \"Debug message\\n\"\nprint(result.result)  # 42\n</code></pre>"},{"location":"en/api/executor/#security-features","title":"Security Features","text":"<p>The Code Executor has built-in security constraints to prevent malicious code execution.</p>"},{"location":"en/api/executor/#forbidden-imports","title":"Forbidden Imports","text":"<p>The following modules are blocked by default:</p> <ul> <li>System Access: <code>os</code>, <code>sys</code>, <code>subprocess</code>, <code>shutil</code></li> <li>File I/O: <code>open</code> (built-in), <code>io</code> (restricted)</li> <li>Network: <code>socket</code>, <code>urllib</code>, <code>requests</code>, <code>http</code></li> <li>Process Control: <code>multiprocessing</code>, <code>threading</code> (restricted)</li> <li>Code Execution: <code>eval</code>, <code>exec</code>, <code>compile</code> (built-in)</li> <li>Dangerous Modules: <code>pickle</code>, <code>ctypes</code>, <code>importlib</code></li> </ul>"},{"location":"en/api/executor/#allowed-imports","title":"Allowed Imports","text":"<p>Safe modules that are allowed by default:</p> <pre><code>ALLOWED_IMPORTS = {\n    \"math\",\n    \"statistics\",\n    \"random\",\n    \"datetime\",\n    \"json\",\n    \"re\",\n    \"collections\",\n    \"itertools\",\n    \"functools\",\n    \"typing\",\n}\n</code></pre>"},{"location":"en/api/executor/#ast-validation","title":"AST Validation","text":"<p>Before execution, code is analyzed using Python's Abstract Syntax Tree (AST) to detect:</p> <ul> <li>Forbidden function calls (<code>eval</code>, <code>exec</code>, <code>open</code>, etc.)</li> <li>Forbidden imports</li> <li>Dangerous operations</li> </ul> <p>Example validation error:</p> <pre><code>result = await executor.execute(\"\"\"\nimport os\nresult = os.system('ls')\n\"\"\")\n\nprint(result.error)\n# \"Forbidden import: os\"\n</code></pre>"},{"location":"en/api/executor/#resource-limits","title":"Resource Limits","text":"<ul> <li>Timeout: Code execution is terminated after the timeout period</li> <li>Memory: Process memory is monitored (platform-dependent)</li> <li>CPU: No infinite loops allowed (enforced via timeout)</li> </ul>"},{"location":"en/api/executor/#advanced-usage","title":"Advanced Usage","text":""},{"location":"en/api/executor/#custom-allowed-imports","title":"Custom Allowed Imports","text":"<pre><code>executor = CodeExecutor(\n    allowed_imports={\"math\", \"numpy\", \"pandas\"}\n)\n\nresult = await executor.execute(\"\"\"\nimport numpy as np\nresult = np.array([1, 2, 3]).mean()\n\"\"\")\n</code></pre>"},{"location":"en/api/executor/#error-recovery","title":"Error Recovery","text":"<pre><code>executor = CodeExecutor()\n\ncode = \"\"\"\nimport math\nresult = math.factorial(10)\n\"\"\"\n\ntry:\n    result = await executor.execute(code)\n    if result.success:\n        print(f\"Success: {result.result}\")\n    else:\n        print(f\"Execution error: {result.error}\")\nexcept TimeoutError:\n    print(\"Code execution timed out\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"en/api/executor/#combining-with-agents","title":"Combining with Agents","text":"<pre><code>from kagura import agent\nfrom kagura.core.executor import CodeExecutor\n\nexecutor = CodeExecutor()\n\n@agent\nasync def generate_code(task: str) -&gt; str:\n    '''Generate Python code to: {{ task }}\n\n    Return only the code, nothing else.\n    '''\n    pass\n\nasync def run_task(task: str):\n    # Generate code\n    code = await generate_code(task)\n\n    # Execute code\n    result = await executor.execute(code)\n\n    return result\n\n# Use it\nresult = await run_task(\"Calculate fibonacci(15)\")\nprint(result.result)\n</code></pre>"},{"location":"en/api/executor/#best-practices","title":"Best Practices","text":""},{"location":"en/api/executor/#1-always-check-success","title":"1. Always Check Success","text":"<pre><code>result = await execute_code(\"some task\")\n\nif result[\"success\"]:\n    # Use result[\"result\"]\n    process(result[\"result\"])\nelse:\n    # Handle error\n    log_error(result[\"error\"])\n</code></pre>"},{"location":"en/api/executor/#2-set-appropriate-timeouts","title":"2. Set Appropriate Timeouts","text":"<pre><code># Short tasks\nexecutor = CodeExecutor(timeout=5.0)\n\n# Long computations\nexecutor = CodeExecutor(timeout=300.0)\n</code></pre>"},{"location":"en/api/executor/#3-use-result-variable","title":"3. Use result Variable","text":"<p>The executor looks for a variable named <code>result</code>:</p> <pre><code># Good\nresult = await executor.execute(\"\"\"\nx = 10\ny = 20\nresult = x + y\n\"\"\")\n\n# Won't work - no 'result' variable\nresult = await executor.execute(\"\"\"\nx = 10\ny = 20\nprint(x + y)\n\"\"\")\n</code></pre>"},{"location":"en/api/executor/#4-handle-errors-gracefully","title":"4. Handle Errors Gracefully","text":"<pre><code>result = await execute_code(task)\n\nif not result[\"success\"]:\n    # Retry with more explicit instructions\n    task = f\"{task}. Show step by step.\"\n    result = await execute_code(task)\n</code></pre>"},{"location":"en/api/executor/#limitations","title":"Limitations","text":"<ol> <li>No File I/O: Cannot read or write files</li> <li>No Network Access: Cannot make HTTP requests</li> <li>No System Commands: Cannot execute shell commands</li> <li>Limited Libraries: Only safe, pre-approved libraries</li> <li>Memory Constraints: Large data structures may fail</li> <li>Execution Time: Long-running code will timeout</li> </ol>"},{"location":"en/api/executor/#security-considerations","title":"Security Considerations","text":"<p>\u26a0\ufe0f Important: While the Code Executor has security constraints, it should still be used with caution:</p> <ol> <li>User Input: Be careful with untrusted user input</li> <li>Production Use: Consider additional sandboxing for production</li> <li>Resource Limits: Set appropriate timeouts and memory limits</li> <li>Monitoring: Log all code execution for auditing</li> </ol>"},{"location":"en/api/executor/#related","title":"Related","text":"<ul> <li>@agent Decorator - Creating AI agents</li> <li>Code Generator Example - Full example</li> <li>Quick Start - Getting started</li> </ul>"},{"location":"en/api/hooks/","title":"Hooks API","text":"<p>Hooks allow you to intercept and modify command execution flow.</p>"},{"location":"en/api/hooks/#overview","title":"Overview","text":"<p>The hooks system provides three types of hooks:</p> <ol> <li>PreToolUse: Execute before a tool is invoked</li> <li>PostToolUse: Execute after a tool completes</li> <li>Validation: Validate command parameters before execution</li> </ol> <p>Hooks can: - \u2705 Block execution - \u2705 Modify inputs - \u2705 Suggest alternatives - \u2705 Log execution</p>"},{"location":"en/api/hooks/#hookresult-class","title":"HookResult Class","text":"<p>Result from hook execution.</p>"},{"location":"en/api/hooks/#constructor","title":"Constructor","text":"<pre><code>HookResult(\n    action: HookAction,\n    message: Optional[str] = None,\n    modified_input: Optional[dict[str, Any]] = None\n)\n</code></pre>"},{"location":"en/api/hooks/#factory-methods","title":"Factory Methods","text":""},{"location":"en/api/hooks/#ok","title":"ok","text":"<pre><code>HookResult.ok(message: Optional[str] = None) -&gt; HookResult\n</code></pre> <p>Continue execution normally.</p> <p>Example:</p> <pre><code>@hook.pre_tool_use(\"bash\")\ndef allow_command(tool_input):\n    return HookResult.ok(\"Command allowed\")\n</code></pre>"},{"location":"en/api/hooks/#block","title":"block","text":"<pre><code>HookResult.block(message: str) -&gt; HookResult\n</code></pre> <p>Block execution with error message.</p> <p>Example:</p> <pre><code>@hook.pre_tool_use(\"bash\")\ndef block_dangerous(tool_input):\n    if \"rm -rf /\" in tool_input[\"command\"]:\n        return HookResult.block(\"Dangerous command blocked!\")\n    return HookResult.ok()\n</code></pre>"},{"location":"en/api/hooks/#suggest","title":"suggest","text":"<pre><code>HookResult.suggest(message: str) -&gt; HookResult\n</code></pre> <p>Suggest an alternative (doesn't block execution).</p> <p>Example:</p> <pre><code>@hook.pre_tool_use(\"bash\")\ndef suggest_alternative(tool_input):\n    if \"grep\" in tool_input[\"command\"]:\n        return HookResult.suggest(\"Consider using 'rg' instead\")\n    return HookResult.ok()\n</code></pre>"},{"location":"en/api/hooks/#modify","title":"modify","text":"<pre><code>HookResult.modify(\n    modified_input: dict[str, Any],\n    message: Optional[str] = None\n) -&gt; HookResult\n</code></pre> <p>Modify input before execution.</p> <p>Example:</p> <pre><code>@hook.pre_tool_use(\"bash\")\ndef add_safety_flag(tool_input):\n    cmd = tool_input[\"command\"]\n    if cmd.startswith(\"rm \"):\n        modified = {\"command\": f\"{cmd} --interactive\"}\n        return HookResult.modify(modified, \"Added --interactive flag\")\n    return HookResult.ok()\n</code></pre>"},{"location":"en/api/hooks/#methods","title":"Methods","text":""},{"location":"en/api/hooks/#is_ok","title":"is_ok","text":"<pre><code>result.is_ok() -&gt; bool\n</code></pre> <p>Check if result allows execution.</p>"},{"location":"en/api/hooks/#is_blocked","title":"is_blocked","text":"<pre><code>result.is_blocked() -&gt; bool\n</code></pre> <p>Check if result blocks execution.</p>"},{"location":"en/api/hooks/#hook-class","title":"Hook Class","text":"<p>Base hook class.</p>"},{"location":"en/api/hooks/#constructor_1","title":"Constructor","text":"<pre><code>Hook(\n    name: str,\n    hook_type: HookType,\n    matcher: str,\n    callback: Callable[[dict[str, Any]], HookResult],\n    enabled: bool = True\n)\n</code></pre> <p>Parameters:</p> <ul> <li><code>name</code>: Hook name (unique identifier)</li> <li><code>hook_type</code>: Type of hook (PRE_TOOL_USE, POST_TOOL_USE, VALIDATION)</li> <li><code>matcher</code>: Tool name pattern (<code>\"bash\"</code>, <code>\"git\"</code>, <code>\"*\"</code> for all)</li> <li><code>callback</code>: Function to call when hook is triggered</li> <li><code>enabled</code>: Whether hook is active</li> </ul> <p>Example:</p> <pre><code>from kagura.commands import Hook, HookType, HookResult\n\ndef validate_bash(tool_input):\n    if dangerous(tool_input[\"command\"]):\n        return HookResult.block(\"Blocked!\")\n    return HookResult.ok()\n\nhook = Hook(\n    name=\"bash-validator\",\n    hook_type=HookType.PRE_TOOL_USE,\n    matcher=\"bash\",\n    callback=validate_bash\n)\n</code></pre>"},{"location":"en/api/hooks/#methods_1","title":"Methods","text":""},{"location":"en/api/hooks/#matches","title":"matches","text":"<pre><code>hook.matches(tool_name: str) -&gt; bool\n</code></pre> <p>Check if hook applies to the given tool.</p> <p>Example:</p> <pre><code>bash_hook = Hook(..., matcher=\"bash\", ...)\nbash_hook.matches(\"bash\")  # True\nbash_hook.matches(\"git\")   # False\n\nall_hook = Hook(..., matcher=\"*\", ...)\nall_hook.matches(\"bash\")  # True\nall_hook.matches(\"git\")   # True\n</code></pre>"},{"location":"en/api/hooks/#execute","title":"execute","text":"<pre><code>hook.execute(tool_input: dict[str, Any]) -&gt; HookResult\n</code></pre> <p>Execute hook callback.</p> <p>Parameters:</p> <ul> <li><code>tool_input</code>: Input dictionary containing tool information</li> </ul> <p>Returns: HookResult</p>"},{"location":"en/api/hooks/#hookregistry-class","title":"HookRegistry Class","text":"<p>Registry for managing hooks.</p>"},{"location":"en/api/hooks/#constructor_2","title":"Constructor","text":"<pre><code>HookRegistry()\n</code></pre> <p>Creates a new hook registry.</p>"},{"location":"en/api/hooks/#methods_2","title":"Methods","text":""},{"location":"en/api/hooks/#register","title":"register","text":"<pre><code>registry.register(hook: Hook) -&gt; None\n</code></pre> <p>Register a hook.</p> <p>Example:</p> <pre><code>from kagura.commands import HookRegistry, Hook, HookType, HookResult\n\nregistry = HookRegistry()\n\ndef callback(tool_input):\n    return HookResult.ok()\n\nhook = Hook(\n    name=\"my-hook\",\n    hook_type=HookType.PRE_TOOL_USE,\n    matcher=\"bash\",\n    callback=callback\n)\n\nregistry.register(hook)\n</code></pre>"},{"location":"en/api/hooks/#unregister","title":"unregister","text":"<pre><code>registry.unregister(\n    hook_name: str,\n    hook_type: Optional[HookType] = None\n) -&gt; bool\n</code></pre> <p>Unregister a hook by name.</p> <p>Returns: <code>True</code> if removed, <code>False</code> if not found</p> <p>Example:</p> <pre><code>removed = registry.unregister(\"my-hook\")\nif removed:\n    print(\"Hook removed\")\n</code></pre>"},{"location":"en/api/hooks/#get_hooks","title":"get_hooks","text":"<pre><code>registry.get_hooks(hook_type: HookType, tool_name: str) -&gt; list[Hook]\n</code></pre> <p>Get all hooks matching the given type and tool.</p> <p>Example:</p> <pre><code># Get all pre-tool-use hooks for bash\nhooks = registry.get_hooks(HookType.PRE_TOOL_USE, \"bash\")\n</code></pre>"},{"location":"en/api/hooks/#execute_hooks","title":"execute_hooks","text":"<pre><code>registry.execute_hooks(\n    hook_type: HookType,\n    tool_name: str,\n    tool_input: dict[str, Any]\n) -&gt; list[HookResult]\n</code></pre> <p>Execute all matching hooks.</p> <p>Returns: List of HookResult (stops on first block)</p> <p>Example:</p> <pre><code>results = registry.execute_hooks(\n    HookType.PRE_TOOL_USE,\n    \"bash\",\n    {\"command\": \"ls\"}\n)\n\nfor result in results:\n    if result.is_blocked():\n        print(f\"Blocked: {result.message}\")\n</code></pre>"},{"location":"en/api/hooks/#clear","title":"clear","text":"<pre><code>registry.clear(hook_type: Optional[HookType] = None) -&gt; None\n</code></pre> <p>Clear hooks. If <code>hook_type</code> is None, clears all hooks.</p> <p>Example:</p> <pre><code># Clear only pre-tool-use hooks\nregistry.clear(HookType.PRE_TOOL_USE)\n\n# Clear all hooks\nregistry.clear()\n</code></pre>"},{"location":"en/api/hooks/#count","title":"count","text":"<pre><code>registry.count(hook_type: Optional[HookType] = None) -&gt; int\n</code></pre> <p>Count registered hooks.</p> <p>Example:</p> <pre><code># Count all hooks\ntotal = registry.count()\n\n# Count specific type\npre_hooks = registry.count(HookType.PRE_TOOL_USE)\n</code></pre>"},{"location":"en/api/hooks/#decorator-api","title":"Decorator API","text":"<p>Convenient decorators for registering hooks.</p>"},{"location":"en/api/hooks/#hookpre_tool_use","title":"@hook.pre_tool_use","text":"<pre><code>@hook.pre_tool_use(matcher: str = \"*\", name: str | None = None)\n</code></pre> <p>Decorator for PreToolUse hooks.</p> <p>Parameters:</p> <ul> <li><code>matcher</code>: Tool name pattern (default: <code>\"*\"</code> for all)</li> <li><code>name</code>: Optional hook name (default: function name)</li> </ul> <p>Example:</p> <pre><code>from kagura.commands import hook, HookResult\n\n@hook.pre_tool_use(\"bash\")\ndef validate_bash(tool_input):\n    cmd = tool_input.get(\"command\", \"\")\n    if \"rm -rf /\" in cmd:\n        return HookResult.block(\"Dangerous command!\")\n    return HookResult.ok()\n\n@hook.pre_tool_use(\"*\")  # All tools\ndef log_all(tool_input):\n    print(f\"Tool: {tool_input}\")\n    return HookResult.ok()\n</code></pre>"},{"location":"en/api/hooks/#hookpost_tool_use","title":"@hook.post_tool_use","text":"<pre><code>@hook.post_tool_use(matcher: str = \"*\", name: str | None = None)\n</code></pre> <p>Decorator for PostToolUse hooks.</p> <p>Parameters:</p> <ul> <li><code>matcher</code>: Tool name pattern</li> <li><code>name</code>: Optional hook name</li> </ul> <p>Example:</p> <pre><code>@hook.post_tool_use(\"git\")\ndef log_git_usage(tool_input):\n    cmd = tool_input.get(\"command\", \"\")\n    output = tool_input.get(\"output\", \"\")\n    print(f\"Git command '{cmd}' executed\")\n    print(f\"Output: {output}\")\n    return HookResult.ok()\n</code></pre>"},{"location":"en/api/hooks/#hookvalidation","title":"@hook.validation","text":"<pre><code>@hook.validation(matcher: str = \"*\", name: str | None = None)\n</code></pre> <p>Decorator for Validation hooks.</p> <p>Parameters:</p> <ul> <li><code>matcher</code>: Command name pattern</li> <li><code>name</code>: Optional hook name</li> </ul> <p>Example:</p> <pre><code>@hook.validation(\"*\")\ndef validate_parameters(tool_input):\n    params = tool_input.get(\"parameters\", {})\n    if not params:\n        return HookResult.block(\"Parameters required!\")\n    return HookResult.ok()\n</code></pre>"},{"location":"en/api/hooks/#global-registry","title":"Global Registry","text":"<pre><code>from kagura.commands import get_registry\n\nregistry = get_registry()\n</code></pre> <p>Get the global hook registry used by CommandExecutor.</p> <p>Example:</p> <pre><code>from kagura.commands import get_registry, Hook, HookType, HookResult\n\n# Get global registry\nregistry = get_registry()\n\n# Register hook directly\ndef callback(tool_input):\n    return HookResult.ok()\n\nhook = Hook(\n    name=\"custom\",\n    hook_type=HookType.PRE_TOOL_USE,\n    matcher=\"bash\",\n    callback=callback\n)\nregistry.register(hook)\n\n# Or use decorator (automatically uses global registry)\nfrom kagura.commands import hook\n\n@hook.pre_tool_use(\"bash\")\ndef validate(tool_input):\n    return HookResult.ok()\n</code></pre>"},{"location":"en/api/hooks/#complete-example","title":"Complete Example","text":"<pre><code>from kagura.commands import (\n    Command,\n    CommandExecutor,\n    hook,\n    HookResult,\n    get_registry\n)\n\n# Define hooks using decorators\n@hook.pre_tool_use(\"bash\")\ndef block_dangerous(tool_input):\n    \"\"\"Block dangerous bash commands.\"\"\"\n    cmd = tool_input.get(\"command\", \"\")\n\n    dangerous_patterns = [\"rm -rf /\", \":(){ :|:&amp; };:\"]\n    for pattern in dangerous_patterns:\n        if pattern in cmd:\n            return HookResult.block(\n                f\"Dangerous command blocked: {pattern}\"\n            )\n\n    return HookResult.ok()\n\n@hook.pre_tool_use(\"bash\")\ndef suggest_safer(tool_input):\n    \"\"\"Suggest safer alternatives.\"\"\"\n    cmd = tool_input.get(\"command\", \"\")\n\n    if cmd.startswith(\"rm \") and \"--interactive\" not in cmd:\n        return HookResult.suggest(\n            \"Consider using 'rm --interactive' for safety\"\n        )\n\n    return HookResult.ok()\n\n@hook.post_tool_use(\"*\")\ndef log_execution(tool_input):\n    \"\"\"Log all tool executions.\"\"\"\n    tool = tool_input.get(\"tool\", \"unknown\")\n    cmd = tool_input.get(\"command\", \"\")\n    print(f\"[LOG] {tool}: {cmd}\")\n    return HookResult.ok()\n\n@hook.validation(\"*\")\ndef ensure_parameters(tool_input):\n    \"\"\"Ensure required parameters are provided.\"\"\"\n    params = tool_input.get(\"parameters\", {})\n    cmd_name = tool_input.get(\"command_name\", \"\")\n\n    if cmd_name == \"deploy\" and \"environment\" not in params:\n        return HookResult.block(\n            \"Deployment requires 'environment' parameter\"\n        )\n\n    return HookResult.ok()\n\n# Create command\ncommand = Command(\n    name=\"deploy\",\n    description=\"Deploy application\",\n    template=\"Deploying to {{ environment }}: !`git rev-parse HEAD`\",\n    parameters={\"environment\": \"string\"}\n)\n\n# Execute (hooks are automatically applied)\nexecutor = CommandExecutor()\n\ntry:\n    result = executor.render(command, {\"environment\": \"production\"})\n    print(result)\nexcept ValueError as e:\n    print(f\"Validation failed: {e}\")\n</code></pre>"},{"location":"en/api/hooks/#hook-execution-order","title":"Hook Execution Order","text":"<ol> <li>Validation Hooks: Run before parameter validation</li> <li>Parameter Validation: Built-in validation (if hook didn't block)</li> <li>PreToolUse Hooks: Run before each inline command execution</li> <li>Tool Execution: Execute the actual command</li> <li>PostToolUse Hooks: Run after tool completes</li> </ol>"},{"location":"en/api/hooks/#see-also","title":"See Also","text":"<ul> <li>Hooks Guide - Usage guide with examples</li> <li>Commands API - Command system API</li> <li>CLI Reference - CLI commands</li> </ul>"},{"location":"en/api/mcp/","title":"MCP API Reference","text":""},{"location":"en/api/mcp/#overview","title":"Overview","text":"<p>The MCP (Model Context Protocol) module enables Kagura agents to be exposed as MCP tools, allowing integration with Claude Desktop, Claude Code, Cline, and other MCP-compatible clients.</p>"},{"location":"en/api/mcp/#module-kaguramcp","title":"Module: <code>kagura.mcp</code>","text":""},{"location":"en/api/mcp/#create_mcp_servername-str-kagura-ai-server","title":"<code>create_mcp_server(name: str = \"kagura-ai\") -&gt; Server</code>","text":"<p>Creates an MCP server instance that exposes registered Kagura agents as tools.</p> <p>Parameters: - <code>name</code> (str, optional): Server name. Defaults to \"kagura-ai\".</p> <p>Returns: - <code>Server</code>: Configured MCP server instance</p> <p>Example: <pre><code>from kagura.mcp import create_mcp_server\n\nserver = create_mcp_server(\"my-server\")\n</code></pre></p>"},{"location":"en/api/mcp/#module-kaguramcpschema","title":"Module: <code>kagura.mcp.schema</code>","text":""},{"location":"en/api/mcp/#generate_json_schemafunc-callable-dict","title":"<code>generate_json_schema(func: Callable) -&gt; dict</code>","text":"<p>Generates JSON Schema from a Python function signature.</p> <p>Parameters: - <code>func</code> (Callable): Function to generate schema for</p> <p>Returns: - <code>dict</code>: JSON Schema with <code>type</code>, <code>properties</code>, and optionally <code>required</code></p> <p>Example: <pre><code>from kagura.mcp.schema import generate_json_schema\n\ndef my_func(name: str, age: int = 18) -&gt; str:\n    \"\"\"Sample function\n\n    name: Person's name\n    age: Person's age\n    \"\"\"\n    pass\n\nschema = generate_json_schema(my_func)\n# {\n#     \"type\": \"object\",\n#     \"properties\": {\n#         \"name\": {\"type\": \"string\", \"description\": \"Person's name\"},\n#         \"age\": {\"type\": \"integer\", \"description\": \"Person's age\"}\n#     },\n#     \"required\": [\"name\"]\n# }\n</code></pre></p>"},{"location":"en/api/mcp/#python_type_to_json_schemapy_type-type-dict","title":"<code>python_type_to_json_schema(py_type: type) -&gt; dict</code>","text":"<p>Converts a Python type to JSON Schema format.</p> <p>Parameters: - <code>py_type</code> (type): Python type annotation</p> <p>Returns: - <code>dict</code>: JSON Schema representation</p> <p>Supported Types: - Basic: <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code> - Collections: <code>list[T]</code>, <code>dict[K, V]</code> - Optional: <code>T | None</code>, <code>Optional[T]</code> - Pydantic: <code>BaseModel</code> subclasses</p> <p>Example: <pre><code>from kagura.mcp.schema import python_type_to_json_schema\n\n# Basic types\npython_type_to_json_schema(str)\n# {\"type\": \"string\"}\n\n# Lists\npython_type_to_json_schema(list[int])\n# {\"type\": \"array\", \"items\": {\"type\": \"integer\"}}\n\n# Dicts\npython_type_to_json_schema(dict[str, float])\n# {\"type\": \"object\", \"additionalProperties\": {\"type\": \"number\"}}\n\n# Optional\npython_type_to_json_schema(str | None)\n# {\"type\": [\"string\", \"null\"]}\n</code></pre></p>"},{"location":"en/api/mcp/#module-kaguracoreregistry","title":"Module: <code>kagura.core.registry</code>","text":""},{"location":"en/api/mcp/#class-agentregistry","title":"<code>class AgentRegistry</code>","text":"<p>Global registry for all Kagura agents.</p>"},{"location":"en/api/mcp/#methods","title":"Methods","text":""},{"location":"en/api/mcp/#registername-str-func-callable-none","title":"<code>register(name: str, func: Callable) -&gt; None</code>","text":"<p>Register an agent.</p> <p>Parameters: - <code>name</code> (str): Agent name (must be unique) - <code>func</code> (Callable): Agent function</p> <p>Raises: - <code>ValueError</code>: If agent name is already registered</p> <p>Example: <pre><code>from kagura.core.registry import agent_registry\n\ndef my_agent():\n    pass\n\nagent_registry.register(\"my_agent\", my_agent)\n</code></pre></p>"},{"location":"en/api/mcp/#getname-str-callable-none","title":"<code>get(name: str) -&gt; Callable | None</code>","text":"<p>Get agent by name.</p> <p>Parameters: - <code>name</code> (str): Agent name</p> <p>Returns: - <code>Callable | None</code>: Agent function, or None if not found</p> <p>Example: <pre><code>agent_func = agent_registry.get(\"my_agent\")\nif agent_func:\n    result = await agent_func()\n</code></pre></p>"},{"location":"en/api/mcp/#get_all-dictstr-callable","title":"<code>get_all() -&gt; dict[str, Callable]</code>","text":"<p>Get all registered agents.</p> <p>Returns: - <code>dict[str, Callable]</code>: Dictionary of agent_name -&gt; agent_function</p> <p>Example: <pre><code>agents = agent_registry.get_all()\nfor name, func in agents.items():\n    print(f\"Agent: {name}\")\n</code></pre></p>"},{"location":"en/api/mcp/#list_names-liststr","title":"<code>list_names() -&gt; list[str]</code>","text":"<p>List all agent names.</p> <p>Returns: - <code>list[str]</code>: List of agent names</p> <p>Example: <pre><code>names = agent_registry.list_names()\nprint(f\"Registered agents: {', '.join(names)}\")\n</code></pre></p>"},{"location":"en/api/mcp/#unregistername-str-none","title":"<code>unregister(name: str) -&gt; None</code>","text":"<p>Unregister an agent.</p> <p>Parameters: - <code>name</code> (str): Agent name to remove</p> <p>Raises: - <code>KeyError</code>: If agent name is not registered</p>"},{"location":"en/api/mcp/#clear-none","title":"<code>clear() -&gt; None</code>","text":"<p>Clear all agents from registry.</p>"},{"location":"en/api/mcp/#auto_discovermodule_path-str-none","title":"<code>auto_discover(module_path: str) -&gt; None</code>","text":"<p>Auto-discover agents in a module.</p> <p>Parameters: - <code>module_path</code> (str): Python module path (e.g., \"my_package.agents\")</p> <p>Raises: - <code>ValueError</code>: If module is not found</p> <p>Example: <pre><code># Discover all agents in a module\nagent_registry.auto_discover(\"my_package.agents\")\n\n# All @agent decorated functions in the module are now registered\n</code></pre></p>"},{"location":"en/api/mcp/#global-instance-agent_registry","title":"Global Instance: <code>agent_registry</code>","text":"<p>A global <code>AgentRegistry</code> instance is available for use:</p> <pre><code>from kagura.core.registry import agent_registry\n\n# Agents decorated with @agent are automatically registered here\n</code></pre>"},{"location":"en/api/mcp/#cli-commands","title":"CLI Commands","text":""},{"location":"en/api/mcp/#kagura-mcp-serve","title":"<code>kagura mcp serve</code>","text":"<p>Start MCP server using stdio transport.</p> <p>Usage: <pre><code>kagura mcp serve [OPTIONS]\n</code></pre></p> <p>Options: - <code>--name TEXT</code>: Server name (default: \"kagura-ai\")</p> <p>Example: <pre><code># Start server\nkagura mcp serve\n\n# Custom server name\nkagura mcp serve --name my-server\n\n# Verbose logging\nkagura -v mcp serve\n</code></pre></p>"},{"location":"en/api/mcp/#kagura-mcp-list","title":"<code>kagura mcp list</code>","text":"<p>List all registered agents.</p> <p>Usage: <pre><code>kagura mcp list\n</code></pre></p> <p>Output: <pre><code>Registered agents (3):\n\n  \u2022 analyze_code\n    Analyze code quality and suggest improvements\n\n  \u2022 review_code\n    Review code and provide feedback\n\n  \u2022 generate_tests\n    Generate unit tests for the code\n</code></pre></p>"},{"location":"en/api/mcp/#agent-metadata","title":"Agent Metadata","text":"<p>Agents decorated with <code>@agent</code> have special attributes for MCP integration:</p>"},{"location":"en/api/mcp/#_is_agent-bool","title":"<code>_is_agent: bool</code>","text":"<p>Flag indicating this is a Kagura agent.</p> <pre><code>from kagura import agent\n\n@agent\nasync def my_agent():\n    pass\n\nprint(my_agent._is_agent)  # True\n</code></pre>"},{"location":"en/api/mcp/#_agent_config-llmconfig","title":"<code>_agent_config: LLMConfig</code>","text":"<p>LLM configuration for the agent.</p> <pre><code>print(my_agent._agent_config.model)  # \"gpt-4o-mini\"\nprint(my_agent._agent_config.temperature)  # 0.7\n</code></pre>"},{"location":"en/api/mcp/#_agent_template-str","title":"<code>_agent_template: str</code>","text":"<p>Jinja2 template extracted from docstring.</p> <pre><code>@agent\nasync def greet(name: str):\n    \"\"\"Say hello to {{ name }}\"\"\"\n    pass\n\nprint(greet._agent_template)  # \"Say hello to {{ name }}\"\n</code></pre>"},{"location":"en/api/mcp/#mcp-tool-naming","title":"MCP Tool Naming","text":"<p>Agents are exposed to MCP clients with the <code>kagura_</code> prefix:</p> Agent Function Name MCP Tool Name <code>analyze_code</code> <code>kagura_analyze_code</code> <code>review_code</code> <code>kagura_review_code</code> <code>translate</code> <code>kagura_translate</code> <p>This prefix prevents naming conflicts with other MCP tools.</p>"},{"location":"en/api/mcp/#type-conversion-table","title":"Type Conversion Table","text":""},{"location":"en/api/mcp/#python-json-schema","title":"Python \u2192 JSON Schema","text":"Python Type JSON Schema <code>str</code> <code>{\"type\": \"string\"}</code> <code>int</code> <code>{\"type\": \"integer\"}</code> <code>float</code> <code>{\"type\": \"number\"}</code> <code>bool</code> <code>{\"type\": \"boolean\"}</code> <code>list[T]</code> <code>{\"type\": \"array\", \"items\": {...}}</code> <code>dict[str, T]</code> <code>{\"type\": \"object\", \"additionalProperties\": {...}}</code> <code>T \\| None</code> <code>{\"type\": [\"T\", \"null\"]}</code> <code>BaseModel</code> Pydantic's <code>model_json_schema()</code>"},{"location":"en/api/mcp/#complete-example","title":"Complete Example","text":"<pre><code>from kagura import agent\nfrom kagura.core.registry import agent_registry\nfrom kagura.mcp import create_mcp_server\nfrom kagura.mcp.schema import generate_json_schema\n\n# Define agent\n@agent\nasync def analyze_sentiment(text: str, detailed: bool = False) -&gt; dict:\n    \"\"\"\n    Analyze sentiment of text\n\n    text: Text to analyze\n    detailed: Include detailed breakdown\n    \"\"\"\n    pass\n\n# Agent is automatically registered\nprint(agent_registry.get(\"analyze_sentiment\"))  # &lt;function ...&gt;\n\n# Generate schema\nschema = generate_json_schema(analyze_sentiment)\nprint(schema)\n# {\n#     \"type\": \"object\",\n#     \"properties\": {\n#         \"text\": {\"type\": \"string\", \"description\": \"Text to analyze\"},\n#         \"detailed\": {\"type\": \"boolean\", \"description\": \"Include detailed breakdown\"}\n#     },\n#     \"required\": [\"text\"]\n# }\n\n# Create MCP server\nserver = create_mcp_server()\n\n# Server exposes agent as \"kagura_analyze_sentiment\" tool\n</code></pre>"},{"location":"en/api/mcp/#see-also","title":"See Also","text":"<ul> <li>MCP Integration Tutorial</li> <li>CLI Reference</li> <li>Agent Decorator</li> <li>MCP Specification</li> </ul>"},{"location":"en/api/memory/","title":"Memory Management API","text":"<p>Kagura AI provides a comprehensive memory management system for building agents with persistent knowledge and context awareness.</p>"},{"location":"en/api/memory/#overview","title":"Overview","text":"<p>The memory system consists of four main components:</p> <ul> <li>WorkingMemory: Temporary storage during agent execution</li> <li>ContextMemory: Conversation history and session management</li> <li>PersistentMemory: Long-term storage using SQLite</li> <li>MemoryManager: Unified interface to all memory types</li> </ul>"},{"location":"en/api/memory/#memorymanager","title":"MemoryManager","text":"<p>The main interface for memory operations.</p>"},{"location":"en/api/memory/#constructor","title":"Constructor","text":"<pre><code>MemoryManager(\n    agent_name: Optional[str] = None,\n    persist_dir: Optional[Path] = None,\n    max_messages: int = 100\n)\n</code></pre> <p>Parameters:</p> <ul> <li><code>agent_name</code>: Optional agent name for scoping persistent memory</li> <li><code>persist_dir</code>: Directory for persistent storage (default: <code>~/.kagura</code>)</li> <li><code>max_messages</code>: Maximum messages to keep in context</li> </ul>"},{"location":"en/api/memory/#working-memory-methods","title":"Working Memory Methods","text":"<p>Temporary storage that's cleared when agent execution completes.</p>"},{"location":"en/api/memory/#set_temp","title":"set_temp","text":"<pre><code>manager.set_temp(key: str, value: Any) -&gt; None\n</code></pre> <p>Store temporary data.</p> <p>Example:</p> <pre><code>manager.set_temp(\"current_task\", \"summarization\")\nmanager.set_temp(\"retry_count\", 3)\n</code></pre>"},{"location":"en/api/memory/#get_temp","title":"get_temp","text":"<pre><code>manager.get_temp(key: str, default: Any = None) -&gt; Any\n</code></pre> <p>Retrieve temporary data.</p> <p>Example:</p> <pre><code>task = manager.get_temp(\"current_task\")  # Returns \"summarization\"\ncount = manager.get_temp(\"retry_count\", 0)  # Returns 3\nmissing = manager.get_temp(\"nonexistent\", \"default\")  # Returns \"default\"\n</code></pre>"},{"location":"en/api/memory/#has_temp","title":"has_temp","text":"<pre><code>manager.has_temp(key: str) -&gt; bool\n</code></pre> <p>Check if temporary key exists.</p>"},{"location":"en/api/memory/#delete_temp","title":"delete_temp","text":"<pre><code>manager.delete_temp(key: str) -&gt; None\n</code></pre> <p>Delete temporary data.</p>"},{"location":"en/api/memory/#context-memory-methods","title":"Context Memory Methods","text":"<p>Manages conversation history with automatic pruning.</p>"},{"location":"en/api/memory/#add_message","title":"add_message","text":"<pre><code>manager.add_message(\n    role: str,\n    content: str,\n    metadata: Optional[dict] = None\n) -&gt; None\n</code></pre> <p>Add message to conversation context.</p> <p>Parameters:</p> <ul> <li><code>role</code>: Message role (<code>\"user\"</code>, <code>\"assistant\"</code>, <code>\"system\"</code>)</li> <li><code>content</code>: Message content</li> <li><code>metadata</code>: Optional metadata dictionary</li> </ul> <p>Example:</p> <pre><code>manager.add_message(\"user\", \"What is machine learning?\")\nmanager.add_message(\n    \"assistant\",\n    \"Machine learning is...\",\n    metadata={\"confidence\": 0.95}\n)\n</code></pre>"},{"location":"en/api/memory/#get_context","title":"get_context","text":"<pre><code>manager.get_context(last_n: Optional[int] = None) -&gt; list[Message]\n</code></pre> <p>Get conversation context as Message objects.</p> <p>Example:</p> <pre><code># Get all messages\nall_messages = manager.get_context()\n\n# Get last 5 messages\nrecent = manager.get_context(last_n=5)\n</code></pre>"},{"location":"en/api/memory/#get_llm_context","title":"get_llm_context","text":"<pre><code>manager.get_llm_context(last_n: Optional[int] = None) -&gt; list[dict]\n</code></pre> <p>Get context formatted for LLM API.</p> <p>Returns: List of <code>{\"role\": str, \"content\": str}</code> dictionaries.</p> <p>Example:</p> <pre><code>context = manager.get_llm_context(last_n=10)\n# [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]\n</code></pre>"},{"location":"en/api/memory/#get_last_message","title":"get_last_message","text":"<pre><code>manager.get_last_message(role: Optional[str] = None) -&gt; Optional[Message]\n</code></pre> <p>Get the last message, optionally filtered by role.</p> <p>Example:</p> <pre><code>last_msg = manager.get_last_message()\nlast_user_msg = manager.get_last_message(role=\"user\")\n</code></pre>"},{"location":"en/api/memory/#set_session_id-get_session_id","title":"set_session_id / get_session_id","text":"<pre><code>manager.set_session_id(session_id: str) -&gt; None\nmanager.get_session_id() -&gt; Optional[str]\n</code></pre> <p>Manage session identifiers.</p>"},{"location":"en/api/memory/#persistent-memory-methods","title":"Persistent Memory Methods","text":"<p>Long-term storage using SQLite with optional agent scoping.</p>"},{"location":"en/api/memory/#remember","title":"remember","text":"<pre><code>manager.remember(\n    key: str,\n    value: Any,\n    metadata: Optional[dict] = None\n) -&gt; None\n</code></pre> <p>Store persistent memory.</p> <p>Example:</p> <pre><code>manager.remember(\"user_preferences\", {\n    \"theme\": \"dark\",\n    \"language\": \"en\"\n})\n\nmanager.remember(\n    \"api_key\",\n    \"sk-...\",\n    metadata={\"created\": \"2025-01-01\"}\n)\n</code></pre>"},{"location":"en/api/memory/#recall","title":"recall","text":"<pre><code>manager.recall(key: str) -&gt; Optional[Any]\n</code></pre> <p>Retrieve persistent memory.</p> <p>Example:</p> <pre><code>prefs = manager.recall(\"user_preferences\")\napi_key = manager.recall(\"api_key\")\n</code></pre>"},{"location":"en/api/memory/#search_memory","title":"search_memory","text":"<pre><code>manager.search_memory(query: str, limit: int = 10) -&gt; list[dict]\n</code></pre> <p>Search persistent memory using SQL LIKE pattern.</p> <p>Example:</p> <pre><code># Find all user-related memories\nresults = manager.search_memory(\"user\")\n\n# Each result contains: key, value, created_at, updated_at, metadata\nfor mem in results:\n    print(f\"{mem['key']}: {mem['value']}\")\n</code></pre>"},{"location":"en/api/memory/#forget","title":"forget","text":"<pre><code>manager.forget(key: str) -&gt; None\n</code></pre> <p>Delete persistent memory.</p> <p>Example:</p> <pre><code>manager.forget(\"api_key\")\n</code></pre>"},{"location":"en/api/memory/#prune_old","title":"prune_old","text":"<pre><code>manager.prune_old(older_than_days: int = 90) -&gt; int\n</code></pre> <p>Remove old memories.</p> <p>Returns: Number of deleted memories.</p> <p>Example:</p> <pre><code># Delete memories older than 30 days\ndeleted = manager.prune_old(older_than_days=30)\nprint(f\"Deleted {deleted} old memories\")\n</code></pre>"},{"location":"en/api/memory/#session-management","title":"Session Management","text":""},{"location":"en/api/memory/#save_session","title":"save_session","text":"<pre><code>manager.save_session(session_name: str) -&gt; None\n</code></pre> <p>Save current session (working + context memory) to persistent storage.</p> <p>Example:</p> <pre><code>manager.add_message(\"user\", \"Hello\")\nmanager.set_temp(\"step\", 1)\nmanager.save_session(\"my_session\")\n</code></pre>"},{"location":"en/api/memory/#load_session","title":"load_session","text":"<pre><code>manager.load_session(session_name: str) -&gt; bool\n</code></pre> <p>Load saved session.</p> <p>Returns: <code>True</code> if session was loaded successfully.</p> <p>Example:</p> <pre><code>if manager.load_session(\"my_session\"):\n    print(\"Session restored\")\n    messages = manager.get_context()\n</code></pre>"},{"location":"en/api/memory/#clear_all","title":"clear_all","text":"<pre><code>manager.clear_all() -&gt; None\n</code></pre> <p>Clear all temporary and context memory (does not clear persistent memory).</p> <p>Example:</p> <pre><code>manager.clear_all()\n</code></pre>"},{"location":"en/api/memory/#message-class","title":"Message Class","text":"<p>Represents a single message in conversation context.</p>"},{"location":"en/api/memory/#attributes","title":"Attributes","text":"<pre><code>@dataclass\nclass Message:\n    role: str              # \"user\", \"assistant\", \"system\"\n    content: str           # Message content\n    timestamp: datetime    # When message was created\n    metadata: Optional[dict] = None  # Optional metadata\n</code></pre>"},{"location":"en/api/memory/#methods","title":"Methods","text":""},{"location":"en/api/memory/#to_dict","title":"to_dict","text":"<pre><code>message.to_dict() -&gt; dict\n</code></pre> <p>Convert to dictionary representation.</p>"},{"location":"en/api/memory/#workingmemory","title":"WorkingMemory","text":"<p>Direct access to working memory (also available via <code>MemoryManager.working</code>).</p>"},{"location":"en/api/memory/#methods_1","title":"Methods","text":"<ul> <li><code>set(key: str, value: Any) -&gt; None</code></li> <li><code>get(key: str, default: Any = None) -&gt; Any</code></li> <li><code>has(key: str) -&gt; bool</code></li> <li><code>delete(key: str) -&gt; None</code></li> <li><code>clear() -&gt; None</code></li> <li><code>keys() -&gt; list[str]</code></li> <li><code>to_dict() -&gt; dict</code></li> </ul>"},{"location":"en/api/memory/#contextmemory","title":"ContextMemory","text":"<p>Direct access to context memory (also available via <code>MemoryManager.context</code>).</p>"},{"location":"en/api/memory/#methods_2","title":"Methods","text":"<ul> <li><code>add_message(role: str, content: str, metadata: Optional[dict] = None) -&gt; None</code></li> <li><code>get_messages(last_n: Optional[int] = None, role: Optional[str] = None) -&gt; list[Message]</code></li> <li><code>get_last_message(role: Optional[str] = None) -&gt; Optional[Message]</code></li> <li><code>clear() -&gt; None</code></li> <li><code>set_session_id(session_id: str) -&gt; None</code></li> <li><code>get_session_id() -&gt; Optional[str]</code></li> <li><code>to_llm_format(last_n: Optional[int] = None) -&gt; list[dict]</code></li> <li><code>to_dict() -&gt; dict</code></li> </ul>"},{"location":"en/api/memory/#persistentmemory","title":"PersistentMemory","text":"<p>Direct access to persistent memory (also available via <code>MemoryManager.persistent</code>).</p>"},{"location":"en/api/memory/#methods_3","title":"Methods","text":"<ul> <li><code>store(key: str, value: Any, agent_name: Optional[str] = None, metadata: Optional[dict] = None) -&gt; None</code></li> <li><code>recall(key: str, agent_name: Optional[str] = None) -&gt; Optional[Any]</code></li> <li><code>search(query: str, agent_name: Optional[str] = None, limit: int = 10) -&gt; list[dict]</code></li> <li><code>forget(key: str, agent_name: Optional[str] = None) -&gt; None</code></li> <li><code>prune(older_than_days: int = 90, agent_name: Optional[str] = None) -&gt; int</code></li> <li><code>count(agent_name: Optional[str] = None) -&gt; int</code></li> </ul>"},{"location":"en/api/memory/#memoryrag","title":"MemoryRAG","text":"<p>Vector-based semantic memory search using ChromaDB for Retrieval-Augmented Generation (RAG).</p>"},{"location":"en/api/memory/#constructor_1","title":"Constructor","text":"<pre><code>from kagura.core.memory import MemoryRAG\n\nrag = MemoryRAG(\n    collection_name: str = \"kagura_memory\",\n    persist_dir: Optional[Path] = None\n)\n</code></pre> <p>Parameters:</p> <ul> <li><code>collection_name</code>: Name for the vector collection (default: <code>\"kagura_memory\"</code>)</li> <li><code>persist_dir</code>: Directory for persistent storage (default: <code>~/.kagura/vector_db</code>)</li> </ul> <p>Requires: <code>pip install chromadb</code></p> <p>Example:</p> <pre><code>from pathlib import Path\nfrom kagura.core.memory import MemoryRAG\n\n# Default location\nrag = MemoryRAG()\n\n# Custom location\nrag = MemoryRAG(\n    collection_name=\"my_agent_memory\",\n    persist_dir=Path.home() / \".myapp\" / \"vectors\"\n)\n</code></pre>"},{"location":"en/api/memory/#store","title":"store()","text":"<p>Store memory with automatic embedding.</p> <pre><code>rag.store(\n    content: str,\n    metadata: Optional[dict[str, Any]] = None,\n    agent_name: Optional[str] = None\n) -&gt; str\n</code></pre> <p>Parameters:</p> <ul> <li><code>content</code>: Content to store (will be automatically embedded)</li> <li><code>metadata</code>: Optional metadata dictionary</li> <li><code>agent_name</code>: Optional agent name for scoping</li> </ul> <p>Returns: Content hash (unique ID)</p> <p>Example:</p> <pre><code># Store facts\nrag.store(\"Python is a programming language created by Guido van Rossum\")\nrag.store(\"The Eiffel Tower is in Paris, France\")\n\n# With metadata\nrag.store(\n    \"User prefers dark mode\",\n    metadata={\"category\": \"preference\", \"user_id\": \"123\"},\n    agent_name=\"assistant\"\n)\n</code></pre>"},{"location":"en/api/memory/#recall_1","title":"recall()","text":"<p>Semantic search for memories using vector similarity.</p> <pre><code>rag.recall(\n    query: str,\n    top_k: int = 5,\n    agent_name: Optional[str] = None\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Parameters:</p> <ul> <li><code>query</code>: Search query (will be embedded automatically)</li> <li><code>top_k</code>: Number of results to return (sorted by similarity)</li> <li><code>agent_name</code>: Optional agent name filter</li> </ul> <p>Returns: List of memory dictionaries containing: - <code>content</code> (<code>str</code>): Original memory text - <code>distance</code> (<code>float</code>): Cosine distance (lower = more similar, range 0.0-2.0) - <code>metadata</code> (<code>dict</code>): Optional metadata</p> <p>Example:</p> <pre><code># Store knowledge\nrag.store(\"Python is a programming language\")\nrag.store(\"Java is a programming language\")\nrag.store(\"The Eiffel Tower is in Paris\")\n\n# Semantic search\nresults = rag.recall(\"What is Python?\", top_k=2)\n\nfor result in results:\n    print(f\"Content: {result['content']}\")\n    print(f\"Distance: {result['distance']:.3f}\")  # e.g., 0.342\n    print(f\"Metadata: {result.get('metadata')}\")\n</code></pre>"},{"location":"en/api/memory/#delete_all","title":"delete_all()","text":"<p>Delete all memories.</p> <pre><code>rag.delete_all(agent_name: Optional[str] = None) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>agent_name</code>: Optional agent name filter (deletes only that agent's memories)</li> </ul> <p>Example:</p> <pre><code># Delete all memories\nrag.delete_all()\n\n# Delete only specific agent's memories\nrag.delete_all(agent_name=\"assistant\")\n</code></pre>"},{"location":"en/api/memory/#count","title":"count()","text":"<p>Count stored memories.</p> <pre><code>rag.count(agent_name: Optional[str] = None) -&gt; int\n</code></pre> <p>Parameters:</p> <ul> <li><code>agent_name</code>: Optional agent name filter</li> </ul> <p>Returns: Number of memories</p> <p>Example:</p> <pre><code>total = rag.count()\nprint(f\"Total memories: {total}\")\n\nagent_memories = rag.count(agent_name=\"assistant\")\nprint(f\"Assistant memories: {agent_memories}\")\n</code></pre>"},{"location":"en/api/memory/#memorymanager-integration","title":"MemoryManager Integration","text":"<p>Use RAG with MemoryManager by setting <code>enable_rag=True</code>:</p> <pre><code>from kagura.core.memory import MemoryManager\n\n# Initialize with RAG enabled\nmemory = MemoryManager(\n    agent_name=\"my_agent\",\n    enable_rag=True\n)\n\n# Store semantically\nmemory.add_message(\"user\", \"Python is great for AI development\")\n\n# Semantic recall\nresults = memory.recall_semantic(\"Tell me about Python\", top_k=3)\nfor result in results:\n    print(result['content'])\n</code></pre> <p>Note: When <code>enable_rag=True</code>, MemoryManager automatically stores conversation messages in the RAG vector database for semantic retrieval.</p>"},{"location":"en/api/memory/#complete-rag-example","title":"Complete RAG Example","text":"<pre><code>from kagura.core.memory import MemoryRAG\n\n# Initialize\nrag = MemoryRAG(collection_name=\"knowledge_base\")\n\n# Store domain knowledge\nrag.store(\"Machine learning is a subset of artificial intelligence\")\nrag.store(\"Deep learning uses neural networks with multiple layers\")\nrag.store(\"Natural language processing deals with text and speech\")\nrag.store(\"Computer vision focuses on image and video analysis\")\n\n# Semantic search\nquery = \"What is deep learning?\"\nresults = rag.recall(query, top_k=2)\n\nprint(f\"Query: {query}\\n\")\nfor i, result in enumerate(results, 1):\n    print(f\"{i}. {result['content']}\")\n    print(f\"   Similarity: {1 - result['distance']/2:.2%}\\n\")\n\n# Output:\n# Query: What is deep learning?\n#\n# 1. Deep learning uses neural networks with multiple layers\n#    Similarity: 89%\n#\n# 2. Machine learning is a subset of artificial intelligence\n#    Similarity: 72%\n</code></pre>"},{"location":"en/api/memory/#rag-with-agent-integration","title":"RAG with Agent Integration","text":"<pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n@agent(enable_memory=True)\nasync def knowledge_agent(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Answer {{ query }} using semantic memory\"\"\"\n\n    # Store query in RAG (if RAG enabled in MemoryManager)\n    memory.add_message(\"user\", query)\n\n    # Semantic search over past conversations\n    if memory.rag:\n        relevant = memory.recall_semantic(query, top_k=3)\n        context = \"\\n\".join([r['content'] for r in relevant])\n        enriched_query = f\"Context: {context}\\n\\nQuery: {query}\"\n        # Use enriched_query for LLM call\n    else:\n        enriched_query = query\n\n    # Process with LLM...\n    response = f\"Processing: {enriched_query}\"\n    memory.add_message(\"assistant\", response)\n\n    return response\n</code></pre>"},{"location":"en/api/memory/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Meaningful Content: Store complete, self-contained information    <pre><code># Good\nrag.store(\"The capital of France is Paris\")\n\n# Less good (lacks context)\nrag.store(\"Paris\")\n</code></pre></p> </li> <li> <p>Use Metadata for Filtering:    <pre><code>rag.store(\"User prefers Python\", metadata={\"type\": \"preference\"})\nrag.store(\"Project deadline is March 1\", metadata={\"type\": \"deadline\"})\n</code></pre></p> </li> <li> <p>Agent Scoping:    <pre><code># Separate knowledge per agent\nrag.store(\"Translation context\", agent_name=\"translator\")\nrag.store(\"Code review context\", agent_name=\"reviewer\")\n\n# Query specific agent's knowledge\nresults = rag.recall(\"translate\", agent_name=\"translator\")\n</code></pre></p> </li> <li> <p>Semantic vs Keyword Search:    <pre><code># Semantic search - finds conceptually similar content\nrag.recall(\"programming languages\")  # Finds \"Python\", \"Java\", etc.\n\n# Keyword search would miss variations\nmemory.search_memory(\"programming language\")  # Exact match only\n</code></pre></p> </li> </ol>"},{"location":"en/api/memory/#agent-integration","title":"Agent Integration","text":"<p>Enable memory in agents using the <code>enable_memory</code> parameter:</p> <pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n@agent(enable_memory=True, max_messages=50)\nasync def my_agent(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Answer {{ query }} using memory\"\"\"\n\n    # Add to context\n    memory.add_message(\"user\", query)\n\n    # Remember facts\n    memory.remember(\"last_query\", query)\n\n    # Recall past information\n    past = memory.recall(\"user_name\")\n\n    response = f\"Processing {query}\"\n    memory.add_message(\"assistant\", response)\n\n    return response\n</code></pre>"},{"location":"en/api/memory/#parameters","title":"Parameters","text":"<ul> <li><code>enable_memory</code>: Enable memory management (default: <code>False</code>)</li> <li><code>persist_dir</code>: Custom directory for persistent storage</li> <li><code>max_messages</code>: Maximum messages in context (default: 100)</li> </ul>"},{"location":"en/api/memory/#examples","title":"Examples","text":""},{"location":"en/api/memory/#basic-usage","title":"Basic Usage","text":"<pre><code>from kagura.core.memory import MemoryManager\n\n# Create manager\nmemory = MemoryManager(agent_name=\"my_agent\")\n\n# Store and recall\nmemory.remember(\"api_key\", \"sk-...\")\napi_key = memory.recall(\"api_key\")\n\n# Conversation context\nmemory.add_message(\"user\", \"Hello\")\nmemory.add_message(\"assistant\", \"Hi there!\")\ncontext = memory.get_llm_context()\n\n# Search\nresults = memory.search_memory(\"api\")\n</code></pre>"},{"location":"en/api/memory/#session-persistence","title":"Session Persistence","text":"<pre><code># Save session\nmemory.add_message(\"user\", \"What is AI?\")\nmemory.add_message(\"assistant\", \"AI stands for...\")\nmemory.save_session(\"conversation_1\")\n\n# Later... restore session\nnew_memory = MemoryManager(agent_name=\"my_agent\")\nif new_memory.load_session(\"conversation_1\"):\n    messages = new_memory.get_context()\n    print(f\"Restored {len(messages)} messages\")\n</code></pre>"},{"location":"en/api/memory/#agent-with-memory","title":"Agent with Memory","text":"<pre><code>@agent(enable_memory=True, persist_dir=Path(\"./data\"))\nasync def assistant(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Personal assistant: {{ query }}\"\"\"\n\n    # Track conversation\n    memory.add_message(\"user\", query)\n\n    # Remember user preferences\n    if \"my name is\" in query.lower():\n        name = query.split(\"my name is\")[-1].strip()\n        memory.remember(\"user_name\", name)\n\n    # Use remembered information\n    user_name = memory.recall(\"user_name\") or \"there\"\n    response = f\"Hello {user_name}! How can I help?\"\n\n    memory.add_message(\"assistant\", response)\n    return response\n\n# Usage\nresult = await assistant(\"Hello, my name is Alice\")\n# \"Hello Alice! How can I help?\"\n\nresult = await assistant(\"What's the weather?\")\n# \"Hello Alice! How can I help?\" (remembers name)\n</code></pre>"},{"location":"en/api/memory/#see-also","title":"See Also","text":"<ul> <li>Memory Management Tutorial</li> <li>@agent Decorator API</li> <li>Code Execution API</li> </ul>"},{"location":"en/api/meta/","title":"Meta Agent API Reference","text":"<p>API reference for Kagura AI's Meta Agent - AI-powered agent code generator.</p>"},{"location":"en/api/meta/#overview","title":"Overview","text":"<p>The Meta Agent system allows you to generate complete Kagura agent code from natural language descriptions. It uses a multi-stage pipeline:</p> <ol> <li>Natural Language Parsing \u2192 Extract structured specification</li> <li>Code Generation \u2192 Generate Python code from templates</li> <li>Security Validation \u2192 Ensure generated code is safe</li> <li>File Creation \u2192 Save the agent to a file</li> </ol>"},{"location":"en/api/meta/#metaagent","title":"MetaAgent","text":"<p>Main class for AI-powered agent code generation.</p>"},{"location":"en/api/meta/#class-definition","title":"Class Definition","text":"<pre><code>from kagura.meta import MetaAgent\n\nclass MetaAgent:\n    \"\"\"AI-powered agent code generator\n\n    Generate Kagura agent code from natural language descriptions.\n\n    Args:\n        model: LLM model for spec parsing (default: \"gpt-4o-mini\")\n        template_dir: Custom template directory (optional)\n        validate: Whether to validate generated code (default: True)\n\n    Example:\n        &gt;&gt;&gt; meta = MetaAgent()\n        &gt;&gt;&gt; code = await meta.generate(\"Translate English to Japanese\")\n        &gt;&gt;&gt; print(code)  # Complete Python agent code\n    \"\"\"\n</code></pre>"},{"location":"en/api/meta/#methods","title":"Methods","text":""},{"location":"en/api/meta/#__init__modelgpt-4o-mini-template_dirnone-validatetrue","title":"<code>__init__(model=\"gpt-4o-mini\", template_dir=None, validate=True)</code>","text":"<p>Initialize MetaAgent.</p> <p>Parameters: - <code>model</code> (str): LLM model for parsing descriptions (default: \"gpt-4o-mini\") - <code>template_dir</code> (Path | None): Custom template directory (optional) - <code>validate</code> (bool): Whether to validate generated code (default: True)</p> <p>Example: <pre><code>meta = MetaAgent(model=\"gpt-4o-mini\", validate=True)\n</code></pre></p>"},{"location":"en/api/meta/#async-generatedescription-str-str","title":"<code>async generate(description: str) -&gt; str</code>","text":"<p>Generate agent code from natural language description.</p> <p>Parameters: - <code>description</code> (str): Natural language agent description</p> <p>Returns: - <code>str</code>: Generated Python code</p> <p>Raises: - <code>ValidationError</code>: If generated code is invalid (when validate=True)</p> <p>Example: <pre><code>meta = MetaAgent()\ncode = await meta.generate(\"Create a chatbot that remembers conversation history\")\nprint(code)  # Complete Python agent code with @agent decorator\n</code></pre></p>"},{"location":"en/api/meta/#async-generate_from_specspec-agentspec-str","title":"<code>async generate_from_spec(spec: AgentSpec) -&gt; str</code>","text":"<p>Generate agent code from AgentSpec.</p> <p>Parameters: - <code>spec</code> (AgentSpec): Agent specification</p> <p>Returns: - <code>str</code>: Generated Python code</p> <p>Raises: - <code>ValidationError</code>: If generated code is invalid</p> <p>Example: <pre><code>from kagura.meta.spec import AgentSpec\n\nspec = AgentSpec(\n    name=\"translator\",\n    description=\"Translate text\",\n    input_type=\"str\",\n    output_type=\"str\",\n    system_prompt=\"You are a professional translator.\"\n)\n\nmeta = MetaAgent()\ncode = await meta.generate_from_spec(spec)\n</code></pre></p>"},{"location":"en/api/meta/#async-generate_and_savedescription-str-output_path-path-tuplestr-path","title":"<code>async generate_and_save(description: str, output_path: Path) -&gt; tuple[str, Path]</code>","text":"<p>Generate agent code and save to file.</p> <p>Parameters: - <code>description</code> (str): Natural language agent description - <code>output_path</code> (Path): Output file path</p> <p>Returns: - <code>tuple[str, Path]</code>: (generated_code, output_path)</p> <p>Raises: - <code>ValidationError</code>: If generated code is invalid</p> <p>Example: <pre><code>from pathlib import Path\n\nmeta = MetaAgent()\ncode, path = await meta.generate_and_save(\n    \"Create a translator agent\",\n    Path(\"agents/translator.py\")\n)\nprint(f\"Saved to {path}\")\n</code></pre></p>"},{"location":"en/api/meta/#agentspec","title":"AgentSpec","text":"<p>Structured specification for an agent.</p>"},{"location":"en/api/meta/#class-definition_1","title":"Class Definition","text":"<pre><code>from kagura.meta.spec import AgentSpec\nfrom pydantic import BaseModel\n\nclass AgentSpec(BaseModel):\n    \"\"\"Agent specification parsed from natural language\n\n    Structured representation of agent requirements.\n\n    Fields:\n        name: Agent function name (snake_case)\n        description: What the agent does (1-2 sentences)\n        input_type: Parameter type (str, dict, list, etc.)\n        output_type: Return type (str, dict, list, etc.)\n        tools: List of required tools (optional)\n        has_memory: Whether agent needs conversation memory\n        system_prompt: Agent's system instructions\n        examples: Example inputs/outputs (optional)\n    \"\"\"\n</code></pre>"},{"location":"en/api/meta/#fields","title":"Fields","text":""},{"location":"en/api/meta/#name-str","title":"<code>name: str</code>","text":"<p>Agent function name in snake_case.</p> <p>Example: <pre><code>spec = AgentSpec(\n    name=\"translator\",\n    description=\"Translate text\",\n    system_prompt=\"You are a translator\"\n)\n</code></pre></p>"},{"location":"en/api/meta/#description-str","title":"<code>description: str</code>","text":"<p>What the agent does (1-2 sentences).</p> <p>Example: <pre><code>spec = AgentSpec(\n    name=\"summarizer\",\n    description=\"Summarize articles in 3 bullet points\",\n    system_prompt=\"You are a summarizer\"\n)\n</code></pre></p>"},{"location":"en/api/meta/#input_type-str-str","title":"<code>input_type: str = \"str\"</code>","text":"<p>Parameter type annotation.</p> <p>Default: <code>\"str\"</code></p> <p>Common types: <code>\"str\"</code>, <code>\"dict\"</code>, <code>\"list\"</code>, <code>\"int\"</code>, <code>\"float\"</code></p> <p>Example: <pre><code>spec = AgentSpec(\n    name=\"calculator\",\n    description=\"Calculate math\",\n    input_type=\"str\",\n    output_type=\"float\",\n    system_prompt=\"Calculate the result\"\n)\n</code></pre></p>"},{"location":"en/api/meta/#output_type-str-str","title":"<code>output_type: str = \"str\"</code>","text":"<p>Return type annotation.</p> <p>Default: <code>\"str\"</code></p>"},{"location":"en/api/meta/#tools-liststr","title":"<code>tools: list[str] = []</code>","text":"<p>List of required tools.</p> <p>Available tools: - <code>\"code_executor\"</code>: Execute Python code - <code>\"web_search\"</code>: Search the web - <code>\"memory\"</code>: Conversation memory - <code>\"file_ops\"</code>: File operations</p> <p>Default: <code>[]</code></p> <p>Example: <pre><code>spec = AgentSpec(\n    name=\"math_solver\",\n    description=\"Solve math problems\",\n    tools=[\"code_executor\"],\n    system_prompt=\"Solve math problems by executing Python code\"\n)\n</code></pre></p>"},{"location":"en/api/meta/#has_memory-bool-false","title":"<code>has_memory: bool = False</code>","text":"<p>Whether agent needs conversation memory.</p> <p>Default: <code>False</code></p> <p>Example: <pre><code>spec = AgentSpec(\n    name=\"chatbot\",\n    description=\"Conversational chatbot\",\n    has_memory=True,\n    system_prompt=\"You are a friendly chatbot\"\n)\n</code></pre></p>"},{"location":"en/api/meta/#system_prompt-str","title":"<code>system_prompt: str</code>","text":"<p>Agent's system instructions.</p> <p>Required field</p> <p>Example: <pre><code>spec = AgentSpec(\n    name=\"translator\",\n    description=\"Translate text\",\n    system_prompt=\"You are a professional translator. Translate text accurately while preserving meaning and tone.\"\n)\n</code></pre></p>"},{"location":"en/api/meta/#examples-listdictstr-str","title":"<code>examples: list[dict[str, str]] = []</code>","text":"<p>Example inputs/outputs (optional).</p> <p>Default: <code>[]</code></p> <p>Format: <code>[{\"input\": \"...\", \"output\": \"...\"}]</code></p> <p>Example: <pre><code>spec = AgentSpec(\n    name=\"translator\",\n    description=\"Translate text\",\n    system_prompt=\"You are a translator\",\n    examples=[\n        {\"input\": \"Hello\", \"output\": \"\u3053\u3093\u306b\u3061\u306f\"},\n        {\"input\": \"Thank you\", \"output\": \"\u3042\u308a\u304c\u3068\u3046\"}\n    ]\n)\n</code></pre></p>"},{"location":"en/api/meta/#nlspecparser","title":"NLSpecParser","text":"<p>Parse natural language descriptions into structured AgentSpec.</p>"},{"location":"en/api/meta/#class-definition_2","title":"Class Definition","text":"<pre><code>from kagura.meta.parser import NLSpecParser\n\nclass NLSpecParser:\n    \"\"\"Parse natural language agent descriptions into AgentSpec\n\n    Uses LLM to extract structured information from user descriptions.\n\n    Args:\n        model: LLM model to use for parsing (default: \"gpt-4o-mini\")\n\n    Example:\n        &gt;&gt;&gt; parser = NLSpecParser()\n        &gt;&gt;&gt; desc = \"Create an agent that translates English to Japanese\"\n        &gt;&gt;&gt; spec = await parser.parse(desc)\n        &gt;&gt;&gt; print(spec.name)  # \"translator\"\n    \"\"\"\n</code></pre>"},{"location":"en/api/meta/#methods_1","title":"Methods","text":""},{"location":"en/api/meta/#__init__modelgpt-4o-mini","title":"<code>__init__(model=\"gpt-4o-mini\")</code>","text":"<p>Initialize parser with LLM model.</p> <p>Parameters: - <code>model</code> (str): LLM model for parsing (default: \"gpt-4o-mini\")</p> <p>Example: <pre><code>parser = NLSpecParser(model=\"gpt-4o-mini\")\n</code></pre></p>"},{"location":"en/api/meta/#async-parsedescription-str-agentspec","title":"<code>async parse(description: str) -&gt; AgentSpec</code>","text":"<p>Parse natural language description into AgentSpec.</p> <p>Parameters: - <code>description</code> (str): Natural language agent description</p> <p>Returns: - <code>AgentSpec</code>: Structured specification</p> <p>Example: <pre><code>parser = NLSpecParser()\nspec = await parser.parse(\"Summarize articles in 3 bullet points\")\nprint(spec.name)  # \"article_summarizer\"\nprint(spec.output_type)  # \"str\"\n</code></pre></p>"},{"location":"en/api/meta/#detect_toolsdescription-str-liststr","title":"<code>detect_tools(description: str) -&gt; list[str]</code>","text":"<p>Detect required tools from description using pattern matching.</p> <p>Parameters: - <code>description</code> (str): Natural language description</p> <p>Returns: - <code>list[str]</code>: List of detected tool names</p> <p>Example: <pre><code>parser = NLSpecParser()\n\n# Code execution detection\ntools = parser.detect_tools(\"Execute Python code to solve math problems\")\nprint(tools)  # [\"code_executor\"]\n\n# Web search detection\ntools = parser.detect_tools(\"Search the web for information\")\nprint(tools)  # [\"web_search\"]\n\n# Memory detection\ntools = parser.detect_tools(\"Remember user preferences in conversation\")\nprint(tools)  # [\"memory\"]\n</code></pre></p> <p>Tool patterns: - code_executor: \"execute code\", \"run python\", \"calculate\" - web_search: \"search\", \"google\", \"find online\", \"web\" - memory: \"remember\", \"conversation\", \"history\" - file_ops: \"read file\", \"write file\"</p>"},{"location":"en/api/meta/#codegenerator","title":"CodeGenerator","text":"<p>Generate Python agent code from AgentSpec using Jinja2 templates.</p>"},{"location":"en/api/meta/#class-definition_3","title":"Class Definition","text":"<pre><code>from kagura.meta.generator import CodeGenerator\nfrom pathlib import Path\n\nclass CodeGenerator:\n    \"\"\"Generate agent Python code from AgentSpec\n\n    Uses Jinja2 templates to generate complete, runnable agent code.\n\n    Args:\n        template_dir: Directory containing Jinja2 templates\n                     (default: kagura/meta/templates/)\n\n    Example:\n        &gt;&gt;&gt; generator = CodeGenerator()\n        &gt;&gt;&gt; code = generator.generate(spec)\n        &gt;&gt;&gt; print(code)  # Complete Python code with @agent decorator\n    \"\"\"\n</code></pre>"},{"location":"en/api/meta/#methods_2","title":"Methods","text":""},{"location":"en/api/meta/#__init__template_dirnone","title":"<code>__init__(template_dir=None)</code>","text":"<p>Initialize with template directory.</p> <p>Parameters: - <code>template_dir</code> (Path | None): Directory containing Jinja2 templates (optional)</p> <p>Example: <pre><code>generator = CodeGenerator()\n</code></pre></p>"},{"location":"en/api/meta/#generatespec-agentspec-str","title":"<code>generate(spec: AgentSpec) -&gt; str</code>","text":"<p>Generate complete agent code.</p> <p>Parameters: - <code>spec</code> (AgentSpec): Agent specification</p> <p>Returns: - <code>str</code>: Python code as string</p> <p>Example: <pre><code>from kagura.meta.spec import AgentSpec\n\nspec = AgentSpec(\n    name=\"translator\",\n    description=\"Translate text\",\n    system_prompt=\"You are a translator\"\n)\n\ngenerator = CodeGenerator()\ncode = generator.generate(spec)\n\nassert \"@agent\" in code\nassert \"async def translator\" in code\n</code></pre></p>"},{"location":"en/api/meta/#savecode-str-output_path-path-none","title":"<code>save(code: str, output_path: Path) -&gt; None</code>","text":"<p>Save generated code to file.</p> <p>Parameters: - <code>code</code> (str): Generated Python code - <code>output_path</code> (Path): Output file path</p> <p>Example: <pre><code>from pathlib import Path\n\ngenerator = CodeGenerator()\ncode = generator.generate(spec)\ngenerator.save(code, Path(\"agents/my_agent.py\"))\n</code></pre></p>"},{"location":"en/api/meta/#codevalidator","title":"CodeValidator","text":"<p>Validate generated agent code for security and correctness.</p>"},{"location":"en/api/meta/#class-definition_4","title":"Class Definition","text":"<pre><code>from kagura.meta.validator import CodeValidator\n\nclass CodeValidator:\n    \"\"\"Validate generated agent code\n\n    Reuses security checks from kagura.core.executor.ASTValidator\n    to ensure generated code is safe and correct.\n\n    Args:\n        allowed_imports: Set of allowed import modules (optional)\n\n    Example:\n        &gt;&gt;&gt; validator = CodeValidator()\n        &gt;&gt;&gt; try:\n        ...     validator.validate(code)\n        ...     print(\"Code is valid\")\n        ... except ValidationError as e:\n        ...     print(f\"Validation failed: {e}\")\n    \"\"\"\n</code></pre>"},{"location":"en/api/meta/#methods_3","title":"Methods","text":""},{"location":"en/api/meta/#__init__allowed_importsnone","title":"<code>__init__(allowed_imports=None)</code>","text":"<p>Initialize validator.</p> <p>Parameters: - <code>allowed_imports</code> (set[str] | None): Set of allowed import modules (optional)</p> <p>Default allowed imports: - <code>kagura</code> - <code>kagura.core</code> - <code>kagura.core.executor</code> - <code>kagura.core.memory</code> - <code>pydantic</code> - <code>typing</code> - <code>datetime</code> - <code>pathlib</code> - <code>asyncio</code></p> <p>Example: <pre><code>validator = CodeValidator()\n</code></pre></p>"},{"location":"en/api/meta/#validatecode-str-bool","title":"<code>validate(code: str) -&gt; bool</code>","text":"<p>Validate agent code (raises ValidationError if invalid).</p> <p>Parameters: - <code>code</code> (str): Python code to validate</p> <p>Returns: - <code>bool</code>: True if valid</p> <p>Raises: - <code>ValidationError</code>: If code is invalid or insecure</p> <p>Checks performed: 1. \u2705 Syntax checking 2. \u2705 Security validation (disallowed imports, dangerous functions) 3. \u2705 @agent decorator verification</p> <p>Example: <pre><code>validator = CodeValidator()\n\n# Valid code\ncode = \"\"\"\nfrom kagura import agent\n\n@agent(name=\"test\")\nasync def test_agent(x: str) -&gt; str:\n    return x\n\"\"\"\nvalidator.validate(code)  # Returns True\n\n# Invalid code (missing decorator)\nbad_code = \"\"\"\nfrom kagura import agent\n\nasync def test_agent(x: str) -&gt; str:\n    return x\n\"\"\"\ntry:\n    validator.validate(bad_code)\nexcept ValidationError as e:\n    print(e)  # \"Missing @agent decorator\"\n</code></pre></p>"},{"location":"en/api/meta/#validationerror","title":"ValidationError","text":"<p>Exception raised when agent code validation fails.</p>"},{"location":"en/api/meta/#class-definition_5","title":"Class Definition","text":"<pre><code>from kagura.meta.validator import ValidationError\n\nclass ValidationError(Exception):\n    \"\"\"Agent validation failed\"\"\"\n</code></pre>"},{"location":"en/api/meta/#common-validation-errors","title":"Common Validation Errors","text":""},{"location":"en/api/meta/#missing-agent-decorator","title":"Missing @agent decorator","text":"<p>Error: <code>ValidationError: Missing @agent decorator</code></p> <p>Cause: Generated code doesn't include <code>@agent</code> decorator</p> <p>Solution: Report as bug</p>"},{"location":"en/api/meta/#disallowed-import","title":"Disallowed import","text":"<p>Error: <code>ValidationError: Disallowed import: subprocess</code></p> <p>Cause: Generated code includes dangerous imports</p> <p>Example: <pre><code>try:\n    validator.validate(code_with_subprocess)\nexcept ValidationError as e:\n    print(e)  # \"Disallowed import: subprocess\"\n</code></pre></p>"},{"location":"en/api/meta/#disallowed-name","title":"Disallowed name","text":"<p>Error: <code>ValidationError: Disallowed name: eval</code></p> <p>Cause: Generated code uses dangerous functions like <code>eval()</code>, <code>exec()</code></p> <p>Example: <pre><code>try:\n    validator.validate(code_with_eval)\nexcept ValidationError as e:\n    print(e)  # \"Disallowed name: eval\"\n</code></pre></p>"},{"location":"en/api/meta/#syntax-error","title":"Syntax error","text":"<p>Error: <code>ValidationError: Syntax error: ...</code></p> <p>Cause: Generated code has invalid Python syntax</p>"},{"location":"en/api/meta/#cli-commands","title":"CLI Commands","text":""},{"location":"en/api/meta/#kagura-build-agent","title":"kagura build agent","text":"<p>Generate agent code from natural language description.</p> <p>Usage: <pre><code>kagura build agent [OPTIONS]\n</code></pre></p> <p>Options: - <code>-d, --description TEXT</code>: Natural language agent description - <code>-o, --output PATH</code>: Output file path (default: <code>agents/&lt;name&gt;.py</code>) - <code>--model TEXT</code>: LLM model for code generation (default: <code>gpt-4o-mini</code>) - <code>--interactive / --no-interactive</code>: Interactive mode (default: <code>True</code>) - <code>--no-validate</code>: Skip code validation</p> <p>Interactive Mode (default): <pre><code>kagura build agent\n</code></pre></p> <p>Output: <pre><code>\ud83e\udd16 Kagura Agent Builder\nDescribe your agent in natural language and I'll generate the code.\n\nWhat should your agent do? Translate English to Japanese\n\n\ud83d\udd0d Parsing agent specification...\n\n\ud83d\udccb Agent Specification\nName: translator\nDescription: Translate English to Japanese\nInput: str\nOutput: str\nTools: None\nMemory: No\n\n\u2699\ufe0f  Generating agent code...\n\ud83d\udd12 Validating code security...\n\u2705 Code validated\n\n\u2705 Agent created: agents/translator.py\n</code></pre></p> <p>Non-Interactive Mode: <pre><code>kagura build agent \\\n  --description \"Translate English to Japanese\" \\\n  --output translator.py \\\n  --no-interactive\n</code></pre></p> <p>Examples: <pre><code># Interactive mode\nkagura build agent\n\n# Direct generation\nkagura build agent -d \"Summarize text in 3 bullet points\" -o summarizer.py\n\n# Use GPT-4\nkagura build agent -d \"Complex reasoning task\" --model gpt-4o\n\n# Skip validation (not recommended)\nkagura build agent -d \"Test agent\" --no-validate\n</code></pre></p>"},{"location":"en/api/meta/#complete-example","title":"Complete Example","text":"<p>Here's a complete example using the Meta Agent API:</p> <pre><code>import asyncio\nfrom pathlib import Path\nfrom kagura.meta import MetaAgent\nfrom kagura.meta.spec import AgentSpec\nfrom kagura.meta.validator import ValidationError\n\nasync def main():\n    # Method 1: Generate from natural language\n    meta = MetaAgent(model=\"gpt-4o-mini\", validate=True)\n\n    try:\n        code = await meta.generate(\"Create a chatbot that remembers conversation history\")\n        print(\"Generated code:\")\n        print(code)\n\n        # Save to file\n        output_path = Path(\"agents/chatbot.py\")\n        output_path.parent.mkdir(parents=True, exist_ok=True)\n        output_path.write_text(code)\n        print(f\"\\nSaved to {output_path}\")\n\n    except ValidationError as e:\n        print(f\"Validation failed: {e}\")\n\n    # Method 2: Generate from AgentSpec\n    spec = AgentSpec(\n        name=\"translator\",\n        description=\"Translate text between languages\",\n        input_type=\"str\",\n        output_type=\"str\",\n        system_prompt=\"\"\"You are a professional translator.\n        Translate text accurately while preserving meaning and tone.\"\"\",\n        examples=[\n            {\"input\": \"Hello\", \"output\": \"\u3053\u3093\u306b\u3061\u306f\"},\n            {\"input\": \"Thank you\", \"output\": \"\u3042\u308a\u304c\u3068\u3046\"}\n        ]\n    )\n\n    code = await meta.generate_from_spec(spec)\n    print(\"\\nGenerated from spec:\")\n    print(code)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/api/meta/#template-customization","title":"Template Customization","text":""},{"location":"en/api/meta/#default-templates","title":"Default Templates","text":"<p>Meta Agent includes three default templates:</p> <ol> <li>agent_base.py.j2: Basic agent</li> <li>agent_with_tools.py.j2: Agent with tools</li> <li>agent_with_memory.py.j2: Agent with memory</li> </ol>"},{"location":"en/api/meta/#custom-templates","title":"Custom Templates","text":"<p>You can provide custom templates:</p> <pre><code>from pathlib import Path\nfrom kagura.meta import MetaAgent\n\n# Custom template directory\ntemplate_dir = Path(\"my_templates\")\n\nmeta = MetaAgent(template_dir=template_dir)\ncode = await meta.generate(\"My agent description\")\n</code></pre> <p>Template variables: - <code>spec</code>: AgentSpec object - <code>timestamp</code>: Generation timestamp - <code>kagura_version</code>: Kagura version - <code>tool_descriptions</code>: Tool descriptions dict</p>"},{"location":"en/api/meta/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Always validate generated code (default: <code>validate=True</code>)</li> <li>Review generated code before running in production</li> <li>Use specific descriptions to avoid unexpected behavior</li> <li>Test generated agents thoroughly</li> <li>Keep Kagura up-to-date for latest security fixes</li> </ol>"},{"location":"en/api/meta/#see-also","title":"See Also","text":"<ul> <li>Meta Agent User Guide</li> <li>Agent API Reference</li> <li>CLI Reference</li> <li>Code Executor API</li> </ul>"},{"location":"en/api/observability/","title":"Observability API","text":"<p>Telemetry tracking and monitoring for agent execution.</p>"},{"location":"en/api/observability/#overview","title":"Overview","text":"<p>The <code>kagura.observability</code> module provides tools for monitoring agent behavior: - EventStore: SQLite-based telemetry storage - Dashboard: Rich TUI for visualization - CLI Commands: <code>kagura monitor</code> commands</p> <p>Telemetry is automatically tracked for all agent executions.</p>"},{"location":"en/api/observability/#class-eventstore","title":"Class: EventStore","text":"<p>Store and query telemetry events in SQLite database.</p> <pre><code>from kagura.observability import EventStore\n\nstore = EventStore()  # Uses ~/.kagura/telemetry.db\n</code></pre>"},{"location":"en/api/observability/#constructor","title":"Constructor","text":"<pre><code>def __init__(self, db_path: Optional[Path | str] = None) -&gt; None\n</code></pre> <p>Parameters: - db_path (<code>Optional[Path | str]</code>, default: <code>None</code>): Database path   - <code>None</code>: Uses <code>~/.kagura/telemetry.db</code>   - <code>\":memory:\"</code>: In-memory database (testing)   - <code>Path</code> or <code>str</code>: Custom file path</p> <p>Example: <pre><code># Default location\nstore = EventStore()\n\n# Custom location\nstore = EventStore(Path.home() / \"my_telemetry.db\")\n\n# In-memory (testing)\nstore = EventStore(\":memory:\")\n</code></pre></p>"},{"location":"en/api/observability/#save_execution","title":"save_execution()","text":"<p>Save execution record.</p> <pre><code>async def save_execution(self, execution: dict[str, Any]) -&gt; None\n</code></pre> <p>Parameters: - execution (<code>dict[str, Any]</code>): Execution data containing:   - <code>id</code> (<code>str</code>, required): Execution ID   - <code>agent_name</code> (<code>str</code>, required): Agent name   - <code>started_at</code> (<code>float</code>, required): Start timestamp   - <code>ended_at</code> (<code>float</code>, optional): End timestamp   - <code>duration</code> (<code>float</code>, optional): Duration in seconds   - <code>status</code> (<code>str</code>, optional): Status (<code>\"completed\"</code>, <code>\"failed\"</code>)   - <code>error</code> (<code>str</code>, optional): Error message if failed   - <code>kwargs</code> (<code>dict</code>, optional): Agent arguments   - <code>events</code> (<code>list</code>, optional): List of events   - <code>metrics</code> (<code>dict</code>, optional): Metrics dictionary</p> <p>Example: <pre><code>import time\n\nawait store.save_execution({\n    \"id\": \"exec_123\",\n    \"agent_name\": \"translator\",\n    \"started_at\": time.time(),\n    \"ended_at\": time.time() + 0.5,\n    \"duration\": 0.5,\n    \"status\": \"completed\",\n    \"metrics\": {\n        \"total_cost\": 0.0003,\n        \"total_tokens\": 85,\n        \"llm_calls\": 1\n    }\n})\n</code></pre></p>"},{"location":"en/api/observability/#get_execution","title":"get_execution()","text":"<p>Get execution by ID.</p> <pre><code>def get_execution(self, execution_id: str) -&gt; Optional[dict[str, Any]]\n</code></pre> <p>Parameters: - execution_id (<code>str</code>): Execution ID</p> <p>Returns: Execution dict or <code>None</code> if not found</p> <p>Example: <pre><code>execution = store.get_execution(\"exec_123\")\nif execution:\n    print(f\"Status: {execution['status']}\")\n    print(f\"Duration: {execution['duration']:.2f}s\")\n</code></pre></p>"},{"location":"en/api/observability/#get_executions","title":"get_executions()","text":"<p>Query execution records.</p> <pre><code>def get_executions(\n    self,\n    agent_name: Optional[str] = None,\n    status: Optional[str] = None,\n    since: Optional[float] = None,\n    limit: int = 100,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Parameters: - agent_name (<code>Optional[str]</code>): Filter by agent name - status (<code>Optional[str]</code>): Filter by status (<code>\"completed\"</code>, <code>\"failed\"</code>) - since (<code>Optional[float]</code>): Filter by start time (timestamp) - limit (<code>int</code>, default: <code>100</code>): Maximum number of records</p> <p>Returns: List of execution dictionaries (sorted by most recent first)</p> <p>Example: <pre><code>import time\n\n# Get all executions\nall_execs = store.get_executions(limit=1000)\n\n# Get translator executions\ntranslator_execs = store.get_executions(agent_name=\"translator\")\n\n# Get failed executions\nfailed = store.get_executions(status=\"failed\")\n\n# Get last 24 hours\nsince = time.time() - 86400\nrecent = store.get_executions(since=since)\n\n# Combined filters\nrecent_failed = store.get_executions(\n    agent_name=\"translator\",\n    status=\"failed\",\n    since=since,\n    limit=50\n)\n</code></pre></p>"},{"location":"en/api/observability/#get_summary_stats","title":"get_summary_stats()","text":"<p>Get summary statistics.</p> <pre><code>def get_summary_stats(\n    self, agent_name: Optional[str] = None, since: Optional[float] = None\n) -&gt; dict[str, Any]\n</code></pre> <p>Parameters: - agent_name (<code>Optional[str]</code>): Filter by agent name - since (<code>Optional[float]</code>): Filter by start time (timestamp)</p> <p>Returns: Dictionary containing: - <code>total_executions</code> (<code>int</code>): Total number of executions - <code>completed</code> (<code>int</code>): Number of completed executions - <code>failed</code> (<code>int</code>): Number of failed executions - <code>avg_duration</code> (<code>float</code>): Average duration in seconds</p> <p>Example: <pre><code># Overall stats\nstats = store.get_summary_stats()\nprint(f\"Total: {stats['total_executions']}\")\nprint(f\"Success rate: {stats['completed'] / stats['total_executions'] * 100:.1f}%\")\n\n# Agent-specific stats\ntranslator_stats = store.get_summary_stats(agent_name=\"translator\")\nprint(f\"Avg duration: {translator_stats['avg_duration']:.2f}s\")\n</code></pre></p>"},{"location":"en/api/observability/#delete_old_executions","title":"delete_old_executions()","text":"<p>Delete executions older than timestamp.</p> <pre><code>def delete_old_executions(self, older_than: float) -&gt; int\n</code></pre> <p>Parameters: - older_than (<code>float</code>): Timestamp threshold</p> <p>Returns: Number of deleted records</p> <p>Example: <pre><code>import time\n\n# Delete executions older than 30 days\nthirty_days_ago = time.time() - (30 * 86400)\ndeleted = store.delete_old_executions(older_than=thirty_days_ago)\nprint(f\"Deleted {deleted} old executions\")\n</code></pre></p>"},{"location":"en/api/observability/#clear_all","title":"clear_all()","text":"<p>Clear all execution records.</p> <pre><code>def clear_all(self) -&gt; None\n</code></pre> <p>Example: <pre><code># Use with caution!\nstore.clear_all()\n</code></pre></p>"},{"location":"en/api/observability/#class-dashboard","title":"Class: Dashboard","text":"<p>Rich TUI dashboard for visualizing telemetry data.</p> <pre><code>from kagura.observability import Dashboard\n\ndashboard = Dashboard(store)\n</code></pre>"},{"location":"en/api/observability/#constructor_1","title":"Constructor","text":"<pre><code>def __init__(self, store: EventStore) -&gt; None\n</code></pre> <p>Parameters: - store (<code>EventStore</code>): Event store to query data from</p> <p>Example: <pre><code>from kagura.observability import EventStore, Dashboard\n\nstore = EventStore()\ndashboard = Dashboard(store)\n</code></pre></p>"},{"location":"en/api/observability/#show_live","title":"show_live()","text":"<p>Show live monitoring dashboard (auto-refreshing).</p> <pre><code>def show_live(\n    self, agent_name: Optional[str] = None, refresh_rate: float = 1.0\n) -&gt; None\n</code></pre> <p>Parameters: - agent_name (<code>Optional[str]</code>): Filter by agent name - refresh_rate (<code>float</code>, default: <code>1.0</code>): Refresh interval in seconds</p> <p>Example: <pre><code># Monitor all agents (refresh every 1 second)\ndashboard.show_live()\n\n# Monitor specific agent\ndashboard.show_live(agent_name=\"translator\")\n\n# Custom refresh rate\ndashboard.show_live(refresh_rate=2.0)\n</code></pre></p> <p>Output: <pre><code>\ud83d\udcca Kagura Agent Monitor\nTotal: 42 | Completed: 40 | Failed: 2\n\n\u250c\u2500 Recent Activity \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Time     Agent         Status      Duration  Cost     \u2502\n\u2502 14:32:15 translator    \u2713 COMPLETED 0.52s    $0.0003  \u2502\n\u2502 14:31:58 chatbot       \u2713 COMPLETED 1.23s    $0.0012  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"en/api/observability/#show_list","title":"show_list()","text":"<p>Show execution list.</p> <pre><code>def show_list(\n    self,\n    agent_name: Optional[str] = None,\n    limit: int = 20,\n    status: Optional[str] = None,\n) -&gt; None\n</code></pre> <p>Parameters: - agent_name (<code>Optional[str]</code>): Filter by agent name - limit (<code>int</code>, default: <code>20</code>): Maximum number of executions - status (<code>Optional[str]</code>): Filter by status</p> <p>Example: <pre><code># Show last 20 executions\ndashboard.show_list()\n\n# Show translator executions\ndashboard.show_list(agent_name=\"translator\", limit=50)\n\n# Show failed executions\ndashboard.show_list(status=\"failed\")\n</code></pre></p>"},{"location":"en/api/observability/#show_stats","title":"show_stats()","text":"<p>Show statistics summary.</p> <pre><code>def show_stats(\n    self, agent_name: Optional[str] = None, since: Optional[float] = None\n) -&gt; None\n</code></pre> <p>Parameters: - agent_name (<code>Optional[str]</code>): Filter by agent name - since (<code>Optional[float]</code>): Filter by start time (timestamp)</p> <p>Example: <pre><code>import time\n\n# Overall statistics\ndashboard.show_stats()\n\n# Agent-specific stats\ndashboard.show_stats(agent_name=\"translator\")\n\n# Last 24 hours\nsince = time.time() - 86400\ndashboard.show_stats(since=since)\n</code></pre></p> <p>Output: <pre><code>\ud83d\udcca Summary Statistics\n\nTotal Executions: 42\n  \u2022 Completed: 40\n  \u2022 Failed: 2\nAvg Duration: 1.34s\nTotal Cost: $0.0512\nTotal Tokens: 12,450\nLLM Calls: 45\nTool Calls: 12\n\nSuccess Rate: 95.2%\n</code></pre></p>"},{"location":"en/api/observability/#show_trace","title":"show_trace()","text":"<p>Show detailed trace for specific execution.</p> <pre><code>def show_trace(self, execution_id: str) -&gt; None\n</code></pre> <p>Parameters: - execution_id (<code>str</code>): Execution ID</p> <p>Example: <pre><code>dashboard.show_trace(\"exec_abc123\")\n</code></pre></p> <p>Output: <pre><code>\ud83d\udccd Execution Trace: translator (exec_abc123)\n\nExecution Info\n\u251c\u2500\u2500 Started: 14:32:15\n\u251c\u2500\u2500 Status: \u2713 COMPLETED\n\u251c\u2500\u2500 Duration: 0.52s\n\nMetrics\n\u251c\u2500\u2500 total_cost: $0.0003\n\u251c\u2500\u2500 total_tokens: 85\n\u251c\u2500\u2500 llm_calls: 1\n\u2514\u2500\u2500 tool_calls: 0\n\nEvents Timeline (3 events)\n\u251c\u2500\u2500 [0.00s] LLM Call (gpt-4o-mini) - 85 tokens, $0.0003, 0.48s\n\u251c\u2500\u2500 [0.48s] Memory Op (store) - 0.02s\n\u2514\u2500\u2500 [0.50s] Completion\n</code></pre></p>"},{"location":"en/api/observability/#show_cost_summary","title":"show_cost_summary()","text":"<p>Show cost summary.</p> <pre><code>def show_cost_summary(\n    self, since: Optional[float] = None, group_by: str = \"agent\"\n) -&gt; None\n</code></pre> <p>Parameters: - since (<code>Optional[float]</code>): Filter by start time (timestamp) - group_by (<code>str</code>, default: <code>\"agent\"</code>): Group by <code>\"agent\"</code> or <code>\"date\"</code></p> <p>Example: <pre><code># Cost by agent\ndashboard.show_cost_summary(group_by=\"agent\")\n\n# Cost by date\ndashboard.show_cost_summary(group_by=\"date\")\n\n# Last 7 days\nimport time\nsince = time.time() - (7 * 86400)\ndashboard.show_cost_summary(since=since)\n</code></pre></p> <p>Output (by agent): <pre><code>\u250c\u2500 Cost by Agent \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Agent          Calls  Tokens    Cost     \u2502\n\u2502 translator     23     5,123     $0.0234  \u2502\n\u2502 chatbot        15     4,892     $0.0189  \u2502\n\u2502 researcher     4      2,435     $0.0089  \u2502\n\u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502 Total          42     12,450    $0.0512  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nEstimated monthly cost: $1.54\n</code></pre></p>"},{"location":"en/api/observability/#cli-commands","title":"CLI Commands","text":"<p>The <code>kagura monitor</code> command provides quick access to observability features.</p>"},{"location":"en/api/observability/#live-monitoring","title":"Live Monitoring","text":"<pre><code># Monitor all agents\nkagura monitor\n\n# Monitor specific agent\nkagura monitor --agent translator\n\n# Custom refresh rate\nkagura monitor --refresh 2.0\n\n# Custom database\nkagura monitor --db /path/to/telemetry.db\n</code></pre>"},{"location":"en/api/observability/#execution-list","title":"Execution List","text":"<pre><code># List recent executions\nkagura monitor list\n\n# Filter by agent\nkagura monitor list --agent translator\n\n# Filter by status\nkagura monitor list --status failed\n\n# Limit results\nkagura monitor list --limit 50\n</code></pre>"},{"location":"en/api/observability/#statistics","title":"Statistics","text":"<pre><code># Overall statistics\nkagura monitor stats\n\n# Agent-specific stats\nkagura monitor stats --agent translator\n</code></pre>"},{"location":"en/api/observability/#detailed-trace","title":"Detailed Trace","text":"<pre><code># Show trace for specific execution\nkagura monitor trace exec_abc123\n</code></pre>"},{"location":"en/api/observability/#cost-analysis","title":"Cost Analysis","text":"<pre><code># Cost by agent\nkagura monitor cost\n\n# Cost by date\nkagura monitor cost --group-by date\n</code></pre>"},{"location":"en/api/observability/#complete-example","title":"Complete Example","text":"<pre><code>import asyncio\nimport time\nfrom pathlib import Path\nfrom kagura import agent\nfrom kagura.observability import EventStore, Dashboard\n\n\n@agent(model=\"gpt-4o-mini\")\nasync def translator(text: str, target_lang: str) -&gt; str:\n    '''Translate \"{{ text }}\" to {{ target_lang }}'''\n    pass\n\n\nasync def main():\n    # Run agent multiple times\n    translations = [\n        (\"Hello\", \"French\"),\n        (\"Goodbye\", \"Japanese\"),\n        (\"Thank you\", \"Spanish\"),\n    ]\n\n    for text, lang in translations:\n        result = await translator(text, target_lang=lang)\n        print(f\"{text} \u2192 {lang}: {result}\")\n\n    # === Analyze Telemetry ===\n\n    # Initialize\n    store = EventStore()\n    dashboard = Dashboard(store)\n\n    # Get executions\n    executions = store.get_executions(agent_name=\"translator\", limit=10)\n    print(f\"\\n{len(executions)} executions found\")\n\n    # Show statistics\n    stats = store.get_summary_stats(agent_name=\"translator\")\n    print(f\"Avg duration: {stats['avg_duration']:.2f}s\")\n\n    # Show dashboard views\n    print(\"\\n\" + \"=\" * 50)\n    print(\"EXECUTION LIST\")\n    print(\"=\" * 50)\n    dashboard.show_list(agent_name=\"translator\")\n\n    print(\"\\n\" + \"=\" * 50)\n    print(\"STATISTICS\")\n    print(\"=\" * 50)\n    dashboard.show_stats(agent_name=\"translator\")\n\n    print(\"\\n\" + \"=\" * 50)\n    print(\"COST SUMMARY\")\n    print(\"=\" * 50)\n    dashboard.show_cost_summary()\n\n    # === Cleanup old data ===\n    thirty_days_ago = time.time() - (30 * 86400)\n    deleted = store.delete_old_executions(older_than=thirty_days_ago)\n    print(f\"\\nDeleted {deleted} old executions\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/api/observability/#best-practices","title":"Best Practices","text":""},{"location":"en/api/observability/#1-regular-monitoring","title":"1. Regular Monitoring","text":"<p>Check your agents regularly:</p> <pre><code># Daily health check\nkagura monitor stats\n\n# Weekly cost review\nkagura monitor cost\n</code></pre>"},{"location":"en/api/observability/#2-automated-alerts","title":"2. Automated Alerts","text":"<p>Create scripts to alert on issues:</p> <pre><code>def check_failure_rate(agent_name: str, threshold: float = 0.2) -&gt; None:\n    \"\"\"Alert if failure rate exceeds threshold.\"\"\"\n    store = EventStore()\n    stats = store.get_summary_stats(agent_name=agent_name)\n\n    if stats['total_executions'] == 0:\n        return\n\n    failure_rate = stats['failed'] / stats['total_executions']\n\n    if failure_rate &gt; threshold:\n        print(f\"\u26a0\ufe0f  ALERT: {agent_name} failure rate: {failure_rate:.1%}\")\n        # Send notification (email, Slack, etc.)\n</code></pre>"},{"location":"en/api/observability/#3-cost-tracking","title":"3. Cost Tracking","text":"<p>Monitor spending by project:</p> <pre><code>def get_project_cost(project_prefix: str) -&gt; float:\n    \"\"\"Get total cost for project.\"\"\"\n    store = EventStore()\n    executions = store.get_executions(limit=10000)\n\n    total_cost = 0.0\n    for exec in executions:\n        if exec['agent_name'].startswith(project_prefix):\n            total_cost += exec.get('metrics', {}).get('total_cost', 0.0)\n\n    return total_cost\n\n# Example\ncost = get_project_cost(\"project_a_\")\nprint(f\"Project A cost: ${cost:.2f}\")\n</code></pre>"},{"location":"en/api/observability/#4-performance-baselines","title":"4. Performance Baselines","text":"<p>Track performance trends:</p> <pre><code>def detect_performance_regression(\n    agent_name: str, threshold: float = 1.5\n) -&gt; bool:\n    \"\"\"Detect if agent has slowed down.\"\"\"\n    store = EventStore()\n\n    # Baseline (last 100 executions)\n    baseline = store.get_executions(agent_name=agent_name, limit=100)\n    baseline_avg = sum(e['duration'] for e in baseline) / len(baseline)\n\n    # Recent (last 10 executions)\n    recent = store.get_executions(agent_name=agent_name, limit=10)\n    recent_avg = sum(e['duration'] for e in recent) / len(recent)\n\n    return recent_avg &gt; baseline_avg * threshold\n</code></pre>"},{"location":"en/api/observability/#error-handling","title":"Error Handling","text":"<pre><code>from pathlib import Path\nfrom kagura.observability import EventStore\n\ntry:\n    # Access database\n    store = EventStore()\n    executions = store.get_executions()\nexcept Exception as e:\n    print(f\"Database error: {e}\")\n\ntry:\n    # Get specific execution\n    execution = store.get_execution(\"exec_123\")\n    if execution is None:\n        print(\"Execution not found\")\nexcept Exception as e:\n    print(f\"Query error: {e}\")\n</code></pre>"},{"location":"en/api/observability/#related","title":"Related","text":"<ul> <li>Tutorial: Observability - Step-by-step guide</li> <li>@agent Decorator - Core agent decorator</li> <li>Testing API - Agent testing</li> </ul>"},{"location":"en/api/observability/#see-also","title":"See Also","text":"<ul> <li>Quick Start - Getting started</li> <li>Tutorial: Agent Builder - Building agents</li> <li>Tutorial: Testing - Testing agents</li> </ul>"},{"location":"en/api/routing/","title":"Agent Routing API","text":"<p>Automatic agent selection based on user input patterns.</p>"},{"location":"en/api/routing/#overview","title":"Overview","text":"<p>The routing system provides intelligent agent selection based on user input. It supports two routing strategies:</p> <ol> <li>Intent-based routing: Keyword matching for fast, simple routing</li> <li>Semantic routing: Embedding-based matching using semantic similarity</li> </ol> <p>Agents are registered with intent keywords or sample queries, and the router calculates confidence scores to determine the best match.</p> <p>Key Features: - Intent-based keyword matching - Semantic similarity matching (via semantic-router) - Confidence scoring - Fallback mechanism - Case-insensitive matching - Unicode support - Multiple encoder options (OpenAI, Cohere)</p>"},{"location":"en/api/routing/#agentrouter-class","title":"AgentRouter Class","text":"<p>Routes user input to appropriate agents using intent-based matching.</p>"},{"location":"en/api/routing/#constructor","title":"Constructor","text":"<pre><code>AgentRouter(\n    strategy: str = \"intent\",\n    fallback_agent: Callable | None = None,\n    confidence_threshold: float = 0.3,\n    encoder: str = \"openai\"\n)\n</code></pre> <p>Parameters:</p> <ul> <li><code>strategy</code>: Routing strategy</li> <li><code>\"intent\"</code>: Keyword-based matching (default, no API calls)</li> <li><code>\"semantic\"</code>: Embedding-based semantic matching (requires API key)</li> <li><code>fallback_agent</code>: Default agent to use when no match is found or confidence is below threshold</li> <li><code>confidence_threshold</code>: Minimum confidence score (0.0-1.0) required for routing. Lower values are more lenient. Default: 0.3</li> <li><code>encoder</code>: Encoder for semantic routing (only used when <code>strategy=\"semantic\"</code>)</li> <li><code>\"openai\"</code>: OpenAI embeddings (default)</li> <li><code>\"cohere\"</code>: Cohere embeddings</li> </ul> <p>Raises: - <code>InvalidRouterStrategyError</code>: If strategy is not valid</p> <p>Example:</p> <pre><code>from kagura.routing import AgentRouter\n\n# Intent-based router (fast, no API calls)\nrouter = AgentRouter()\n\n# Semantic router (embedding-based)\nrouter = AgentRouter(strategy=\"semantic\")\n\n# Router with fallback\nrouter = AgentRouter(\n    strategy=\"semantic\",\n    fallback_agent=general_assistant,\n    confidence_threshold=0.5,\n    encoder=\"openai\"\n)\n</code></pre> <p>Installation:</p> <p>For semantic routing, install the AI extra (includes routing):</p> <pre><code>pip install kagura-ai[ai]\n</code></pre>"},{"location":"en/api/routing/#methods","title":"Methods","text":""},{"location":"en/api/routing/#register","title":"register","text":"<pre><code>router.register(\n    agent: Callable,\n    intents: list[str] | None = None,\n    samples: list[str] | None = None,\n    description: str = \"\",\n    name: str | None = None\n) -&gt; None\n</code></pre> <p>Register an agent with routing patterns.</p> <p>Parameters:</p> <ul> <li><code>agent</code>: Agent function to register</li> <li><code>intents</code>: List of intent keywords/patterns for matching. Case-insensitive matching is used. (For <code>strategy=\"intent\"</code>)</li> <li><code>samples</code>: List of sample queries for semantic matching. (For <code>strategy=\"semantic\"</code>)</li> <li><code>description</code>: Human-readable description of the agent</li> <li><code>name</code>: Agent name (defaults to function name)</li> </ul> <p>Example:</p> <pre><code>from kagura import agent\n\n@agent\nasync def code_reviewer(code: str) -&gt; str:\n    '''Review code: {{ code }}'''\n    pass\n\n# Intent-based routing\nrouter_intent = AgentRouter(strategy=\"intent\")\nrouter_intent.register(\n    code_reviewer,\n    intents=[\"review\", \"check\", \"analyze\"],\n    description=\"Reviews code for quality and bugs\"\n)\n\n# Semantic routing\nrouter_semantic = AgentRouter(strategy=\"semantic\")\nrouter_semantic.register(\n    code_reviewer,\n    samples=[\n        \"Can you review this code?\",\n        \"Check my implementation\",\n        \"\u3053\u306e\u30b3\u30fc\u30c9\u3092\u30ec\u30d3\u30e5\u30fc\u3057\u3066\"\n    ],\n    description=\"Reviews code for quality and bugs\"\n)\n</code></pre>"},{"location":"en/api/routing/#route","title":"route","text":"<pre><code>async router.route(\n    user_input: str,\n    context: dict[str, Any] | None = None,\n    **kwargs: Any\n) -&gt; Any\n</code></pre> <p>Route user input to the most appropriate agent.</p> <p>Parameters:</p> <ul> <li><code>user_input</code>: User's natural language input</li> <li><code>context</code>: Optional context information (reserved for future use)</li> <li><code>**kwargs</code>: Additional arguments to pass to the selected agent</li> </ul> <p>Returns: - Result from executing the selected agent</p> <p>Raises: - <code>NoAgentFoundError</code>: When no suitable agent is found and no fallback agent is configured</p> <p>Example:</p> <pre><code># Automatic routing\nresult = await router.route(\"Please review this code\")\n# \u2192 Automatically selects and executes code_reviewer\n\n# With additional arguments\nresult = await router.route(\n    \"Translate this text\",\n    target_lang=\"ja\"\n)\n</code></pre>"},{"location":"en/api/routing/#get_matched_agents","title":"get_matched_agents","text":"<pre><code>router.get_matched_agents(\n    user_input: str,\n    top_k: int = 3\n) -&gt; list[tuple[Callable, float]]\n</code></pre> <p>Get top-k matched agents with confidence scores.</p> <p>Parameters:</p> <ul> <li><code>user_input</code>: User input to match against</li> <li><code>top_k</code>: Number of top matches to return</li> </ul> <p>Returns: - List of <code>(agent_function, confidence_score)</code> tuples, sorted by confidence (highest first)</p> <p>Example:</p> <pre><code>matches = router.get_matched_agents(\"review my code\", top_k=3)\n\nfor agent, score in matches:\n    print(f\"{agent.__name__}: {score:.2f}\")\n# Output:\n# code_reviewer: 0.67\n# general_assistant: 0.33\n</code></pre>"},{"location":"en/api/routing/#list_agents","title":"list_agents","text":"<pre><code>router.list_agents() -&gt; list[str]\n</code></pre> <p>List all registered agent names.</p> <p>Returns: - List of registered agent names</p> <p>Example:</p> <pre><code>agents = router.list_agents()\nprint(agents)\n# ['code_reviewer', 'translator', 'data_analyzer']\n</code></pre>"},{"location":"en/api/routing/#get_agent_info","title":"get_agent_info","text":"<pre><code>router.get_agent_info(agent_name: str) -&gt; dict[str, Any]\n</code></pre> <p>Get information about a registered agent.</p> <p>Parameters:</p> <ul> <li><code>agent_name</code>: Name of the agent</li> </ul> <p>Returns: - Dictionary containing agent metadata:   - <code>name</code>: Agent name   - <code>intents</code>: List of intent keywords   - <code>description</code>: Agent description</p> <p>Raises: - <code>AgentNotRegisteredError</code>: If agent is not registered</p> <p>Example:</p> <pre><code>info = router.get_agent_info(\"code_reviewer\")\nprint(info[\"description\"])\n# Reviews code for quality and bugs\n\nprint(info[\"intents\"])\n# ['review', 'check', 'analyze']\n</code></pre>"},{"location":"en/api/routing/#exceptions","title":"Exceptions","text":""},{"location":"en/api/routing/#routingerror","title":"RoutingError","text":"<p>Base exception for routing errors.</p> <pre><code>class RoutingError(Exception):\n    pass\n</code></pre>"},{"location":"en/api/routing/#noagentfounderror","title":"NoAgentFoundError","text":"<p>Raised when no suitable agent is found for routing.</p> <pre><code>class NoAgentFoundError(RoutingError):\n    def __init__(\n        self,\n        message: str,\n        user_input: str | None = None\n    ):\n        ...\n\n    user_input: str | None  # User input that failed to route\n</code></pre> <p>Example:</p> <pre><code>from kagura.routing import NoAgentFoundError\n\ntry:\n    result = await router.route(\"Unknown request\")\nexcept NoAgentFoundError as e:\n    print(f\"Failed to route: {e.user_input}\")\n</code></pre>"},{"location":"en/api/routing/#agentnotregisterederror","title":"AgentNotRegisteredError","text":"<p>Raised when trying to access an unregistered agent.</p> <pre><code>class AgentNotRegisteredError(RoutingError):\n    def __init__(self, agent_name: str):\n        ...\n\n    agent_name: str  # Name of unregistered agent\n</code></pre>"},{"location":"en/api/routing/#invalidrouterstrategyerror","title":"InvalidRouterStrategyError","text":"<p>Raised when an invalid routing strategy is specified.</p> <pre><code>class InvalidRouterStrategyError(RoutingError):\n    def __init__(\n        self,\n        strategy: str,\n        valid_strategies: list[str]\n    ):\n        ...\n\n    strategy: str  # Invalid strategy name\n    valid_strategies: list[str]  # List of valid strategies\n</code></pre>"},{"location":"en/api/routing/#complete-example","title":"Complete Example","text":"<pre><code>from kagura import agent\nfrom kagura.routing import AgentRouter\n\n# Define agents\n@agent\nasync def code_reviewer(code: str) -&gt; str:\n    '''Review code quality: {{ code }}'''\n    pass\n\n@agent\nasync def translator(text: str, target_lang: str = \"en\") -&gt; str:\n    '''Translate {{ text }} to {{ target_lang }}'''\n    pass\n\n@agent\nasync def data_analyzer(data: str) -&gt; str:\n    '''Analyze data: {{ data }}'''\n    pass\n\n@agent\nasync def general_assistant(query: str) -&gt; str:\n    '''General assistant: {{ query }}'''\n    pass\n\n# Create router with fallback\nrouter = AgentRouter(\n    fallback_agent=general_assistant,\n    confidence_threshold=0.4\n)\n\n# Register agents\nrouter.register(\n    code_reviewer,\n    intents=[\"review\", \"check\", \"analyze\"],\n    description=\"Code review and quality analysis\"\n)\n\nrouter.register(\n    translator,\n    intents=[\"translate\", \"\u7ffb\u8a33\", \"translation\"],\n    description=\"Text translation between languages\"\n)\n\nrouter.register(\n    data_analyzer,\n    intents=[\"analyze\", \"statistics\", \"\u30c7\u30fc\u30bf\u5206\u6790\"],\n    description=\"Data analysis and statistics\"\n)\n\n# Use routing\nasync def main():\n    # Code review request\n    result1 = await router.route(\"Please review this Python code\")\n    # \u2192 code_reviewer is automatically selected\n\n    # Translation request\n    result2 = await router.route(\"Translate 'Hello' to Japanese\")\n    # \u2192 translator is automatically selected\n\n    # Unknown request \u2192 fallback\n    result3 = await router.route(\"What's the weather today?\")\n    # \u2192 general_assistant (fallback) is used\n\n    # Check matched agents\n    matches = router.get_matched_agents(\"Check code quality\")\n    for agent, score in matches:\n        print(f\"{agent.__name__}: {score:.2f}\")\n\n# Run\nawait main()\n</code></pre>"},{"location":"en/api/routing/#intent-matching-algorithm","title":"Intent Matching Algorithm","text":"<p>The intent matching algorithm works as follows:</p> <ol> <li>Keyword Matching: For each registered agent, check if any of its intent keywords appear in the user input (case-insensitive)</li> <li>Score Calculation: Score = (number of matched intents) / (total number of intents)</li> <li>Ranking: Agents are ranked by score in descending order</li> <li>Threshold Check: If the top agent's score is below <code>confidence_threshold</code>, use fallback agent</li> <li>Execution: Execute the top-ranked agent with the user input</li> </ol> <p>Example Scoring:</p> <pre><code># Agent registered with intents: [\"review\", \"check\", \"analyze\"]\nuser_input = \"review and check code\"\n\n# Matching:\n# - \"review\" \u2713 found in input\n# - \"check\"  \u2713 found in input\n# - \"analyze\" \u2717 not found in input\n\n# Score = 2 / 3 = 0.67\n</code></pre>"},{"location":"en/api/routing/#best-practices","title":"Best Practices","text":""},{"location":"en/api/routing/#1-choose-specific-intents","title":"1. Choose Specific Intents","text":"<p>Use specific, distinctive keywords that clearly identify the agent's purpose:</p> <pre><code># \u2705 Good: Specific intents\nrouter.register(\n    billing_agent,\n    intents=[\"billing\", \"payment\", \"invoice\", \"subscription\"]\n)\n\n# \u274c Bad: Generic intents\nrouter.register(\n    billing_agent,\n    intents=[\"help\", \"question\", \"issue\"]\n)\n</code></pre>"},{"location":"en/api/routing/#2-set-appropriate-threshold","title":"2. Set Appropriate Threshold","text":"<p>Adjust <code>confidence_threshold</code> based on your use case:</p> <pre><code># Strict matching (fewer false positives)\nrouter = AgentRouter(confidence_threshold=0.6)\n\n# Lenient matching (better coverage)\nrouter = AgentRouter(confidence_threshold=0.3)\n</code></pre>"},{"location":"en/api/routing/#3-always-provide-fallback","title":"3. Always Provide Fallback","text":"<p>Ensure there's a fallback agent for unmatched requests:</p> <pre><code>@agent\nasync def general_assistant(query: str) -&gt; str:\n    '''General purpose assistant: {{ query }}'''\n    pass\n\nrouter = AgentRouter(fallback_agent=general_assistant)\n</code></pre>"},{"location":"en/api/routing/#4-support-multiple-languages","title":"4. Support Multiple Languages","text":"<p>Include multilingual intent keywords for international support:</p> <pre><code>router.register(\n    translator,\n    intents=[\n        \"translate\", \"\u7ffb\u8a33\", \"\ubc88\uc5ed\",  # English, Japanese, Korean\n        \"translation\", \"traduire\"     # English, French\n    ]\n)\n</code></pre>"},{"location":"en/api/routing/#5-test-your-intents","title":"5. Test Your Intents","text":"<p>Test with various user inputs to ensure correct routing:</p> <pre><code># Test suite\ntest_cases = [\n    (\"review this code\", \"code_reviewer\"),\n    (\"check code quality\", \"code_reviewer\"),\n    (\"translate to Japanese\", \"translator\"),\n    (\"what's the weather\", \"fallback\"),\n]\n\nfor input_text, expected in test_cases:\n    matches = router.get_matched_agents(input_text, top_k=1)\n    if matches:\n        assert matches[0][0].__name__ == expected\n</code></pre>"},{"location":"en/api/routing/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Matching Speed: ~1ms for intent-based matching (very fast)</li> <li>Memory Usage: Minimal (stores only intent keywords per agent)</li> <li>Scalability: Efficient for up to 100+ registered agents</li> </ul>"},{"location":"en/api/routing/#limitations","title":"Limitations","text":""},{"location":"en/api/routing/#phase-1-limitations","title":"Phase 1 Limitations","text":"<ul> <li>Only supports intent-based (keyword) matching</li> <li>No semantic understanding (e.g., synonyms)</li> <li>Simple substring matching (not NLP-based)</li> </ul> <p>Future Phases: - Phase 2: Semantic routing with embeddings - Phase 3: Agent chaining and conditional routing</p>"},{"location":"en/api/routing/#memoryawarerouter","title":"MemoryAwareRouter","text":"<p>Context-aware routing that considers conversation history for better agent selection.</p>"},{"location":"en/api/routing/#overview_1","title":"Overview","text":"<p><code>MemoryAwareRouter</code> extends <code>AgentRouter</code> with memory-aware capabilities: - Detects context-dependent queries (pronouns, implicit references) - Retrieves relevant context from conversation history - Enhances queries with context before routing - Supports semantic context retrieval via RAG</p>"},{"location":"en/api/routing/#constructor_1","title":"Constructor","text":"<pre><code>from kagura.core.memory import MemoryManager\nfrom kagura.routing import MemoryAwareRouter\n\nmemory = MemoryManager(agent_name=\"assistant\", enable_rag=True)\nrouter = MemoryAwareRouter(\n    memory=memory,\n    strategy=\"intent\",\n    fallback_agent=None,\n    confidence_threshold=0.3,\n    encoder=\"openai\",\n    context_window=5,\n    use_semantic_context=True\n)\n</code></pre> <p>Parameters:</p> <ul> <li>memory (<code>MemoryManager</code>, required): Memory manager instance</li> <li>strategy (<code>str</code>, default: <code>\"intent\"</code>): Routing strategy (<code>\"intent\"</code> or <code>\"semantic\"</code>)</li> <li>fallback_agent (<code>Optional[Callable]</code>, default: <code>None</code>): Default agent</li> <li>confidence_threshold (<code>float</code>, default: <code>0.3</code>): Minimum confidence score</li> <li>encoder (<code>str</code>, default: <code>\"openai\"</code>): Encoder for semantic routing</li> <li>context_window (<code>int</code>, default: <code>5</code>): Number of recent messages to consider</li> <li>use_semantic_context (<code>bool</code>, default: <code>True</code>): Enable RAG-based context retrieval</li> </ul>"},{"location":"en/api/routing/#route_1","title":"route()","text":"<p>Route user input with memory awareness.</p> <pre><code>async def route(\n    self,\n    user_input: str,\n    context: Optional[dict[str, Any]] = None,\n    **kwargs: Any\n) -&gt; Any\n</code></pre> <p>Parameters:</p> <ul> <li>user_input (<code>str</code>): User's natural language input</li> <li>context (<code>Optional[dict]</code>): Optional context information</li> <li>kwargs: Additional arguments to pass to the selected agent</li> </ul> <p>Returns: Result from executing the selected agent</p> <p>Example:</p> <pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\nfrom kagura.routing import MemoryAwareRouter\n\n# Define agents\n@agent\nasync def translator(text: str, target_lang: str) -&gt; str:\n    '''Translate \"{{ text }}\" to {{ target_lang }}'''\n    pass\n\n# Initialize memory and router\nmemory = MemoryManager(agent_name=\"assistant\", enable_rag=True)\nrouter = MemoryAwareRouter(memory=memory)\n\n# Register agent\nrouter.register(translator, intents=[\"translate\", \"\u7ffb\u8a33\"])\n\n# First query (explicit)\nresult = await router.route(\"Translate 'hello' to French\")\n# Routes to translator, translates to French\n\n# Second query (context-dependent)\nresult = await router.route(\"What about Spanish?\")\n# Router understands \"Spanish\" refers to translation\n# Enhances query with context: \"Previous: Translate 'hello' to French. Current: What about Spanish?\"\n# Routes to translator with inferred context\n</code></pre>"},{"location":"en/api/routing/#context-detection","title":"Context Detection","text":"<p>The router automatically detects context-dependent queries:</p> <p>Pronouns: - it, this, that, them, etc. - Example: \"What about it?\"</p> <p>Implicit References: - also, too, again, similar, same, etc. - Example: \"Do that again\"</p> <p>Follow-up Patterns: - \"What about...\", \"How about...\", \"And if...\" - Example: \"What about Japanese?\"</p>"},{"location":"en/api/routing/#context-enhancement","title":"Context Enhancement","text":"<p>When context is needed, the router performs two-stage enhancement:</p> <p>Stage 1: Recent Conversation - Retrieves last N messages from ContextMemory - Resolves pronouns and implicit references - Combines with current query</p> <p>Stage 2: Semantic Context (Optional) - If RAG enabled, queries ChromaDB for semantically similar past conversations - Appends top-k relevant messages as additional context</p>"},{"location":"en/api/routing/#complete-example_1","title":"Complete Example","text":"<pre><code>import asyncio\nfrom kagura import agent\nfrom kagura.core.memory import MemoryManager\nfrom kagura.routing import MemoryAwareRouter\n\n\n@agent\nasync def translator(text: str, target_lang: str) -&gt; str:\n    '''Translate \"{{ text }}\" to {{ target_lang }}'''\n    pass\n\n\n@agent\nasync def summarizer(text: str) -&gt; str:\n    '''Summarize: {{ text }}'''\n    pass\n\n\nasync def main():\n    # Initialize with memory\n    memory = MemoryManager(\n        agent_name=\"assistant\",\n        enable_rag=True  # Enable semantic context\n    )\n\n    router = MemoryAwareRouter(\n        memory=memory,\n        context_window=5,  # Consider last 5 messages\n        use_semantic_context=True  # Use RAG\n    )\n\n    # Register agents\n    router.register(translator, intents=[\"translate\", \"translation\"])\n    router.register(summarizer, intents=[\"summarize\", \"summary\"])\n\n    # Conversation with context\n    print(\"Query 1:\")\n    result = await router.route(\"Translate 'hello world' to French\")\n    print(f\"Result: {result}\\n\")\n\n    print(\"Query 2 (context-dependent):\")\n    result = await router.route(\"What about Japanese?\")\n    # Router understands \"Japanese\" refers to translation\n    print(f\"Result: {result}\\n\")\n\n    print(\"Query 3 (another context):\")\n    result = await router.route(\"Summarize the previous translation\")\n    # Router understands \"previous translation\" from context\n    print(f\"Result: {result}\\n\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/api/routing/#utility-methods","title":"Utility Methods","text":""},{"location":"en/api/routing/#get_conversation_summary","title":"get_conversation_summary()","text":"<p>Get a summary of recent conversation.</p> <pre><code>summary = router.get_conversation_summary(last_n=10)\nprint(summary)\n\n# Output:\n# User: Translate 'hello' to French\n# Assistant: Bonjour\n# User: What about Spanish?\n# Assistant: Hola\n</code></pre>"},{"location":"en/api/routing/#clear_context","title":"clear_context()","text":"<p>Clear conversation context from memory.</p> <pre><code>router.clear_context()\n</code></pre>"},{"location":"en/api/routing/#best-practices_1","title":"Best Practices","text":"<ol> <li> <p>Enable RAG for Better Context:    <pre><code>memory = MemoryManager(enable_rag=True)\nrouter = MemoryAwareRouter(memory=memory, use_semantic_context=True)\n</code></pre></p> </li> <li> <p>Adjust Context Window:    <pre><code># Short conversations\nrouter = MemoryAwareRouter(memory=memory, context_window=3)\n\n# Long conversations\nrouter = MemoryAwareRouter(memory=memory, context_window=10)\n</code></pre></p> </li> <li> <p>Store Conversation History:    <pre><code># Router automatically stores messages, but you can also manually add context\nmemory.add_message(\"system\", \"User prefers concise responses\")\n</code></pre></p> </li> <li> <p>Clear Context Between Sessions:    <pre><code># Start new conversation\nrouter.clear_context()\n</code></pre></p> </li> </ol>"},{"location":"en/api/routing/#limitations_1","title":"Limitations","text":"<ul> <li>Context detection is heuristic-based (may miss some edge cases)</li> <li>Semantic context requires ChromaDB installation</li> <li>Performance depends on RAG query speed (~100ms)</li> </ul>"},{"location":"en/api/routing/#see-also","title":"See Also","text":"<ul> <li>Agent Routing Tutorial</li> <li>Memory Management API</li> <li>Agent Decorator API</li> <li>RFC-016: Agent Routing System</li> <li>RFC-020: Memory-Aware Routing</li> </ul>"},{"location":"en/api/shell/","title":"Shell API Reference","text":""},{"location":"en/api/shell/#overview","title":"Overview","text":"<p>The Shell module provides secure shell command execution with security controls including command whitelisting, blacklisting, and timeout management.</p>"},{"location":"en/api/shell/#module-kaguracoreshell","title":"Module: <code>kagura.core.shell</code>","text":""},{"location":"en/api/shell/#class-shellexecutor","title":"<code>class ShellExecutor</code>","text":"<p>Secure shell command executor with security controls.</p> <p>Constructor: <pre><code>ShellExecutor(\n    allowed_commands: Optional[list[str]] = None,\n    blocked_commands: Optional[list[str]] = None,\n    working_dir: Optional[Path] = None,\n    timeout: int = 30,\n    require_confirmation: bool = False\n)\n</code></pre></p> <p>Parameters: - <code>allowed_commands</code>: Whitelist of allowed commands (None = use defaults) - <code>blocked_commands</code>: Blacklist of blocked commands (None = use defaults) - <code>working_dir</code>: Working directory for command execution - <code>timeout</code>: Command timeout in seconds (default: 30) - <code>require_confirmation</code>: Whether to require user confirmation</p> <p>Methods:</p>"},{"location":"en/api/shell/#async-execcommand-str-env-optionaldictstr-str-none-capture_output-bool-true-shellresult","title":"<code>async exec(command: str, env: Optional[dict[str, str]] = None, capture_output: bool = True) -&gt; ShellResult</code>","text":"<p>Execute shell command securely.</p> <p>Parameters: - <code>command</code>: Shell command to execute - <code>env</code>: Environment variables (optional) - <code>capture_output</code>: Whether to capture stdout/stderr</p> <p>Returns: - <code>ShellResult</code> containing execution results</p> <p>Raises: - <code>SecurityError</code>: If command violates security policy - <code>TimeoutError</code>: If command exceeds timeout - <code>UserCancelledError</code>: If user cancels execution</p> <p>Example: <pre><code>from kagura.core.shell import ShellExecutor\nfrom pathlib import Path\n\nexecutor = ShellExecutor(\n    allowed_commands=[\"git\", \"npm\"],\n    timeout=60,\n    working_dir=Path(\"./project\")\n)\n\nresult = await executor.exec(\"git status\")\nif result.success:\n    print(result.stdout)\n</code></pre></p>"},{"location":"en/api/shell/#validate_commandcommand-str-bool","title":"<code>validate_command(command: str) -&gt; bool</code>","text":"<p>Validate command against security policies.</p> <p>Parameters: - <code>command</code>: Shell command to validate</p> <p>Returns: - <code>True</code> if command is valid</p> <p>Raises: - <code>SecurityError</code>: If command violates security policy</p> <p>Example: <pre><code>executor = ShellExecutor(allowed_commands=[\"echo\", \"ls\"])\n\n# Will pass\nexecutor.validate_command(\"echo hello\")\n\n# Will raise SecurityError\nexecutor.validate_command(\"rm -rf /\")\n</code></pre></p>"},{"location":"en/api/shell/#class-shellresult","title":"<code>class ShellResult</code>","text":"<p>Result of shell command execution.</p> <p>Attributes: - <code>return_code: int</code> - Process exit code - <code>stdout: str</code> - Standard output - <code>stderr: str</code> - Standard error - <code>command: str</code> - Executed command</p> <p>Properties:</p>"},{"location":"en/api/shell/#success-bool","title":"<code>success: bool</code>","text":"<p>Check if command executed successfully (return code == 0).</p> <p>Example: <pre><code>result = await executor.exec(\"ls\")\nif result.success:\n    print(\"Command succeeded\")\n</code></pre></p>"},{"location":"en/api/shell/#exceptions","title":"Exceptions","text":""},{"location":"en/api/shell/#securityerror","title":"<code>SecurityError</code>","text":"<p>Raised when command violates security policy.</p> <pre><code>from kagura.core.shell import SecurityError\n\ntry:\n    await executor.exec(\"sudo rm -rf /\")\nexcept SecurityError as e:\n    print(f\"Command blocked: {e}\")\n</code></pre>"},{"location":"en/api/shell/#usercancellederror","title":"<code>UserCancelledError</code>","text":"<p>Raised when user cancels command execution.</p>"},{"location":"en/api/shell/#module-kagurabuiltin","title":"Module: <code>kagura.builtin</code>","text":""},{"location":"en/api/shell/#built-in-shell-functions","title":"Built-in Shell Functions","text":""},{"location":"en/api/shell/#async-shellcommand-str-working_dir-str-str","title":"<code>async shell(command: str, working_dir: str = \".\") -&gt; str</code>","text":"<p>Execute a shell command safely.</p> <p>Parameters: - <code>command</code>: The shell command to execute - <code>working_dir</code>: Working directory (default: current directory)</p> <p>Returns: - Command output (stdout if success, stderr if failed)</p> <p>Raises: - <code>RuntimeError</code>: If command execution fails - <code>SecurityError</code>: If command violates security policy</p> <p>Example: <pre><code>from kagura.builtin import shell\n\noutput = await shell(\"ls -la\")\nprint(output)\n\noutput = await shell(\"pwd\", working_dir=\"/tmp\")\n</code></pre></p>"},{"location":"en/api/shell/#built-in-git-functions","title":"Built-in Git Functions","text":""},{"location":"en/api/shell/#async-git_commitmessage-str-files-liststr-none-none-all-bool-false-str","title":"<code>async git_commit(message: str, files: list[str] | None = None, all: bool = False) -&gt; str</code>","text":"<p>Create a git commit.</p> <p>Parameters: - <code>message</code>: Commit message - <code>files</code>: Specific files to commit (optional) - <code>all</code>: Commit all changes (git commit -a)</p> <p>Returns: - Git commit output</p> <p>Example: <pre><code>from kagura.builtin import git_commit\n\nawait git_commit(\"feat: add feature\", files=[\"src/main.py\"])\nawait git_commit(\"fix: bug fix\", all=True)\n</code></pre></p>"},{"location":"en/api/shell/#async-git_pushremote-str-origin-branch-str-none-none-str","title":"<code>async git_push(remote: str = \"origin\", branch: str | None = None) -&gt; str</code>","text":"<p>Push commits to remote repository.</p> <p>Parameters: - <code>remote</code>: Remote name (default: origin) - <code>branch</code>: Branch name (default: current branch)</p> <p>Returns: - Git push output</p> <p>Example: <pre><code>from kagura.builtin import git_push\n\nawait git_push()\nawait git_push(remote=\"origin\", branch=\"main\")\n</code></pre></p>"},{"location":"en/api/shell/#async-git_status-str","title":"<code>async git_status() -&gt; str</code>","text":"<p>Get git repository status.</p> <p>Returns: - Git status output</p> <p>Example: <pre><code>from kagura.builtin import git_status\n\nstatus = await git_status()\nprint(status)\n</code></pre></p>"},{"location":"en/api/shell/#async-git_create_prtitle-str-body-str-base-str-main-str","title":"<code>async git_create_pr(title: str, body: str, base: str = \"main\") -&gt; str</code>","text":"<p>Create a pull request using GitHub CLI.</p> <p>Requires: GitHub CLI (<code>gh</code>) installed and authenticated</p> <p>Parameters: - <code>title</code>: PR title - <code>body</code>: PR description - <code>base</code>: Base branch (default: main)</p> <p>Returns: - PR URL</p> <p>Example: <pre><code>from kagura.builtin import git_create_pr\n\npr_url = await git_create_pr(\n    title=\"feat: new feature\",\n    body=\"This PR adds a new feature\"\n)\n</code></pre></p>"},{"location":"en/api/shell/#built-in-file-functions","title":"Built-in File Functions","text":""},{"location":"en/api/shell/#async-file_searchpattern-str-directory-str-file_type-str-liststr","title":"<code>async file_search(pattern: str, directory: str = \".\", file_type: str = \"*\") -&gt; list[str]</code>","text":"<p>Search for files matching pattern.</p> <p>Parameters: - <code>pattern</code>: File name pattern to search for - <code>directory</code>: Directory to search in (default: current directory) - <code>file_type</code>: File extension filter (e.g., \".py\", \".txt\")</p> <p>Returns: - List of matching file paths</p> <p>Example: <pre><code>from kagura.builtin import file_search\n\nfiles = await file_search(\"test\", directory=\"./tests\", file_type=\"*.py\")\nprint(f\"Found {len(files)} test files\")\n</code></pre></p>"},{"location":"en/api/shell/#async-grep_contentpattern-str-files-liststr-dictstr-liststr","title":"<code>async grep_content(pattern: str, files: list[str]) -&gt; dict[str, list[str]]</code>","text":"<p>Search for content in files.</p> <p>Parameters: - <code>pattern</code>: Text pattern to search for - <code>files</code>: List of file paths to search in</p> <p>Returns: - Dictionary mapping file paths to matching lines</p> <p>Example: <pre><code>from kagura.builtin import grep_content\n\nresults = await grep_content(\"TODO\", [\"src/main.py\", \"src/utils.py\"])\nfor file, lines in results.items():\n    print(f\"{file}: {len(lines)} matches\")\n</code></pre></p>"},{"location":"en/api/shell/#security-configuration","title":"Security Configuration","text":""},{"location":"en/api/shell/#default-allowed-commands","title":"Default Allowed Commands","text":"<pre><code>[\n    # Git\n    \"git\", \"gh\",\n    # File operations\n    \"ls\", \"cat\", \"find\", \"grep\", \"mkdir\", \"rm\", \"cp\", \"mv\", \"pwd\",\n    # Package managers\n    \"npm\", \"pip\", \"uv\", \"poetry\", \"yarn\", \"pnpm\",\n    # Build tools\n    \"make\", \"cmake\", \"cargo\", \"go\",\n    # Testing\n    \"pytest\", \"jest\", \"vitest\",\n    # Others\n    \"echo\", \"which\", \"wc\", \"sort\", \"uniq\"\n]\n</code></pre>"},{"location":"en/api/shell/#default-blocked-commands","title":"Default Blocked Commands","text":"<pre><code>[\n    \"sudo\", \"su\", \"passwd\", \"shutdown\", \"reboot\",\n    \"dd\", \"mkfs\", \"fdisk\", \"parted\",\n    \"eval\", \"exec\", \"source\",\n    \"curl -s | sh\", \"wget -O - | sh\", \"rm -rf /\"\n]\n</code></pre>"},{"location":"en/api/shell/#see-also","title":"See Also","text":"<ul> <li>Shell Integration Tutorial</li> <li>Built-in Functions</li> </ul>"},{"location":"en/api/testing/","title":"Testing API","text":"<p>Framework for testing AI agents with assertions designed for non-deterministic LLM outputs.</p>"},{"location":"en/api/testing/#overview","title":"Overview","text":"<p>The <code>kagura.testing</code> module provides tools for testing AI agents: - AgentTestCase: Base class with assertion methods - LLMMock/LLMRecorder: Mock and record LLM calls - ToolMock: Mock tool executions - Timer: Measure execution time</p>"},{"location":"en/api/testing/#class-agenttestcase","title":"Class: AgentTestCase","text":"<p>Base class for testing Kagura agents.</p> <pre><code>from kagura.testing import AgentTestCase\nimport pytest\n\n\nclass TestMyAgent(AgentTestCase):\n    agent = my_agent  # Agent to test\n\n    @pytest.mark.asyncio\n    async def test_example(self):\n        result = await self.agent(\"test input\")\n        self.assert_not_empty(result)\n</code></pre>"},{"location":"en/api/testing/#constructor","title":"Constructor","text":"<pre><code>def __init__(self) -&gt; None\n</code></pre> <p>Initializes test case with empty telemetry tracking.</p>"},{"location":"en/api/testing/#content-assertions","title":"Content Assertions","text":""},{"location":"en/api/testing/#assert_contains","title":"assert_contains()","text":"<p>Assert text contains substring.</p> <pre><code>def assert_contains(self, text: str, substring: str) -&gt; None\n</code></pre> <p>Parameters: - text (<code>str</code>): Text to check - substring (<code>str</code>): Expected substring</p> <p>Raises: <code>AssertionError</code> if substring not found</p> <p>Example: <pre><code>result = await self.agent(\"Hello, Alice\")\nself.assert_contains(result, \"Alice\")\n</code></pre></p>"},{"location":"en/api/testing/#assert_contains_any","title":"assert_contains_any()","text":"<p>Assert text contains at least one of the options.</p> <pre><code>def assert_contains_any(self, text: str, options: list[str]) -&gt; None\n</code></pre> <p>Parameters: - text (<code>str</code>): Text to check - options (<code>list[str]</code>): List of possible substrings</p> <p>Raises: <code>AssertionError</code> if none of the options found</p> <p>Example: <pre><code>result = await self.agent(\"greet\")\nself.assert_contains_any(result, [\"Hello\", \"Hi\", \"Hey\"])\n</code></pre></p>"},{"location":"en/api/testing/#assert_not_contains","title":"assert_not_contains()","text":"<p>Assert text does not contain substring.</p> <pre><code>def assert_not_contains(self, text: str, substring: str) -&gt; None\n</code></pre> <p>Parameters: - text (<code>str</code>): Text to check - substring (<code>str</code>): Forbidden substring</p> <p>Raises: <code>AssertionError</code> if substring found</p> <p>Example: <pre><code>result = await self.agent(\"test\")\nself.assert_not_contains(result, \"error\")\n</code></pre></p>"},{"location":"en/api/testing/#assert_matches_pattern","title":"assert_matches_pattern()","text":"<p>Assert text matches regex pattern.</p> <pre><code>def assert_matches_pattern(self, text: str, pattern: str) -&gt; None\n</code></pre> <p>Parameters: - text (<code>str</code>): Text to check - pattern (<code>str</code>): Regex pattern</p> <p>Raises: <code>AssertionError</code> if pattern doesn't match</p> <p>Example: <pre><code>result = await self.agent(\"extract email\")\nself.assert_matches_pattern(result, r'\\w+@\\w+\\.\\w+')\n</code></pre></p>"},{"location":"en/api/testing/#assert_not_empty","title":"assert_not_empty()","text":"<p>Assert text is not empty.</p> <pre><code>def assert_not_empty(self, text: str) -&gt; None\n</code></pre> <p>Parameters: - text (<code>str</code>): Text to check</p> <p>Raises: <code>AssertionError</code> if text is empty or only whitespace</p> <p>Example: <pre><code>result = await self.agent(\"test\")\nself.assert_not_empty(result)\n</code></pre></p>"},{"location":"en/api/testing/#assert_language","title":"assert_language()","text":"<p>Assert text is in expected language.</p> <pre><code>def assert_language(self, text: str, expected_lang: str) -&gt; None\n</code></pre> <p>Parameters: - text (<code>str</code>): Text to check - expected_lang (<code>str</code>): Expected language code (e.g., <code>\"en\"</code>, <code>\"ja\"</code>, <code>\"fr\"</code>)</p> <p>Raises: - <code>AssertionError</code>: If language doesn't match - <code>ImportError</code>: If <code>langdetect</code> not installed</p> <p>Requires: <code>pip install langdetect</code></p> <p>Example: <pre><code>result = await self.agent(\"translate to French\")\nself.assert_language(result, \"fr\")\n</code></pre></p>"},{"location":"en/api/testing/#llm-behavior-assertions","title":"LLM Behavior Assertions","text":""},{"location":"en/api/testing/#assert_llm_calls","title":"assert_llm_calls()","text":"<p>Assert number and characteristics of LLM calls.</p> <pre><code>def assert_llm_calls(\n    self,\n    count: Optional[int] = None,\n    model: Optional[str] = None,\n) -&gt; None\n</code></pre> <p>Parameters: - count (<code>Optional[int]</code>): Expected number of LLM calls - model (<code>Optional[str]</code>): Expected model name</p> <p>Raises: <code>AssertionError</code> if LLM calls don't match expectations</p> <p>Example: <pre><code>with self.record_llm_calls():\n    result = await self.agent(\"test\")\n\n# Assert exactly 1 call\nself.assert_llm_calls(count=1)\n\n# Assert correct model\nself.assert_llm_calls(model=\"gpt-4o-mini\")\n\n# Assert both\nself.assert_llm_calls(count=1, model=\"gpt-4o-mini\")\n</code></pre></p>"},{"location":"en/api/testing/#assert_token_usage","title":"assert_token_usage()","text":"<p>Assert token usage is within bounds.</p> <pre><code>def assert_token_usage(\n    self,\n    max_tokens: Optional[int] = None,\n    min_tokens: Optional[int] = None,\n) -&gt; None\n</code></pre> <p>Parameters: - max_tokens (<code>Optional[int]</code>): Maximum allowed tokens - min_tokens (<code>Optional[int]</code>): Minimum expected tokens</p> <p>Raises: <code>AssertionError</code> if token usage out of bounds</p> <p>Example: <pre><code>with self.record_llm_calls():\n    result = await self.agent(\"test\")\n\n# Assert under budget\nself.assert_token_usage(max_tokens=500)\n\n# Assert meaningful response\nself.assert_token_usage(min_tokens=10)\n</code></pre></p>"},{"location":"en/api/testing/#assert_tool_calls","title":"assert_tool_calls()","text":"<p>Assert specific tools were called.</p> <pre><code>def assert_tool_calls(self, expected_tools: list[str]) -&gt; None\n</code></pre> <p>Parameters: - expected_tools (<code>list[str]</code>): List of expected tool names</p> <p>Raises: <code>AssertionError</code> if expected tools not called</p> <p>Example: <pre><code>result = await self.agent(\"search for Python\")\nself.assert_tool_calls([\"search_web\"])\n</code></pre></p>"},{"location":"en/api/testing/#performance-assertions","title":"Performance Assertions","text":""},{"location":"en/api/testing/#assert_duration","title":"assert_duration()","text":"<p>Assert execution duration is within limit.</p> <pre><code>def assert_duration(self, max_seconds: float) -&gt; None\n</code></pre> <p>Parameters: - max_seconds (<code>float</code>): Maximum allowed duration in seconds</p> <p>Raises: <code>AssertionError</code> if duration exceeds limit</p> <p>Example: <pre><code>with self.measure_time():\n    result = await self.agent(\"test\")\n\nself.assert_duration(5.0)  # Must complete within 5 seconds\n</code></pre></p>"},{"location":"en/api/testing/#assert_cost","title":"assert_cost()","text":"<p>Assert execution cost is within budget.</p> <pre><code>def assert_cost(self, max_cost: float) -&gt; None\n</code></pre> <p>Parameters: - max_cost (<code>float</code>): Maximum allowed cost in USD</p> <p>Raises: <code>AssertionError</code> if cost exceeds budget</p> <p>Example: <pre><code>with self.record_llm_calls():\n    result = await self.agent(\"test\")\n\nself.assert_cost(0.01)  # Must cost less than $0.01\n</code></pre></p>"},{"location":"en/api/testing/#structured-output-assertions","title":"Structured Output Assertions","text":""},{"location":"en/api/testing/#assert_valid_model","title":"assert_valid_model()","text":"<p>Assert result is valid instance of Pydantic model.</p> <pre><code>def assert_valid_model(self, result: Any, model_class: type) -&gt; None\n</code></pre> <p>Parameters: - result (<code>Any</code>): Result to check - model_class (<code>type</code>): Expected Pydantic model class</p> <p>Raises: <code>AssertionError</code> if result is not instance of model_class</p> <p>Example: <pre><code>from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\nresult = await self.agent(\"extract person\")\nself.assert_valid_model(result, Person)\n</code></pre></p>"},{"location":"en/api/testing/#assert_field_value","title":"assert_field_value()","text":"<p>Assert model field has expected value.</p> <pre><code>def assert_field_value(\n    self, result: Any, field: str, expected: Any\n) -&gt; None\n</code></pre> <p>Parameters: - result (<code>Any</code>): Pydantic model instance - field (<code>str</code>): Field name - expected (<code>Any</code>): Expected value</p> <p>Raises: <code>AssertionError</code> if field value doesn't match</p> <p>Example: <pre><code>person = await self.agent(\"extract person\")\nself.assert_field_value(person, \"name\", \"Alice\")\nself.assert_field_value(person, \"age\", 30)\n</code></pre></p>"},{"location":"en/api/testing/#context-managers","title":"Context Managers","text":""},{"location":"en/api/testing/#record_llm_calls","title":"record_llm_calls()","text":"<p>Context manager to record LLM calls.</p> <pre><code>def record_llm_calls(self) -&gt; LLMRecorder\n</code></pre> <p>Returns: <code>LLMRecorder</code> context manager</p> <p>Example: <pre><code>with self.record_llm_calls():\n    result = await self.agent(\"test\")\n\nself.assert_llm_calls(count=1)\n</code></pre></p>"},{"location":"en/api/testing/#mock_llm","title":"mock_llm()","text":"<p>Context manager to mock LLM responses.</p> <pre><code>def mock_llm(self, response: str) -&gt; LLMMock\n</code></pre> <p>Parameters: - response (<code>str</code>): Mock response to return</p> <p>Returns: <code>LLMMock</code> context manager</p> <p>Example: <pre><code>with self.mock_llm(\"Mocked response\"):\n    result = await self.agent(\"test\")\n\nassert result == \"Mocked response\"\n</code></pre></p>"},{"location":"en/api/testing/#mock_tool","title":"mock_tool()","text":"<p>Context manager to mock tool calls.</p> <pre><code>def mock_tool(self, tool_name: str, return_value: Any) -&gt; ToolMock\n</code></pre> <p>Parameters: - tool_name (<code>str</code>): Name of tool to mock - return_value (<code>Any</code>): Value to return</p> <p>Returns: <code>ToolMock</code> context manager</p> <p>Example: <pre><code>with self.mock_tool(\"search_web\", return_value=[\"result1\", \"result2\"]):\n    result = await self.agent(\"search query\")\n</code></pre></p>"},{"location":"en/api/testing/#measure_time","title":"measure_time()","text":"<p>Context manager to measure execution time.</p> <pre><code>def measure_time(self) -&gt; Timer\n</code></pre> <p>Returns: <code>Timer</code> context manager</p> <p>Example: <pre><code>with self.measure_time() as timer:\n    result = await self.agent(\"test\")\n\nprint(f\"Took {timer.duration:.2f}s\")\nself.assert_duration(5.0)\n</code></pre></p>"},{"location":"en/api/testing/#complete-example","title":"Complete Example","text":"<pre><code>import pytest\nfrom pydantic import BaseModel\nfrom kagura import agent\nfrom kagura.testing import AgentTestCase\n\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n\n@agent(model=\"gpt-4o-mini\")\nasync def person_extractor(text: str) -&gt; Person:\n    '''Extract person information from: {{ text }}'''\n    pass\n\n\nclass TestPersonExtractor(AgentTestCase):\n    agent = person_extractor\n\n    @pytest.mark.asyncio\n    async def test_extracts_person(self):\n        \"\"\"Test person extraction.\"\"\"\n        text = \"Alice is 30 years old and works as a software engineer\"\n        result = await self.agent(text)\n\n        # Structured output assertions\n        self.assert_valid_model(result, Person)\n        self.assert_field_value(result, \"name\", \"Alice\")\n        self.assert_field_value(result, \"age\", 30)\n        self.assert_field_value(result, \"occupation\", \"software engineer\")\n\n    @pytest.mark.asyncio\n    async def test_llm_behavior(self):\n        \"\"\"Test LLM call characteristics.\"\"\"\n        with self.record_llm_calls():\n            result = await self.agent(\"Test input\")\n\n        # LLM behavior assertions\n        self.assert_llm_calls(count=1, model=\"gpt-4o-mini\")\n        self.assert_token_usage(max_tokens=200)\n\n    @pytest.mark.asyncio\n    async def test_performance(self):\n        \"\"\"Test performance requirements.\"\"\"\n        with self.measure_time():\n            result = await self.agent(\"Test input\")\n\n        # Performance assertions\n        self.assert_duration(5.0)\n\n    @pytest.mark.asyncio\n    async def test_with_mock(self):\n        \"\"\"Test with mocked LLM response.\"\"\"\n        mock_person = Person(name=\"Mock\", age=25, occupation=\"tester\")\n\n        with self.mock_llm(mock_person.model_dump_json()):\n            result = await self.agent(\"Test input\")\n\n        self.assert_field_value(result, \"name\", \"Mock\")\n\n    @pytest.mark.asyncio\n    async def test_multiple_assertions(self):\n        \"\"\"Test with multiple assertion types.\"\"\"\n        text = \"Bob is 40 years old and is a doctor\"\n\n        # Execute\n        with self.record_llm_calls():\n            with self.measure_time():\n                result = await self.agent(text)\n\n        # Content assertions\n        self.assert_valid_model(result, Person)\n\n        # LLM behavior assertions\n        self.assert_llm_calls(count=1)\n        self.assert_token_usage(max_tokens=300)\n\n        # Performance assertions\n        self.assert_duration(5.0)\n</code></pre>"},{"location":"en/api/testing/#best-practices","title":"Best Practices","text":""},{"location":"en/api/testing/#1-test-patterns-not-exact-text","title":"1. Test Patterns, Not Exact Text","text":"<pre><code># Good - flexible\nself.assert_contains_any(result, [\"hello\", \"hi\", \"greetings\"])\n\n# Bad - brittle\nassert result == \"Hello, World!\"\n</code></pre>"},{"location":"en/api/testing/#2-use-mocks-for-fast-tests","title":"2. Use Mocks for Fast Tests","text":"<pre><code># Fast - mocked (use for unit tests)\nwith self.mock_llm(\"Mocked\"):\n    result = await self.agent(\"test\")\n\n# Slow - real LLM call (use for integration tests)\nresult = await self.agent(\"test\")\n</code></pre>"},{"location":"en/api/testing/#3-combine-assertions","title":"3. Combine Assertions","text":"<pre><code>@pytest.mark.asyncio\nasync def test_comprehensive(self):\n    with self.record_llm_calls():\n        with self.measure_time():\n            result = await self.agent(\"test\")\n\n    # Multiple assertions in one test\n    self.assert_not_empty(result)\n    self.assert_llm_calls(count=1)\n    self.assert_token_usage(max_tokens=500)\n    self.assert_duration(5.0)\n</code></pre>"},{"location":"en/api/testing/#4-parametrize-tests","title":"4. Parametrize Tests","text":"<pre><code>@pytest.mark.asyncio\n@pytest.mark.parametrize(\"text,expected_lang\", [\n    (\"Hello\", \"en\"),\n    (\"Bonjour\", \"fr\"),\n    (\"\u3053\u3093\u306b\u3061\u306f\", \"ja\"),\n])\nasync def test_languages(self, text, expected_lang):\n    result = await self.agent(text)\n    self.assert_language(result, expected_lang)\n</code></pre>"},{"location":"en/api/testing/#common-patterns","title":"Common Patterns","text":""},{"location":"en/api/testing/#pattern-1-golden-test","title":"Pattern 1: Golden Test","text":"<pre><code>@pytest.mark.asyncio\nasync def test_golden_output(self):\n    with self.mock_llm(\"Expected output\"):\n        result = await self.agent(\"test\")\n\n    with open(\"golden_output.txt\") as f:\n        expected = f.read()\n\n    assert result == expected\n</code></pre>"},{"location":"en/api/testing/#pattern-2-regression-test","title":"Pattern 2: Regression Test","text":"<pre><code>@pytest.mark.asyncio\nasync def test_no_regression(self):\n    with self.mock_llm(\"Previous version output\"):\n        result = await self.agent(\"test\")\n\n    self.assert_not_empty(result)\n</code></pre>"},{"location":"en/api/testing/#pattern-3-error-handling","title":"Pattern 3: Error Handling","text":"<pre><code>@pytest.mark.asyncio\nasync def test_handles_empty_response(self):\n    with self.mock_llm(\"\"):\n        result = await self.agent(\"test\")\n\n    # Agent should handle gracefully\n    # (implementation-dependent)\n</code></pre>"},{"location":"en/api/testing/#error-handling","title":"Error Handling","text":"<pre><code>from pydantic import ValidationError\nfrom litellm import APIError\n\n@pytest.mark.asyncio\nasync def test_validation_error(self):\n    \"\"\"Test validation error handling.\"\"\"\n    with pytest.raises(ValidationError):\n        result = await self.agent(\"invalid input\")\n\n@pytest.mark.asyncio\nasync def test_api_error(self):\n    \"\"\"Test API error handling.\"\"\"\n    with pytest.raises(APIError):\n        result = await self.agent(\"test\")\n</code></pre>"},{"location":"en/api/testing/#related","title":"Related","text":"<ul> <li>Tutorial: Testing - Step-by-step testing guide</li> <li>@agent Decorator - Core agent decorator</li> <li>Tutorial: Agent Builder - Building agents</li> </ul>"},{"location":"en/api/testing/#see-also","title":"See Also","text":"<ul> <li>Quick Start - Getting started</li> <li>Tutorial: Observability - Monitoring agents</li> </ul>"},{"location":"en/api/tools/","title":"Tools API Reference","text":""},{"location":"en/api/tools/#overview","title":"Overview","text":"<p>The Tools API provides decorators and utilities for creating non-LLM functions that can be called by agents and exposed via MCP.</p>"},{"location":"en/api/tools/#tool-decorator","title":"<code>@tool</code> Decorator","text":"<p>Convert a regular Python function into a registered tool.</p>"},{"location":"en/api/tools/#signature","title":"Signature","text":"<pre><code>@tool\ndef function_name(...) -&gt; ReturnType:\n    \"\"\"Function docstring\"\"\"\n    pass\n\n# Or with custom name\n@tool(name=\"custom_name\")\ndef function_name(...) -&gt; ReturnType:\n    \"\"\"Function docstring\"\"\"\n    pass\n</code></pre>"},{"location":"en/api/tools/#parameters","title":"Parameters","text":"<ul> <li>fn (<code>Callable[P, T] | None</code>): Function to decorate (optional, for use without parentheses)</li> <li>name (<code>str | None</code>): Custom tool name (defaults to function name)</li> </ul>"},{"location":"en/api/tools/#returns","title":"Returns","text":"<ul> <li>Callable[P, T]: Decorated function with type validation and registry integration</li> </ul>"},{"location":"en/api/tools/#behavior","title":"Behavior","text":"<ol> <li>Type Validation: Validates arguments against function signature at call time</li> <li>Registry Integration: Automatically registers tool in global <code>tool_registry</code></li> <li>Metadata Preservation: Preserves function name, docstring, and signature</li> <li>Error Handling: Raises <code>TypeError</code> for invalid arguments</li> </ol>"},{"location":"en/api/tools/#metadata-attributes","title":"Metadata Attributes","text":"<p>Decorated functions have the following metadata attributes:</p> <ul> <li><code>_is_tool</code> (<code>bool</code>): Always <code>True</code> for tool-decorated functions</li> <li><code>_tool_name</code> (<code>str</code>): Tool name (function name or custom name)</li> <li><code>_tool_signature</code> (<code>inspect.Signature</code>): Function signature</li> <li><code>_tool_docstring</code> (<code>str</code>): Function docstring</li> </ul>"},{"location":"en/api/tools/#examples","title":"Examples","text":""},{"location":"en/api/tools/#basic-tool","title":"Basic Tool","text":"<pre><code>from kagura import tool\n\n@tool\ndef add(a: float, b: float) -&gt; float:\n    \"\"\"Add two numbers\"\"\"\n    return a + b\n\nresult = add(5.0, 3.0)  # 8.0\n</code></pre>"},{"location":"en/api/tools/#tool-with-default-parameters","title":"Tool with Default Parameters","text":"<pre><code>@tool\ndef greet(name: str, greeting: str = \"Hello\") -&gt; str:\n    \"\"\"Greet someone\"\"\"\n    return f\"{greeting}, {name}!\"\n\ngreet(\"Alice\")           # \"Hello, Alice!\"\ngreet(\"Bob\", \"Hi\")       # \"Hi, Bob!\"\n</code></pre>"},{"location":"en/api/tools/#tool-with-custom-name","title":"Tool with Custom Name","text":"<pre><code>@tool(name=\"tax_calculator\")\ndef calc_tax(amount: float, rate: float = 0.1) -&gt; float:\n    \"\"\"Calculate tax amount\"\"\"\n    return amount * rate\n\n# Registered as \"tax_calculator\"\n</code></pre>"},{"location":"en/api/tools/#tool-with-complex-return-type","title":"Tool with Complex Return Type","text":"<pre><code>@tool\ndef get_user(user_id: int) -&gt; dict[str, Any]:\n    \"\"\"Get user data\"\"\"\n    return {\n        \"id\": user_id,\n        \"name\": \"Alice\",\n        \"active\": True\n    }\n</code></pre>"},{"location":"en/api/tools/#tool-with-error-handling","title":"Tool with Error Handling","text":"<pre><code>@tool\ndef divide(a: float, b: float) -&gt; float:\n    \"\"\"Divide two numbers\"\"\"\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n\nresult = divide(10.0, 2.0)  # 5.0\ndivide(10.0, 0.0)           # ValueError\n</code></pre>"},{"location":"en/api/tools/#error-handling","title":"Error Handling","text":"<pre><code>@tool\ndef strict_function(x: int, y: int) -&gt; int:\n    \"\"\"Requires exactly 2 arguments\"\"\"\n    return x + y\n\n# Valid\nstrict_function(1, 2)         # \u2705 3\nstrict_function(x=1, y=2)     # \u2705 3\n\n# Invalid - raises TypeError\nstrict_function(1)            # \u274c TypeError: invalid arguments\nstrict_function(1, 2, 3)      # \u274c TypeError: invalid arguments\n</code></pre>"},{"location":"en/api/tools/#tool-registry","title":"Tool Registry","text":""},{"location":"en/api/tools/#toolregistry-class","title":"<code>ToolRegistry</code> Class","text":"<p>Global registry for all Kagura tools.</p>"},{"location":"en/api/tools/#methods","title":"Methods","text":""},{"location":"en/api/tools/#registername-str-func-callable-any-none","title":"<code>register(name: str, func: Callable[..., Any]) -&gt; None</code>","text":"<p>Register a tool.</p> <p>Parameters: - <code>name</code> (<code>str</code>): Tool name (must be unique) - <code>func</code> (<code>Callable</code>): Tool function</p> <p>Raises: - <code>ValueError</code>: If tool name is already registered</p> <p>Example: <pre><code>from kagura.core.tool_registry import tool_registry\n\ndef my_tool():\n    return \"result\"\n\ntool_registry.register(\"my_tool\", my_tool)\n</code></pre></p>"},{"location":"en/api/tools/#getname-str-callable-any-none","title":"<code>get(name: str) -&gt; Callable[..., Any] | None</code>","text":"<p>Get tool by name.</p> <p>Parameters: - <code>name</code> (<code>str</code>): Tool name</p> <p>Returns: - Tool function, or <code>None</code> if not found</p> <p>Example: <pre><code>tool = tool_registry.get(\"my_tool\")\nif tool:\n    result = tool()\n</code></pre></p>"},{"location":"en/api/tools/#get_all-dictstr-callable-any","title":"<code>get_all() -&gt; dict[str, Callable[..., Any]]</code>","text":"<p>Get all registered tools.</p> <p>Returns: - Dictionary of <code>tool_name</code> \u2192 <code>tool_function</code></p> <p>Example: <pre><code>all_tools = tool_registry.get_all()\nfor name, func in all_tools.items():\n    print(f\"{name}: {func.__doc__}\")\n</code></pre></p>"},{"location":"en/api/tools/#list_names-liststr","title":"<code>list_names() -&gt; list[str]</code>","text":"<p>List all tool names.</p> <p>Returns: - List of tool names</p> <p>Example: <pre><code>names = tool_registry.list_names()\nprint(names)  # ['add', 'multiply', 'divide']\n</code></pre></p>"},{"location":"en/api/tools/#unregistername-str-none","title":"<code>unregister(name: str) -&gt; None</code>","text":"<p>Unregister a tool.</p> <p>Parameters: - <code>name</code> (<code>str</code>): Tool name</p> <p>Raises: - <code>KeyError</code>: If tool is not registered</p> <p>Example: <pre><code>tool_registry.unregister(\"my_tool\")\n</code></pre></p>"},{"location":"en/api/tools/#clear-none","title":"<code>clear() -&gt; None</code>","text":"<p>Clear all tools from registry.</p> <p>Example: <pre><code>tool_registry.clear()\nassert len(tool_registry.list_names()) == 0\n</code></pre></p>"},{"location":"en/api/tools/#auto_discovermodule_path-str-none","title":"<code>auto_discover(module_path: str) -&gt; None</code>","text":"<p>Auto-discover tools in a module.</p> <p>Scans a module for functions decorated with <code>@tool</code> and automatically registers them.</p> <p>Parameters: - <code>module_path</code> (<code>str</code>): Python module path (e.g., <code>\"my_package.tools\"</code>)</p> <p>Raises: - <code>ValueError</code>: If module is not found</p> <p>Example: <pre><code># my_package/tools.py\nfrom kagura import tool\n\n@tool\ndef tool1():\n    return 1\n\n@tool\ndef tool2():\n    return 2\n\n# main.py\nfrom kagura.core.tool_registry import tool_registry\n\ntool_registry.auto_discover(\"my_package.tools\")\nprint(tool_registry.list_names())  # ['tool1', 'tool2']\n</code></pre></p>"},{"location":"en/api/tools/#global-registry-instance","title":"Global Registry Instance","text":"<p>The global <code>tool_registry</code> instance is automatically created and available for import:</p> <pre><code>from kagura.core.tool_registry import tool_registry\n\n# Check if tool exists\nif \"my_tool\" in tool_registry.list_names():\n    tool = tool_registry.get(\"my_tool\")\n    result = tool()\n</code></pre>"},{"location":"en/api/tools/#type-validation","title":"Type Validation","text":"<p>Tools validate arguments using <code>inspect.signature</code> at call time.</p>"},{"location":"en/api/tools/#supported-features","title":"Supported Features","text":"<ol> <li> <p>Positional Arguments <pre><code>@tool\ndef func(a: int, b: int) -&gt; int:\n    return a + b\n\nfunc(1, 2)  # \u2705\n</code></pre></p> </li> <li> <p>Keyword Arguments <pre><code>func(a=1, b=2)  # \u2705\nfunc(1, b=2)    # \u2705\n</code></pre></p> </li> <li> <p>Default Parameters <pre><code>@tool\ndef func(a: int, b: int = 10) -&gt; int:\n    return a + b\n\nfunc(5)      # \u2705 15\nfunc(5, 20)  # \u2705 25\n</code></pre></p> </li> <li> <p>Variable Arguments <pre><code>@tool\ndef merge(*dicts: dict) -&gt; dict:\n    result = {}\n    for d in dicts:\n        result.update(d)\n    return result\n\nmerge({\"a\": 1}, {\"b\": 2})  # \u2705 {\"a\": 1, \"b\": 2}\n</code></pre></p> </li> </ol>"},{"location":"en/api/tools/#validation-errors","title":"Validation Errors","text":"<pre><code>@tool\ndef strict(x: int, y: int) -&gt; int:\n    return x + y\n\n# Missing argument\nstrict(1)  # \u274c TypeError: Tool 'strict' called with invalid arguments\n\n# Too many arguments\nstrict(1, 2, 3)  # \u274c TypeError: Tool 'strict' called with invalid arguments\n\n# Invalid keyword\nstrict(1, z=2)  # \u274c TypeError: Tool 'strict' called with invalid arguments\n</code></pre>"},{"location":"en/api/tools/#mcp-integration","title":"MCP Integration","text":"<p>Tools are automatically exposed via MCP when using <code>kagura mcp start</code>.</p>"},{"location":"en/api/tools/#example","title":"Example","text":"<pre><code># my_tools.py\nfrom kagura import tool\n\n@tool\ndef weather_lookup(city: str) -&gt; dict:\n    \"\"\"Get current weather for a city\"\"\"\n    return {\n        \"city\": city,\n        \"temperature\": 72,\n        \"condition\": \"sunny\"\n    }\n\n@tool\ndef currency_convert(amount: float, from_currency: str, to_currency: str) -&gt; float:\n    \"\"\"Convert currency\"\"\"\n    # Simplified example\n    rates = {\"USD\": 1.0, \"EUR\": 0.85, \"JPY\": 110.0}\n    return amount * rates[to_currency] / rates[from_currency]\n</code></pre> <p>Start MCP server: <pre><code>kagura mcp start\n</code></pre></p> <p>Tools are now available to Claude Desktop via MCP protocol.</p>"},{"location":"en/api/tools/#best-practices","title":"Best Practices","text":""},{"location":"en/api/tools/#1-clear-documentation","title":"1. Clear Documentation","text":"<pre><code>@tool\ndef calculate_discount(price: float, discount_percent: float) -&gt; float:\n    \"\"\"\n    Calculate discounted price.\n\n    Args:\n        price: Original price\n        discount_percent: Discount percentage (e.g., 15 for 15%)\n\n    Returns:\n        Final price after discount\n\n    Example:\n        &gt;&gt;&gt; calculate_discount(100.0, 15.0)\n        85.0\n    \"\"\"\n    return price * (1 - discount_percent / 100)\n</code></pre>"},{"location":"en/api/tools/#2-input-validation","title":"2. Input Validation","text":"<pre><code>@tool\ndef withdraw_money(account_id: str, amount: float) -&gt; dict:\n    \"\"\"Withdraw money from account\"\"\"\n    if amount &lt;= 0:\n        raise ValueError(\"Amount must be positive\")\n    if amount &gt; 10000:\n        raise ValueError(\"Exceeds daily limit\")\n\n    # Process withdrawal\n    return {\"success\": True, \"new_balance\": 5000 - amount}\n</code></pre>"},{"location":"en/api/tools/#3-type-hints","title":"3. Type Hints","text":"<p>Always use type hints for better documentation and validation:</p> <pre><code>@tool\ndef process_order(\n    order_id: str,\n    items: list[dict],\n    shipping_address: dict,\n    priority: bool = False\n) -&gt; dict:\n    \"\"\"Process customer order\"\"\"\n    return {\n        \"order_id\": order_id,\n        \"status\": \"processing\",\n        \"estimated_delivery\": \"2025-10-15\"\n    }\n</code></pre>"},{"location":"en/api/tools/#4-error-handling","title":"4. Error Handling","text":"<pre><code>@tool\ndef fetch_user_data(user_id: int) -&gt; dict:\n    \"\"\"Fetch user data from database\"\"\"\n    try:\n        user = database.get_user(user_id)\n        if not user:\n            raise ValueError(f\"User {user_id} not found\")\n        return user\n    except DatabaseError as e:\n        raise RuntimeError(f\"Database error: {e}\") from e\n</code></pre>"},{"location":"en/api/tools/#see-also","title":"See Also","text":"<ul> <li>Tools Tutorial</li> <li>Agent Decorator</li> <li>MCP Integration</li> </ul>"},{"location":"en/api/workflows/","title":"Workflows API Reference","text":""},{"location":"en/api/workflows/#overview","title":"Overview","text":"<p>The Workflows API provides decorators and utilities for creating multi-agent orchestrations that coordinate agents and tools to accomplish complex tasks.</p>"},{"location":"en/api/workflows/#workflow-decorator","title":"<code>@workflow</code> Decorator","text":"<p>Convert an async function into a registered workflow.</p>"},{"location":"en/api/workflows/#signature","title":"Signature","text":"<pre><code>@workflow\nasync def function_name(...) -&gt; ReturnType:\n    \"\"\"Function docstring\"\"\"\n    # Orchestration logic\n    pass\n\n# Or with custom name\n@workflow(name=\"custom_name\")\nasync def function_name(...) -&gt; ReturnType:\n    \"\"\"Function docstring\"\"\"\n    # Orchestration logic\n    pass\n</code></pre>"},{"location":"en/api/workflows/#parameters","title":"Parameters","text":"<ul> <li>fn (<code>Callable[P, Awaitable[T]] | None</code>): Function to decorate (optional, for use without parentheses)</li> <li>name (<code>str | None</code>): Custom workflow name (defaults to function name)</li> </ul>"},{"location":"en/api/workflows/#returns","title":"Returns","text":"<ul> <li>Callable[P, Awaitable[T]]: Decorated async function</li> </ul>"},{"location":"en/api/workflows/#behavior","title":"Behavior","text":"<ol> <li>Execution: Executes the function body (unlike @agent which calls LLM)</li> <li>Registry Integration: Automatically registers workflow in global <code>workflow_registry</code></li> <li>Metadata Preservation: Preserves function name, docstring, and signature</li> <li>Async Support: Fully supports async/await patterns</li> </ol>"},{"location":"en/api/workflows/#metadata-attributes","title":"Metadata Attributes","text":"<p>Decorated functions have the following metadata attributes:</p> <ul> <li><code>_is_workflow</code> (<code>bool</code>): Always <code>True</code> for workflow-decorated functions</li> <li><code>_workflow_name</code> (<code>str</code>): Workflow name (function name or custom name)</li> <li><code>_workflow_signature</code> (<code>inspect.Signature</code>): Function signature</li> <li><code>_workflow_docstring</code> (<code>str</code>): Function docstring</li> </ul>"},{"location":"en/api/workflows/#examples","title":"Examples","text":""},{"location":"en/api/workflows/#basic-workflow","title":"Basic Workflow","text":"<pre><code>from kagura import workflow, agent\n\n@agent\nasync def search(query: str) -&gt; str:\n    \"\"\"Search for {{ query }}\"\"\"\n    ...\n\n@agent\nasync def summarize(text: str) -&gt; str:\n    \"\"\"Summarize: {{ text }}\"\"\"\n    ...\n\n@workflow\nasync def research(topic: str) -&gt; dict:\n    \"\"\"Research workflow\"\"\"\n    results = await search(topic)\n    summary = await summarize(results)\n    return {\"results\": results, \"summary\": summary}\n\ndata = await research(\"AI safety\")\n</code></pre>"},{"location":"en/api/workflows/#workflow-with-custom-name","title":"Workflow with Custom Name","text":"<pre><code>@workflow(name=\"analysis_pipeline\")\nasync def analyze(data: str) -&gt; dict:\n    \"\"\"Data analysis pipeline\"\"\"\n    validated = await validate_agent(data)\n    processed = await process_agent(validated)\n    return {\"validated\": validated, \"processed\": processed}\n\n# Registered as \"analysis_pipeline\"\n</code></pre>"},{"location":"en/api/workflows/#sequential-execution","title":"Sequential Execution","text":"<pre><code>@workflow\nasync def content_pipeline(topic: str) -&gt; dict:\n    \"\"\"Create content through stages\"\"\"\n    research = await research_agent(topic)\n    draft = await writing_agent(research)\n    final = await editing_agent(draft)\n    return {\"research\": research, \"draft\": draft, \"final\": final}\n</code></pre>"},{"location":"en/api/workflows/#parallel-execution","title":"Parallel Execution","text":"<pre><code>import asyncio\n\n@workflow\nasync def multi_source(topic: str) -&gt; dict:\n    \"\"\"Gather from multiple sources\"\"\"\n    results = await asyncio.gather(\n        source_a_agent(topic),\n        source_b_agent(topic),\n        source_c_agent(topic)\n    )\n    a, b, c = results\n    combined = await synthesis_agent(f\"A: {a}\\nB: {b}\\nC: {c}\")\n    return {\"sources\": results, \"synthesis\": combined}\n</code></pre>"},{"location":"en/api/workflows/#conditional-logic","title":"Conditional Logic","text":"<pre><code>@workflow\nasync def adaptive(text: str) -&gt; dict:\n    \"\"\"Adapt processing based on content\"\"\"\n    category = await classifier_agent(text)\n\n    if category == \"technical\":\n        result = await technical_processor(text)\n    else:\n        result = await general_processor(text)\n\n    return {\"category\": category, \"result\": result}\n</code></pre>"},{"location":"en/api/workflows/#error-handling","title":"Error Handling","text":"<pre><code>@workflow\nasync def resilient(task: str) -&gt; dict:\n    \"\"\"Workflow with error handling\"\"\"\n    try:\n        result = await primary_agent(task)\n    except Exception:\n        result = await fallback_agent(task)\n\n    return {\"task\": task, \"result\": result}\n</code></pre>"},{"location":"en/api/workflows/#workflow-registry","title":"Workflow Registry","text":""},{"location":"en/api/workflows/#workflowregistry-class","title":"<code>WorkflowRegistry</code> Class","text":"<p>Global registry for all Kagura workflows.</p>"},{"location":"en/api/workflows/#methods","title":"Methods","text":""},{"location":"en/api/workflows/#registername-str-func-callable-any-none","title":"<code>register(name: str, func: Callable[..., Any]) -&gt; None</code>","text":"<p>Register a workflow.</p> <p>Parameters: - <code>name</code> (<code>str</code>): Workflow name (must be unique) - <code>func</code> (<code>Callable</code>): Workflow function</p> <p>Raises: - <code>ValueError</code>: If workflow name is already registered</p> <p>Example: <pre><code>from kagura.core.workflow_registry import workflow_registry\n\nasync def my_workflow():\n    return \"result\"\n\nworkflow_registry.register(\"my_workflow\", my_workflow)\n</code></pre></p>"},{"location":"en/api/workflows/#getname-str-callable-any-none","title":"<code>get(name: str) -&gt; Callable[..., Any] | None</code>","text":"<p>Get workflow by name.</p> <p>Parameters: - <code>name</code> (<code>str</code>): Workflow name</p> <p>Returns: - Workflow function, or <code>None</code> if not found</p> <p>Example: <pre><code>workflow = workflow_registry.get(\"my_workflow\")\nif workflow:\n    result = await workflow()\n</code></pre></p>"},{"location":"en/api/workflows/#get_all-dictstr-callable-any","title":"<code>get_all() -&gt; dict[str, Callable[..., Any]]</code>","text":"<p>Get all registered workflows.</p> <p>Returns: - Dictionary of <code>workflow_name</code> \u2192 <code>workflow_function</code></p> <p>Example: <pre><code>all_workflows = workflow_registry.get_all()\nfor name, func in all_workflows.items():\n    print(f\"{name}: {func.__doc__}\")\n</code></pre></p>"},{"location":"en/api/workflows/#list_names-liststr","title":"<code>list_names() -&gt; list[str]</code>","text":"<p>List all workflow names.</p> <p>Returns: - List of workflow names</p> <p>Example: <pre><code>names = workflow_registry.list_names()\nprint(names)  # ['research', 'analysis', 'content_pipeline']\n</code></pre></p>"},{"location":"en/api/workflows/#unregistername-str-none","title":"<code>unregister(name: str) -&gt; None</code>","text":"<p>Unregister a workflow.</p> <p>Parameters: - <code>name</code> (<code>str</code>): Workflow name</p> <p>Raises: - <code>KeyError</code>: If workflow is not registered</p> <p>Example: <pre><code>workflow_registry.unregister(\"my_workflow\")\n</code></pre></p>"},{"location":"en/api/workflows/#clear-none","title":"<code>clear() -&gt; None</code>","text":"<p>Clear all workflows from registry.</p> <p>Example: <pre><code>workflow_registry.clear()\nassert len(workflow_registry.list_names()) == 0\n</code></pre></p>"},{"location":"en/api/workflows/#auto_discovermodule_path-str-none","title":"<code>auto_discover(module_path: str) -&gt; None</code>","text":"<p>Auto-discover workflows in a module.</p> <p>Scans a module for functions decorated with <code>@workflow</code> and automatically registers them.</p> <p>Parameters: - <code>module_path</code> (<code>str</code>): Python module path (e.g., <code>\"my_package.workflows\"</code>)</p> <p>Raises: - <code>ValueError</code>: If module is not found</p> <p>Example: <pre><code># my_package/workflows.py\nfrom kagura import workflow\n\n@workflow\nasync def workflow1():\n    return 1\n\n@workflow\nasync def workflow2():\n    return 2\n\n# main.py\nfrom kagura.core.workflow_registry import workflow_registry\n\nworkflow_registry.auto_discover(\"my_package.workflows\")\nprint(workflow_registry.list_names())  # ['workflow1', 'workflow2']\n</code></pre></p>"},{"location":"en/api/workflows/#global-registry-instance","title":"Global Registry Instance","text":"<p>The global <code>workflow_registry</code> instance is automatically created and available for import:</p> <pre><code>from kagura.core.workflow_registry import workflow_registry\n\n# Check if workflow exists\nif \"my_workflow\" in workflow_registry.list_names():\n    workflow = workflow_registry.get(\"my_workflow\")\n    result = await workflow()\n</code></pre>"},{"location":"en/api/workflows/#common-patterns","title":"Common Patterns","text":""},{"location":"en/api/workflows/#chaining-agents","title":"Chaining Agents","text":"<pre><code>@workflow\nasync def chain(input_data: str) -&gt; str:\n    \"\"\"Chain multiple agents\"\"\"\n    step1 = await agent1(input_data)\n    step2 = await agent2(step1)\n    step3 = await agent3(step2)\n    return step3\n</code></pre>"},{"location":"en/api/workflows/#fan-outfan-in","title":"Fan-Out/Fan-In","text":"<pre><code>@workflow\nasync def fan_out_fan_in(input_data: str) -&gt; str:\n    \"\"\"Process in parallel, then combine\"\"\"\n    # Fan-out: Process in parallel\n    results = await asyncio.gather(\n        processor1(input_data),\n        processor2(input_data),\n        processor3(input_data)\n    )\n\n    # Fan-in: Combine results\n    combined = await combiner_agent(results)\n    return combined\n</code></pre>"},{"location":"en/api/workflows/#loop-processing","title":"Loop Processing","text":"<pre><code>@workflow\nasync def batch_process(items: list) -&gt; list:\n    \"\"\"Process multiple items\"\"\"\n    results = []\n    for item in items:\n        result = await processing_agent(item)\n        results.append(result)\n    return results\n</code></pre>"},{"location":"en/api/workflows/#conditional-branching","title":"Conditional Branching","text":"<pre><code>@workflow\nasync def route_by_type(data: str) -&gt; dict:\n    \"\"\"Route based on data type\"\"\"\n    data_type = await type_detector(data)\n\n    if data_type == \"A\":\n        result = await handler_a(data)\n    elif data_type == \"B\":\n        result = await handler_b(data)\n    else:\n        result = await default_handler(data)\n\n    return {\"type\": data_type, \"result\": result}\n</code></pre>"},{"location":"en/api/workflows/#retry-logic","title":"Retry Logic","text":"<pre><code>@workflow\nasync def with_retry(task: str) -&gt; dict:\n    \"\"\"Retry on failure\"\"\"\n    max_attempts = 3\n\n    for attempt in range(max_attempts):\n        try:\n            result = await unreliable_agent(task)\n            return {\"task\": task, \"result\": result, \"attempts\": attempt + 1}\n        except Exception as e:\n            if attempt == max_attempts - 1:\n                raise\n            await asyncio.sleep(2 ** attempt)\n\n    raise RuntimeError(\"Should not reach here\")\n</code></pre>"},{"location":"en/api/workflows/#integration","title":"Integration","text":""},{"location":"en/api/workflows/#with-agents","title":"With Agents","text":"<pre><code>from kagura import workflow, agent\n\n@agent\nasync def my_agent(query: str) -&gt; str:\n    \"\"\"Process {{ query }}\"\"\"\n    ...\n\n@workflow\nasync def my_workflow(input_data: str) -&gt; dict:\n    \"\"\"Use agents in workflow\"\"\"\n    result1 = await my_agent(input_data)\n    result2 = await my_agent(result1)\n    return {\"result1\": result1, \"result2\": result2}\n</code></pre>"},{"location":"en/api/workflows/#with-tools","title":"With Tools","text":"<pre><code>from kagura import workflow, tool, agent\n\n@tool\ndef calculate(x: float, y: float) -&gt; float:\n    \"\"\"Calculate something\"\"\"\n    return x * y\n\n@agent\nasync def analyzer(result: float) -&gt; str:\n    \"\"\"Analyze {{ result }}\"\"\"\n    ...\n\n@workflow\nasync def hybrid(x: float, y: float) -&gt; dict:\n    \"\"\"Combine tools and agents\"\"\"\n    # Use tool\n    calculation = calculate(x, y)\n\n    # Use agent\n    analysis = await analyzer(calculation)\n\n    return {\"calculation\": calculation, \"analysis\": analysis}\n</code></pre>"},{"location":"en/api/workflows/#with-mcp","title":"With MCP","text":"<p>Workflows are automatically exposed via MCP:</p> <pre><code>@workflow\nasync def mcp_workflow(query: str) -&gt; dict:\n    \"\"\"This workflow is available via MCP\"\"\"\n    result = await process_agent(query)\n    return {\"query\": query, \"result\": result}\n\n# Automatically available in MCP\n# Run: kagura mcp start\n</code></pre>"},{"location":"en/api/workflows/#best-practices","title":"Best Practices","text":""},{"location":"en/api/workflows/#1-clear-documentation","title":"1. Clear Documentation","text":"<pre><code>@workflow\nasync def documented_workflow(input_data: str) -&gt; dict:\n    \"\"\"\n    Process data through multiple stages.\n\n    Args:\n        input_data: Raw input to process\n\n    Returns:\n        Dictionary with processed results\n\n    Workflow Stages:\n        1. Validation\n        2. Processing\n        3. Analysis\n        4. Reporting\n    \"\"\"\n    validated = await validation_agent(input_data)\n    processed = await processing_agent(validated)\n    analyzed = await analysis_agent(processed)\n    report = await reporting_agent(analyzed)\n\n    return {\n        \"validated\": validated,\n        \"processed\": processed,\n        \"analyzed\": analyzed,\n        \"report\": report\n    }\n</code></pre>"},{"location":"en/api/workflows/#2-error-handling","title":"2. Error Handling","text":"<pre><code>@workflow\nasync def safe_workflow(task: str) -&gt; dict:\n    \"\"\"Workflow with comprehensive error handling\"\"\"\n    try:\n        result = await risky_agent(task)\n    except ValueError as e:\n        # Handle specific error\n        result = await fallback_agent(task)\n    except Exception as e:\n        # Handle any other error\n        raise RuntimeError(f\"Workflow failed: {e}\") from e\n\n    return {\"task\": task, \"result\": result}\n</code></pre>"},{"location":"en/api/workflows/#3-modular-design","title":"3. Modular Design","text":"<pre><code># Reusable sub-workflows\n@workflow\nasync def data_prep(raw: str) -&gt; dict:\n    \"\"\"Reusable data preparation\"\"\"\n    cleaned = await clean_agent(raw)\n    normalized = await normalize_agent(cleaned)\n    return {\"cleaned\": cleaned, \"normalized\": normalized}\n\n@workflow\nasync def main_workflow(input_data: str) -&gt; dict:\n    \"\"\"Main workflow using sub-workflows\"\"\"\n    prepared = await data_prep(input_data)\n    analysis = await analysis_agent(prepared[\"normalized\"])\n    return {\"prepared\": prepared, \"analysis\": analysis}\n</code></pre>"},{"location":"en/api/workflows/#4-type-hints","title":"4. Type Hints","text":"<pre><code>@workflow\nasync def typed_workflow(\n    data: list[str],\n    options: dict[str, Any]\n) -&gt; dict[str, list[str]]:\n    \"\"\"Workflow with clear type hints\"\"\"\n    results = []\n    for item in data:\n        result = await process_agent(item, options)\n        results.append(result)\n\n    return {\"processed\": results}\n</code></pre>"},{"location":"en/api/workflows/#advanced-workflow-features","title":"Advanced Workflow Features","text":"<p>Kagura provides advanced workflow capabilities for complex multi-agent orchestration.</p>"},{"location":"en/api/workflows/#workflow-context-sharing","title":"Workflow Context Sharing","text":"<p>Share state across workflow steps using context dictionary:</p> <pre><code>@workflow\nasync def context_workflow(input_data: str, workflow_context: dict) -&gt; dict:\n    \"\"\"Workflow with shared context\"\"\"\n\n    # Initialize context\n    workflow_context[\"step_count\"] = 0\n    workflow_context[\"accumulated_data\"] = []\n\n    # Step 1\n    workflow_context[\"step_count\"] += 1\n    result1 = await agent1(input_data)\n    workflow_context[\"accumulated_data\"].append(result1)\n\n    # Step 2 - uses context from step 1\n    workflow_context[\"step_count\"] += 1\n    result2 = await agent2(result1, previous_data=workflow_context[\"accumulated_data\"])\n\n    return {\n        \"final_result\": result2,\n        \"steps_executed\": workflow_context[\"step_count\"]\n    }\n\n# Execute with context\ncontext = {}\nresult = await context_workflow(\"input\", workflow_context=context)\nprint(f\"Executed {context['step_count']} steps\")\n</code></pre>"},{"location":"en/api/workflows/#conditional-branching_1","title":"Conditional Branching","text":"<p>Implement conditional logic in workflows:</p> <pre><code>@workflow\nasync def conditional_workflow(query: str) -&gt; dict:\n    \"\"\"Workflow with conditional branches\"\"\"\n\n    # Classify query\n    classification = await classifier_agent(query)\n\n    # Branch based on classification\n    if classification == \"technical\":\n        result = await technical_agent(query)\n    elif classification == \"business\":\n        result = await business_agent(query)\n    else:\n        result = await general_agent(query)\n\n    return {\"classification\": classification, \"result\": result}\n</code></pre>"},{"location":"en/api/workflows/#parallel-execution_1","title":"Parallel Execution","text":"<p>Execute multiple agents in parallel:</p> <pre><code>import asyncio\n\n@workflow\nasync def parallel_workflow(input_data: str) -&gt; dict:\n    \"\"\"Workflow with parallel agent execution\"\"\"\n\n    # Execute agents in parallel\n    results = await asyncio.gather(\n        agent1(input_data),\n        agent2(input_data),\n        agent3(input_data)\n    )\n\n    # Combine results\n    combined = await synthesis_agent(results)\n\n    return {\"individual\": results, \"combined\": combined}\n</code></pre>"},{"location":"en/api/workflows/#retry-logic_1","title":"Retry Logic","text":"<p>Implement automatic retry for failed steps:</p> <pre><code>@workflow\nasync def retry_workflow(data: str, max_retries: int = 3) -&gt; dict:\n    \"\"\"Workflow with retry logic\"\"\"\n\n    for attempt in range(max_retries):\n        try:\n            result = await unreliable_agent(data)\n            return {\"success\": True, \"result\": result, \"attempts\": attempt + 1}\n        except Exception as e:\n            if attempt == max_retries - 1:\n                # Final attempt failed\n                return {\"success\": False, \"error\": str(e), \"attempts\": attempt + 1}\n            # Wait before retry\n            await asyncio.sleep(2 ** attempt)  # Exponential backoff\n\n    return {\"success\": False, \"error\": \"Max retries exceeded\"}\n</code></pre>"},{"location":"en/api/workflows/#dynamic-agent-selection","title":"Dynamic Agent Selection","text":"<p>Select agents dynamically based on runtime conditions:</p> <pre><code>@workflow\nasync def dynamic_workflow(query: str, agent_pool: dict) -&gt; dict:\n    \"\"\"Workflow with dynamic agent selection\"\"\"\n\n    # Analyze query to determine best agent\n    analysis = await analyzer_agent(query)\n\n    # Select agent from pool\n    selected_agent_name = analysis[\"recommended_agent\"]\n    selected_agent = agent_pool.get(selected_agent_name)\n\n    if not selected_agent:\n        raise ValueError(f\"Agent {selected_agent_name} not found\")\n\n    # Execute selected agent\n    result = await selected_agent(query)\n\n    return {\n        \"selected_agent\": selected_agent_name,\n        \"result\": result\n    }\n\n# Usage\nagents = {\n    \"translator\": translator_agent,\n    \"summarizer\": summarizer_agent,\n    \"analyzer\": analyzer_agent\n}\n\nresult = await dynamic_workflow(\"Translate to French\", agent_pool=agents)\n</code></pre>"},{"location":"en/api/workflows/#workflow-monitoring","title":"Workflow Monitoring","text":"<p>Track workflow execution with telemetry:</p> <pre><code>import time\n\n@workflow\nasync def monitored_workflow(data: str) -&gt; dict:\n    \"\"\"Workflow with execution monitoring\"\"\"\n\n    start_time = time.time()\n    steps_executed = []\n\n    try:\n        # Step 1\n        step_start = time.time()\n        result1 = await agent1(data)\n        steps_executed.append({\n            \"step\": \"agent1\",\n            \"duration\": time.time() - step_start,\n            \"success\": True\n        })\n\n        # Step 2\n        step_start = time.time()\n        result2 = await agent2(result1)\n        steps_executed.append({\n            \"step\": \"agent2\",\n            \"duration\": time.time() - step_start,\n            \"success\": True\n        })\n\n        return {\n            \"result\": result2,\n            \"metadata\": {\n                \"total_duration\": time.time() - start_time,\n                \"steps\": steps_executed\n            }\n        }\n\n    except Exception as e:\n        steps_executed.append({\n            \"step\": \"error\",\n            \"error\": str(e),\n            \"success\": False\n        })\n        raise\n</code></pre>"},{"location":"en/api/workflows/#workflow-composition","title":"Workflow Composition","text":"<p>Compose workflows from sub-workflows:</p> <pre><code>@workflow\nasync def data_processing_workflow(data: str) -&gt; dict:\n    \"\"\"Sub-workflow for data processing\"\"\"\n    cleaned = await clean_agent(data)\n    normalized = await normalize_agent(cleaned)\n    return {\"cleaned\": cleaned, \"normalized\": normalized}\n\n\n@workflow\nasync def analysis_workflow(data: dict) -&gt; dict:\n    \"\"\"Sub-workflow for analysis\"\"\"\n    insights = await analysis_agent(data[\"normalized\"])\n    summary = await summary_agent(insights)\n    return {\"insights\": insights, \"summary\": summary}\n\n\n@workflow\nasync def master_workflow(raw_data: str) -&gt; dict:\n    \"\"\"Master workflow composing sub-workflows\"\"\"\n\n    # Execute sub-workflows in sequence\n    processed = await data_processing_workflow(raw_data)\n    analyzed = await analysis_workflow(processed)\n\n    # Combine results\n    return {\n        \"processing\": processed,\n        \"analysis\": analyzed,\n        \"pipeline\": \"master_workflow\"\n    }\n</code></pre>"},{"location":"en/api/workflows/#complete-advanced-example","title":"Complete Advanced Example","text":"<pre><code>import asyncio\nimport time\nfrom kagura import agent, workflow\n\n\n@agent\nasync def classifier(text: str) -&gt; str:\n    '''Classify {{ text }} as: technical, business, or general'''\n    pass\n\n\n@agent\nasync def technical_expert(query: str) -&gt; str:\n    '''Technical answer: {{ query }}'''\n    pass\n\n\n@agent\nasync def business_expert(query: str) -&gt; str:\n    '''Business answer: {{ query }}'''\n    pass\n\n\n@agent\nasync def summarizer(text: str) -&gt; str:\n    '''Summarize: {{ text }}'''\n    pass\n\n\n@workflow\nasync def intelligent_workflow(\n    query: str,\n    workflow_context: dict,\n    max_retries: int = 3\n) -&gt; dict:\n    \"\"\"Advanced workflow with multiple features\"\"\"\n\n    start_time = time.time()\n    workflow_context[\"steps\"] = []\n\n    # Step 1: Classification\n    classification = await classifier(query)\n    workflow_context[\"steps\"].append({\"step\": \"classification\", \"result\": classification})\n\n    # Step 2: Conditional routing with retry\n    for attempt in range(max_retries):\n        try:\n            if classification == \"technical\":\n                response = await technical_expert(query)\n            elif classification == \"business\":\n                response = await business_expert(query)\n            else:\n                # Parallel execution for general queries\n                responses = await asyncio.gather(\n                    technical_expert(query),\n                    business_expert(query)\n                )\n                response = \" | \".join(responses)\n\n            workflow_context[\"steps\"].append({\"step\": \"response\", \"attempt\": attempt + 1})\n            break\n\n        except Exception as e:\n            if attempt == max_retries - 1:\n                workflow_context[\"steps\"].append({\"step\": \"error\", \"error\": str(e)})\n                raise\n            await asyncio.sleep(1)\n\n    # Step 3: Summarization\n    summary = await summarizer(response)\n    workflow_context[\"steps\"].append({\"step\": \"summary\"})\n\n    # Return comprehensive result\n    return {\n        \"classification\": classification,\n        \"response\": response,\n        \"summary\": summary,\n        \"metadata\": {\n            \"duration\": time.time() - start_time,\n            \"steps_executed\": len(workflow_context[\"steps\"])\n        }\n    }\n\n\n# Execute\nasync def main():\n    context = {}\n    result = await intelligent_workflow(\n        \"Explain machine learning\",\n        workflow_context=context\n    )\n\n    print(f\"Classification: {result['classification']}\")\n    print(f\"Summary: {result['summary']}\")\n    print(f\"Steps executed: {result['metadata']['steps_executed']}\")\n\n\nasyncio.run(main())\n</code></pre>"},{"location":"en/api/workflows/#best-practices-for-advanced-workflows","title":"Best Practices for Advanced Workflows","text":"<ol> <li>Use Context Judiciously: Only share state that's truly needed across steps</li> <li>Handle Errors Gracefully: Implement proper error handling and recovery</li> <li>Monitor Performance: Track execution time and identify bottlenecks</li> <li>Keep It Modular: Break complex workflows into reusable sub-workflows</li> <li>Document Branching Logic: Make conditional logic clear and well-documented</li> </ol>"},{"location":"en/api/workflows/#see-also","title":"See Also","text":"<ul> <li>Workflows Tutorial</li> <li>Agent Decorator</li> <li>Tool Decorator</li> <li>MCP Integration</li> <li>RFC-001: Advanced Workflow System</li> </ul>"},{"location":"en/guides/chat-multimodal/","title":"Multimodal RAG Chat Guide","text":"<p>This guide explains how to use Kagura AI's multimodal RAG (Retrieval-Augmented Generation) feature with the <code>kagura chat</code> command.</p>"},{"location":"en/guides/chat-multimodal/#overview","title":"Overview","text":"<p>Multimodal RAG allows you to: - Index and search across multiple file types (text, images, PDFs, audio, video) - Chat with your entire project directory - Get AI responses grounded in your local files - Automatically process and understand visual content, documents, and more</p>"},{"location":"en/guides/chat-multimodal/#prerequisites","title":"Prerequisites","text":""},{"location":"en/guides/chat-multimodal/#installation","title":"Installation","text":"<p>Install Kagura AI with multimodal support:</p> <pre><code>pip install kagura-ai[multimodal]\n</code></pre> <p>This installs: - <code>google-generativeai</code> - Gemini API for multimodal processing - <code>chromadb</code> - Vector database for semantic search - <code>pillow</code> - Image processing</p>"},{"location":"en/guides/chat-multimodal/#api-key-setup","title":"API Key Setup","text":"<p>Get a Gemini API key from Google AI Studio and set it:</p> <pre><code>export GEMINI_API_KEY=\"your-api-key-here\"\n</code></pre> <p>Or create a <code>.env</code> file in your project:</p> <pre><code>GEMINI_API_KEY=your-api-key-here\n</code></pre>"},{"location":"en/guides/chat-multimodal/#quick-start","title":"Quick Start","text":""},{"location":"en/guides/chat-multimodal/#basic-usage","title":"Basic Usage","text":"<p>Start multimodal chat with a directory:</p> <pre><code>kagura chat --enable-multimodal --dir ./my-project\n</code></pre> <p>This will: 1. Scan <code>./my-project</code> recursively 2. Process all supported files using Gemini 3. Build a vector index with ChromaDB 4. Start an interactive chat session</p>"},{"location":"en/guides/chat-multimodal/#example-session","title":"Example Session","text":"<pre><code>$ kagura chat --enable-multimodal --dir ./docs\n\nInitializing multimodal RAG for: ./docs\n\u2713 Indexed 42 files from ./docs\n\nType your message to chat with AI, or use commands:\n  /help      - Show help\n  /exit      - Exit chat\n\n[You] &gt; What's in the architecture diagram?\n\nSearching indexed files...\n\ud83d\udcac Generating response...\n\n[AI]\nThe architecture diagram (architecture.png) shows a 3-tier system:\n\n1. **Frontend Layer**: React application with TypeScript\n2. **API Layer**: FastAPI backend with REST endpoints\n3. **Data Layer**: PostgreSQL database with SQLAlchemy ORM\n\nThe frontend communicates with the API via HTTP requests, and the API\nconnects to the database using connection pooling for performance.\n\n[You] &gt; Can you show me the authentication flow?\n\n[AI]\nBased on the auth.py file and the sequence diagram, the authentication\nflow works as follows:\n\n1. User submits credentials to /api/auth/login\n2. Backend validates credentials against database\n3. JWT token is generated with user claims\n4. Token is returned to client\n5. Client includes token in Authorization header for subsequent requests\n6. Backend validates token on each request using middleware\n\nThe implementation uses bcrypt for password hashing and PyJWT for token\nmanagement. Token expiry is set to 24 hours by default.\n</code></pre>"},{"location":"en/guides/chat-multimodal/#supported-file-types","title":"Supported File Types","text":"<p>Kagura AI processes different file types using appropriate methods:</p>"},{"location":"en/guides/chat-multimodal/#text-files-direct-indexing","title":"Text Files (Direct Indexing)","text":"<ul> <li>Markdown: <code>.md</code>, <code>.markdown</code></li> <li>Code: <code>.py</code>, <code>.js</code>, <code>.ts</code>, <code>.java</code>, <code>.go</code>, <code>.rs</code>, etc.</li> <li>Documentation: <code>.txt</code>, <code>.rst</code>, <code>.adoc</code></li> <li>Data: <code>.json</code>, <code>.yaml</code>, <code>.toml</code>, <code>.xml</code>, <code>.csv</code></li> </ul> <p>Text files are read directly and indexed without API calls.</p>"},{"location":"en/guides/chat-multimodal/#images-gemini-vision","title":"Images (Gemini Vision)","text":"<ul> <li>Formats: <code>.png</code>, <code>.jpg</code>, <code>.jpeg</code>, <code>.gif</code>, <code>.webp</code></li> <li>Use Cases: Diagrams, screenshots, charts, mockups</li> </ul> <p>Gemini analyzes images and generates descriptive text for indexing.</p>"},{"location":"en/guides/chat-multimodal/#pdfs-gemini-analysis","title":"PDFs (Gemini Analysis)","text":"<ul> <li>Format: <code>.pdf</code></li> <li>Use Cases: Documentation, reports, papers</li> </ul> <p>Gemini extracts and analyzes PDF content, including text and images.</p>"},{"location":"en/guides/chat-multimodal/#audio-gemini-transcription","title":"Audio (Gemini Transcription)","text":"<ul> <li>Formats: <code>.mp3</code>, <code>.wav</code>, <code>.m4a</code>, <code>.ogg</code>, <code>.flac</code></li> <li>Use Cases: Meeting recordings, interviews, voice notes</li> </ul> <p>Gemini transcribes audio to text for searchability.</p>"},{"location":"en/guides/chat-multimodal/#video-gemini-analysis","title":"Video (Gemini Analysis)","text":"<ul> <li>Formats: <code>.mp4</code>, <code>.mov</code>, <code>.avi</code>, <code>.webm</code></li> <li>Use Cases: Tutorials, presentations, demos</li> </ul> <p>Gemini analyzes video frames and audio to generate descriptions.</p>"},{"location":"en/guides/chat-multimodal/#advanced-usage","title":"Advanced Usage","text":""},{"location":"en/guides/chat-multimodal/#programmatic-api","title":"Programmatic API","text":"<p>Use multimodal RAG in your Python code:</p> <pre><code>from pathlib import Path\nfrom kagura import agent\nfrom kagura.core.memory import MultimodalRAG\n\n# Initialize RAG\nrag = MultimodalRAG(\n    directory=Path(\"./project\"),\n    collection_name=\"my_project\",\n    persist_dir=Path(\"./.kagura/rag\")\n)\n\n# Build index (async)\nimport asyncio\nstats = asyncio.run(rag.build_index())\nprint(f\"Indexed {stats['total_files']} files\")\n\n# Query the index\nresults = rag.query(\"authentication implementation\", n_results=3)\nfor result in results:\n    print(f\"Found in: {result['metadata']['file_path']}\")\n    print(f\"Content: {result['content'][:200]}...\")\n</code></pre>"},{"location":"en/guides/chat-multimodal/#agent-integration","title":"Agent Integration","text":"<p>Create an agent with multimodal RAG:</p> <pre><code>from kagura import agent\nfrom kagura.core.memory import MultimodalRAG\nfrom pathlib import Path\n\n@agent(\n    model=\"gemini/gemini-1.5-flash\",\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./docs\")\n)\nasync def docs_assistant(query: str, rag: MultimodalRAG) -&gt; str:\n    \"\"\"Answer questions about the documentation.\n\n    Query: {{ query }}\n\n    Use rag.query() to search relevant documentation.\n    \"\"\"\n    # The agent automatically has access to the RAG instance\n    # and can search through all indexed content\n    pass\n\n# Use the agent\nresponse = await docs_assistant(\"How do I configure authentication?\")\nprint(response)\n</code></pre>"},{"location":"en/guides/chat-multimodal/#incremental-updates","title":"Incremental Updates","text":"<p>Update the index when files change:</p> <pre><code># Initial build\nawait rag.build_index()\n\n# Later, after files are modified\nstats = await rag.incremental_update()\nprint(f\"Updated {stats['total_files']} new/modified files\")\n</code></pre>"},{"location":"en/guides/chat-multimodal/#file-type-filtering","title":"File Type Filtering","text":"<p>Search only specific file types:</p> <pre><code>from kagura.loaders.file_types import FileType\n\n# Search only images\nimage_results = rag.query(\"architecture diagram\", file_type=FileType.IMAGE)\n\n# Search only PDFs\npdf_results = rag.query(\"API documentation\", file_type=FileType.PDF)\n</code></pre>"},{"location":"en/guides/chat-multimodal/#configuration","title":"Configuration","text":""},{"location":"en/guides/chat-multimodal/#directory-scanning","title":"Directory Scanning","text":"<p>Control which files are indexed:</p>"},{"location":"en/guides/chat-multimodal/#gitignore-support","title":".gitignore Support","text":"<p>Kagura respects <code>.gitignore</code> files by default:</p> <pre><code>rag = MultimodalRAG(\n    directory=Path(\"./project\"),\n    respect_gitignore=True  # Default: True\n)\n</code></pre>"},{"location":"en/guides/chat-multimodal/#kaguraignore","title":".kaguraignore","text":"<p>Create a <code>.kaguraignore</code> file for additional exclusions:</p> <pre><code># .kaguraignore\n*.log\n*.tmp\nnode_modules/\n.venv/\n__pycache__/\n</code></pre>"},{"location":"en/guides/chat-multimodal/#caching","title":"Caching","text":"<p>Enable caching to speed up repeated indexing:</p> <pre><code>rag = MultimodalRAG(\n    directory=Path(\"./project\"),\n    enable_cache=True,      # Default: True\n    cache_size_mb=100       # Cache limit in MB\n)\n</code></pre>"},{"location":"en/guides/chat-multimodal/#model-selection","title":"Model Selection","text":"<p>Choose the Gemini model for multimodal processing:</p> <pre><code>from kagura.loaders.gemini import GeminiLoader\n\n# Use Gemini 1.5 Flash (faster, cheaper)\nloader = GeminiLoader(model=\"gemini-1.5-flash\")\n\n# Use Gemini 1.5 Pro (more accurate)\nloader = GeminiLoader(model=\"gemini-1.5-pro\")\n</code></pre> <p>In chat mode:</p> <pre><code># Uses gemini-1.5-flash by default\nkagura chat --enable-multimodal --dir ./project\n\n# Specify model via environment variable\nexport GEMINI_MODEL=\"gemini-1.5-pro\"\nkagura chat --enable-multimodal --dir ./project\n</code></pre>"},{"location":"en/guides/chat-multimodal/#best-practices","title":"Best Practices","text":""},{"location":"en/guides/chat-multimodal/#1-start-small","title":"1. Start Small","text":"<p>Test with a small directory first to verify setup:</p> <pre><code>kagura chat --enable-multimodal --dir ./docs/getting-started\n</code></pre>"},{"location":"en/guides/chat-multimodal/#2-organize-your-files","title":"2. Organize Your Files","text":"<p>Structure your project for better RAG results:</p> <pre><code>project/\n\u251c\u2500\u2500 docs/           # Documentation\n\u251c\u2500\u2500 src/            # Source code\n\u251c\u2500\u2500 tests/          # Tests\n\u251c\u2500\u2500 diagrams/       # Architecture diagrams\n\u2514\u2500\u2500 specs/          # Specifications (PDFs)\n</code></pre>"},{"location":"en/guides/chat-multimodal/#3-use-descriptive-filenames","title":"3. Use Descriptive Filenames","text":"<p>Good filenames improve search relevance:</p> <pre><code>\u2705 auth-flow-diagram.png\n\u2705 api-documentation.pdf\n\u2705 user-authentication.py\n\n\u274c diagram1.png\n\u274c doc.pdf\n\u274c utils.py\n</code></pre>"},{"location":"en/guides/chat-multimodal/#4-keep-files-updated","title":"4. Keep Files Updated","text":"<p>Run incremental updates regularly:</p> <pre><code># In a background task or cron job\nawait rag.incremental_update()\n</code></pre>"},{"location":"en/guides/chat-multimodal/#5-monitor-api-usage","title":"5. Monitor API Usage","text":"<p>Gemini API has rate limits and costs. Monitor usage:</p> <pre><code>stats = await rag.build_index()\nprint(f\"Multimodal files processed: {stats['multimodal_files']}\")\nprint(f\"Cache hit rate: {stats['cache_hit_rate']:.1%}\")\n</code></pre>"},{"location":"en/guides/chat-multimodal/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/chat-multimodal/#importerror-google-generativeai-not-installed","title":"\"ImportError: google-generativeai not installed\"","text":"<p>Install multimodal dependencies:</p> <pre><code>pip install kagura-ai[multimodal]\n</code></pre>"},{"location":"en/guides/chat-multimodal/#authentication-error-invalid-api-key","title":"\"Authentication error: Invalid API key\"","text":"<p>Check your API key:</p> <pre><code>echo $GEMINI_API_KEY\n</code></pre> <p>Get a new key from Google AI Studio.</p>"},{"location":"en/guides/chat-multimodal/#rate-limit-exceeded","title":"\"Rate limit exceeded\"","text":"<p>Gemini API has rate limits. Reduce <code>max_concurrent</code>:</p> <pre><code>await rag.build_index(max_concurrent=1)  # Process 1 file at a time\n</code></pre> <p>Or enable caching to reduce API calls:</p> <pre><code>rag = MultimodalRAG(directory=path, enable_cache=True)\n</code></pre>"},{"location":"en/guides/chat-multimodal/#no-results-found","title":"No Results Found","text":"<p>Check if files were indexed:</p> <pre><code>indexed_files = rag.get_indexed_files()\nprint(f\"Indexed {len(indexed_files)} files\")\nfor file in indexed_files[:10]:\n    print(f\"  - {file}\")\n</code></pre> <p>Try rebuilding the index:</p> <pre><code>await rag.build_index(force_rebuild=True)\n</code></pre>"},{"location":"en/guides/chat-multimodal/#performance-tips","title":"Performance Tips","text":""},{"location":"en/guides/chat-multimodal/#1-use-gemini-15-flash","title":"1. Use Gemini 1.5 Flash","text":"<p>Flash model is 3x faster and cheaper than Pro:</p> <pre><code>loader = GeminiLoader(model=\"gemini-1.5-flash\")\n</code></pre>"},{"location":"en/guides/chat-multimodal/#2-enable-caching","title":"2. Enable Caching","text":"<p>Cache processed files to avoid re-processing:</p> <pre><code>rag = MultimodalRAG(\n    directory=path,\n    enable_cache=True,\n    cache_size_mb=500  # Increase for large projects\n)\n</code></pre>"},{"location":"en/guides/chat-multimodal/#3-parallel-processing","title":"3. Parallel Processing","text":"<p>Increase concurrency for faster indexing:</p> <pre><code>await rag.build_index(max_concurrent=5)  # Default: 3\n</code></pre>"},{"location":"en/guides/chat-multimodal/#4-incremental-updates","title":"4. Incremental Updates","text":"<p>Use incremental updates instead of full rebuilds:</p> <pre><code># Only processes new/modified files\nawait rag.incremental_update()\n</code></pre>"},{"location":"en/guides/chat-multimodal/#examples","title":"Examples","text":""},{"location":"en/guides/chat-multimodal/#example-1-documentation-assistant","title":"Example 1: Documentation Assistant","text":"<pre><code>from kagura import agent\nfrom kagura.core.memory import MultimodalRAG\nfrom pathlib import Path\n\n@agent(\n    model=\"gemini/gemini-1.5-flash\",\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./docs\")\n)\nasync def docs_bot(question: str, rag: MultimodalRAG) -&gt; str:\n    \"\"\"Answer questions about project documentation.\n\n    User question: {{ question }}\n    \"\"\"\n    pass\n\n# Usage\nanswer = await docs_bot(\"How do I deploy to production?\")\n</code></pre>"},{"location":"en/guides/chat-multimodal/#example-2-code-review-with-diagrams","title":"Example 2: Code Review with Diagrams","text":"<pre><code>@agent(\n    model=\"gemini/gemini-1.5-flash\",\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./project\")\n)\nasync def code_reviewer(file_path: str, rag: MultimodalRAG) -&gt; str:\n    \"\"\"Review code file and check against architecture diagrams.\n\n    File to review: {{ file_path }}\n\n    Search for:\n    1. Related architecture diagrams\n    2. Design documentation\n    3. Similar code patterns\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/guides/chat-multimodal/#example-3-meeting-notes-search","title":"Example 3: Meeting Notes Search","text":"<pre><code># Index meeting recordings\nrag = MultimodalRAG(\n    directory=Path(\"./meetings\"),\n    collection_name=\"meeting_notes\"\n)\nawait rag.build_index()\n\n# Search across all meetings\nresults = rag.query(\"Q4 roadmap discussion\", n_results=5)\nfor result in results:\n    print(f\"Meeting: {result['metadata']['file_path']}\")\n    print(f\"Relevant part: {result['content'][:300]}...\")\n    print()\n</code></pre>"},{"location":"en/guides/chat-multimodal/#next-steps","title":"Next Steps","text":"<ul> <li>Web Integration Guide - Add web search to your chat</li> <li>Full-Featured Mode - Combine multimodal RAG and web search</li> <li>API Reference - Detailed API documentation</li> </ul>"},{"location":"en/guides/chat-multimodal/#resources","title":"Resources","text":"<ul> <li>Gemini API Documentation</li> <li>ChromaDB Documentation</li> <li>Kagura AI Examples</li> </ul>"},{"location":"en/guides/cli-performance/","title":"CLI Performance","text":"<p>Kagura CLI uses lazy loading to ensure fast startup times.</p>"},{"location":"en/guides/cli-performance/#startup-performance","title":"Startup Performance","text":"<p>Before optimization: <code>kagura --help</code> took 8.8 seconds</p> <p>After optimization: <code>kagura --help</code> takes 0.1 seconds (98.9% faster!)</p>"},{"location":"en/guides/cli-performance/#how-it-works","title":"How It Works","text":""},{"location":"en/guides/cli-performance/#lazy-loading","title":"Lazy Loading","text":"<p>Subcommands are imported only when invoked:</p> <pre><code># Before (slow)\nfrom .mcp import mcp          # Always imported - 393ms!\nfrom .monitor import monitor  # Always imported\n\n# After (fast)\n@click.group(cls=LazyGroup, lazy_subcommands={\n    \"mcp\": (\"kagura.cli.mcp\", \"mcp\", \"MCP commands\"),     # Import on demand\n    \"monitor\": (\"kagura.cli.monitor\", \"monitor\", \"Monitor telemetry\"),\n})\n</code></pre> <p>Benefits: - <code>kagura --help</code>: No heavy modules loaded - <code>kagura chat</code>: Only chat module loaded - <code>kagura mcp start</code>: Only MCP module loaded</p>"},{"location":"en/guides/cli-performance/#module-level-lazy-imports","title":"Module-level Lazy Imports","text":"<p>The main <code>kagura</code> package also uses lazy imports via <code>__getattr__</code>:</p> <pre><code># kagura/__init__.py\n\ndef __getattr__(name: str):\n    \"\"\"Lazy import attributes on demand\"\"\"\n    if name == \"agent\":\n        from .core.decorators import agent\n        return agent\n    # ...\n</code></pre> <p>Benefits: - CLI startup doesn't load decorators, memory, etc. - User code loads only what it needs</p>"},{"location":"en/guides/cli-performance/#performance-metrics","title":"Performance Metrics","text":"Command Before After Improvement <code>kagura --help</code> 8.8s 0.1s 98.9% faster <code>kagura version</code> 8.8s 0.1s 98.9% faster <code>kagura chat</code> 8.8s 0.5s 94.3% faster <code>kagura mcp start</code> 8.8s 1.0s 88.6% faster"},{"location":"en/guides/cli-performance/#adding-new-commands","title":"Adding New Commands","text":"<p>When adding a new CLI command, use lazy loading to maintain performance:</p> <pre><code># src/kagura/cli/main.py\n\n@click.group(cls=LazyGroup, lazy_subcommands={\n    # Add your command here\n    \"mycommand\": (\"kagura.cli.mycommand\", \"mycommand\", \"My command description\"),\n})\ndef cli():\n    pass\n</code></pre> <p>Guidelines: 1. Always add new commands to <code>lazy_subcommands</code> 2. Provide a short description (third tuple element) 3. Avoid top-level imports in <code>main.py</code></p>"},{"location":"en/guides/cli-performance/#benchmarking","title":"Benchmarking","text":""},{"location":"en/guides/cli-performance/#measure-startup-time","title":"Measure Startup Time","text":"<pre><code># Overall time\ntime kagura --help\n\n# Import time only\npython -c \"\nimport time\nstart = time.time()\nfrom kagura.cli.main import cli\nprint(f'Import: {(time.time()-start)*1000:.0f}ms')\n\"\n</code></pre>"},{"location":"en/guides/cli-performance/#profile-imports","title":"Profile Imports","text":"<pre><code># Detailed import profiling\npython -X importtime -c \"from kagura.cli.main import cli\" 2&gt;&amp;1 | tail -50\n</code></pre>"},{"location":"en/guides/cli-performance/#expected-results","title":"Expected Results","text":"<ul> <li>CLI import: &lt; 50ms</li> <li><code>kagura --help</code>: &lt; 200ms</li> <li>No heavy modules (mcp, observability) loaded on <code>--help</code></li> </ul>"},{"location":"en/guides/cli-performance/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/cli-performance/#q-my-command-is-slow-to-start","title":"Q: My command is slow to start","text":"<p>A: Check if you're importing heavy modules at the top level:</p> <pre><code># Bad - imports immediately\nfrom heavy_module import something\n\n@click.command()\ndef mycommand():\n    pass\n\n# Good - imports on execution\n@click.command()\ndef mycommand():\n    from heavy_module import something  # Import here\n    pass\n</code></pre>"},{"location":"en/guides/cli-performance/#q-how-do-i-know-if-a-module-is-heavy","title":"Q: How do I know if a module is heavy?","text":"<p>A: Use <code>python -X importtime</code>:</p> <pre><code>python -X importtime -c \"import my_module\" 2&gt;&amp;1 | tail -20\n</code></pre> <p>Look for cumulative times &gt; 100ms.</p>"},{"location":"en/guides/cli-performance/#q-can-i-disable-lazy-loading","title":"Q: Can I disable lazy loading?","text":"<p>A: Not recommended, but you can import modules explicitly in <code>main.py</code>:</p> <pre><code># Not recommended - slow startup\nfrom .mcp import mcp\nfrom .monitor import monitor\n# ...\n\ncli.add_command(mcp)\ncli.add_command(monitor)\n</code></pre>"},{"location":"en/guides/cli-performance/#best-practices","title":"Best Practices","text":"<ol> <li>Always use lazy loading for CLI commands</li> <li>Import heavy modules inside functions, not at module level</li> <li>Test startup time in CI (see <code>tests/cli/test_lazy_loading.py</code>)</li> <li>Profile regularly to catch regressions</li> </ol>"},{"location":"en/guides/cli-performance/#future-improvements","title":"Future Improvements","text":"<ul> <li>Pre-compiled bytecode (<code>.pyc</code>) optimization</li> <li>Startup profiling in CI</li> <li>Dynamic help text loading</li> </ul>"},{"location":"en/guides/commands-quickstart/","title":"Custom Commands Quick Start","text":"<p>Learn how to create and use custom commands in Kagura AI.</p>"},{"location":"en/guides/commands-quickstart/#what-are-custom-commands","title":"What are Custom Commands?","text":"<p>Custom commands are reusable AI tasks defined in simple Markdown files. They allow you to:</p> <ul> <li>Define common workflows once, use them repeatedly</li> <li>Share commands with your team via Git</li> <li>Build a library of AI-powered automation</li> <li>Use global commands across all projects</li> <li>Override global commands with project-specific versions</li> </ul>"},{"location":"en/guides/commands-quickstart/#creating-your-first-command","title":"Creating Your First Command","text":""},{"location":"en/guides/commands-quickstart/#step-1-create-commands-directory","title":"Step 1: Create Commands Directory","text":"<p>Option A: Global Commands (available in all projects)</p> <pre><code>mkdir -p ~/.kagura/commands\n</code></pre> <p>Option B: Local Commands (project-specific)</p> <pre><code>mkdir -p .kagura/commands\n</code></pre> <p>Recommended: Use local commands for project-specific workflows, and global commands for general-purpose tasks.</p> <p>By default, Kagura searches both directories: 1. <code>~/.kagura/commands</code> - Global commands 2. <code>./.kagura/commands</code> - Local commands (takes priority)</p>"},{"location":"en/guides/commands-quickstart/#step-2-create-a-command-file","title":"Step 2: Create a Command File","text":"<p>Create <code>~/.kagura/commands/hello.md</code>:</p> <pre><code>---\nname: hello\ndescription: Say hello to someone\n---\n\n# Task\n\nSay hello to the user in a friendly way!\n</code></pre>"},{"location":"en/guides/commands-quickstart/#step-3-load-and-use-the-command","title":"Step 3: Load and Use the Command","text":"<pre><code>from kagura.commands import CommandLoader\n\n# Load commands\nloader = CommandLoader()\ncommands = loader.load_all()\n\n# Get your command\nhello = commands[\"hello\"]\n\nprint(f\"Command: {hello.name}\")\nprint(f\"Description: {hello.description}\")\nprint(f\"Template:\\n{hello.template}\")\n</code></pre>"},{"location":"en/guides/commands-quickstart/#command-structure","title":"Command Structure","text":"<p>Every command file has two parts:</p>"},{"location":"en/guides/commands-quickstart/#1-frontmatter-yaml-metadata","title":"1. Frontmatter (YAML Metadata)","text":"<pre><code>---\nname: my-command          # Command name\ndescription: What it does # Description\nmodel: gpt-4o-mini       # LLM model (optional)\nallowed_tools: [git]      # Allowed tools (optional)\n---\n</code></pre>"},{"location":"en/guides/commands-quickstart/#2-body-markdown-template","title":"2. Body (Markdown Template)","text":"<pre><code># Context\n\nCurrent working directory...\n\n# Task\n\nDo something amazing!\n</code></pre>"},{"location":"en/guides/commands-quickstart/#example-commands","title":"Example Commands","text":""},{"location":"en/guides/commands-quickstart/#git-workflow","title":"Git Workflow","text":"<p><code>~/.kagura/commands/git-workflow.md</code>:</p> <pre><code>---\nname: git-workflow\ndescription: Complete git workflow (commit, push, PR)\nallowed_tools: [git, gh]\nmodel: gpt-4o-mini\n---\n\n# Task\n\nExecute the following git workflow:\n\n1. Create a feature branch (if on main)\n2. Stage and commit all changes\n3. Push to origin\n4. Create a pull request\n\nUse conventional commit format for the commit message.\n</code></pre>"},{"location":"en/guides/commands-quickstart/#code-review","title":"Code Review","text":"<p><code>~/.kagura/commands/code-review.md</code>:</p> <pre><code>---\nname: code-review\ndescription: Review code changes\nmodel: gpt-4o\n---\n\n# Task\n\nReview the recent code changes and provide feedback on:\n\n1. **Code Quality**\n   - Naming conventions\n   - Code organization\n   - Complexity\n\n2. **Best Practices**\n   - Error handling\n   - Type hints\n   - Documentation\n\n3. **Potential Issues**\n   - Security concerns\n   - Performance problems\n   - Edge cases\n\nProvide specific, actionable feedback.\n</code></pre>"},{"location":"en/guides/commands-quickstart/#data-analysis","title":"Data Analysis","text":"<p><code>~/.kagura/commands/analyze-csv.md</code>:</p> <pre><code>---\nname: analyze-csv\ndescription: Analyze CSV data file\nparameters:\n  file: string\n---\n\n# Context\n\nAnalyzing file: {{ file }}\n\n# Task\n\nPerform a comprehensive analysis:\n\n1. Data summary (rows, columns, types)\n2. Missing values analysis\n3. Statistical summary\n4. Key insights and patterns\n5. Recommendations\n\nPresent findings in a clear, structured format.\n</code></pre>"},{"location":"en/guides/commands-quickstart/#using-commands","title":"Using Commands","text":""},{"location":"en/guides/commands-quickstart/#load-all-commands","title":"Load All Commands","text":"<pre><code>from kagura.commands import CommandLoader\n\nloader = CommandLoader()\ncommands = loader.load_all()\n\nprint(f\"Loaded {len(commands)} commands:\")\nfor name in loader.list_commands():\n    cmd = commands[name]\n    print(f\"  - {name}: {cmd.description}\")\n</code></pre>"},{"location":"en/guides/commands-quickstart/#load-single-command","title":"Load Single Command","text":"<pre><code>from pathlib import Path\nfrom kagura.commands import CommandLoader\n\nloader = CommandLoader()\ncommand = loader.load_command(\n    Path(\"~/.kagura/commands/hello.md\").expanduser()\n)\n\nprint(command.name)\nprint(command.template)\n</code></pre>"},{"location":"en/guides/commands-quickstart/#get-command-by-name","title":"Get Command by Name","text":"<pre><code>loader = CommandLoader()\nloader.load_all()\n\n# Get specific command\ncmd = loader.get_command(\"git-workflow\")\nif cmd:\n    print(f\"Found: {cmd.description}\")\nelse:\n    print(\"Command not found\")\n</code></pre>"},{"location":"en/guides/commands-quickstart/#command-features","title":"Command Features","text":""},{"location":"en/guides/commands-quickstart/#allowed-tools","title":"Allowed Tools","text":"<p>Restrict which tools a command can use:</p> <pre><code>---\nallowed_tools: [git, gh, bash]\n---\n</code></pre>"},{"location":"en/guides/commands-quickstart/#custom-model","title":"Custom Model","text":"<p>Use a different LLM model:</p> <pre><code>---\nmodel: gpt-4o  # Use more powerful model\n---\n</code></pre>"},{"location":"en/guides/commands-quickstart/#parameters","title":"Parameters","text":"<p>Define parameters for your command:</p> <pre><code>---\nparameters:\n  filename: string\n  count: int\n  verbose: bool\n---\n\nProcessing {{ filename }} with count={{ count }}\n</code></pre> <p>Validate parameters:</p> <pre><code>command = loader.get_command(\"my-cmd\")\ncommand.validate_parameters({\n    \"filename\": \"data.csv\",\n    \"count\": 10,\n    \"verbose\": True\n})\n</code></pre>"},{"location":"en/guides/commands-quickstart/#custom-metadata","title":"Custom Metadata","text":"<p>Add any custom fields:</p> <pre><code>---\nauthor: Your Name\nversion: 1.0\ntags: [git, automation]\ncategory: workflow\n---\n</code></pre> <p>Access metadata:</p> <pre><code>command = loader.get_command(\"my-cmd\")\nprint(command.metadata[\"author\"])  # \"Your Name\"\nprint(command.metadata[\"tags\"])    # [\"git\", \"automation\"]\n</code></pre>"},{"location":"en/guides/commands-quickstart/#directory-structure","title":"Directory Structure","text":""},{"location":"en/guides/commands-quickstart/#global-vs-local-commands","title":"Global vs Local Commands","text":"<p>Global commands (<code>~/.kagura/commands/</code>): - Available in all projects - General-purpose workflows - Shared across your system</p> <p>Local commands (<code>./.kagura/commands/</code>): - Project-specific workflows - Can be committed to Git - Override global commands with same name</p>"},{"location":"en/guides/commands-quickstart/#example-structure","title":"Example Structure","text":"<p>Global commands: <pre><code>~/.kagura/commands/\n\u251c\u2500\u2500 git-commit-pr.md         # Generic git workflow\n\u251c\u2500\u2500 code-review.md           # General code review\n\u2514\u2500\u2500 translate.md             # Generic translation\n</code></pre></p> <p>Local commands (in project directory): <pre><code>.kagura/commands/\n\u251c\u2500\u2500 deploy.md                # Project-specific deployment\n\u251c\u2500\u2500 test-suite.md            # Project-specific tests\n\u2514\u2500\u2500 git-commit-pr.md         # Overrides global version\n</code></pre></p> <p>When both exist, local takes priority: <pre><code>~/.kagura/commands/deploy.md      \u2190 Not used (global)\n./.kagura/commands/deploy.md      \u2190 Used (local)\n</code></pre></p>"},{"location":"en/guides/commands-quickstart/#organizing-commands","title":"Organizing Commands","text":"<p>You can organize commands by category:</p> <pre><code>.kagura/commands/\n\u251c\u2500\u2500 git-commit.md\n\u251c\u2500\u2500 git-pr.md\n\u251c\u2500\u2500 docs-readme.md\n\u251c\u2500\u2500 docs-changelog.md\n\u251c\u2500\u2500 code-review.md\n\u2514\u2500\u2500 data-analyze.md\n</code></pre> <p>Note: Subdirectory support will be added in a future release. Currently, only top-level <code>.md</code> files are loaded.</p>"},{"location":"en/guides/commands-quickstart/#best-practices","title":"Best Practices","text":""},{"location":"en/guides/commands-quickstart/#1-use-local-commands-for-projects","title":"1. Use Local Commands for Projects","text":"<p>Commit local commands to Git for team collaboration:</p> <pre><code># Add to Git\ngit add .kagura/commands/\ngit commit -m \"Add project commands\"\n</code></pre> <p>This allows your team to: - Use the same workflows - Override with their own local changes - Keep project-specific automation in version control</p>"},{"location":"en/guides/commands-quickstart/#2-clear-descriptive-names","title":"2. Clear, Descriptive Names","text":"<p>\u2705 Good: <pre><code>name: git-commit-push-pr\n</code></pre></p> <p>\u274c Bad: <pre><code>name: cmd1\n</code></pre></p>"},{"location":"en/guides/commands-quickstart/#3-detailed-descriptions","title":"3. Detailed Descriptions","text":"<p>\u2705 Good: <pre><code>description: Create commit, push to origin, and open pull request\n</code></pre></p> <p>\u274c Bad: <pre><code>description: Git stuff\n</code></pre></p>"},{"location":"en/guides/commands-quickstart/#4-specific-task-instructions","title":"4. Specific Task Instructions","text":"<p>\u2705 Good: <pre><code># Task\n\n1. Create feature branch from main\n2. Stage all changes with `git add .`\n3. Create commit with conventional format\n4. Push to origin with `-u` flag\n5. Create PR using `gh pr create`\n</code></pre></p> <p>\u274c Bad: <pre><code># Task\n\nDo git things\n</code></pre></p>"},{"location":"en/guides/commands-quickstart/#5-use-allowed-tools","title":"5. Use Allowed Tools","text":"<p>Restrict tools for security:</p> <pre><code>---\nallowed_tools: [git, gh]  # Only git and GitHub CLI\n---\n</code></pre>"},{"location":"en/guides/commands-quickstart/#6-add-metadata","title":"6. Add Metadata","text":"<p>Help others understand your command:</p> <pre><code>---\nauthor: Team Name\nversion: 2.0\nupdated: 2025-01-15\ncategory: workflow\n---\n</code></pre>"},{"location":"en/guides/commands-quickstart/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/commands-quickstart/#command-not-found","title":"Command Not Found","text":"<pre><code>loader = CommandLoader()\nloader.load_all()\n\nif not loader.get_command(\"my-cmd\"):\n    print(\"Command not found!\")\n    print(\"Available commands:\", loader.list_commands())\n</code></pre>"},{"location":"en/guides/commands-quickstart/#invalid-frontmatter","title":"Invalid Frontmatter","text":"<p>If you see warnings about invalid files, check your YAML syntax:</p> <pre><code>---\nname: my-command\ndescription: My command  # Make sure quotes are balanced\nallowed_tools: [git]     # Make sure brackets match\n---\n</code></pre>"},{"location":"en/guides/commands-quickstart/#directory-doesnt-exist","title":"Directory Doesn't Exist","text":"<p>Create the commands directory if it doesn't exist:</p> <pre><code>mkdir -p ~/.kagura/commands\n</code></pre>"},{"location":"en/guides/commands-quickstart/#inline-command-execution","title":"Inline Command Execution","text":""},{"location":"en/guides/commands-quickstart/#what-are-inline-commands","title":"What are Inline Commands?","text":"<p>Inline commands allow you to embed shell commands directly in your templates using the <code>!</code>command`` syntax. They are executed before the template is rendered.</p>"},{"location":"en/guides/commands-quickstart/#basic-syntax","title":"Basic Syntax","text":"<pre><code>Current directory: !`pwd`\nCurrent user: !`whoami`\nGit branch: !`git branch --show-current`\n</code></pre>"},{"location":"en/guides/commands-quickstart/#example-command-with-inline-execution","title":"Example Command with Inline Execution","text":"<p>Create <code>~/.kagura/commands/system-info.md</code>:</p> <pre><code>---\nname: system-info\ndescription: Show system information\n---\n\n# System Information\n\n**Current User**: !`whoami`\n**Working Directory**: !`pwd`\n**Git Branch**: !`git branch --show-current`\n**Current Date**: !`date +%Y-%m-%d`\n\n## Task\n\nAnalyze the current development environment.\n</code></pre>"},{"location":"en/guides/commands-quickstart/#using-inline-commands-programmatically","title":"Using Inline Commands Programmatically","text":"<pre><code>from kagura.commands import InlineCommandExecutor\n\nexecutor = InlineCommandExecutor()\n\n# Simple command\nresult = executor.execute(\"User: !`whoami`\")\nprint(result)  # \"User: alice\"\n\n# Multiple commands\ntemplate = \"\"\"\nCurrent directory: !`pwd`\nCurrent user: !`whoami`\nGit branch: !`git branch --show-current`\n\"\"\"\nresult = executor.execute(template)\nprint(result)\n</code></pre>"},{"location":"en/guides/commands-quickstart/#inline-commands-with-parameters","title":"Inline Commands with Parameters","text":"<p>Combine Jinja2 parameters with inline commands:</p> <pre><code>---\nname: git-info\ndescription: Show git information\nparameters:\n  project: string\n---\n\n# Git Information for {{ project }}\n\n**Branch**: !`git branch --show-current`\n**Status**: !`git status --short`\n**Last Commit**: !`git log -1 --oneline`\n\nProject {{ project }} is on branch !`git branch --show-current`.\n</code></pre>"},{"location":"en/guides/commands-quickstart/#rendering-order","title":"Rendering Order","text":"<ol> <li>Inline commands execute first: <code>!</code>pwd<code>` \u2192</code>/home/user`</li> <li>Jinja2 renders second: <code>{{ project }}</code> \u2192 <code>my-project</code></li> </ol> <pre><code>from kagura.commands import Command, CommandExecutor\n\ncommand = Command(\n    name=\"example\",\n    description=\"Example\",\n    template=\"{{ name }} is in !`pwd`\",\n    parameters={\"name\": \"string\"}\n)\n\nexecutor = CommandExecutor()\nresult = executor.render(command, {\"name\": \"Alice\"})\n# Result: \"Alice is in /home/alice/project\"\n</code></pre>"},{"location":"en/guides/commands-quickstart/#error-handling","title":"Error Handling","text":"<p>Failed commands show error messages:</p> <pre><code>Result: !`nonexistent_command`\n</code></pre> <p>Renders as:</p> <pre><code>Result: [Error: command not found]\n</code></pre>"},{"location":"en/guides/commands-quickstart/#disabling-inline-execution","title":"Disabling Inline Execution","text":"<pre><code>executor = CommandExecutor(enable_inline=False)\nresult = executor.render(command)\n# Inline commands are NOT executed\n</code></pre>"},{"location":"en/guides/commands-quickstart/#using-the-cli","title":"Using the CLI","text":""},{"location":"en/guides/commands-quickstart/#installing","title":"Installing","text":"<p>After installing Kagura AI, the <code>kagura run</code> command is available:</p> <pre><code>pip install kagura-ai\n</code></pre>"},{"location":"en/guides/commands-quickstart/#basic-usage","title":"Basic Usage","text":"<pre><code># Run a command\nkagura run hello\n\n# Run with parameters\nkagura run greet --param name=Alice --param formal=true\n\n# Use custom commands directory\nkagura run my-cmd --commands-dir ./my-commands\n\n# Disable inline command execution\nkagura run my-cmd --no-inline\n</code></pre>"},{"location":"en/guides/commands-quickstart/#cli-options","title":"CLI Options","text":"<pre><code>kagura run COMMAND_NAME [OPTIONS]\n\nOptions:\n  --param, -p KEY=VALUE    Command parameter (can be used multiple times)\n  --commands-dir PATH      Custom commands directory\n  --no-inline              Disable inline command execution\n  --help                   Show help message\n</code></pre>"},{"location":"en/guides/commands-quickstart/#example-git-workflow","title":"Example: Git Workflow","text":"<p>Create <code>~/.kagura/commands/git-status.md</code>:</p> <pre><code>---\nname: git-status\ndescription: Show detailed git status\nparameters:\n  username: string\n---\n\n# Git Status Report\n\n**User**: {{ username }}\n**Branch**: !`git branch --show-current`\n**Working Directory**: !`pwd`\n\n## Changes\n\n!`git status --short`\n\n## Task\n\nReview the changes and create an appropriate commit message.\n</code></pre> <p>Run it:</p> <pre><code>kagura run git-status --param username=Alice\n</code></pre> <p>Output:</p> <pre><code>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Executing Command    \u2503\n\u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\ngit-status\nShow detailed git status\n\nRendered Command:\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # Git Status Report                \u2503\n\u2503                                     \u2503\n\u2503 **User**: Alice                    \u2503\n\u2503 **Branch**: main                   \u2503\n\u2503 **Working Directory**: /home/alice \u2503\n\u2503                                     \u2503\n\u2503 ## Changes                         \u2503\n\u2503                                     \u2503\n\u2503 M src/main.py                      \u2503\n\u2503 ?? new_file.py                     \u2503\n\u2503                                     \u2503\n\u2503 ## Task                            \u2503\n\u2503                                     \u2503\n\u2503 Review the changes and create an   \u2503\n\u2503 appropriate commit message.        \u2503\n\u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n</code></pre>"},{"location":"en/guides/commands-quickstart/#quiet-mode","title":"Quiet Mode","text":"<p>Use global flags for quiet output:</p> <pre><code>kagura --quiet run my-cmd\n</code></pre> <p>This prints only the rendered result without decorations.</p>"},{"location":"en/guides/commands-quickstart/#verbose-mode","title":"Verbose Mode","text":"<p>Use verbose mode for debugging:</p> <pre><code>kagura --verbose run my-cmd\n</code></pre>"},{"location":"en/guides/commands-quickstart/#advanced-examples","title":"Advanced Examples","text":""},{"location":"en/guides/commands-quickstart/#command-with-multiple-parameters","title":"Command with Multiple Parameters","text":"<p><code>~/.kagura/commands/analyze-file.md</code>:</p> <pre><code>---\nname: analyze-file\ndescription: Analyze a file\nparameters:\n  file: string\n  lines:\n    type: int\n    required: false\n  verbose:\n    type: bool\n    required: false\n---\n\n# File Analysis: {{ file }}\n\n**File Location**: !`realpath {{ file }}`\n**File Size**: !`stat -c%s {{ file }}` bytes\n**Line Count**: !`wc -l &lt; {{ file }}`\n\n{% if lines %}\n**First {{ lines }} lines**:\n\n!`head -n {{ lines }} {{ file }}`\n{% endif %}\n\n## Task\n\n{% if verbose %}\nPerform a detailed analysis of {{ file }}.\n{% else %}\nProvide a summary analysis of {{ file }}.\n{% endif %}\n</code></pre> <p>Run it:</p> <pre><code># Basic usage\nkagura run analyze-file --param file=data.csv\n\n# With optional parameters\nkagura run analyze-file \\\n  --param file=data.csv \\\n  --param lines=10 \\\n  --param verbose=true\n</code></pre>"},{"location":"en/guides/commands-quickstart/#command-with-pipes","title":"Command with Pipes","text":"<p><code>~/.kagura/commands/code-stats.md</code>:</p> <pre><code>---\nname: code-stats\ndescription: Show code statistics\n---\n\n# Code Statistics\n\n**Total Python Files**: !`find . -name \"*.py\" | wc -l`\n**Total Lines of Code**: !`find . -name \"*.py\" -exec wc -l {} + | tail -1 | awk '{print $1}'`\n**Most Recent Change**: !`git log -1 --format=%cr`\n\n## Task\n\nReview the code statistics and provide insights.\n</code></pre> <p>Run it:</p> <pre><code>kagura run code-stats\n</code></pre>"},{"location":"en/guides/commands-quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Read the Commands API Reference</li> <li>Learn about CLI Commands</li> <li>Explore hooks and validation (coming soon)</li> </ul>"},{"location":"en/guides/commands-quickstart/#examples","title":"Examples","text":"<p>Check out example commands in the examples/commands/ directory (coming soon).</p>"},{"location":"en/guides/context-compression/","title":"Context Compression Guide","text":"<p>RFC-024 Phase 1: Token Management</p> <p>Since: v2.5.0</p>"},{"location":"en/guides/context-compression/#overview","title":"Overview","text":"<p>Context compression enables efficient long-form conversations by managing token usage and preventing context window overflow.</p> <p>Phase 1 (current) provides: - \u2705 Accurate token counting for all major LLM models - \u2705 Real-time context usage monitoring - \u2705 Compression recommendations</p> <p>Future phases will add: - \ud83d\udccb Phase 2: Message trimming (Week 2) - \ud83d\udccb Phase 3: LLM-based summarization (Week 3-4) - \ud83d\udccb Phase 4: Automatic compression (Week 5)</p>"},{"location":"en/guides/context-compression/#installation","title":"Installation","text":"<pre><code># Install with AI features (includes context compression)\npip install kagura-ai[ai]\n\n# Or install all features\npip install kagura-ai[all]\n</code></pre> <p>Dependencies: - <code>tiktoken&gt;=0.7.0</code> - OpenAI's token counting library</p>"},{"location":"en/guides/context-compression/#quick-start","title":"Quick Start","text":""},{"location":"en/guides/context-compression/#basic-token-counting","title":"Basic Token Counting","text":"<pre><code>from kagura.core.compression import TokenCounter\n\n# Create counter\ncounter = TokenCounter(model=\"gpt-4o-mini\")\n\n# Count tokens in text\ntext = \"Hello, world!\"\ntokens = counter.count_tokens(text)\nprint(f\"Tokens: {tokens}\")  # Tokens: 4\n\n# Count tokens in messages\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Hello!\"},\n    {\"role\": \"assistant\", \"content\": \"Hi there!\"}\n]\n\ntotal_tokens = counter.count_tokens_messages(messages)\nprint(f\"Total tokens: {total_tokens}\")  # Includes message overhead\n</code></pre>"},{"location":"en/guides/context-compression/#context-usage-monitoring","title":"Context Usage Monitoring","text":"<pre><code>from kagura.core.compression import TokenCounter, ContextMonitor\n\n# Create counter and monitor\ncounter = TokenCounter(model=\"gpt-4o-mini\")\nmonitor = ContextMonitor(counter, max_tokens=10000)\n\n# Check usage\nmessages = [...]  # Your conversation history\nusage = monitor.check_usage(messages, system_prompt=\"Be helpful.\")\n\n# Display usage\nprint(f\"Usage: {usage.usage_ratio:.1%}\")  # e.g., 45.3%\nprint(f\"Tokens: {usage.total_tokens:,} / {usage.max_tokens:,}\")\n\nif usage.should_compress:\n    print(\"\u26a0\ufe0f Context is getting full!\")\n    print(\"Consider compressing (Phase 2+)\")\n</code></pre>"},{"location":"en/guides/context-compression/#advanced-usage","title":"Advanced Usage","text":""},{"location":"en/guides/context-compression/#auto-detect-model-limits","title":"Auto-Detect Model Limits","text":"<pre><code># Automatically detect max tokens from model\ncounter = TokenCounter(model=\"claude-3-5-sonnet\")\nmonitor = ContextMonitor(counter, max_tokens=None)\n\nprint(f\"Max tokens: {monitor.max_tokens:,}\")\n# For Claude 3.5 Sonnet: 196,000 (200k - 4k reserved)\n</code></pre>"},{"location":"en/guides/context-compression/#custom-compression-threshold","title":"Custom Compression Threshold","text":"<pre><code># Trigger compression at 70% instead of default 80%\nshould_compress = counter.should_compress(\n    current_tokens=usage.total_tokens,\n    max_tokens=usage.max_tokens,\n    threshold=0.7  # 70%\n)\n\nif should_compress:\n    print(\"Time to compress!\")\n</code></pre>"},{"location":"en/guides/context-compression/#estimate-context-size","title":"Estimate Context Size","text":"<pre><code># Estimate how much context a conversation will use\nestimate = counter.estimate_context_size(\n    messages=messages,\n    system_prompt=\"You are helpful.\",\n    max_tokens=1000  # Reserve for completion\n)\n\nprint(f\"Prompt: {estimate['prompt_tokens']:,} tokens\")\nprint(f\"Completion: {estimate['completion_tokens']:,} tokens\")\nprint(f\"Total: {estimate['total_tokens']:,} tokens\")\n</code></pre>"},{"location":"en/guides/context-compression/#model-support","title":"Model Support","text":""},{"location":"en/guides/context-compression/#supported-models","title":"Supported Models","text":"<p>All major LLM providers are supported:</p> <pre><code># OpenAI\ncounter_openai = TokenCounter(model=\"gpt-4o-mini\")\n\n# Anthropic Claude\ncounter_claude = TokenCounter(model=\"claude-3-5-sonnet\")\n\n# Google Gemini\ncounter_gemini = TokenCounter(model=\"gemini-1.5-pro\")\n</code></pre>"},{"location":"en/guides/context-compression/#model-limits","title":"Model Limits","text":"<p>Get token limits for any model:</p> <pre><code>limits = counter.get_model_limits(\"gpt-4o-mini\")\nprint(f\"Context window: {limits['context_window']:,}\")  # 128,000\nprint(f\"Max completion: {limits['max_completion']:,}\")  # 16,384\n</code></pre> <p>Available Limits:</p> Model Context Window Max Completion gpt-4o-mini 128,000 16,384 gpt-4o 128,000 16,384 claude-3-5-sonnet 200,000 8,192 gemini-1.5-pro 2,000,000 8,192 <p>For unknown models, defaults to 8,000 / 2,000.</p>"},{"location":"en/guides/context-compression/#best-practices","title":"Best Practices","text":""},{"location":"en/guides/context-compression/#1-monitor-usage-regularly","title":"1. Monitor Usage Regularly","text":"<pre><code># Check usage after each turn\nusage = monitor.check_usage(messages)\n\nif usage.usage_ratio &gt; 0.7:\n    print(f\"\u26a0\ufe0f Warning: {usage.usage_ratio:.0%} full\")\n\nif usage.should_compress:\n    print(\"\ud83d\udea8 Compression recommended\")\n    # In Phase 2+: await compress(messages)\n</code></pre>"},{"location":"en/guides/context-compression/#2-reserve-space-for-completion","title":"2. Reserve Space for Completion","text":"<p>When creating a monitor, ensure you reserve enough tokens for model responses:</p> <pre><code># Good: Auto-detect reserves 4000 tokens\nmonitor = ContextMonitor(counter, max_tokens=None)\n\n# Custom: Reserve explicit amount\nmodel_limit = 128_000\nreserved_for_completion = 8_000\nmonitor = ContextMonitor(counter, max_tokens=model_limit - reserved_for_completion)\n</code></pre>"},{"location":"en/guides/context-compression/#3-choose-appropriate-model","title":"3. Choose Appropriate Model","text":"<p>For long conversations, prefer models with larger context windows:</p> <pre><code># Small context (16k) - frequent compression needed\ncounter_small = TokenCounter(model=\"gpt-3.5-turbo\")\n\n# Large context (128k) - less compression needed\ncounter_large = TokenCounter(model=\"gpt-4o-mini\")\n\n# Huge context (2M) - minimal compression needed\ncounter_huge = TokenCounter(model=\"gemini-1.5-pro\")\n</code></pre>"},{"location":"en/guides/context-compression/#examples","title":"Examples","text":""},{"location":"en/guides/context-compression/#example-1-track-conversation-growth","title":"Example 1: Track Conversation Growth","text":"<pre><code>from kagura.core.compression import TokenCounter, ContextMonitor\n\ncounter = TokenCounter(model=\"gpt-4o-mini\")\nmonitor = ContextMonitor(counter, max_tokens=50000)\n\nmessages = [{\"role\": \"system\", \"content\": \"You are helpful.\"}]\n\nfor turn in range(100):\n    # Add user message\n    messages.append({\"role\": \"user\", \"content\": f\"Question {turn}\"})\n\n    # Check usage before responding\n    usage = monitor.check_usage(messages)\n    print(f\"Turn {turn}: {usage.usage_ratio:.1%} full\")\n\n    if usage.should_compress:\n        print(f\"\u26a0\ufe0f Compression needed at turn {turn}\")\n        break\n\n    # Add assistant response\n    messages.append({\"role\": \"assistant\", \"content\": f\"Answer {turn}\"})\n</code></pre>"},{"location":"en/guides/context-compression/#example-2-multi-model-comparison","title":"Example 2: Multi-Model Comparison","text":"<pre><code>models = [\"gpt-4o-mini\", \"claude-3-5-sonnet\", \"gemini-1.5-pro\"]\n\ntext = \"The quick brown fox jumps over the lazy dog.\"\n\nfor model in models:\n    counter = TokenCounter(model=model)\n    tokens = counter.count_tokens(text)\n    limits = counter.get_model_limits(model)\n\n    print(f\"{model}:\")\n    print(f\"  Tokens: {tokens}\")\n    print(f\"  Context window: {limits['context_window']:,}\")\n</code></pre> <p>Output: <pre><code>gpt-4o-mini:\n  Tokens: 10\n  Context window: 128,000\n\nclaude-3-5-sonnet:\n  Tokens: 10\n  Context window: 200,000\n\ngemini-1.5-pro:\n  Tokens: 10\n  Context window: 2,000,000\n</code></pre></p>"},{"location":"en/guides/context-compression/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/context-compression/#q-token-count-seems-inaccurate","title":"Q: Token count seems inaccurate","text":"<p>A: Different models use different tokenizers. TokenCounter uses <code>tiktoken</code> which is optimized for OpenAI models. For Claude and Gemini, it uses <code>cl100k_base</code> as an approximation (\u00b110% accuracy).</p>"},{"location":"en/guides/context-compression/#q-what-if-i-exceed-context-window","title":"Q: What if I exceed context window?","text":"<p>A: Phase 1 only monitors usage. Phases 2-4 will provide automatic compression: - Phase 2: Message trimming - Phase 3: LLM-based summarization - Phase 4: Automatic compression</p>"},{"location":"en/guides/context-compression/#q-how-accurate-is-token-counting","title":"Q: How accurate is token counting?","text":"<p>A: Very accurate for OpenAI models (\u00b11%). For other models: \u00b15-10%.</p>"},{"location":"en/guides/context-compression/#q-can-i-use-this-with-streaming","title":"Q: Can I use this with streaming?","text":"<p>A: Yes! Count tokens before and after streaming to track usage.</p>"},{"location":"en/guides/context-compression/#next-steps","title":"Next Steps","text":"<p>Phase 1 (current) provides monitoring only.</p> <p>Coming soon: - Phase 2 (Week 2): Message trimming with 4 strategies - Phase 3 (Week 3-4): Context summarization - Phase 4 (Week 5): Automatic compression integrated with <code>@agent</code> decorator</p> <p>Stay tuned for updates!</p>"},{"location":"en/guides/context-compression/#see-also","title":"See Also","text":"<ul> <li>Compression API Reference - Detailed API documentation</li> <li>RFC-024 - Full specification</li> <li>Memory Management - Memory system (integrates in Phase 4)</li> </ul> <p>Phase 1 implementation provides the foundation for efficient long-form conversations!</p>"},{"location":"en/guides/full-featured-mode/","title":"Full-Featured Mode Guide","text":"<p>This guide explains how to use Kagura AI's full-featured mode, which combines multimodal RAG (local file indexing) with web search capabilities for maximum power.</p>"},{"location":"en/guides/full-featured-mode/#overview","title":"Overview","text":"<p>Full-featured mode provides: - Local Knowledge: Search through your project files (code, docs, images, PDFs) - Web Search: Access current information from the internet - Unified Chat: Single interface for both local and web data - Intelligent Routing: AI decides when to use local files vs web search</p>"},{"location":"en/guides/full-featured-mode/#quick-start","title":"Quick Start","text":""},{"location":"en/guides/full-featured-mode/#one-command-setup","title":"One Command Setup","text":"<p>Start full-featured mode with a single command:</p> <pre><code>kagura chat --full --dir ./my-project\n</code></pre> <p>This is equivalent to:</p> <pre><code>kagura chat --enable-multimodal --enable-web --dir ./my-project\n</code></pre>"},{"location":"en/guides/full-featured-mode/#example-session","title":"Example Session","text":"<pre><code>$ kagura chat --full --dir ./my-app\n\nInitializing multimodal RAG for: ./my-app\n\u2713 Indexed 127 files from ./my-app\n\n\ud83d\ude80 Full-Featured Mode\n\u26a1 Multimodal RAG\n   Indexed: ./my-app\n\ud83c\udf10 Web Search\n\nType your message to chat with AI, or use commands:\n  /help      - Show help\n  /exit      - Exit chat\n\n[You] &gt; How does our authentication system work?\n\nSearching indexed files...\nFound 3 relevant documents\n\ud83d\udcac Generating response...\n\n[AI]\nBased on your codebase (auth.py and auth-diagram.png), your authentication\nsystem uses:\n\n1. **JWT Tokens**:\n   - Generated after successful login (auth.py:42)\n   - 24-hour expiry configured in config.py\n   - RSA-256 signature\n\n2. **Password Hashing**:\n   - bcrypt with cost factor 12\n   - Implemented in auth.py:authenticate()\n\n3. **Token Validation**:\n   - Middleware checks Authorization header\n   - Validates signature and expiry\n   - Loads user from database\n\nThe architecture diagram shows the complete flow from login to protected\nresource access.\n\n[You] &gt; What are the current best practices for JWT in 2025?\n\n\ud83c\udf10 Searching the web for: JWT security best practices 2025\n\u2713 Web search completed\n\ud83d\udcac Generating response...\n\n[AI]\nCurrent best practices for JWT in 2025:\n\n1. **Short Expiry Times**:\n   - Access tokens: 15 minutes (recommended)\n   - Your current 24 hours is too long\n   - Use refresh tokens for long sessions\n\n2. **Algorithm Security**:\n   - \u2705 You're using RS256 (good!)\n   - Avoid HS256 for production\n\n3. **Token Storage**:\n   - Never store in localStorage (XSS vulnerable)\n   - Use httpOnly cookies\n   - Consider SameSite=Strict\n\n4. **Token Rotation**:\n   - Implement refresh token rotation\n   - Invalidate old tokens on rotation\n\n5. **Content Minimization**:\n   - Only store essential claims\n   - Avoid PII in tokens\n\n[Sources: OWASP JWT Cheat Sheet 2025, Auth0 Security Blog]\n\n[You] &gt; Can you update our auth.py to follow these best practices?\n\nSearching indexed files...\n\ud83d\udcac Generating response...\n\n[AI]\nI'll suggest updates to auth.py based on 2025 best practices:\n\n\\`\\`\\`python\n# auth.py - Updated with 2025 best practices\n\nfrom datetime import timedelta\n\n# NEW: Shorter token expiry\nACCESS_TOKEN_EXPIRY = timedelta(minutes=15)  # Was: 24 hours\nREFRESH_TOKEN_EXPIRY = timedelta(days=7)\n\n# NEW: Add refresh token support\ndef create_tokens(user_id: str) -&gt; dict:\n    \"\"\"Create access and refresh tokens.\"\"\"\n    access_token = create_jwt(\n        payload={\"sub\": user_id, \"type\": \"access\"},\n        expires_delta=ACCESS_TOKEN_EXPIRY\n    )\n    refresh_token = create_jwt(\n        payload={\"sub\": user_id, \"type\": \"refresh\"},\n        expires_delta=REFRESH_TOKEN_EXPIRY\n    )\n    return {\n        \"access_token\": access_token,\n        \"refresh_token\": refresh_token\n    }\n\n# NEW: Token refresh endpoint\n@app.post(\"/auth/refresh\")\nasync def refresh_access_token(refresh_token: str):\n    \"\"\"Refresh access token using refresh token.\"\"\"\n    payload = verify_jwt(refresh_token)\n    if payload.get(\"type\") != \"refresh\":\n        raise HTTPException(401, \"Invalid token type\")\n\n    new_access_token = create_jwt(\n        payload={\"sub\": payload[\"sub\"], \"type\": \"access\"},\n        expires_delta=ACCESS_TOKEN_EXPIRY\n    )\n    return {\"access_token\": new_access_token}\n\\`\\`\\`\n\nKey changes:\n1. Reduced access token to 15 minutes\n2. Added refresh token with 7-day expiry\n3. New /auth/refresh endpoint for token rotation\n4. Type field to distinguish token types\n\nWould you like me to also update the frontend to handle token refresh?\n</code></pre>"},{"location":"en/guides/full-featured-mode/#prerequisites","title":"Prerequisites","text":""},{"location":"en/guides/full-featured-mode/#installation","title":"Installation","text":"<p>Install both multimodal and web dependencies:</p> <pre><code>pip install kagura-ai[web]\n</code></pre> <p>Or install all extras at once:</p> <pre><code>pip install kagura-ai[all]\n</code></pre>"},{"location":"en/guides/full-featured-mode/#api-keys","title":"API Keys","text":"<ol> <li> <p>Gemini API (for multimodal):    <pre><code>export GEMINI_API_KEY=\"your-gemini-key\"\n</code></pre></p> </li> <li> <p>Brave Search (optional, for better web results):    <pre><code>export BRAVE_API_KEY=\"your-brave-key\"\n</code></pre></p> </li> </ol> <p>Without Brave key, Kagura falls back to DuckDuckGo (no API key required).</p>"},{"location":"en/guides/full-featured-mode/#use-cases","title":"Use Cases","text":""},{"location":"en/guides/full-featured-mode/#1-code-analysis-web-research","title":"1. Code Analysis + Web Research","text":"<p>Analyze your code with context from latest best practices:</p> <pre><code>[You] &gt; Review our database connection pool code and compare with current best practices\n\n# AI will:\n# 1. Read your db.py and related files\n# 2. Search web for \"database connection pool best practices 2025\"\n# 3. Compare your code with current recommendations\n# 4. Suggest improvements\n</code></pre>"},{"location":"en/guides/full-featured-mode/#2-documentation-api-lookup","title":"2. Documentation + API Lookup","text":"<p>Work with your docs and external API documentation:</p> <pre><code>[You] &gt; How do I integrate Stripe payments in our checkout flow?\n\n# AI will:\n# 1. Find your checkout code\n# 2. Search Stripe's latest API docs\n# 3. Provide implementation guide\n# 4. Reference your existing payment structure\n</code></pre>"},{"location":"en/guides/full-featured-mode/#3-debugging-error-research","title":"3. Debugging + Error Research","text":"<p>Debug with your code context and web solutions:</p> <pre><code>[You] &gt; Why am I getting \"Connection refused\" in docker-compose?\n\n# AI will:\n# 1. Read your docker-compose.yml\n# 2. Check your Dockerfile\n# 3. Search web for common docker connection issues\n# 4. Diagnose specific to your setup\n</code></pre>"},{"location":"en/guides/full-featured-mode/#4-project-planning-market-research","title":"4. Project Planning + Market Research","text":"<p>Plan features with local context and market data:</p> <pre><code>[You] &gt; What features should we add to compete with [competitor]?\n\n# AI will:\n# 1. Analyze your current features (from code/docs)\n# 2. Research competitor's features (web search)\n# 3. Find industry trends (web search)\n# 4. Suggest prioritized feature list\n</code></pre>"},{"location":"en/guides/full-featured-mode/#programmatic-usage","title":"Programmatic Usage","text":""},{"location":"en/guides/full-featured-mode/#full-featured-agent","title":"Full-Featured Agent","text":"<p>Create an agent with both capabilities:</p> <pre><code>from kagura import agent\nfrom kagura.core.memory import MultimodalRAG\nfrom kagura.web import web_search\nfrom pathlib import Path\n\nasync def search_tool(query: str) -&gt; str:\n    \"\"\"Search the web for information.\"\"\"\n    return await web_search(query)\n\n@agent(\n    model=\"gemini/gemini-1.5-flash\",\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./project\"),\n    tools=[search_tool]\n)\nasync def full_featured_assistant(question: str, rag: MultimodalRAG) -&gt; str:\n    \"\"\"Answer questions using both local files and web search.\n\n    Question: {{ question }}\n\n    Use rag.query() to search local files.\n    Use search_tool() to search the web.\n    \"\"\"\n    pass\n\n# Usage\nanswer = await full_featured_assistant(\n    \"Compare our API design with REST best practices 2025\"\n)\n</code></pre>"},{"location":"en/guides/full-featured-mode/#manual-control","title":"Manual Control","text":"<p>Control when to use each source:</p> <pre><code>from kagura.core.memory import MultimodalRAG\nfrom kagura.web import web_search\nfrom pathlib import Path\n\n# Initialize RAG\nrag = MultimodalRAG(directory=Path(\"./project\"))\nawait rag.build_index()\n\nasync def hybrid_search(query: str) -&gt; dict:\n    \"\"\"Search both local and web.\"\"\"\n\n    # Search local files\n    local_results = rag.query(query, n_results=3)\n\n    # Search web\n    web_results = await web_search(query)\n\n    return {\n        \"local\": local_results,\n        \"web\": web_results\n    }\n\n# Usage\nresults = await hybrid_search(\"authentication implementation\")\n</code></pre>"},{"location":"en/guides/full-featured-mode/#configuration","title":"Configuration","text":""},{"location":"en/guides/full-featured-mode/#command-line-options","title":"Command-Line Options","text":"<pre><code># Full mode (recommended)\nkagura chat --full --dir ./project\n\n# Equivalent long form\nkagura chat --enable-multimodal --enable-web --dir ./project\n\n# With model selection\nkagura chat --full --dir ./project --model gpt-4o\n\n# With custom session directory\nkagura chat --full --dir ./project --session-dir ./my-sessions\n</code></pre>"},{"location":"en/guides/full-featured-mode/#programmatic-configuration","title":"Programmatic Configuration","text":"<pre><code>from kagura.chat import ChatSession\nfrom pathlib import Path\n\nsession = ChatSession(\n    model=\"gemini/gemini-1.5-flash\",\n    enable_multimodal=True,\n    rag_directory=Path(\"./project\"),\n    enable_web=True,\n    session_dir=Path(\"./.kagura/sessions\")\n)\n\nawait session.run()\n</code></pre>"},{"location":"en/guides/full-featured-mode/#how-it-works","title":"How It Works","text":""},{"location":"en/guides/full-featured-mode/#intelligent-routing","title":"Intelligent Routing","text":"<p>The AI decides when to use each source:</p> <pre><code>Question: \"How does our auth work?\"\n\u2192 Uses: Local RAG (reads your code)\n\nQuestion: \"What are JWT best practices?\"\n\u2192 Uses: Web search (gets current info)\n\nQuestion: \"Update our auth to follow best practices\"\n\u2192 Uses: Both (reads code + researches practices)\n</code></pre>"},{"location":"en/guides/full-featured-mode/#data-flow","title":"Data Flow","text":"<pre><code>User Query\n    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Chat Session    \u2502\n\u2502   (Memory)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2193           \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   RAG   \u2502  \u2502   Web   \u2502\n\u2502 Search  \u2502  \u2502 Search  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2193           \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Context         \u2502\n\u2502   Aggregation     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   LLM             \u2502\n\u2502   (Gemini/GPT)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2193\n  Response\n</code></pre>"},{"location":"en/guides/full-featured-mode/#best-practices","title":"Best Practices","text":""},{"location":"en/guides/full-featured-mode/#1-organize-your-project","title":"1. Organize Your Project","text":"<p>Structure for better RAG results:</p> <pre><code>project/\n\u251c\u2500\u2500 src/              # Source code\n\u251c\u2500\u2500 docs/             # Documentation\n\u251c\u2500\u2500 diagrams/         # Architecture diagrams\n\u251c\u2500\u2500 specs/            # Requirements, RFCs\n\u2514\u2500\u2500 .kaguraignore     # Exclude build artifacts\n</code></pre>"},{"location":"en/guides/full-featured-mode/#2-use-descriptive-queries","title":"2. Use Descriptive Queries","text":"<p>Good queries get better results:</p> <pre><code>\u2705 \"How does our rate limiting implementation compare to industry standards?\"\n\u2705 \"What security vulnerabilities exist in our authentication code?\"\n\u2705 \"Refactor our database layer using 2025 best practices\"\n\n\u274c \"Check this\"\n\u274c \"Is this good?\"\n\u274c \"Help\"\n</code></pre>"},{"location":"en/guides/full-featured-mode/#3-iterative-refinement","title":"3. Iterative Refinement","text":"<p>Build on previous context:</p> <pre><code>[You] &gt; What payment methods do we support?\n[AI] &gt; You support: Credit cards (Stripe), PayPal...\n\n[You] &gt; What other payment methods are popular now?\n[AI] &gt; [Searches web for current trends]\n\n[You] &gt; Add Apple Pay to our payment flow\n[AI] &gt; [References your code + Apple Pay docs]\n</code></pre>"},{"location":"en/guides/full-featured-mode/#4-monitor-costs","title":"4. Monitor Costs","text":"<p>Full-featured mode uses APIs for both RAG and web:</p> <pre><code># Track API usage\nstats = await rag.build_index()\nprint(f\"Files processed with Gemini: {stats['multimodal_files']}\")\n\n# Use caching to reduce costs\nrag = MultimodalRAG(\n    directory=Path(\"./project\"),\n    enable_cache=True,\n    cache_size_mb=500\n)\n</code></pre>"},{"location":"en/guides/full-featured-mode/#5-incremental-updates","title":"5. Incremental Updates","text":"<p>Keep RAG index fresh:</p> <pre><code># Initial build (run once)\nawait rag.build_index()\n\n# Incremental updates (run periodically)\nawait rag.incremental_update()  # Only new/modified files\n</code></pre>"},{"location":"en/guides/full-featured-mode/#performance-optimization","title":"Performance Optimization","text":""},{"location":"en/guides/full-featured-mode/#1-choose-the-right-model","title":"1. Choose the Right Model","text":"<p>Different models for different needs:</p> <pre><code># Fast and cheap (recommended)\nkagura chat --full --dir . --model gemini/gemini-1.5-flash\n\n# More accurate\nkagura chat --full --dir . --model gemini/gemini-1.5-pro\n\n# Code-focused\nkagura chat --full --dir . --model gpt-4o\n</code></pre>"},{"location":"en/guides/full-featured-mode/#2-enable-caching","title":"2. Enable Caching","text":"<p>Cache both RAG and web results:</p> <pre><code>from kagura.core.memory import MultimodalRAG\nfrom kagura.web.scraper import WebScraper\n\n# RAG caching\nrag = MultimodalRAG(\n    directory=Path(\"./project\"),\n    enable_cache=True,\n    cache_size_mb=500\n)\n\n# Web scraping with rate limiting\nscraper = WebScraper(rate_limit_delay=1.0)\n</code></pre>"},{"location":"en/guides/full-featured-mode/#3-parallel-processing","title":"3. Parallel Processing","text":"<p>Process files in parallel:</p> <pre><code>await rag.build_index(max_concurrent=5)  # Default: 3\n</code></pre>"},{"location":"en/guides/full-featured-mode/#4-selective-indexing","title":"4. Selective Indexing","text":"<p>Use <code>.kaguraignore</code> to exclude unnecessary files:</p> <pre><code># .kaguraignore\nnode_modules/\n.venv/\n*.log\n*.tmp\nbuild/\ndist/\n__pycache__/\n.git/\n</code></pre>"},{"location":"en/guides/full-featured-mode/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/full-featured-mode/#no-local-results-found","title":"\"No local results found\"","text":"<p>Check if files are indexed:</p> <pre><code>indexed_files = rag.get_indexed_files()\nprint(f\"Indexed: {len(indexed_files)} files\")\n\n# Rebuild if needed\nawait rag.build_index(force_rebuild=True)\n</code></pre>"},{"location":"en/guides/full-featured-mode/#web-search-failed","title":"\"Web search failed\"","text":"<p>Check API keys:</p> <pre><code>echo $BRAVE_API_KEY\necho $GEMINI_API_KEY\n</code></pre> <p>Fallback is automatic (Brave \u2192 DuckDuckGo).</p>"},{"location":"en/guides/full-featured-mode/#out-of-memory","title":"\"Out of memory\"","text":"<p>Reduce cache size or concurrent processing:</p> <pre><code>rag = MultimodalRAG(\n    directory=Path(\"./project\"),\n    cache_size_mb=100  # Reduce from 500\n)\n\nawait rag.build_index(max_concurrent=1)  # Process one at a time\n</code></pre>"},{"location":"en/guides/full-featured-mode/#api-rate-limit-exceeded","title":"\"API rate limit exceeded\"","text":"<p>For Gemini:</p> <pre><code>await rag.build_index(max_concurrent=1)  # Slower but within limits\n</code></pre> <p>For Brave/web:</p> <pre><code>scraper = WebScraper(rate_limit_delay=2.0)  # Increase delay\n</code></pre>"},{"location":"en/guides/full-featured-mode/#examples","title":"Examples","text":""},{"location":"en/guides/full-featured-mode/#example-1-full-stack-development-assistant","title":"Example 1: Full Stack Development Assistant","text":"<pre><code>from kagura import agent\nfrom kagura.core.memory import MultimodalRAG\nfrom kagura.web import web_search\nfrom pathlib import Path\n\nasync def web_tool(query: str) -&gt; str:\n    return await web_search(query)\n\n@agent(\n    model=\"gemini/gemini-1.5-flash\",\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./fullstack-app\"),\n    tools=[web_tool]\n)\nasync def dev_assistant(task: str, rag: MultimodalRAG) -&gt; str:\n    \"\"\"Help with full-stack development tasks.\n\n    Task: {{ task }}\n\n    You have access to:\n    - Local codebase (frontend + backend)\n    - Architecture diagrams\n    - Web search for current best practices\n    \"\"\"\n    pass\n\n# Usage\nresponse = await dev_assistant(\n    \"Add real-time notifications using WebSockets\"\n)\n</code></pre>"},{"location":"en/guides/full-featured-mode/#example-2-security-audit","title":"Example 2: Security Audit","text":"<pre><code>@agent(\n    model=\"gpt-4o\",\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./app\"),\n    tools=[web_tool]\n)\nasync def security_auditor(component: str, rag: MultimodalRAG) -&gt; str:\n    \"\"\"Audit {{ component }} for security vulnerabilities.\n\n    1. Analyze the code\n    2. Research current CVEs and vulnerabilities\n    3. Check against OWASP Top 10\n    4. Provide actionable recommendations\n    \"\"\"\n    pass\n\n# Usage\nreport = await security_auditor(\"authentication module\")\n</code></pre>"},{"location":"en/guides/full-featured-mode/#example-3-documentation-writer","title":"Example 3: Documentation Writer","text":"<pre><code>@agent(\n    model=\"gemini/gemini-1.5-flash\",\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./project\"),\n    tools=[web_tool]\n)\nasync def doc_writer(topic: str, rag: MultimodalRAG) -&gt; str:\n    \"\"\"Write documentation for {{ topic }}.\n\n    1. Read the implementation code\n    2. Research documentation best practices\n    3. Generate comprehensive docs with examples\n    \"\"\"\n    pass\n\n# Usage\ndocs = await doc_writer(\"API authentication endpoints\")\n</code></pre>"},{"location":"en/guides/full-featured-mode/#cost-estimation","title":"Cost Estimation","text":"<p>Approximate costs for full-featured mode:</p>"},{"location":"en/guides/full-featured-mode/#gemini-api-multimodal-rag","title":"Gemini API (Multimodal RAG)","text":"<ul> <li>Flash (1.5): $0.25 per 1M input tokens</li> <li>Pro (1.5): $1.25 per 1M input tokens</li> </ul> <p>Example: Indexing 1000 files (~50MB text) \u2248 $0.10-0.50</p>"},{"location":"en/guides/full-featured-mode/#brave-search-api","title":"Brave Search API","text":"<ul> <li>Free tier: 2000 queries/month</li> <li>Paid: $5/month for 20,000 queries</li> </ul>"},{"location":"en/guides/full-featured-mode/#typical-monthly-cost","title":"Typical Monthly Cost","text":"<ul> <li>Small project (&lt; 5000 files): &lt; $10/month</li> <li>Medium project (5000-20000 files): $10-50/month</li> <li>Large project (&gt; 20000 files): $50-200/month</li> </ul> <p>Optimization tips: - Enable caching (reduce repeat processing) - Use incremental updates (process only changed files) - Use Flash model (3x cheaper than Pro) - Cache web search results</p>"},{"location":"en/guides/full-featured-mode/#next-steps","title":"Next Steps","text":"<ul> <li>Multimodal RAG Guide - Deep dive into local indexing</li> <li>Web Integration Guide - Advanced web search techniques</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"en/guides/full-featured-mode/#resources","title":"Resources","text":"<ul> <li>Gemini API Pricing</li> <li>Brave Search API</li> <li>ChromaDB Documentation</li> <li>Kagura AI Examples</li> </ul>"},{"location":"en/guides/hooks-guide/","title":"Hooks Guide","text":"<p>Learn how to use hooks to intercept and control command execution.</p>"},{"location":"en/guides/hooks-guide/#what-are-hooks","title":"What are Hooks?","text":"<p>Hooks allow you to:</p> <ul> <li>\ud83d\udee1\ufe0f Block dangerous commands</li> <li>\u270f\ufe0f Modify inputs before execution</li> <li>\ud83d\udcca Log and monitor tool usage</li> <li>\u2705 Validate parameters</li> <li>\ud83d\udca1 Suggest better alternatives</li> </ul>"},{"location":"en/guides/hooks-guide/#hook-types","title":"Hook Types","text":""},{"location":"en/guides/hooks-guide/#1-pretooluse-hooks","title":"1. PreToolUse Hooks","text":"<p>Execute before a tool is invoked.</p> <p>Use cases: - Security validation - Input modification - Command blocking</p> <p>Example:</p> <pre><code>from kagura.commands import hook, HookResult\n\n@hook.pre_tool_use(\"bash\")\ndef block_dangerous(tool_input):\n    cmd = tool_input.get(\"command\", \"\")\n    if \"rm -rf /\" in cmd:\n        return HookResult.block(\"Dangerous command blocked!\")\n    return HookResult.ok()\n</code></pre>"},{"location":"en/guides/hooks-guide/#2-posttooluse-hooks","title":"2. PostToolUse Hooks","text":"<p>Execute after a tool completes.</p> <p>Use cases: - Logging - Metrics collection - Output processing</p> <p>Example:</p> <pre><code>@hook.post_tool_use(\"git\")\ndef log_git(tool_input):\n    cmd = tool_input[\"command\"]\n    output = tool_input[\"output\"]\n    print(f\"Git: {cmd} -&gt; {output}\")\n    return HookResult.ok()\n</code></pre>"},{"location":"en/guides/hooks-guide/#3-validation-hooks","title":"3. Validation Hooks","text":"<p>Execute before parameter validation.</p> <p>Use cases: - Custom validation rules - Parameter transformation - Environment checks</p> <p>Example:</p> <pre><code>@hook.validation(\"deploy\")\ndef require_environment(tool_input):\n    params = tool_input.get(\"parameters\", {})\n    if \"environment\" not in params:\n        return HookResult.block(\"Missing 'environment' parameter\")\n    return HookResult.ok()\n</code></pre>"},{"location":"en/guides/hooks-guide/#quick-start","title":"Quick Start","text":""},{"location":"en/guides/hooks-guide/#step-1-define-a-hook","title":"Step 1: Define a Hook","text":"<pre><code>from kagura.commands import hook, HookResult\n\n@hook.pre_tool_use(\"bash\")\ndef safety_check(tool_input):\n    \"\"\"Block dangerous bash commands.\"\"\"\n    cmd = tool_input.get(\"command\", \"\")\n\n    # Block dangerous commands\n    if any(pattern in cmd for pattern in [\"rm -rf /\", \"dd if=\"]):\n        return HookResult.block(\"Dangerous command blocked!\")\n\n    return HookResult.ok()\n</code></pre>"},{"location":"en/guides/hooks-guide/#step-2-use-commands","title":"Step 2: Use Commands","text":"<p>Hooks are automatically applied when executing commands:</p> <pre><code>from kagura.commands import Command, CommandExecutor\n\ncommand = Command(\n    name=\"check-files\",\n    description=\"Check files\",\n    template=\"Files: !`ls`\"\n)\n\nexecutor = CommandExecutor()\nresult = executor.render(command)  # Hook automatically applied\nprint(result)\n</code></pre>"},{"location":"en/guides/hooks-guide/#step-3-blocked-execution","title":"Step 3: Blocked Execution","text":"<p>If a hook blocks execution:</p> <pre><code>Files: [Blocked: Dangerous command blocked!]\n</code></pre>"},{"location":"en/guides/hooks-guide/#common-use-cases","title":"Common Use Cases","text":""},{"location":"en/guides/hooks-guide/#security-block-dangerous-commands","title":"Security: Block Dangerous Commands","text":"<pre><code>from kagura.commands import hook, HookResult\n\n# Block specific commands\n@hook.pre_tool_use(\"bash\")\ndef block_dangerous(tool_input):\n    cmd = tool_input.get(\"command\", \"\")\n\n    dangerous = [\n        \"rm -rf /\",\n        \":(){ :|:&amp; };:\",  # Fork bomb\n        \"mkfs.\",  # Format filesystem\n        \"&gt; /dev/sda\",  # Overwrite disk\n    ]\n\n    for pattern in dangerous:\n        if pattern in cmd:\n            return HookResult.block(f\"Blocked: {pattern}\")\n\n    return HookResult.ok()\n</code></pre>"},{"location":"en/guides/hooks-guide/#safety-add-interactive-flags","title":"Safety: Add Interactive Flags","text":"<pre><code>@hook.pre_tool_use(\"bash\")\ndef add_interactive(tool_input):\n    \"\"\"Add --interactive flag to rm commands.\"\"\"\n    cmd = tool_input.get(\"command\", \"\")\n\n    if cmd.startswith(\"rm \") and \"--interactive\" not in cmd:\n        # Modify command\n        modified = {\"command\": f\"{cmd} --interactive\"}\n        return HookResult.modify(modified, \"Added --interactive\")\n\n    return HookResult.ok()\n</code></pre>"},{"location":"en/guides/hooks-guide/#logging-track-tool-usage","title":"Logging: Track Tool Usage","text":"<pre><code>import logging\n\n@hook.post_tool_use(\"*\")  # All tools\ndef log_execution(tool_input):\n    \"\"\"Log all tool executions.\"\"\"\n    tool = tool_input.get(\"tool\", \"unknown\")\n    cmd = tool_input.get(\"command\", \"\")\n    returncode = tool_input.get(\"returncode\", 0)\n\n    if returncode == 0:\n        logging.info(f\"{tool}: {cmd} - SUCCESS\")\n    else:\n        logging.error(f\"{tool}: {cmd} - FAILED ({returncode})\")\n\n    return HookResult.ok()\n</code></pre>"},{"location":"en/guides/hooks-guide/#suggestions-recommend-better-tools","title":"Suggestions: Recommend Better Tools","text":"<pre><code>@hook.pre_tool_use(\"bash\")\ndef suggest_modern_tools(tool_input):\n    \"\"\"Suggest modern alternatives.\"\"\"\n    cmd = tool_input.get(\"command\", \"\")\n\n    suggestions = {\n        \"grep\": \"rg (ripgrep)\",\n        \"find\": \"fd\",\n        \"cat\": \"bat\",\n        \"ls\": \"exa\",\n    }\n\n    for old_tool, new_tool in suggestions.items():\n        if cmd.startswith(old_tool):\n            return HookResult.suggest(f\"Consider using '{new_tool}'\")\n\n    return HookResult.ok()\n</code></pre>"},{"location":"en/guides/hooks-guide/#validation-enforce-rules","title":"Validation: Enforce Rules","text":"<pre><code>@hook.validation(\"deploy\")\ndef validate_deploy(tool_input):\n    \"\"\"Validate deployment parameters.\"\"\"\n    params = tool_input.get(\"parameters\", {})\n    env = params.get(\"environment\")\n\n    # Require environment\n    if not env:\n        return HookResult.block(\"Missing 'environment' parameter\")\n\n    # Only allow specific environments\n    allowed = [\"development\", \"staging\", \"production\"]\n    if env not in allowed:\n        return HookResult.block(\n            f\"Invalid environment '{env}'. Allowed: {allowed}\"\n        )\n\n    # Production requires confirmation\n    if env == \"production\" and not params.get(\"confirmed\"):\n        return HookResult.block(\n            \"Production deployment requires 'confirmed=true'\"\n        )\n\n    return HookResult.ok()\n</code></pre>"},{"location":"en/guides/hooks-guide/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"en/guides/hooks-guide/#conditional-modification","title":"Conditional Modification","text":"<pre><code>@hook.pre_tool_use(\"bash\")\ndef add_timeout(tool_input):\n    \"\"\"Add timeout to long-running commands.\"\"\"\n    cmd = tool_input.get(\"command\", \"\")\n\n    # Commands that might hang\n    risky_commands = [\"curl\", \"wget\", \"ssh\"]\n\n    for risky in risky_commands:\n        if cmd.startswith(risky) and \"timeout\" not in cmd:\n            modified = {\"command\": f\"timeout 30 {cmd}\"}\n            return HookResult.modify(modified, \"Added 30s timeout\")\n\n    return HookResult.ok()\n</code></pre>"},{"location":"en/guides/hooks-guide/#environment-specific-hooks","title":"Environment-Specific Hooks","text":"<pre><code>import os\n\n@hook.pre_tool_use(\"*\")\ndef production_safety(tool_input):\n    \"\"\"Extra safety in production.\"\"\"\n    if os.getenv(\"ENVIRONMENT\") != \"production\":\n        return HookResult.ok()\n\n    # In production, require confirmation for destructive operations\n    cmd = tool_input.get(\"command\", \"\")\n    destructive = [\"rm\", \"drop\", \"delete\", \"truncate\"]\n\n    if any(op in cmd.lower() for op in destructive):\n        return HookResult.block(\n            \"Destructive operations require manual confirmation in production\"\n        )\n\n    return HookResult.ok()\n</code></pre>"},{"location":"en/guides/hooks-guide/#chaining-hooks","title":"Chaining Hooks","text":"<p>Multiple hooks can be registered for the same tool:</p> <pre><code>@hook.pre_tool_use(\"bash\")\ndef security_check(tool_input):\n    \"\"\"First check: security.\"\"\"\n    if \"rm -rf /\" in tool_input.get(\"command\", \"\"):\n        return HookResult.block(\"Security: Blocked\")\n    return HookResult.ok()\n\n@hook.pre_tool_use(\"bash\")\ndef add_safety_flags(tool_input):\n    \"\"\"Second check: add flags.\"\"\"\n    cmd = tool_input.get(\"command\", \"\")\n    if cmd.startswith(\"rm \"):\n        modified = {\"command\": f\"{cmd} --interactive\"}\n        return HookResult.modify(modified)\n    return HookResult.ok()\n\n# Both hooks run in order\n# If first blocks, second never runs\n</code></pre>"},{"location":"en/guides/hooks-guide/#hook-management","title":"Hook Management","text":""},{"location":"en/guides/hooks-guide/#disable-a-hook","title":"Disable a Hook","text":"<pre><code>from kagura.commands import get_registry, HookType\n\nregistry = get_registry()\n\n# Find and disable\nhooks = registry.get_hooks(HookType.PRE_TOOL_USE, \"bash\")\nfor h in hooks:\n    if h.name == \"security_check\":\n        h.enabled = False\n</code></pre>"},{"location":"en/guides/hooks-guide/#remove-a-hook","title":"Remove a Hook","text":"<pre><code>from kagura.commands import get_registry\n\nregistry = get_registry()\nregistry.unregister(\"security_check\")\n</code></pre>"},{"location":"en/guides/hooks-guide/#clear-all-hooks","title":"Clear All Hooks","text":"<pre><code>from kagura.commands import get_registry, HookType\n\nregistry = get_registry()\n\n# Clear specific type\nregistry.clear(HookType.PRE_TOOL_USE)\n\n# Clear all\nregistry.clear()\n</code></pre>"},{"location":"en/guides/hooks-guide/#count-hooks","title":"Count Hooks","text":"<pre><code>from kagura.commands import get_registry, HookType\n\nregistry = get_registry()\n\nprint(f\"Total hooks: {registry.count()}\")\nprint(f\"Pre-tool-use hooks: {registry.count(HookType.PRE_TOOL_USE)}\")\nprint(f\"Post-tool-use hooks: {registry.count(HookType.POST_TOOL_USE)}\")\nprint(f\"Validation hooks: {registry.count(HookType.VALIDATION)}\")\n</code></pre>"},{"location":"en/guides/hooks-guide/#best-practices","title":"Best Practices","text":""},{"location":"en/guides/hooks-guide/#1-fail-safe","title":"1. Fail Safe","text":"<p>Hooks should not break execution if they fail:</p> <pre><code>@hook.pre_tool_use(\"*\")\ndef safe_hook(tool_input):\n    try:\n        # Your logic here\n        return HookResult.ok()\n    except Exception as e:\n        # Log error but don't block\n        logging.error(f\"Hook failed: {e}\")\n        return HookResult.ok()\n</code></pre>"},{"location":"en/guides/hooks-guide/#2-specific-matchers","title":"2. Specific Matchers","text":"<p>Use specific matchers when possible:</p> <pre><code># \u2705 Good: Specific\n@hook.pre_tool_use(\"bash\")\ndef validate_bash(tool_input):\n    ...\n\n# \u26a0\ufe0f OK but slower: Catch-all\n@hook.pre_tool_use(\"*\")\ndef validate_all(tool_input):\n    ...\n</code></pre>"},{"location":"en/guides/hooks-guide/#3-clear-error-messages","title":"3. Clear Error Messages","text":"<p>Provide helpful error messages when blocking:</p> <pre><code># \u2705 Good: Clear and actionable\nreturn HookResult.block(\n    \"Command 'rm -rf /' is not allowed. Use 'rm -rf ./directory' instead.\"\n)\n\n# \u274c Bad: Vague\nreturn HookResult.block(\"Blocked\")\n</code></pre>"},{"location":"en/guides/hooks-guide/#4-document-hooks","title":"4. Document Hooks","text":"<p>Add docstrings to explain hook purpose:</p> <pre><code>@hook.pre_tool_use(\"bash\")\ndef block_fork_bombs(tool_input):\n    \"\"\"Block fork bomb patterns.\n\n    Prevents execution of commands containing fork bomb syntax:\n    - :(){ :|:&amp; };:\n    - .(){.|.&amp;};.\n\n    These patterns can crash the system by consuming all resources.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"en/guides/hooks-guide/#5-test-hooks","title":"5. Test Hooks","text":"<p>Test your hooks to ensure they work correctly:</p> <pre><code>def test_block_dangerous():\n    \"\"\"Test that dangerous commands are blocked.\"\"\"\n    from kagura.commands import InlineCommandExecutor, HookRegistry\n\n    registry = HookRegistry()\n\n    @hook.pre_tool_use(\"bash\")\n    def block_rm_rf(tool_input):\n        if \"rm -rf /\" in tool_input.get(\"command\", \"\"):\n            return HookResult.block(\"Blocked\")\n        return HookResult.ok()\n\n    executor = InlineCommandExecutor(hook_registry=registry)\n    result = executor.execute(\"!`rm -rf /`\")\n\n    assert \"[Blocked:\" in result\n</code></pre>"},{"location":"en/guides/hooks-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/hooks-guide/#hook-not-firing","title":"Hook Not Firing","text":"<ol> <li>Check matcher: Ensure matcher matches the tool name</li> <li>Check enabled: Verify <code>hook.enabled == True</code></li> <li>Check registry: Use correct registry instance</li> </ol> <pre><code>from kagura.commands import get_registry, HookType\n\nregistry = get_registry()\nhooks = registry.get_hooks(HookType.PRE_TOOL_USE, \"bash\")\n\nfor h in hooks:\n    print(f\"{h.name}: enabled={h.enabled}, matcher={h.matcher}\")\n</code></pre>"},{"location":"en/guides/hooks-guide/#hook-blocks-too-much","title":"Hook Blocks Too Much","text":"<p>Refine your hook logic:</p> <pre><code># \u274c Too broad\n@hook.pre_tool_use(\"bash\")\ndef block_all_rm(tool_input):\n    if \"rm\" in tool_input.get(\"command\", \"\"):\n        return HookResult.block(\"Blocked\")\n    return HookResult.ok()\n\n# \u2705 More specific\n@hook.pre_tool_use(\"bash\")\ndef block_dangerous_rm(tool_input):\n    cmd = tool_input.get(\"command\", \"\")\n    if \"rm -rf /\" in cmd or \"rm -rf ~\" in cmd:\n        return HookResult.block(\"Blocked\")\n    return HookResult.ok()\n</code></pre>"},{"location":"en/guides/hooks-guide/#hook-exceptions","title":"Hook Exceptions","text":"<p>Hooks should handle their own exceptions:</p> <pre><code>@hook.pre_tool_use(\"bash\")\ndef safe_hook(tool_input):\n    try:\n        # Risky operation\n        result = some_operation(tool_input)\n        return HookResult.ok()\n    except Exception as e:\n        # Log and continue\n        logging.error(f\"Hook failed: {e}\")\n        return HookResult.ok()  # Don't block on error\n</code></pre>"},{"location":"en/guides/hooks-guide/#examples","title":"Examples","text":""},{"location":"en/guides/hooks-guide/#complete-security-setup","title":"Complete Security Setup","text":"<pre><code>from kagura.commands import hook, HookResult\nimport logging\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\n\n@hook.pre_tool_use(\"bash\")\ndef security_validator(tool_input):\n    \"\"\"Comprehensive security validation.\"\"\"\n    cmd = tool_input.get(\"command\", \"\")\n\n    # Block list\n    dangerous = [\n        \"rm -rf /\",\n        \"dd if=/dev/zero of=/dev/sda\",\n        \"mkfs\",\n        \":(){ :|:&amp; };:\",\n    ]\n\n    for pattern in dangerous:\n        if pattern in cmd:\n            logging.warning(f\"SECURITY: Blocked '{cmd}'\")\n            return HookResult.block(f\"Security: '{pattern}' not allowed\")\n\n    return HookResult.ok()\n\n@hook.pre_tool_use(\"bash\")\ndef add_safety_nets(tool_input):\n    \"\"\"Add safety flags to destructive commands.\"\"\"\n    cmd = tool_input.get(\"command\", \"\")\n\n    if cmd.startswith(\"rm \") and \"-i\" not in cmd:\n        modified = {\"command\": f\"{cmd} -i\"}\n        return HookResult.modify(modified, \"Added -i flag\")\n\n    return HookResult.ok()\n\n@hook.post_tool_use(\"*\")\ndef audit_log(tool_input):\n    \"\"\"Audit all command executions.\"\"\"\n    tool = tool_input.get(\"tool\", \"unknown\")\n    cmd = tool_input.get(\"command\", \"\")\n    returncode = tool_input.get(\"returncode\", 0)\n\n    logging.info(f\"AUDIT: {tool} | {cmd} | exit={returncode}\")\n    return HookResult.ok()\n</code></pre>"},{"location":"en/guides/hooks-guide/#next-steps","title":"Next Steps","text":"<ul> <li>Read the Hooks API Reference</li> <li>Learn about Custom Commands</li> <li>Explore Advanced Patterns</li> </ul>"},{"location":"en/guides/hooks-guide/#see-also","title":"See Also","text":"<ul> <li>Hooks API - Complete API reference</li> <li>Commands Guide - Custom commands</li> <li>CLI Reference - Command-line interface</li> </ul>"},{"location":"en/guides/meta-agent/","title":"Meta Agent: AI-Powered Agent Code Generator","text":""},{"location":"en/guides/meta-agent/#overview","title":"Overview","text":"<p>The Meta Agent is an AI-powered code generator that creates Kagura agents from natural language descriptions. Simply describe what you want your agent to do, and Meta Agent will generate complete, production-ready Python code.</p>"},{"location":"en/guides/meta-agent/#quick-start","title":"Quick Start","text":""},{"location":"en/guides/meta-agent/#interactive-mode","title":"Interactive Mode","text":"<pre><code>kagura build agent\n</code></pre> <p>You'll be prompted to describe your agent:</p> <pre><code>\ud83e\udd16 Kagura Agent Builder\nDescribe your agent in natural language and I'll generate the code.\n\nWhat should your agent do? Translate English to Japanese\n\n\ud83d\udd0d Parsing agent specification...\n\n\ud83d\udccb Agent Specification\nName: translator\nDescription: Translate English to Japanese\nInput: str\nOutput: str\nTools: None\nMemory: No\n\n\u2699\ufe0f  Generating agent code...\n\ud83d\udd12 Validating code security...\n\u2705 Code validated\n\n\u2705 Agent created: agents/translator.py\n</code></pre>"},{"location":"en/guides/meta-agent/#non-interactive-mode","title":"Non-Interactive Mode","text":"<pre><code>kagura build agent \\\n  --description \"Translate English to Japanese\" \\\n  --output translator.py \\\n  --no-interactive\n</code></pre>"},{"location":"en/guides/meta-agent/#generated-code-example","title":"Generated Code Example","text":"<p>For the description \"Translate English to Japanese\", Meta Agent generates:</p> <pre><code>\"\"\"Translate English to Japanese\n\nAuto-generated by Kagura Meta Agent\nCreated: 2025-10-13 12:00:00\nKagura Version: 2.5.0\n\"\"\"\n\nfrom kagura import agent\n\n\n@agent(\n    model=\"gpt-4o-mini\",\n    temperature=0.7,\n)\nasync def translator(input_data: str) -&gt; str:\n    \"\"\"Translate English to Japanese\n\n    Args:\n        input_data: str - Input data\n\n    Returns:\n        str - Generated result\n    \"\"\"\n    # System prompt for this agent\n    system_prompt = \"\"\"You are a professional translator. Translate text from English to Japanese.\"\"\"\n\n    # Template variable for LLM (will be rendered at runtime)\n    return f\"{system_prompt}\\n\\nInput: {input_data}\"\n</code></pre>"},{"location":"en/guides/meta-agent/#advanced-features","title":"Advanced Features","text":""},{"location":"en/guides/meta-agent/#agent-with-tools","title":"Agent with Tools","text":"<p>If your description mentions code execution, web search, or other tools, Meta Agent will automatically include them:</p> <pre><code>kagura build agent -d \"Execute Python code to solve math problems\" --no-interactive\n</code></pre> <p>Generated code will include:</p> <pre><code>from kagura import agent\nfrom kagura.core.executor import CodeExecutor\n\n@agent(\n    model=\"gpt-4o-mini\",\n    temperature=0.7,\n    tools=[CodeExecutor()],\n)\nasync def math_solver(input_data: str) -&gt; str:\n    \"\"\"Solve math problems using Python\"\"\"\n    # ...\n</code></pre>"},{"location":"en/guides/meta-agent/#agent-with-memory","title":"Agent with Memory","text":"<p>For conversational agents:</p> <pre><code>kagura build agent -d \"Chatbot that remembers conversation history\" --no-interactive\n</code></pre> <p>Generated code will include:</p> <pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n@agent(\n    model=\"gpt-4o-mini\",\n    temperature=0.7,\n    enable_memory=True,\n    max_messages=100,\n)\nasync def chatbot(input_data: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Conversational chatbot with memory\"\"\"\n    memory.add_message(\"user\", str(input_data))\n    # ...\n</code></pre>"},{"location":"en/guides/meta-agent/#cli-options","title":"CLI Options","text":""},{"location":"en/guides/meta-agent/#kagura-build-agent","title":"<code>kagura build agent</code>","text":"<p>Options:</p> <ul> <li><code>-d, --description TEXT</code>: Natural language agent description</li> <li><code>-o, --output PATH</code>: Output file path (default: <code>agents/&lt;name&gt;.py</code>)</li> <li><code>--model TEXT</code>: LLM model for code generation (default: <code>gpt-4o-mini</code>)</li> <li><code>--interactive / --no-interactive</code>: Interactive mode (default: <code>True</code>)</li> <li><code>--no-validate</code>: Skip code validation</li> </ul>"},{"location":"en/guides/meta-agent/#examples","title":"Examples","text":"<pre><code># Interactive mode (default)\nkagura build agent\n\n# Direct generation\nkagura build agent -d \"Summarize text in 3 bullet points\" -o summarizer.py\n\n# Use GPT-4\nkagura build agent -d \"Complex reasoning task\" --model gpt-4o\n\n# Skip validation (not recommended)\nkagura build agent -d \"Test agent\" --no-validate\n</code></pre>"},{"location":"en/guides/meta-agent/#how-it-works","title":"How It Works","text":"<p>Meta Agent uses a multi-stage pipeline:</p> <ol> <li>Natural Language Parsing: Uses LLM to extract structured specification from your description</li> <li>Code Generation: Uses Jinja2 templates to generate clean Python code</li> <li>Security Validation: AST analysis ensures generated code is safe</li> <li>File Creation: Saves the generated agent to a file</li> </ol>"},{"location":"en/guides/meta-agent/#architecture","title":"Architecture","text":"<pre><code>Natural Language \u2192 NLSpecParser \u2192 AgentSpec \u2192 CodeGenerator \u2192 Python Code\n                                                    \u2193\n                                              CodeValidator (Security)\n</code></pre>"},{"location":"en/guides/meta-agent/#security","title":"Security","text":"<p>All generated code is validated for security:</p> <ul> <li>\u2705 Syntax checking</li> <li>\u2705 Forbidden import detection (subprocess, eval, etc.)</li> <li>\u2705 Dangerous function call detection</li> <li>\u2705 Required @agent decorator verification</li> </ul> <p>Dangerous code will be rejected before saving.</p>"},{"location":"en/guides/meta-agent/#best-practices","title":"Best Practices","text":""},{"location":"en/guides/meta-agent/#writing-good-descriptions","title":"Writing Good Descriptions","text":"<p>Good descriptions are specific:</p> <p>\u2705 \"Translate English to Japanese\" \u2705 \"Summarize articles in 3 bullet points\" \u2705 \"Execute Python code to solve math problems\"</p> <p>Avoid vague descriptions:</p> <p>\u274c \"Do something with text\" \u274c \"Help me\" \u274c \"Agent\"</p>"},{"location":"en/guides/meta-agent/#tool-detection","title":"Tool Detection","text":"<p>Meta Agent automatically detects when tools are needed:</p> <ul> <li>Code Execution: \"execute code\", \"run python\", \"calculate\"</li> <li>Web Search: \"search web\", \"google\", \"find online\"</li> <li>Memory: \"remember\", \"conversation history\", \"recall\"</li> <li>File Operations: \"read file\", \"write file\"</li> </ul> <p>Be explicit if you need specific tools.</p>"},{"location":"en/guides/meta-agent/#programmatic-usage","title":"Programmatic Usage","text":"<p>You can also use Meta Agent from Python:</p> <pre><code>from kagura.meta import MetaAgent\n\n# Initialize\nmeta = MetaAgent(model=\"gpt-4o-mini\")\n\n# Generate from description\ncode = await meta.generate(\"Translate English to Japanese\")\nprint(code)\n\n# Generate from spec\nfrom kagura.meta.spec import AgentSpec\n\nspec = AgentSpec(\n    name=\"translator\",\n    description=\"Translate text\",\n    input_type=\"str\",\n    output_type=\"str\",\n    system_prompt=\"You are a professional translator.\"\n)\n\ncode = await meta.generate_from_spec(spec)\n</code></pre>"},{"location":"en/guides/meta-agent/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/meta-agent/#validation-failed-missing-agent-decorator","title":"\"Validation failed: Missing @agent decorator\"","text":"<p>The generated code doesn't include the <code>@agent</code> decorator. This is a bug - please report it.</p>"},{"location":"en/guides/meta-agent/#validation-failed-disallowed-import-subprocess","title":"\"Validation failed: Disallowed import: subprocess\"","text":"<p>The LLM generated code with dangerous imports. Try a more specific description or use <code>--no-validate</code> (not recommended).</p>"},{"location":"en/guides/meta-agent/#generated-code-doesnt-work","title":"Generated code doesn't work","text":"<p>The generated code is a starting point. You may need to:</p> <ol> <li>Adjust the system prompt</li> <li>Add more specific logic</li> <li>Test and iterate</li> </ol>"},{"location":"en/guides/meta-agent/#examples_1","title":"Examples","text":"<p>See <code>examples/meta_agent/</code> for complete examples:</p> <ul> <li><code>translator.py</code>: Simple translation agent</li> <li><code>code_solver.py</code>: Agent with code execution</li> <li><code>chatbot.py</code>: Agent with memory</li> </ul>"},{"location":"en/guides/meta-agent/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Agent Builder for more complex configurations</li> <li>Explore Testing Framework for testing generated agents</li> <li>Read the Meta Agent API Reference</li> </ul>"},{"location":"en/guides/oauth2-authentication/","title":"OAuth2 Authentication Guide","text":"<p>Learn how to use OAuth2 authentication with Kagura AI to access Google models (like Gemini) without managing API keys.</p> <p>\ud83d\udccc Important Note</p> <p>For most users, using API Keys is recommended as it's simpler and faster to set up: - Gemini: Get API key from Google AI Studio \u2192 Set <code>GOOGLE_API_KEY</code> - Claude: Get API key from Anthropic Console \u2192 Set <code>ANTHROPIC_API_KEY</code> - OpenAI: Get API key from OpenAI Platform \u2192 Set <code>OPENAI_API_KEY</code></p> <p>OAuth2 is an advanced feature for specific use cases like: - Multi-user applications where each user authenticates with their own Google account - Production environments requiring strict access controls - Applications that need per-user quota management</p> <p>Currently, only Google/Gemini supports OAuth2. Claude and OpenAI use API keys only.</p>"},{"location":"en/guides/oauth2-authentication/#overview","title":"Overview","text":"<p>Kagura AI supports OAuth2 authentication for Google services only, allowing you to:</p> <ul> <li>No API Key Management: Use Google models without storing API keys</li> <li>Secure Authentication: OAuth2 tokens are encrypted locally (Fernet/AES-128)</li> <li>Automatic Token Refresh: Tokens are automatically refreshed when expired</li> <li>Simple CLI Commands: Easy login/logout/status management</li> </ul>"},{"location":"en/guides/oauth2-authentication/#prerequisites","title":"Prerequisites","text":"<ol> <li>Google Cloud Project with Generative Language API enabled</li> <li>OAuth 2.0 Client ID (Desktop application type)</li> <li>Kagura AI with OAuth support installed:</li> </ol> <pre><code>pip install kagura-ai[auth]\n</code></pre>"},{"location":"en/guides/oauth2-authentication/#setup-guide","title":"Setup Guide","text":""},{"location":"en/guides/oauth2-authentication/#step-1-create-oauth-20-client-id","title":"Step 1: Create OAuth 2.0 Client ID","text":"<ol> <li>Go to Google Cloud Console - Credentials</li> <li>Click \"Create Credentials\" \u2192 \"OAuth client ID\"</li> <li>Select \"Desktop app\" as the application type</li> <li>Name it (e.g., \"Kagura AI Desktop\")</li> <li>Click \"Create\"</li> <li>Download the JSON file</li> </ol>"},{"location":"en/guides/oauth2-authentication/#step-2-save-client-secrets","title":"Step 2: Save Client Secrets","text":"<p>Save the downloaded JSON file as <code>~/.kagura/client_secrets.json</code>:</p> <pre><code>mkdir -p ~/.kagura\nmv ~/Downloads/client_secret_*.json ~/.kagura/client_secrets.json\nchmod 600 ~/.kagura/client_secrets.json\n</code></pre> <p>Important: Keep this file secure! It contains your OAuth client credentials.</p>"},{"location":"en/guides/oauth2-authentication/#step-3-login","title":"Step 3: Login","text":"<p>Run the <code>kagura auth login</code> command:</p> <pre><code>kagura auth login --provider google\n</code></pre> <p>This will: 1. Open your browser for Google OAuth2 authentication 2. Ask you to authorize Kagura AI to access Google Generative Language API 3. Save encrypted credentials to <code>~/.kagura/credentials.json.enc</code></p> <p>Output: <pre><code>\u2713 Authentication successful!\n\u2713 Credentials saved to: /home/user/.kagura/credentials.json.enc\n</code></pre></p>"},{"location":"en/guides/oauth2-authentication/#step-4-verify-authentication","title":"Step 4: Verify Authentication","text":"<p>Check your authentication status:</p> <pre><code>kagura auth status --provider google\n</code></pre> <p>Output: <pre><code>\u2713 Authenticated with google\nToken expires: 2025-10-13 15:30:00 UTC\n</code></pre></p>"},{"location":"en/guides/oauth2-authentication/#using-oauth2-in-your-code","title":"Using OAuth2 in Your Code","text":""},{"location":"en/guides/oauth2-authentication/#basic-usage-with-llmconfig","title":"Basic Usage with LLMConfig","text":"<pre><code>from kagura.core.llm import LLMConfig, call_llm\n\n# Configure OAuth2 authentication\nconfig = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\"\n)\n\n# Call LLM (OAuth2 token retrieved automatically)\nresponse = await call_llm(\"What is the capital of France?\", config)\nprint(response)  # \"The capital of France is Paris.\"\n</code></pre>"},{"location":"en/guides/oauth2-authentication/#using-with-agent-decorator","title":"Using with @agent Decorator","text":"<pre><code>from kagura import agent\nfrom kagura.core.llm import LLMConfig\n\n# Create OAuth2 config\ngemini_config = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\",\n    temperature=0.7\n)\n\n@agent(\n    name=\"translator\",\n    template=\"Translate '{{ text }}' to {{ language }}\",\n    llm_config=gemini_config\n)\ndef translate(text: str, language: str) -&gt; str:\n    pass\n\n# Use the agent\nresult = translate(\"Hello\", \"Japanese\")\nprint(result)  # \"\u3053\u3093\u306b\u3061\u306f\"\n</code></pre>"},{"location":"en/guides/oauth2-authentication/#switching-between-api-key-and-oauth2","title":"Switching Between API Key and OAuth2","text":"<p>You can use both authentication methods in the same project:</p> <pre><code>from kagura.core.llm import LLMConfig\n\n# OpenAI with API key (uses OPENAI_API_KEY env var)\nopenai_config = LLMConfig(\n    model=\"gpt-4o-mini\",\n    auth_type=\"api_key\"  # default\n)\n\n# Gemini with OAuth2\ngemini_config = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\"\n)\n</code></pre>"},{"location":"en/guides/oauth2-authentication/#cli-commands","title":"CLI Commands","text":""},{"location":"en/guides/oauth2-authentication/#login","title":"Login","text":"<p>Authenticate with Google OAuth2:</p> <pre><code>kagura auth login --provider google\n</code></pre> <p>Options: - <code>--provider</code>: OAuth2 provider (default: <code>google</code>)</p>"},{"location":"en/guides/oauth2-authentication/#logout","title":"Logout","text":"<p>Remove stored credentials:</p> <pre><code>kagura auth logout --provider google\n</code></pre> <p>Output: <pre><code>\u2713 Logged out from google\n</code></pre></p>"},{"location":"en/guides/oauth2-authentication/#status","title":"Status","text":"<p>Check authentication status:</p> <pre><code>kagura auth status --provider google\n</code></pre> <p>Possible outputs:</p> <p>Authenticated: <pre><code>\u2713 Authenticated with google\nToken expires: 2025-10-13 15:30:00 UTC\n</code></pre></p> <p>Not Authenticated: <pre><code>\u2717 Not authenticated with google\nRun: kagura auth login --provider google\n</code></pre></p>"},{"location":"en/guides/oauth2-authentication/#security","title":"Security","text":""},{"location":"en/guides/oauth2-authentication/#credential-storage","title":"Credential Storage","text":"<p>OAuth2 credentials are stored securely:</p> <ul> <li>Location: <code>~/.kagura/credentials.json.enc</code></li> <li>Encryption: Fernet (AES-128 in CBC mode)</li> <li>Key Storage: <code>~/.kagura/.key</code> (with 0600 permissions)</li> <li>File Permissions: Both files have 0600 (owner read/write only)</li> </ul>"},{"location":"en/guides/oauth2-authentication/#token-refresh","title":"Token Refresh","text":"<p>Access tokens are automatically refreshed:</p> <ol> <li>Automatic: Tokens are checked before each API call</li> <li>Transparent: Refresh happens automatically when expired</li> <li>Secure: Refresh tokens are encrypted and stored locally</li> </ol>"},{"location":"en/guides/oauth2-authentication/#best-practices","title":"Best Practices","text":"<ol> <li>Never commit <code>~/.kagura/</code> directory to version control</li> <li>Keep <code>client_secrets.json</code> secure - it's like a password</li> <li>Don't share your <code>credentials.json.enc</code> file</li> <li>Logout when you're done on shared machines</li> <li>Regenerate OAuth client ID if credentials are compromised</li> </ol>"},{"location":"en/guides/oauth2-authentication/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/oauth2-authentication/#client-secrets-file-not-found","title":"\"Client secrets file not found\"","text":"<p>Error: <pre><code>FileNotFoundError: Client secrets file not found: /home/user/.kagura/client_secrets.json\n</code></pre></p> <p>Solution: 1. Download OAuth 2.0 Client ID JSON from Google Cloud Console 2. Save it as <code>~/.kagura/client_secrets.json</code></p>"},{"location":"en/guides/oauth2-authentication/#not-authenticated-with-google","title":"\"Not authenticated with google\"","text":"<p>Error: <pre><code>NotAuthenticatedError: Not authenticated with google. Please run: kagura auth login --provider google\n</code></pre></p> <p>Solution: Run <code>kagura auth login --provider google</code> to authenticate.</p>"},{"location":"en/guides/oauth2-authentication/#token-refresh-failed","title":"\"Token refresh failed\"","text":"<p>Error: <pre><code>TokenRefreshError: Failed to refresh token for google\n</code></pre></p> <p>Solution: 1. Logout: <code>kagura auth logout --provider google</code> 2. Login again: <code>kagura auth login --provider google</code></p>"},{"location":"en/guides/oauth2-authentication/#invalid-credentials","title":"\"Invalid credentials\"","text":"<p>Error: <pre><code>InvalidCredentialsError: Failed to decrypt credentials\n</code></pre></p> <p>Possible causes: - Corrupted credentials file - Encryption key was regenerated</p> <p>Solution: 1. Remove credentials: <code>rm ~/.kagura/credentials.json.enc</code> 2. Login again: <code>kagura auth login --provider google</code></p>"},{"location":"en/guides/oauth2-authentication/#environment-variables","title":"Environment Variables","text":"<p>OAuth2 authentication does NOT use environment variables. All authentication is handled through the OAuth2 flow and stored encrypted credentials.</p> <p>If you prefer to use API keys instead:</p> <pre><code># For Gemini (using API key)\nexport GOOGLE_API_KEY=\"your-api-key\"\n\n# Then use api_key auth type (default)\nconfig = LLMConfig(model=\"gemini/gemini-1.5-flash\")\n</code></pre>"},{"location":"en/guides/oauth2-authentication/#comparison-oauth2-vs-api-key","title":"Comparison: OAuth2 vs API Key","text":"Feature OAuth2 API Key Supported LLMs Google/Gemini only All LLMs (OpenAI, Claude, Gemini) Setup Complexity Complex (Google Cloud Console setup required) Simple (just get API key) Security OAuth2 tokens (short-lived, auto-refresh) Long-lived API keys Use Case Multi-user apps, production with strict access control Personal development, prototyping, CI/CD Recommended For Advanced users with specific needs Most users (recommended) Expiration Auto-refresh Manual rotation Revocation Can revoke from Google Console Delete/regenerate key"},{"location":"en/guides/oauth2-authentication/#when-to-use-api-key-recommended","title":"When to Use API Key (Recommended)","text":"<p>\u2705 Use API Key if: - You're doing personal development or prototyping - You want quick and simple setup - You're using Claude or OpenAI (OAuth2 not supported) - You're running in CI/CD pipelines - You're building single-user applications</p> <p>How to get API Keys: - Gemini: Google AI Studio (fastest way!) - Claude: Anthropic Console - OpenAI: OpenAI Platform</p>"},{"location":"en/guides/oauth2-authentication/#when-to-use-oauth2-advanced","title":"When to Use OAuth2 (Advanced)","text":"<p>\u26a0\ufe0f Use OAuth2 only if: - You're building a multi-user application - Each user needs their own Google account authentication - You need strict per-user quota management - You have specific security requirements - You're comfortable with Google Cloud Console setup</p> <p>Note: OAuth2 is only available for Google/Gemini.</p>"},{"location":"en/guides/oauth2-authentication/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"en/guides/oauth2-authentication/#custom-client-secrets-path","title":"Custom Client Secrets Path","text":"<p>If you want to store <code>client_secrets.json</code> in a custom location:</p> <pre><code>from kagura.auth import OAuth2Manager, AuthConfig\nfrom pathlib import Path\n\n# Custom config\nconfig = AuthConfig(\n    provider=\"google\",\n    client_secrets_path=Path(\"/custom/path/client_secrets.json\")\n)\n\n# Use custom config\nauth = OAuth2Manager(config=config)\nauth.login()\n</code></pre>"},{"location":"en/guides/oauth2-authentication/#custom-scopes","title":"Custom Scopes","text":"<p>The default scopes are: - <code>https://www.googleapis.com/auth/generative-language</code> - <code>openid</code></p> <p>To use custom scopes:</p> <pre><code>from kagura.auth import OAuth2Manager, AuthConfig\n\nconfig = AuthConfig(\n    provider=\"google\",\n    scopes=[\n        \"https://www.googleapis.com/auth/generative-language\",\n        \"openid\",\n        \"https://www.googleapis.com/auth/userinfo.email\"\n    ]\n)\n\nauth = OAuth2Manager(config=config)\n</code></pre>"},{"location":"en/guides/oauth2-authentication/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Agent Routing</li> <li>Explore Memory Management</li> <li>Try MCP Integration</li> </ul>"},{"location":"en/guides/oauth2-authentication/#related-documentation","title":"Related Documentation","text":"<ul> <li>API Reference: OAuth2Manager</li> <li>Installation Guide</li> <li>Quickstart Tutorial</li> </ul>"},{"location":"en/guides/performance-caching/","title":"Performance: LLM Response Caching","text":"<p>Reduce response times by 70% and API costs by 60% through intelligent LLM response caching.</p>"},{"location":"en/guides/performance-caching/#overview","title":"Overview","text":"<p>Kagura AI automatically caches LLM responses to:</p> <ul> <li>Reduce response times: 70%+ faster for cached queries</li> <li>Lower API costs: 60%+ cost reduction through cache reuse</li> <li>Improve scalability: Handle more concurrent users</li> <li>Better UX: Instant responses for repeated queries</li> </ul>"},{"location":"en/guides/performance-caching/#how-it-works","title":"How It Works","text":"<pre><code>from kagura import agent, LLMConfig\n\n# Caching is enabled by default\nconfig = LLMConfig(model=\"gpt-4o-mini\", enable_cache=True)\n\n@agent(config=config)\nasync def translator(text: str, target_lang: str) -&gt; str:\n    \"\"\"Translate {{ text }} to {{ target_lang }}\"\"\"\n    pass\n\n# First call: Cache miss (~2s)\nresult1 = await translator(\"Hello\", \"Japanese\")\n\n# Second call: Cache hit (~0ms) \u26a1\nresult2 = await translator(\"Hello\", \"Japanese\")  # Instant!\n</code></pre>"},{"location":"en/guides/performance-caching/#quick-start","title":"Quick Start","text":""},{"location":"en/guides/performance-caching/#default-behavior","title":"Default Behavior","text":"<p>Caching is enabled by default with sensible defaults:</p> <pre><code>from kagura import LLMConfig\n\n# These are equivalent:\nconfig1 = LLMConfig(model=\"gpt-4o-mini\")\nconfig2 = LLMConfig(\n    model=\"gpt-4o-mini\",\n    enable_cache=True,      # Enabled by default\n    cache_ttl=3600,         # 1 hour TTL\n    cache_backend=\"memory\"  # In-memory cache\n)\n</code></pre>"},{"location":"en/guides/performance-caching/#disabling-cache","title":"Disabling Cache","text":"<p>For non-deterministic or time-sensitive queries:</p> <pre><code>config = LLMConfig(\n    model=\"gpt-4o-mini\",\n    enable_cache=False  # Disable caching\n)\n\n@agent(config=config)\nasync def breaking_news() -&gt; str:\n    \"\"\"Get latest breaking news\"\"\"\n    pass\n</code></pre>"},{"location":"en/guides/performance-caching/#configuration","title":"Configuration","text":""},{"location":"en/guides/performance-caching/#cache-ttl-time-to-live","title":"Cache TTL (Time-To-Live)","text":"<p>Control how long responses are cached:</p> <pre><code># Short TTL for frequently changing data\nconfig_short = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_ttl=300  # 5 minutes\n)\n\n# Long TTL for stable data\nconfig_long = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_ttl=86400  # 24 hours\n)\n\n# No expiration (cache indefinitely)\nconfig_infinite = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_ttl=0  # Never expires (use with caution!)\n)\n</code></pre>"},{"location":"en/guides/performance-caching/#cache-backend","title":"Cache Backend","text":"<p>Choose between in-memory and Redis backends:</p> <pre><code># In-memory cache (default, fast, single-process)\nconfig_memory = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_backend=\"memory\"\n)\n\n# Redis cache (shared across processes, persistent)\n# Note: Redis backend will be available in Phase 1 Day 3\nconfig_redis = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_backend=\"redis\"  # Coming soon!\n)\n</code></pre>"},{"location":"en/guides/performance-caching/#cache-management","title":"Cache Management","text":""},{"location":"en/guides/performance-caching/#inspecting-cache","title":"Inspecting Cache","text":"<p>Get cache statistics:</p> <pre><code>from kagura.core.llm import get_llm_cache\n\ncache = get_llm_cache()\nstats = cache.stats()\n\nprint(f\"Cache size: {stats['size']}/{stats['max_size']}\")\nprint(f\"Hit rate: {stats['hit_rate']:.1%}\")\nprint(f\"Hits: {stats['hits']}, Misses: {stats['misses']}\")\n</code></pre> <p>Example output: <pre><code>Cache size: 243/1000\nHit rate: 87.3%\nHits: 1247, Misses: 182\n</code></pre></p>"},{"location":"en/guides/performance-caching/#cache-invalidation","title":"Cache Invalidation","text":"<p>Clear cache when data changes:</p> <pre><code>cache = get_llm_cache()\n\n# Clear all cache entries\nawait cache.invalidate()\n\n# Clear specific pattern\nawait cache.invalidate(\"translate\")  # Clears all translation caches\n</code></pre>"},{"location":"en/guides/performance-caching/#custom-cache-instance","title":"Custom Cache Instance","text":"<p>Use a custom cache configuration:</p> <pre><code>from kagura.core.cache import LLMCache\nfrom kagura.core.llm import set_llm_cache\n\n# Create custom cache\ncustom_cache = LLMCache(\n    max_size=5000,      # Store up to 5000 entries\n    default_ttl=7200    # 2 hour default TTL\n)\n\nset_llm_cache(custom_cache)\n</code></pre>"},{"location":"en/guides/performance-caching/#best-practices","title":"Best Practices","text":""},{"location":"en/guides/performance-caching/#1-enable-caching-for-stable-queries","title":"1. Enable Caching for Stable Queries","text":"<p>\u2705 Good use cases: - Translation services - Text summarization - Code generation (same prompt) - General knowledge queries</p> <pre><code>@agent(config=LLMConfig(enable_cache=True))\nasync def translator(text: str) -&gt; str:\n    \"\"\"Translate {{ text }} to English\"\"\"\n    pass\n</code></pre> <p>\u274c Bad use cases: - Real-time data (news, weather, stock prices) - User-specific personalized responses - Queries with timestamps</p> <pre><code>@agent(config=LLMConfig(enable_cache=False))\nasync def weather_now() -&gt; str:\n    \"\"\"Get current weather\"\"\"\n    pass\n</code></pre>"},{"location":"en/guides/performance-caching/#2-adjust-ttl-based-on-data-stability","title":"2. Adjust TTL Based on Data Stability","text":"<pre><code># Fast-changing data: Short TTL\nnews_config = LLMConfig(cache_ttl=300)  # 5 min\n\n# Stable data: Long TTL\ndocs_config = LLMConfig(cache_ttl=86400)  # 24 hours\n\n# Never changes: Very long TTL\nconst_config = LLMConfig(cache_ttl=604800)  # 1 week\n</code></pre>"},{"location":"en/guides/performance-caching/#3-tool-functions-disable-caching","title":"3. Tool Functions Disable Caching","text":"<p>Caching is automatically disabled when using tool functions:</p> <pre><code>@agent(config=LLMConfig(enable_cache=True))\nasync def research(query: str) -&gt; str:\n    \"\"\"Research {{ query }}\"\"\"\n    pass\n\n# Caching enabled (no tools)\nresult1 = await research(\"AI trends\")\n\n# Caching disabled (tools provided)\nresult2 = await research(\n    \"AI trends\",\n    tools=[web_search, calculator]  # Tools disable cache\n)\n</code></pre> <p>Reason: Tool functions may have side effects or return different results each time.</p>"},{"location":"en/guides/performance-caching/#4-monitor-cache-performance","title":"4. Monitor Cache Performance","text":"<p>Track hit rate to optimize:</p> <pre><code>import asyncio\nfrom kagura.core.llm import get_llm_cache\n\nasync def monitor_cache():\n    while True:\n        cache = get_llm_cache()\n        stats = cache.stats()\n\n        hit_rate = stats['hit_rate']\n        if hit_rate &lt; 0.5:\n            print(f\"\u26a0\ufe0f Low hit rate: {hit_rate:.1%}\")\n            print(\"Consider: Longer TTL or fewer unique queries\")\n\n        await asyncio.sleep(60)  # Check every minute\n</code></pre> <p>Target hit rate: 70-90% for most applications</p>"},{"location":"en/guides/performance-caching/#performance-benchmarks","title":"Performance Benchmarks","text":""},{"location":"en/guides/performance-caching/#response-time-reduction","title":"Response Time Reduction","text":"Scenario Without Cache With Cache (Hit) Improvement Simple query 1.5s ~0ms 99.9% faster \u26a1 Complex query 3.2s ~0ms 99.9% faster \u26a1 Translation 1.8s ~0ms 99.9% faster \u26a1"},{"location":"en/guides/performance-caching/#cost-reduction","title":"Cost Reduction","text":"<p>Assuming 1000 requests/day with 85% cache hit rate:</p> Model Without Cache With Cache Savings gpt-4o-mini $2.00/day $0.30/day 85% cheaper \ud83d\udcb0 gpt-4o $30.00/day $4.50/day 85% cheaper \ud83d\udcb0 claude-3-5-sonnet $15.00/day $2.25/day 85% cheaper \ud83d\udcb0"},{"location":"en/guides/performance-caching/#advanced-topics","title":"Advanced Topics","text":""},{"location":"en/guides/performance-caching/#cache-key-generation","title":"Cache Key Generation","text":"<p>Cache keys include: - Prompt text - Model name - All LLM parameters (temperature, max_tokens, etc.)</p> <pre><code># Same cache key (identical parameters)\nconfig = LLMConfig(model=\"gpt-4o-mini\", temperature=0.7)\nresult1 = await call_llm(\"Hello\", config)\nresult2 = await call_llm(\"Hello\", config)  # Cache hit \u2705\n\n# Different cache key (different temperature)\nconfig2 = LLMConfig(model=\"gpt-4o-mini\", temperature=0.9)\nresult3 = await call_llm(\"Hello\", config2)  # Cache miss \u274c\n</code></pre>"},{"location":"en/guides/performance-caching/#cache-eviction","title":"Cache Eviction","text":"<p>When cache reaches <code>max_size</code>, the oldest entries are evicted (LRU):</p> <pre><code>cache = LLMCache(max_size=1000)\n\n# After 1000 unique queries:\n# - Query 1001: Evicts oldest entry\n# - Query 1002: Evicts next oldest entry\n</code></pre> <p>Tip: Increase <code>max_size</code> if you have many unique queries.</p>"},{"location":"en/guides/performance-caching/#memory-usage","title":"Memory Usage","text":"<p>Approximate memory usage per cached entry:</p> <ul> <li>Simple response (100 chars): ~500 bytes</li> <li>Complex response (2000 chars): ~8 KB</li> <li>1000 entries: ~5-8 MB</li> </ul> <pre><code># Low memory: Small cache\nlow_mem_cache = LLMCache(max_size=100)\n\n# High memory: Large cache\nhigh_mem_cache = LLMCache(max_size=10000)\n</code></pre>"},{"location":"en/guides/performance-caching/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/performance-caching/#cache-not-working","title":"Cache Not Working","text":"<p>Symptom: All queries are cache misses</p> <p>Possible causes: 1. Caching disabled: <code>enable_cache=False</code> 2. Tool functions provided (auto-disables cache) 3. Different parameters on each call</p> <p>Solution: <pre><code># Check cache is enabled\nconfig = LLMConfig(enable_cache=True)\n\n# Verify no tools\nresult = await call_llm(prompt, config, tool_functions=None)\n\n# Check stats\ncache = get_llm_cache()\nprint(cache.stats())\n</code></pre></p>"},{"location":"en/guides/performance-caching/#low-hit-rate","title":"Low Hit Rate","text":"<p>Symptom: Hit rate &lt; 50%</p> <p>Possible causes: 1. Too many unique queries 2. TTL too short (entries expiring) 3. Dynamic prompts (timestamps, user IDs in prompt)</p> <p>Solution: <pre><code># Increase TTL\nconfig = LLMConfig(cache_ttl=7200)  # 2 hours\n\n# Remove dynamic parts from prompt\n# \u274c Bad: Includes timestamp\nprompt = f\"Translate 'hello' at {datetime.now()}\"\n\n# \u2705 Good: Static prompt\nprompt = \"Translate 'hello' to French\"\n</code></pre></p>"},{"location":"en/guides/performance-caching/#memory-issues","title":"Memory Issues","text":"<p>Symptom: High memory usage</p> <p>Solution: <pre><code># Reduce cache size\ncache = LLMCache(max_size=500)  # Smaller cache\nset_llm_cache(cache)\n\n# Or invalidate periodically\nawait cache.invalidate()  # Clear all entries\n</code></pre></p>"},{"location":"en/guides/performance-caching/#next-steps","title":"Next Steps","text":"<ul> <li>API Reference: cache.py</li> <li>API Reference: llm.py</li> <li>Performance Optimization Guide (coming soon)</li> </ul> <p>Need help? Open an issue</p>"},{"location":"en/guides/performance-parallelization/","title":"Performance: Parallel Execution","text":"<p>Speed up independent operations by 40-50% through intelligent parallelization.</p>"},{"location":"en/guides/performance-parallelization/#overview","title":"Overview","text":"<p>Kagura AI provides utilities for executing multiple async operations in parallel:</p> <ul> <li>parallel_gather(): Execute multiple coroutines concurrently</li> <li>parallel_map(): Apply async function to items with concurrency limit</li> <li>parallel_map_unordered(): Process items as they complete</li> </ul>"},{"location":"en/guides/performance-parallelization/#automatic-parallelization","title":"Automatic Parallelization","text":"<p>Several Kagura components use parallelization automatically:</p> <ul> <li>\u2705 MemoryAwareRouter: Context analysis + routing in parallel (40% faster)</li> <li>\u2705 MultimodalRAG: File loading in parallel (50% faster for 10+ files)</li> </ul>"},{"location":"en/guides/performance-parallelization/#quick-start","title":"Quick Start","text":""},{"location":"en/guides/performance-parallelization/#parallel-llm-calls","title":"Parallel LLM Calls","text":"<pre><code>from kagura import LLMConfig\nfrom kagura.core import parallel_gather\nfrom kagura.core.llm import call_llm\n\nconfig = LLMConfig(model=\"gpt-4o-mini\")\n\n# Serial: 4.5s (1.5s each)\nresult1 = await call_llm(\"Translate 'hello' to Japanese\", config)\nresult2 = await call_llm(\"Translate 'hello' to French\", config)\nresult3 = await call_llm(\"Translate 'hello' to Spanish\", config)\n\n# Parallel: 1.5s (all concurrent) \u26a1\nresults = await parallel_gather(\n    call_llm(\"Translate 'hello' to Japanese\", config),\n    call_llm(\"Translate 'hello' to French\", config),\n    call_llm(\"Translate 'hello' to Spanish\", config)\n)\n# ['\u3053\u3093\u306b\u3061\u306f', 'bonjour', 'hola']\n</code></pre> <p>Performance: 3x speedup (4.5s \u2192 1.5s)</p>"},{"location":"en/guides/performance-parallelization/#api-reference","title":"API Reference","text":""},{"location":"en/guides/performance-parallelization/#parallel_gather","title":"parallel_gather()","text":"<p>Execute multiple coroutines concurrently:</p> <pre><code>from kagura.core import parallel_gather\n\nresults = await parallel_gather(\n    async_operation1(),\n    async_operation2(),\n    async_operation3()\n)\n</code></pre> <p>Features: - Returns results in input order - Fail-fast on first exception - Type-safe return types</p>"},{"location":"en/guides/performance-parallelization/#parallel_map","title":"parallel_map()","text":"<p>Apply async function to items with concurrency limit:</p> <pre><code>from kagura.core import parallel_map\n\nasync def process_item(item: str) -&gt; str:\n    # Expensive operation\n    return await expensive_llm_call(item)\n\nitems = [\"item1\", \"item2\", ..., \"item50\"]\n\n# Process 50 items with max 5 concurrent\nresults = await parallel_map(\n    process_item,\n    items,\n    max_concurrent=5  # Limit concurrent operations\n)\n</code></pre> <p>Features: - Concurrency control via semaphore - Preserves input order - Prevents resource exhaustion</p> <p>Performance: - Serial (50 items, 0.5s each): 25s - Parallel (max_concurrent=5): ~5s (5x speedup)</p>"},{"location":"en/guides/performance-parallelization/#parallel_map_unordered","title":"parallel_map_unordered()","text":"<p>Process items returning results as they complete:</p> <pre><code>from kagura.core import parallel_map_unordered\n\nresults = await parallel_map_unordered(\n    process_item,\n    items,\n    max_concurrent=5\n)\n# Results in completion order (not input order)\n</code></pre> <p>Use case: When you want to process results immediately as they arrive.</p>"},{"location":"en/guides/performance-parallelization/#use-cases","title":"Use Cases","text":""},{"location":"en/guides/performance-parallelization/#1-multi-language-translation","title":"1. Multi-Language Translation","text":"<pre><code>from kagura import agent, LLMConfig\nfrom kagura.core import parallel_gather\n\nconfig = LLMConfig(model=\"gpt-4o-mini\")\n\n@agent(config=config)\nasync def translator(text: str, target_lang: str) -&gt; str:\n    \"\"\"Translate {{ text }} to {{ target_lang }}\"\"\"\n    pass\n\n# Translate to multiple languages in parallel\ntext = \"Hello, world!\"\nlanguages = [\"Japanese\", \"French\", \"Spanish\", \"German\"]\n\ntranslations = await parallel_gather(*[\n    translator(text, lang) for lang in languages\n])\n\n# Results: ['\u3053\u3093\u306b\u3061\u306f\u3001\u4e16\u754c\uff01', 'Bonjour le monde!', ...]\n</code></pre> <p>Performance: 4x speedup vs serial</p>"},{"location":"en/guides/performance-parallelization/#2-batch-document-processing","title":"2. Batch Document Processing","text":"<pre><code>from pathlib import Path\nfrom kagura import agent\nfrom kagura.core import parallel_map\n\n@agent\nasync def summarizer(text: str) -&gt; str:\n    \"\"\"Summarize: {{ text }}\"\"\"\n    pass\n\n# Process 100 documents\ndocs = [Path(f\"doc{i}.txt\") for i in range(100)]\n\nasync def process_doc(path: Path) -&gt; str:\n    content = path.read_text()\n    return await summarizer(content)\n\n# Process with concurrency limit\nsummaries = await parallel_map(\n    process_doc,\n    docs,\n    max_concurrent=10  # 10 concurrent LLM calls\n)\n</code></pre> <p>Performance: - Serial: 100 docs * 2s = 200s (~3.3 min) - Parallel (max 10): 100 / 10 * 2s = 20s (10x speedup)</p>"},{"location":"en/guides/performance-parallelization/#3-multi-agent-workflow","title":"3. Multi-Agent Workflow","text":"<pre><code>from kagura import agent\nfrom kagura.core import parallel_gather\n\n@agent\nasync def research_agent(topic: str) -&gt; str:\n    \"\"\"Research {{ topic }}\"\"\"\n    pass\n\n@agent\nasync def summarize_agent(text: str) -&gt; str:\n    \"\"\"Summarize: {{ text }}\"\"\"\n    pass\n\n@agent\nasync def translate_agent(text: str) -&gt; str:\n    \"\"\"Translate {{ text }} to Japanese\"\"\"\n    pass\n\n# Execute 3 agents in parallel\ntopic = \"Quantum computing\"\nresearch, summary, translation = await parallel_gather(\n    research_agent(topic),\n    summarize_agent(topic),\n    translate_agent(topic)\n)\n</code></pre> <p>Performance: 3x speedup vs serial</p>"},{"location":"en/guides/performance-parallelization/#automatic-parallelization_1","title":"Automatic Parallelization","text":""},{"location":"en/guides/performance-parallelization/#memoryawarerouter","title":"MemoryAwareRouter","text":"<p>Automatically parallelizes context analysis and routing:</p> <pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\nfrom kagura.routing import MemoryAwareRouter\n\nmemory = MemoryManager(agent_name=\"assistant\")\nrouter = MemoryAwareRouter(memory=memory)\n\n# Register agents\n@agent\nasync def translator(text: str) -&gt; str:\n    \"\"\"Translate {{ text }}\"\"\"\n    pass\n\nrouter.register(translator, intents=[\"translate\"])\n\n# Parallel execution automatically applied\nresult = await router.route(\"Translate this to French\")\n</code></pre> <p>Performance: - Serial (old): Context analysis (1.5s) + routing (1.5s) = 2.5s - Parallel (new): Both concurrent = 1.5s (40% faster)</p>"},{"location":"en/guides/performance-parallelization/#multimodalrag","title":"MultimodalRAG","text":"<p>Automatically parallelizes file loading:</p> <pre><code>from pathlib import Path\nfrom kagura.core.memory import MultimodalRAG\n\nrag = MultimodalRAG(directory=Path(\"./docs\"))\n\n# Files loaded in parallel automatically\nawait rag.build_index(max_concurrent=5)\n</code></pre> <p>Performance: - Serial: 50 files * 0.5s = 25s - Parallel (max_concurrent=5): 50 / 5 * 0.5s = 5s (5x speedup)</p>"},{"location":"en/guides/performance-parallelization/#best-practices","title":"Best Practices","text":""},{"location":"en/guides/performance-parallelization/#1-choose-appropriate-concurrency-limits","title":"1. Choose Appropriate Concurrency Limits","text":"<pre><code># \u2705 Good: Reasonable limit\nawait parallel_map(func, items, max_concurrent=5)\n\n# \u26a0\ufe0f Risky: Too high (may hit rate limits)\nawait parallel_map(func, items, max_concurrent=100)\n\n# \u274c Bad: No limit (resource exhaustion)\nawait asyncio.gather(*[func(item) for item in items])  # Unbounded!\n</code></pre> <p>Recommended limits: - LLM API calls: 3-10 (respect rate limits) - File I/O: 10-20 (avoid file handle exhaustion) - Network requests: 5-15 (avoid overwhelming servers)</p>"},{"location":"en/guides/performance-parallelization/#2-use-caching-with-parallelization","title":"2. Use Caching with Parallelization","text":"<p>Combine caching and parallelization for maximum performance:</p> <pre><code>from kagura import LLMConfig\nfrom kagura.core import parallel_map\n\nconfig = LLMConfig(\n    model=\"gpt-4o-mini\",\n    enable_cache=True,  # Enable caching\n    cache_ttl=3600\n)\n\n# First run: All cache misses (parallel)\nresults = await parallel_map(\n    lambda item: call_llm(item, config),\n    items,\n    max_concurrent=5\n)\n\n# Second run: All cache hits (instant) \u26a1\nresults = await parallel_map(\n    lambda item: call_llm(item, config),\n    items,\n    max_concurrent=5\n)\n</code></pre> <p>Performance: - First run: 50% faster (parallelization) - Second run: 99% faster (caching + parallelization)</p>"},{"location":"en/guides/performance-parallelization/#3-error-handling","title":"3. Error Handling","text":"<pre><code>from kagura.core import parallel_gather\n\ntry:\n    results = await parallel_gather(\n        risky_operation1(),\n        risky_operation2(),\n        risky_operation3()\n    )\nexcept Exception as e:\n    # One operation failed, all are cancelled\n    print(f\"Operation failed: {e}\")\n</code></pre> <p>Note: <code>parallel_gather()</code> is fail-fast. Use <code>return_exceptions=True</code> for resilience:</p> <pre><code>import asyncio\n\nresults = await asyncio.gather(\n    operation1(),\n    operation2(),\n    operation3(),\n    return_exceptions=True\n)\n\n# Check for exceptions\nfor i, result in enumerate(results):\n    if isinstance(result, Exception):\n        print(f\"Operation {i} failed: {result}\")\n</code></pre>"},{"location":"en/guides/performance-parallelization/#performance-benchmarks","title":"Performance Benchmarks","text":""},{"location":"en/guides/performance-parallelization/#routing-performance","title":"Routing Performance","text":"Scenario Serial Parallel Improvement MemoryAwareRouter (context needed) 2.5s 1.5s 40% faster \u26a1 MemoryAwareRouter (no context) 1.5s 1.5s No change (fast path)"},{"location":"en/guides/performance-parallelization/#multimodal-file-loading","title":"Multimodal File Loading","text":"Files Serial Parallel (max=5) Improvement 10 files 5s 2.5s 50% faster \u26a1 50 files 25s 13s 48% faster \u26a1 100 files 50s 25s 50% faster \u26a1"},{"location":"en/guides/performance-parallelization/#multi-agent-workflows","title":"Multi-Agent Workflows","text":"Agents Serial Parallel Improvement 3 agents 4.5s 1.5s 67% faster \u26a1 5 agents 7.5s 1.5s 80% faster \u26a1"},{"location":"en/guides/performance-parallelization/#advanced-topics","title":"Advanced Topics","text":""},{"location":"en/guides/performance-parallelization/#custom-concurrency-control","title":"Custom Concurrency Control","text":"<pre><code>import asyncio\nfrom kagura.core import parallel_map\n\n# Custom semaphore for fine-grained control\nsemaphore = asyncio.Semaphore(3)\n\nasync def controlled_operation(item):\n    async with semaphore:\n        return await expensive_operation(item)\n\nresults = await asyncio.gather(*[\n    controlled_operation(item) for item in items\n])\n</code></pre>"},{"location":"en/guides/performance-parallelization/#batching","title":"Batching","text":"<p>For very large datasets, process in batches:</p> <pre><code>from kagura.core import parallel_map\n\nasync def process_batch(batch: list[str]) -&gt; list[str]:\n    return await parallel_map(\n        process_item,\n        batch,\n        max_concurrent=5\n    )\n\n# Process 1000 items in batches of 100\nall_results = []\nfor i in range(0, len(items), 100):\n    batch = items[i:i+100]\n    batch_results = await process_batch(batch)\n    all_results.extend(batch_results)\n</code></pre>"},{"location":"en/guides/performance-parallelization/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/performance-parallelization/#rate-limiting-errors","title":"Rate Limiting Errors","text":"<p>Symptom: HTTP 429 Too Many Requests</p> <p>Solution: Reduce <code>max_concurrent</code>: <pre><code># \u274c Too aggressive\nawait parallel_map(func, items, max_concurrent=20)\n\n# \u2705 Better\nawait parallel_map(func, items, max_concurrent=5)\n</code></pre></p>"},{"location":"en/guides/performance-parallelization/#memory-issues","title":"Memory Issues","text":"<p>Symptom: Out of memory errors</p> <p>Solution: Process in smaller batches or reduce concurrency.</p>"},{"location":"en/guides/performance-parallelization/#slower-than-expected","title":"Slower Than Expected","text":"<p>Possible causes: 1. Operations are not truly independent 2. API rate limiting kicking in 3. Caching not enabled</p> <p>Check: <pre><code>import time\n\nstart = time.time()\nresults = await parallel_map(func, items, max_concurrent=5)\nduration = time.time() - start\n\nprint(f\"Processed {len(items)} items in {duration:.2f}s\")\nprint(f\"Average: {duration / len(items):.2f}s per item\")\n</code></pre></p>"},{"location":"en/guides/performance-parallelization/#next-steps","title":"Next Steps","text":"<ul> <li>Caching Guide</li> <li>Streaming Guide (coming soon)</li> <li>API Reference: parallel.py (coming soon)</li> </ul> <p>Need help? Open an issue</p>"},{"location":"en/guides/web-integration/","title":"Web Integration Guide","text":"<p>This guide explains how to use Kagura AI's web search and scraping capabilities to access real-time information from the internet.</p>"},{"location":"en/guides/web-integration/#overview","title":"Overview","text":"<p>Web integration allows you to: - Search the web for current information - Scrape content from websites - Combine local knowledge (RAG) with web data - Get up-to-date answers beyond LLM training cutoff</p>"},{"location":"en/guides/web-integration/#prerequisites","title":"Prerequisites","text":""},{"location":"en/guides/web-integration/#installation","title":"Installation","text":"<p>Install Kagura AI with web support:</p> <pre><code>pip install kagura-ai[web]\n</code></pre> <p>This installs: - <code>httpx</code> - Async HTTP client - <code>beautifulsoup4</code> - HTML parsing - <code>lxml</code> - Fast XML/HTML parser - <code>duckduckgo-search</code> - DuckDuckGo search (optional)</p>"},{"location":"en/guides/web-integration/#api-key-setup-optional","title":"API Key Setup (Optional)","text":"<p>For Brave Search (recommended for better results):</p> <pre><code>export BRAVE_API_KEY=\"your-brave-api-key\"\n</code></pre> <p>Get a free API key from Brave Search API (2000 queries/month free).</p> <p>Without API key: Kagura automatically falls back to DuckDuckGo (no API key required).</p>"},{"location":"en/guides/web-integration/#quick-start","title":"Quick Start","text":""},{"location":"en/guides/web-integration/#basic-usage","title":"Basic Usage","text":"<p>Start chat with web search enabled:</p> <pre><code>kagura chat --enable-web\n</code></pre> <p>The AI will automatically search the web when needed:</p> <pre><code>$ kagura chat --enable-web\n\n[You] &gt; What are the latest AI news today?\n\n\ud83c\udf10 Searching the web for: latest AI news\n\u2713 Web search completed\n\ud83d\udcac Generating response...\n\n[AI]\nHere are today's top AI news:\n\n1. **OpenAI releases GPT-5 Preview** - OpenAI announced a preview of\n   GPT-5 with improved reasoning capabilities...\n\n2. **Google's Gemini 2.0 launched** - Google released Gemini 2.0 with\n   native multimodal support...\n\n3. **AI regulation update** - EU Parliament approved new AI safety\n   regulations affecting...\n\n[Sources: TechCrunch, The Verge, MIT Technology Review]\n</code></pre>"},{"location":"en/guides/web-integration/#web-search","title":"Web Search","text":""},{"location":"en/guides/web-integration/#automatic-search-detection","title":"Automatic Search Detection","text":"<p>The AI decides when to search the web:</p> <pre><code>from kagura import agent\n\n@agent(\n    model=\"gpt-4o-mini\",\n    enable_web=True  # Enable automatic web search\n)\nasync def research_assistant(question: str) -&gt; str:\n    \"\"\"Answer the user's question.\n\n    Question: {{ question }}\n\n    If you need current information, use web search.\n    \"\"\"\n    pass\n\n# The agent will automatically search when needed\nresponse = await research_assistant(\"What's the weather in Tokyo?\")\n</code></pre>"},{"location":"en/guides/web-integration/#manual-web-search","title":"Manual Web Search","text":"<p>Use the <code>web_search</code> function directly:</p> <pre><code>from kagura.web import web_search\n\n# Search the web\nresults_text = await web_search(\"Python async best practices 2025\")\nprint(results_text)\n</code></pre> <p>Output format:</p> <pre><code>Search results for: Python async best practices 2025\n\n1. Best Practices for Async Python in 2025\n   https://realpython.com/async-python-2025\n   Comprehensive guide to async/await patterns, asyncio best practices...\n\n2. Asyncio Performance Tips - 2025 Edition\n   https://python.org/asyncio-tips\n   Learn how to optimize asyncio applications for production...\n</code></pre>"},{"location":"en/guides/web-integration/#search-engines","title":"Search Engines","text":"<p>Kagura supports multiple search engines:</p>"},{"location":"en/guides/web-integration/#1-brave-search-recommended","title":"1. Brave Search (Recommended)","text":"<p>Best quality results, requires API key:</p> <pre><code>from kagura.web.search import BraveSearch\n\nsearch = BraveSearch(api_key=\"your-key\")\nresults = await search.search(\"query\", max_results=10)\n\nfor result in results:\n    print(f\"{result.title}: {result.url}\")\n</code></pre>"},{"location":"en/guides/web-integration/#2-duckduckgo-fallback","title":"2. DuckDuckGo (Fallback)","text":"<p>No API key required, rate limited:</p> <pre><code>from kagura.web.search import DuckDuckGoSearch\n\nsearch = DuckDuckGoSearch()\nresults = await search.search(\"query\", max_results=10)\n</code></pre>"},{"location":"en/guides/web-integration/#search-api","title":"Search API","text":"<pre><code>from kagura.web.search import SearchResult\n\n# Search returns list of SearchResult objects\nresults: list[SearchResult] = await search.search(\"query\")\n\nfor result in results:\n    print(f\"Title: {result.title}\")\n    print(f\"URL: {result.url}\")\n    print(f\"Snippet: {result.snippet}\")\n    print(f\"Source: {result.source}\")  # \"brave\" or \"duckduckgo\"\n    print()\n</code></pre>"},{"location":"en/guides/web-integration/#web-scraping","title":"Web Scraping","text":""},{"location":"en/guides/web-integration/#basic-scraping","title":"Basic Scraping","text":"<p>Fetch and parse webpage content:</p> <pre><code>from kagura.web.scraper import WebScraper\n\nscraper = WebScraper()\n\n# Fetch HTML\nhtml = await scraper.fetch(\"https://example.com\")\n\n# Extract text content\ntext = await scraper.fetch_text(\"https://example.com\")\nprint(text)  # Clean, readable text\n\n# Scrape with CSS selectors\ntitles = await scraper.scrape(\n    \"https://news.ycombinator.com\",\n    selector=\"span.titleline &gt; a\"\n)\nfor title in titles:\n    print(title)\n</code></pre>"},{"location":"en/guides/web-integration/#robotstxt-compliance","title":"robots.txt Compliance","text":"<p>Kagura respects robots.txt by default:</p> <pre><code>scraper = WebScraper(\n    respect_robots_txt=True,  # Default: True\n    user_agent=\"KaguraAI/2.5.0\",\n    rate_limit_delay=1.0  # Delay between requests (seconds)\n)\n</code></pre> <p>If a site disallows scraping:</p> <pre><code>try:\n    html = await scraper.fetch(\"https://example.com/private\")\nexcept ValueError as e:\n    print(f\"Blocked by robots.txt: {e}\")\n</code></pre>"},{"location":"en/guides/web-integration/#rate-limiting","title":"Rate Limiting","text":"<p>Automatic rate limiting prevents overwhelming servers:</p> <pre><code>from kagura.web.scraper import WebScraper\n\nscraper = WebScraper(rate_limit_delay=2.0)  # 2 seconds between requests\n\n# These will be rate-limited automatically\nawait scraper.fetch(\"https://example.com/page1\")\nawait scraper.fetch(\"https://example.com/page2\")  # Waits 2 seconds\nawait scraper.fetch(\"https://example.com/page3\")  # Waits 2 seconds\n</code></pre>"},{"location":"en/guides/web-integration/#advanced-scraping","title":"Advanced Scraping","text":"<pre><code>from kagura.web.scraper import WebScraper\n\nscraper = WebScraper(\n    user_agent=\"MyBot/1.0 (+https://mysite.com/bot)\",\n    respect_robots_txt=True,\n    rate_limit_delay=1.5\n)\n\n# Custom timeout\nhtml = await scraper.fetch(\"https://slow-site.com\", timeout=60.0)\n\n# Parse specific elements\narticles = await scraper.scrape(\n    \"https://blog.com\",\n    selector=\"article.post\"\n)\n</code></pre>"},{"location":"en/guides/web-integration/#agent-integration","title":"Agent Integration","text":""},{"location":"en/guides/web-integration/#web-enabled-agent","title":"Web-Enabled Agent","text":"<p>Create an agent that can search the web:</p> <pre><code>from kagura import agent\nfrom kagura.web import web_search\n\nasync def search_tool(query: str) -&gt; str:\n    \"\"\"Search the web for information.\"\"\"\n    return await web_search(query)\n\n@agent(\n    model=\"gpt-4o-mini\",\n    tools=[search_tool]\n)\nasync def research_agent(topic: str) -&gt; str:\n    \"\"\"Research {{ topic }} using web search.\n\n    Use search_tool(query) to search the web.\n    \"\"\"\n    pass\n\n# The agent will use the tool when needed\nreport = await research_agent(\"AI safety regulations 2025\")\n</code></pre>"},{"location":"en/guides/web-integration/#custom-web-tools","title":"Custom Web Tools","text":"<p>Create specialized web tools:</p> <pre><code>from kagura import agent\nfrom kagura.web.scraper import WebScraper\n\nasync def fetch_news(topic: str) -&gt; str:\n    \"\"\"Fetch latest news about a topic.\"\"\"\n    scraper = WebScraper()\n\n    # Scrape news site\n    headlines = await scraper.scrape(\n        f\"https://news-site.com/search?q={topic}\",\n        selector=\"h2.headline\"\n    )\n\n    return \"\\n\".join(headlines[:5])\n\n@agent(tools=[fetch_news])\nasync def news_assistant(query: str) -&gt; str:\n    \"\"\"Answer questions about current news.\n\n    Query: {{ query }}\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/guides/web-integration/#configuration","title":"Configuration","text":""},{"location":"en/guides/web-integration/#environment-variables","title":"Environment Variables","text":"<pre><code># Brave Search (optional)\nexport BRAVE_API_KEY=\"your-key\"\n\n# User agent (optional)\nexport USER_AGENT=\"MyBot/1.0\"\n\n# Rate limiting (optional)\nexport WEB_RATE_LIMIT=1.5\n</code></pre>"},{"location":"en/guides/web-integration/#programmatic-configuration","title":"Programmatic Configuration","text":"<pre><code>from kagura.web.search import BraveSearch, DuckDuckGoSearch\nfrom kagura.web.scraper import WebScraper\nimport os\n\n# Configure search\nif os.getenv(\"BRAVE_API_KEY\"):\n    search = BraveSearch(api_key=os.getenv(\"BRAVE_API_KEY\"))\nelse:\n    search = DuckDuckGoSearch()\n\n# Configure scraper\nscraper = WebScraper(\n    user_agent=os.getenv(\"USER_AGENT\", \"KaguraAI/2.5.0\"),\n    respect_robots_txt=True,\n    rate_limit_delay=float(os.getenv(\"WEB_RATE_LIMIT\", \"1.0\"))\n)\n</code></pre>"},{"location":"en/guides/web-integration/#best-practices","title":"Best Practices","text":""},{"location":"en/guides/web-integration/#1-respect-robotstxt","title":"1. Respect robots.txt","text":"<p>Always check robots.txt before scraping:</p> <pre><code>scraper = WebScraper(respect_robots_txt=True)  # Default\n</code></pre>"},{"location":"en/guides/web-integration/#2-use-appropriate-user-agent","title":"2. Use Appropriate User Agent","text":"<p>Identify your bot:</p> <pre><code>scraper = WebScraper(\n    user_agent=\"MyBot/1.0 (+https://mysite.com/bot-info)\"\n)\n</code></pre>"},{"location":"en/guides/web-integration/#3-rate-limiting","title":"3. Rate Limiting","text":"<p>Be a good citizen:</p> <pre><code>scraper = WebScraper(rate_limit_delay=1.0)  # Minimum 1 second\n</code></pre>"},{"location":"en/guides/web-integration/#4-handle-errors","title":"4. Handle Errors","text":"<pre><code>from httpx import HTTPError\n\ntry:\n    content = await scraper.fetch_text(url)\nexcept HTTPError as e:\n    print(f\"HTTP error: {e}\")\nexcept ValueError as e:\n    print(f\"Blocked by robots.txt: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"en/guides/web-integration/#5-cache-results","title":"5. Cache Results","text":"<p>Avoid repeated requests:</p> <pre><code>from functools import lru_cache\n\n@lru_cache(maxsize=100)\nasync def cached_search(query: str) -&gt; str:\n    return await web_search(query)\n</code></pre>"},{"location":"en/guides/web-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/web-integration/#importerror-httpx-not-installed","title":"\"ImportError: httpx not installed\"","text":"<p>Install web dependencies:</p> <pre><code>pip install kagura-ai[web]\n</code></pre>"},{"location":"en/guides/web-integration/#rate-limit-exceeded","title":"\"Rate limit exceeded\"","text":"<p>Increase delay between requests:</p> <pre><code>scraper = WebScraper(rate_limit_delay=2.0)\n</code></pre> <p>Or wait before retrying:</p> <pre><code>import asyncio\n\ntry:\n    results = await search.search(query)\nexcept Exception as e:\n    print(f\"Rate limited, waiting...\")\n    await asyncio.sleep(60)\n    results = await search.search(query)\n</code></pre>"},{"location":"en/guides/web-integration/#robotstxt-disallows-fetching","title":"\"robots.txt disallows fetching\"","text":"<p>Either:</p> <ol> <li>Respect the site's wishes (recommended)</li> <li>Disable robots.txt check (not recommended):</li> </ol> <pre><code>scraper = WebScraper(respect_robots_txt=False)\n</code></pre>"},{"location":"en/guides/web-integration/#connection-timeout","title":"Connection Timeout","text":"<p>Increase timeout:</p> <pre><code>html = await scraper.fetch(url, timeout=60.0)  # 60 seconds\n</code></pre>"},{"location":"en/guides/web-integration/#examples","title":"Examples","text":""},{"location":"en/guides/web-integration/#example-1-news-aggregator","title":"Example 1: News Aggregator","text":"<pre><code>from kagura import agent\nfrom kagura.web import web_search\n\n@agent(model=\"gpt-4o-mini\")\nasync def news_bot(topic: str) -&gt; str:\n    \"\"\"Fetch and summarize news about {{ topic }}.\n\n    Use web_search() to find latest news.\n    \"\"\"\n    pass\n\n# Usage\nsummary = await news_bot(\"AI breakthroughs\")\n</code></pre>"},{"location":"en/guides/web-integration/#example-2-documentation-fetcher","title":"Example 2: Documentation Fetcher","text":"<pre><code>from kagura.web.scraper import WebScraper\n\nasync def fetch_api_docs(library: str) -&gt; str:\n    \"\"\"Fetch API documentation for a library.\"\"\"\n    scraper = WebScraper()\n\n    # Fetch official docs\n    docs_url = f\"https://{library}.readthedocs.io/\"\n    text = await scraper.fetch_text(docs_url)\n\n    return text[:5000]  # First 5000 chars\n\n# Usage\ndocs = await fetch_api_docs(\"httpx\")\n</code></pre>"},{"location":"en/guides/web-integration/#example-3-competitor-analysis","title":"Example 3: Competitor Analysis","text":"<pre><code>from kagura import agent\nfrom kagura.web import web_search\nfrom kagura.web.scraper import WebScraper\n\nasync def analyze_competitor(competitor_url: str) -&gt; dict:\n    \"\"\"Analyze competitor website.\"\"\"\n    scraper = WebScraper()\n\n    # Fetch homepage\n    text = await scraper.fetch_text(competitor_url)\n\n    # Extract features\n    features = await scraper.scrape(\n        competitor_url,\n        selector=\"div.feature h3\"\n    )\n\n    return {\n        \"content\": text[:2000],\n        \"features\": features\n    }\n\n@agent\nasync def market_analyst(company_name: str) -&gt; str:\n    \"\"\"Analyze {{ company_name }} and competitors.\"\"\"\n    pass\n</code></pre>"},{"location":"en/guides/web-integration/#performance-tips","title":"Performance Tips","text":""},{"location":"en/guides/web-integration/#1-parallel-requests","title":"1. Parallel Requests","text":"<p>Use asyncio.gather for parallel fetching:</p> <pre><code>import asyncio\n\nurls = [\"https://site1.com\", \"https://site2.com\", \"https://site3.com\"]\n\n# Fetch in parallel\nresults = await asyncio.gather(\n    *[scraper.fetch_text(url) for url in urls]\n)\n</code></pre>"},{"location":"en/guides/web-integration/#2-connection-pooling","title":"2. Connection Pooling","text":"<p>httpx automatically pools connections:</p> <pre><code># Reuse scraper instance\nscraper = WebScraper()\n\nfor url in urls:\n    await scraper.fetch(url)  # Reuses connections\n</code></pre>"},{"location":"en/guides/web-integration/#3-timeout-management","title":"3. Timeout Management","text":"<p>Set appropriate timeouts:</p> <pre><code># Fast timeout for quick checks\nawait scraper.fetch(url, timeout=5.0)\n\n# Longer timeout for heavy pages\nawait scraper.fetch(url, timeout=30.0)\n</code></pre>"},{"location":"en/guides/web-integration/#next-steps","title":"Next Steps","text":"<ul> <li>Multimodal RAG Guide - Add local file indexing</li> <li>Full-Featured Mode - Combine all features</li> <li>API Reference - Detailed API documentation</li> </ul>"},{"location":"en/guides/web-integration/#resources","title":"Resources","text":"<ul> <li>Brave Search API</li> <li>httpx Documentation</li> <li>BeautifulSoup Documentation</li> <li>robots.txt Specification</li> </ul>"},{"location":"en/tutorials/01-basic-agent/","title":"Tutorial 1: Creating Your First Agent","text":"<p>Learn how to create a basic AI agent using the <code>@agent</code> decorator.</p>"},{"location":"en/tutorials/01-basic-agent/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed (<code>pip install kagura-ai</code>)</li> <li>OpenAI API key (or other LLM provider)</li> </ul>"},{"location":"en/tutorials/01-basic-agent/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand the <code>@agent</code> decorator - Create a simple conversational agent - Run and test your agent - Understand how prompts work</p>"},{"location":"en/tutorials/01-basic-agent/#step-1-set-up-your-environment","title":"Step 1: Set Up Your Environment","text":"<p>First, set your API key:</p> <pre><code>export OPENAI_API_KEY=\"your-key-here\"\n</code></pre> <p>Create a new file called <code>hello_agent.py</code>:</p> <pre><code>touch hello_agent.py\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#step-2-import-kagura","title":"Step 2: Import Kagura","text":"<p>Open <code>hello_agent.py</code> and add the import:</p> <pre><code>import asyncio\nfrom kagura import agent\n</code></pre> <p>Explanation: - <code>asyncio</code>: Python's built-in library for async operations - <code>agent</code>: The core decorator from Kagura AI</p>"},{"location":"en/tutorials/01-basic-agent/#step-3-define-your-first-agent","title":"Step 3: Define Your First Agent","text":"<p>Add this agent definition:</p> <pre><code>@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n</code></pre> <p>Let's break this down:</p> <ol> <li><code>@agent</code> - The decorator that converts the function into an AI agent</li> <li><code>async def hello</code> - An async function (required for all agents)</li> <li><code>(name: str)</code> - Function parameter with type hint</li> <li><code>-&gt; str</code> - Return type annotation (tells parser to expect a string)</li> <li><code>'''Say hello to {{ name }}'''</code> - The prompt template using Jinja2 syntax</li> <li><code>pass</code> - Function body (ignored, as decorator replaces it)</li> </ol>"},{"location":"en/tutorials/01-basic-agent/#step-4-create-a-main-function","title":"Step 4: Create a Main Function","text":"<p>Add code to run the agent:</p> <pre><code>async def main():\n    # Call the agent\n    result = await hello(\"World\")\n    print(result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#step-5-run-your-agent","title":"Step 5: Run Your Agent","text":"<p>Execute the script:</p> <pre><code>python hello_agent.py\n</code></pre> <p>Expected output: <pre><code>Hello, World! How can I assist you today?\n</code></pre></p> <p>\ud83c\udf89 Congratulations! You've created your first AI agent.</p>"},{"location":"en/tutorials/01-basic-agent/#complete-code","title":"Complete Code","text":"<p>Here's the full <code>hello_agent.py</code>:</p> <pre><code>import asyncio\nfrom kagura import agent\n\n\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\n\nasync def main():\n    result = await hello(\"World\")\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#understanding-what-happened","title":"Understanding What Happened","text":"<p>Let's trace the execution:</p> <ol> <li>You call: <code>await hello(\"World\")</code></li> <li>Decorator extracts: Parameter <code>name = \"World\"</code></li> <li>Template renders: <code>\"Say hello to World\"</code></li> <li>LLM is called: With the rendered prompt</li> <li>Response is parsed: As a string (because <code>-&gt; str</code>)</li> <li>Result returned: <code>\"Hello, World! How can I assist you today?\"</code></li> </ol>"},{"location":"en/tutorials/01-basic-agent/#experiment-different-names","title":"Experiment: Different Names","text":"<p>Try calling with different names:</p> <pre><code>async def main():\n    print(await hello(\"Alice\"))\n    print(await hello(\"Bob\"))\n    print(await hello(\"\u795e\u697d\"))  # Japanese name\n</code></pre> <p>Output: <pre><code>Hello, Alice! How can I help you?\nHello, Bob! Nice to meet you!\n\u3053\u3093\u306b\u3061\u306f\u3001\u795e\u697d\u3055\u3093\uff01\u304a\u624b\u4f1d\u3044\u3067\u304d\u308b\u3053\u3068\u306f\u3042\u308a\u307e\u3059\u304b\uff1f\n</code></pre></p> <p>Notice how the LLM adapts its response based on the input!</p>"},{"location":"en/tutorials/01-basic-agent/#experiment-multiple-parameters","title":"Experiment: Multiple Parameters","text":"<p>Let's create an agent with multiple parameters:</p> <pre><code>@agent\nasync def greet(name: str, time_of_day: str = \"morning\") -&gt; str:\n    '''Good {{ time_of_day }}, {{ name }}! How are you doing?'''\n    pass\n\n\nasync def main():\n    print(await greet(\"Alice\"))\n    print(await greet(\"Bob\", \"evening\"))\n</code></pre> <p>Output: <pre><code>Good morning, Alice! How are you doing?\nI hope you're doing well!\n\nGood evening, Bob! How are you doing?\nI hope you had a great day!\n</code></pre></p>"},{"location":"en/tutorials/01-basic-agent/#experiment-different-prompts","title":"Experiment: Different Prompts","text":"<p>The prompt greatly affects the response. Try these variations:</p>"},{"location":"en/tutorials/01-basic-agent/#formal-greeting","title":"Formal Greeting","text":"<pre><code>@agent\nasync def formal_greet(name: str) -&gt; str:\n    '''Provide a formal business greeting to {{ name }}, a potential client.'''\n    pass\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#casual-greeting","title":"Casual Greeting","text":"<pre><code>@agent\nasync def casual_greet(name: str) -&gt; str:\n    '''Give a super casual, friendly greeting to {{ name }}, your best friend.'''\n    pass\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#poetic-greeting","title":"Poetic Greeting","text":"<pre><code>@agent\nasync def poetic_greet(name: str) -&gt; str:\n    '''Write a short, poetic greeting to {{ name }} (2-3 lines).'''\n    pass\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"en/tutorials/01-basic-agent/#1-the-agent-decorator","title":"1. The @agent Decorator","text":"<p>Converts a function into an AI agent: - Extracts function signature - Uses docstring as prompt template - Calls LLM automatically - Parses response based on return type</p>"},{"location":"en/tutorials/01-basic-agent/#2-asyncawait","title":"2. Async/Await","text":"<p>All agents are async functions: <pre><code>result = await hello(\"World\")  # \u2713 Correct\nresult = hello(\"World\")        # \u2717 Wrong - missing await\n</code></pre></p>"},{"location":"en/tutorials/01-basic-agent/#3-type-hints","title":"3. Type Hints","text":"<p>Type hints tell the parser how to handle the response: <pre><code>async def hello(name: str) -&gt; str:  # Returns string\n    pass\n</code></pre></p>"},{"location":"en/tutorials/01-basic-agent/#4-prompt-templates","title":"4. Prompt Templates","text":"<p>Docstrings use Jinja2 syntax for dynamic prompts: <pre><code>'''Say hello to {{ name }}'''  # {{ }} injects variables\n</code></pre></p>"},{"location":"en/tutorials/01-basic-agent/#common-mistakes","title":"Common Mistakes","text":""},{"location":"en/tutorials/01-basic-agent/#1-forgetting-asyncawait","title":"1. Forgetting <code>async</code>/<code>await</code>","text":"<pre><code># Wrong\n@agent\ndef hello(name: str) -&gt; str:  # Missing 'async'\n    pass\n\nresult = hello(\"World\")  # Missing 'await'\n\n# Correct\n@agent\nasync def hello(name: str) -&gt; str:\n    pass\n\nresult = await hello(\"World\")\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#2-missing-return-type","title":"2. Missing Return Type","text":"<pre><code># Less good\n@agent\nasync def hello(name: str):  # No return type\n    pass\n\n# Better\n@agent\nasync def hello(name: str) -&gt; str:  # Explicit return type\n    pass\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#3-empty-docstring","title":"3. Empty Docstring","text":"<pre><code># Won't work well\n@agent\nasync def hello(name: str) -&gt; str:\n    pass  # No docstring = no prompt!\n\n# Correct\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#next-steps","title":"Next Steps","text":"<p>Now that you understand basic agents, you can:</p> <ol> <li>Learn about templates - Tutorial 2: Template Engine</li> <li>Explore type parsing - Tutorial 3: Type-Based Parsing</li> <li>Try the REPL - Run <code>kagura repl</code> for interactive testing</li> </ol>"},{"location":"en/tutorials/01-basic-agent/#practice-exercises","title":"Practice Exercises","text":""},{"location":"en/tutorials/01-basic-agent/#exercise-1-sentiment-analysis","title":"Exercise 1: Sentiment Analysis","text":"<p>Create an agent that analyzes sentiment:</p> <pre><code>@agent\nasync def analyze_sentiment(text: str) -&gt; str:\n    '''Analyze the sentiment (positive/negative/neutral) of: {{ text }}'''\n    pass\n</code></pre> <p>Test it: <pre><code>print(await analyze_sentiment(\"I love this product!\"))\nprint(await analyze_sentiment(\"This is terrible.\"))\nprint(await analyze_sentiment(\"It's okay.\"))\n</code></pre></p>"},{"location":"en/tutorials/01-basic-agent/#exercise-2-language-translation","title":"Exercise 2: Language Translation","text":"<p>Create a translation agent:</p> <pre><code>@agent\nasync def translate(text: str, target_language: str) -&gt; str:\n    '''Translate to {{ target_language }}: {{ text }}'''\n    pass\n</code></pre> <p>Test it: <pre><code>print(await translate(\"Hello, world!\", \"Japanese\"))\nprint(await translate(\"Hello, world!\", \"French\"))\n</code></pre></p>"},{"location":"en/tutorials/01-basic-agent/#exercise-3-question-answering","title":"Exercise 3: Question Answering","text":"<p>Create a Q&amp;A agent:</p> <pre><code>@agent\nasync def answer_question(question: str) -&gt; str:\n    '''Answer this question concisely: {{ question }}'''\n    pass\n</code></pre> <p>Test it: <pre><code>print(await answer_question(\"What is Python?\"))\nprint(await answer_question(\"How do I install Kagura AI?\"))\n</code></pre></p>"},{"location":"en/tutorials/01-basic-agent/#summary","title":"Summary","text":"<p>You learned: - \u2713 How to use the <code>@agent</code> decorator - \u2713 How to create async agent functions - \u2713 How to use type hints for return types - \u2713 How to write prompt templates with Jinja2 - \u2713 How to call and test agents</p> <p>Continue to Tutorial 2: Template Engine to learn more advanced prompting techniques!</p>"},{"location":"en/tutorials/02-templates/","title":"Tutorial 02: Template Engine","text":"<p>Learn how to use Jinja2 templates in your AI agents to create dynamic prompts.</p>"},{"location":"en/tutorials/02-templates/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How to use Jinja2 template syntax in agent docstrings</li> <li>Template variables and expressions</li> <li>Advanced template features (loops, conditionals)</li> <li>Best practices for prompt engineering</li> </ul>"},{"location":"en/tutorials/02-templates/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Tutorial 01: Your First Agent</li> <li>Basic understanding of Python f-strings</li> </ul>"},{"location":"en/tutorials/02-templates/#template-basics","title":"Template Basics","text":"<p>Kagura uses Jinja2 template syntax in agent docstrings. Templates are rendered before being sent to the LLM.</p>"},{"location":"en/tutorials/02-templates/#simple-variables","title":"Simple Variables","text":"<pre><code>from kagura import agent\n\n@agent\nasync def greet(name: str) -&gt; str:\n    \"\"\"Say hello to {{ name }}\"\"\"\n    pass\n\n# Template renders to: \"Say hello to Alice\"\nresult = await greet(\"Alice\")\n</code></pre> <p>Key Points: - Use <code>{{ variable }}</code> to insert values - Variable names must match function parameters - Values are automatically escaped</p>"},{"location":"en/tutorials/02-templates/#multiple-variables","title":"Multiple Variables","text":"<pre><code>@agent\nasync def introduce(name: str, age: int, occupation: str) -&gt; str:\n    \"\"\"\n    Introduce yourself as {{ name }}, a {{ age }}-year-old {{ occupation }}.\n    Be friendly and professional.\n    \"\"\"\n    pass\n\nresult = await introduce(\"Bob\", 30, \"engineer\")\n# Template renders to: \"Introduce yourself as Bob, a 30-year-old engineer...\"\n</code></pre>"},{"location":"en/tutorials/02-templates/#template-expressions","title":"Template Expressions","text":"<p>Jinja2 supports Python-like expressions:</p> <pre><code>@agent\nasync def analyze(score: int) -&gt; str:\n    \"\"\"\n    The score is {{ score }}.\n    {% if score &gt;= 80 %}\n    This is excellent performance!\n    {% elif score &gt;= 60 %}\n    This is good performance.\n    {% else %}\n    This needs improvement.\n    {% endif %}\n    \"\"\"\n    pass\n</code></pre> <p>Expressions You Can Use: - Arithmetic: <code>{{ price * 1.1 }}</code> - Comparison: <code>{% if age &gt; 18 %}</code> - String methods: <code>{{ name.upper() }}</code> - List access: <code>{{ items[0] }}</code></p>"},{"location":"en/tutorials/02-templates/#loops","title":"Loops","text":"<p>Process lists and dictionaries in templates:</p> <pre><code>from typing import List\n\n@agent\nasync def summarize_items(items: List[str]) -&gt; str:\n    \"\"\"\n    Summarize the following items:\n    {% for item in items %}\n    - {{ item }}\n    {% endfor %}\n\n    Provide a brief overview.\n    \"\"\"\n    pass\n\nresult = await summarize_items([\"apples\", \"oranges\", \"bananas\"])\n</code></pre> <p>Loop Features: - <code>{% for item in list %}</code>: Iterate over lists - <code>{{ loop.index }}</code>: Current iteration (1-based) - <code>{{ loop.first }}</code>: True on first iteration - <code>{{ loop.last }}</code>: True on last iteration</p>"},{"location":"en/tutorials/02-templates/#filters","title":"Filters","text":"<p>Transform values with filters:</p> <pre><code>@agent\nasync def format_text(text: str) -&gt; str:\n    \"\"\"\n    Original: {{ text }}\n    Uppercase: {{ text | upper }}\n    Capitalized: {{ text | capitalize }}\n    First 50 chars: {{ text[:50] }}\n    \"\"\"\n    pass\n</code></pre> <p>Common Filters: - <code>upper</code>, <code>lower</code>, <code>capitalize</code>: Text transformation - <code>length</code>: Get length of string/list - <code>default(value)</code>: Default value if undefined - <code>join(separator)</code>: Join list items</p>"},{"location":"en/tutorials/02-templates/#complex-data-structures","title":"Complex Data Structures","text":"<p>Work with dictionaries and objects:</p> <pre><code>from pydantic import BaseModel\nfrom typing import Dict\n\nclass User(BaseModel):\n    name: str\n    email: str\n    age: int\n\n@agent\nasync def analyze_user(user: User) -&gt; str:\n    \"\"\"\n    Analyze user profile:\n    - Name: {{ user.name }}\n    - Email: {{ user.email }}\n    - Age: {{ user.age }}\n\n    Provide insights about this user.\n    \"\"\"\n    pass\n\nuser = User(name=\"Alice\", email=\"alice@example.com\", age=25)\nresult = await analyze_user(user)\n</code></pre> <p>Accessing Data: - Dictionary: <code>{{ data['key'] }}</code> or <code>{{ data.key }}</code> - Object attributes: <code>{{ obj.attribute }}</code> - Nested: <code>{{ user.address.city }}</code></p>"},{"location":"en/tutorials/02-templates/#multiline-templates","title":"Multiline Templates","text":"<p>For complex prompts, use multiline docstrings:</p> <pre><code>@agent\nasync def write_email(\n    recipient: str,\n    subject: str,\n    points: List[str],\n    tone: str = \"professional\"\n) -&gt; str:\n    \"\"\"\n    Write an email with the following specifications:\n\n    To: {{ recipient }}\n    Subject: {{ subject }}\n    Tone: {{ tone }}\n\n    Key points to cover:\n    {% for point in points %}\n    {{ loop.index }}. {{ point }}\n    {% endfor %}\n\n    Make it {{ tone }} and concise.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/02-templates/#1-clear-instructions","title":"1. Clear Instructions","text":"<pre><code># \u2705 Good: Clear instructions\n@agent\nasync def translate(text: str, target_lang: str) -&gt; str:\n    \"\"\"\n    Translate the following text to {{ target_lang }}:\n    {{ text }}\n\n    Return only the translated text, no explanations.\n    \"\"\"\n    pass\n\n# \u274c Bad: Vague instructions\n@agent\nasync def translate(text: str, target_lang: str) -&gt; str:\n    \"\"\"{{ text }} {{ target_lang }}\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#2-structure-your-prompts","title":"2. Structure Your Prompts","text":"<pre><code>@agent\nasync def analyze(data: str) -&gt; str:\n    \"\"\"\n    ## Task\n    Analyze the following data.\n\n    ## Data\n    {{ data }}\n\n    ## Requirements\n    - Identify key trends\n    - Provide insights\n    - Be concise\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#3-use-conditionals-wisely","title":"3. Use Conditionals Wisely","text":"<pre><code>@agent\nasync def respond(message: str, context: str = None) -&gt; str:\n    \"\"\"\n    {% if context %}\n    Context: {{ context }}\n    {% endif %}\n\n    User message: {{ message }}\n\n    Respond appropriately{{ \" based on the context\" if context else \"\" }}.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#4-validate-input","title":"4. Validate Input","text":"<pre><code>@agent\nasync def process(items: List[str]) -&gt; str:\n    \"\"\"\n    {% if items %}\n    Process these items:\n    {% for item in items %}\n    - {{ item }}\n    {% endfor %}\n    {% else %}\n    No items to process.\n    {% endif %}\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#common-patterns","title":"Common Patterns","text":""},{"location":"en/tutorials/02-templates/#chain-of-thought","title":"Chain of Thought","text":"<pre><code>@agent\nasync def solve_math(problem: str) -&gt; str:\n    \"\"\"\n    Solve this math problem: {{ problem }}\n\n    Think step by step:\n    1. First, identify the operation\n    2. Then, calculate the result\n    3. Finally, verify your answer\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#few-shot-learning","title":"Few-Shot Learning","text":"<pre><code>@agent\nasync def classify(text: str) -&gt; str:\n    \"\"\"\n    Classify the sentiment of the text.\n\n    Examples:\n    Text: \"I love this!\" \u2192 Sentiment: positive\n    Text: \"This is terrible\" \u2192 Sentiment: negative\n    Text: \"It's okay\" \u2192 Sentiment: neutral\n\n    Text: {{ text }} \u2192 Sentiment: ?\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#role-based-prompts","title":"Role-Based Prompts","text":"<pre><code>@agent\nasync def code_review(code: str, language: str) -&gt; str:\n    \"\"\"\n    You are an expert {{ language }} developer.\n    Review this code and provide suggestions:\n\n    ```{{ language }}\n    {{ code }}\n    ```\n\n    Focus on:\n    - Code quality\n    - Best practices\n    - Potential bugs\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/02-templates/#template-syntax-errors","title":"Template Syntax Errors","text":"<pre><code># \u274c Wrong: Missing closing tag\n\"\"\"\n{% for item in items %}\n{{ item }}\n\"\"\"\n\n# \u2705 Correct: Proper closing\n\"\"\"\n{% for item in items %}\n{{ item }}\n{% endfor %}\n\"\"\"\n</code></pre>"},{"location":"en/tutorials/02-templates/#variable-not-found","title":"Variable Not Found","text":"<pre><code># \u274c Wrong: Variable doesn't match parameter\n@agent\nasync def greet(name: str) -&gt; str:\n    \"\"\"Hello {{ username }}\"\"\"  # username doesn't exist\n    pass\n\n# \u2705 Correct: Variable matches parameter\n@agent\nasync def greet(name: str) -&gt; str:\n    \"\"\"Hello {{ name }}\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#escaping-special-characters","title":"Escaping Special Characters","text":"<pre><code># If you need literal {{ or }}\n@agent\nasync def explain() -&gt; str:\n    \"\"\"\n    In Jinja2, use {% raw %}{{ variable }}{% endraw %} for templates.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#practice-exercises","title":"Practice Exercises","text":""},{"location":"en/tutorials/02-templates/#exercise-1-user-profile-generator","title":"Exercise 1: User Profile Generator","text":"<p>Create an agent that generates user profiles:</p> <pre><code>from typing import List\n\n@agent\nasync def create_profile(\n    name: str,\n    skills: List[str],\n    experience_years: int\n) -&gt; str:\n    \"\"\"\n    # TODO: Write template that:\n    # - Introduces the person\n    # - Lists their skills\n    # - Mentions experience level\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#exercise-2-conditional-email-writer","title":"Exercise 2: Conditional Email Writer","text":"<p>Create an agent with conditional formatting:</p> <pre><code>@agent\nasync def write_email(\n    recipient: str,\n    is_urgent: bool,\n    has_attachments: bool\n) -&gt; str:\n    \"\"\"\n    # TODO: Write template that:\n    # - Adds [URGENT] to subject if urgent\n    # - Mentions attachments if present\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#exercise-3-data-analyzer","title":"Exercise 3: Data Analyzer","text":"<p>Create an agent that analyzes data with loops:</p> <pre><code>from typing import Dict\n\n@agent\nasync def analyze_metrics(metrics: Dict[str, float]) -&gt; str:\n    \"\"\"\n    # TODO: Write template that:\n    # - Iterates over metrics\n    # - Highlights values &gt; 80\n    # - Provides summary\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial 03: Type-Based Parsing - Learn how to parse structured responses</li> <li>API Reference: Templates - Complete template documentation</li> </ul>"},{"location":"en/tutorials/02-templates/#additional-resources","title":"Additional Resources","text":"<ul> <li>Jinja2 Documentation</li> <li>Prompt Engineering Guide</li> </ul>"},{"location":"en/tutorials/03-type-parsing/","title":"Tutorial 03: Type-Based Parsing","text":"<p>Learn how to use Python type hints to automatically parse LLM responses into structured data.</p>"},{"location":"en/tutorials/03-type-parsing/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How type-based parsing works in Kagura</li> <li>Using Pydantic models for complex structures</li> <li>Handling lists, dicts, and nested objects</li> <li>Error handling and validation</li> </ul>"},{"location":"en/tutorials/03-type-parsing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Tutorial 01: Basic Agent</li> <li>Basic understanding of Python type hints</li> <li>Familiarity with Pydantic (helpful but not required)</li> </ul>"},{"location":"en/tutorials/03-type-parsing/#why-type-based-parsing","title":"Why Type-Based Parsing?","text":"<p>LLMs return unstructured text, but your application needs structured data. Kagura automatically converts LLM responses to Python types based on your return type annotation.</p> <pre><code># Without parsing: raw string\nasync def get_age(name: str) -&gt; str:\n    \"\"\"What is {{ name }}'s age?\"\"\"\n    pass\n\nresult = await get_age(\"Alice\")\n# result = \"Alice is 25 years old.\"  \u2190 Hard to use in code\n\n# With parsing: structured data\nasync def get_age(name: str) -&gt; int:\n    \"\"\"What is {{ name }}'s age? Return only the number.\"\"\"\n    pass\n\nresult = await get_age(\"Alice\")\n# result = 25  \u2190 Easy to use!\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#basic-types","title":"Basic Types","text":""},{"location":"en/tutorials/03-type-parsing/#strings","title":"Strings","text":"<pre><code>from kagura import agent\n\n@agent\nasync def summarize(text: str) -&gt; str:\n    \"\"\"Summarize this in one sentence: {{ text }}\"\"\"\n    pass\n\nresult = await summarize(\"Long article...\")\n# result: str = \"Article summary.\"\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#numbers","title":"Numbers","text":"<pre><code>@agent\nasync def count_words(text: str) -&gt; int:\n    \"\"\"Count the words in: {{ text }}. Return only the number.\"\"\"\n    pass\n\nresult = await count_words(\"Hello world\")\n# result: int = 2\n\n@agent\nasync def calculate_average(numbers: list[int]) -&gt; float:\n    \"\"\"Calculate the average of {{ numbers }}. Return only the number.\"\"\"\n    pass\n\nresult = await calculate_average([1, 2, 3, 4, 5])\n# result: float = 3.0\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#booleans","title":"Booleans","text":"<pre><code>@agent\nasync def is_positive(text: str) -&gt; bool:\n    \"\"\"Is this text positive in sentiment? {{ text }}\n    Return only 'true' or 'false'.\"\"\"\n    pass\n\nresult = await is_positive(\"I love this!\")\n# result: bool = True\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#collections","title":"Collections","text":""},{"location":"en/tutorials/03-type-parsing/#lists","title":"Lists","text":"<pre><code>from typing import List\n\n@agent\nasync def extract_keywords(text: str) -&gt; List[str]:\n    \"\"\"Extract keywords from: {{ text }}\n    Return as JSON array.\"\"\"\n    pass\n\nresult = await extract_keywords(\"Python is great for AI\")\n# result: List[str] = [\"Python\", \"AI\", \"programming\"]\n</code></pre> <p>Supported List Types: - <code>List[str]</code>: List of strings - <code>List[int]</code>: List of integers - <code>List[float]</code>: List of floats - <code>List[YourModel]</code>: List of Pydantic models</p>"},{"location":"en/tutorials/03-type-parsing/#dictionaries","title":"Dictionaries","text":"<pre><code>from typing import Dict\n\n@agent\nasync def extract_metadata(text: str) -&gt; Dict[str, str]:\n    \"\"\"Extract metadata from: {{ text }}\n    Return as JSON object.\"\"\"\n    pass\n\nresult = await extract_metadata(\"Title: Hello\\nAuthor: Alice\")\n# result: Dict[str, str] = {\"title\": \"Hello\", \"author\": \"Alice\"}\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#pydantic-models","title":"Pydantic Models","text":"<p>For complex structures, use Pydantic models:</p> <pre><code>from pydantic import BaseModel, Field\nfrom typing import List\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    email: str\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    \"\"\"Extract person information from: {{ text }}\n    Return as JSON object with fields: name, age, email.\"\"\"\n    pass\n\nresult = await extract_person(\"Alice (25) - alice@example.com\")\n# result: Person = Person(name=\"Alice\", age=25, email=\"alice@example.com\")\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#model-validation","title":"Model Validation","text":"<p>Pydantic automatically validates the data:</p> <pre><code>from pydantic import BaseModel, EmailStr, validator\n\nclass User(BaseModel):\n    name: str\n    email: EmailStr  # Validates email format\n    age: int\n\n    @validator('age')\n    def age_must_be_positive(cls, v):\n        if v &lt; 0:\n            raise ValueError('age must be positive')\n        return v\n\n@agent\nasync def extract_user(text: str) -&gt; User:\n    \"\"\"Extract user info from: {{ text }}\n    Return as JSON: {name, email, age}\"\"\"\n    pass\n\n# Valid input\nresult = await extract_user(\"Bob, bob@example.com, 30\")\n# result: User(name=\"Bob\", email=\"bob@example.com\", age=30)\n\n# Invalid input (bad email)\n# Will raise ValidationError\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#field-descriptions","title":"Field Descriptions","text":"<p>Help the LLM understand fields:</p> <pre><code>class Article(BaseModel):\n    title: str = Field(description=\"The article title\")\n    summary: str = Field(description=\"Brief summary, max 100 words\")\n    tags: List[str] = Field(description=\"Relevant tags, 3-5 items\")\n    published: bool = Field(description=\"Whether article is published\")\n\n@agent\nasync def analyze_article(content: str) -&gt; Article:\n    \"\"\"Analyze this article: {{ content }}\n    Return as JSON with: title, summary, tags, published.\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#nested-structures","title":"Nested Structures","text":""},{"location":"en/tutorials/03-type-parsing/#nested-models","title":"Nested Models","text":"<pre><code>class Address(BaseModel):\n    street: str\n    city: str\n    country: str\n\nclass Company(BaseModel):\n    name: str\n    address: Address\n    employees: int\n\n@agent\nasync def extract_company(text: str) -&gt; Company:\n    \"\"\"Extract company information from: {{ text }}\n    Return as JSON with nested address object.\"\"\"\n    pass\n\nresult = await extract_company(\"Acme Corp, 123 Main St, NYC, USA, 500 employees\")\n# result: Company(\n#     name=\"Acme Corp\",\n#     address=Address(street=\"123 Main St\", city=\"NYC\", country=\"USA\"),\n#     employees=500\n# )\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#lists-of-models","title":"Lists of Models","text":"<pre><code>class Task(BaseModel):\n    title: str\n    priority: str\n    estimated_hours: int\n\n@agent\nasync def extract_tasks(text: str) -&gt; List[Task]:\n    \"\"\"Extract tasks from: {{ text }}\n    Return as JSON array of objects.\"\"\"\n    pass\n\nresult = await extract_tasks(\"\"\"\n    1. Fix bug - High priority - 3 hours\n    2. Write docs - Low priority - 5 hours\n\"\"\")\n# result: List[Task] = [\n#     Task(title=\"Fix bug\", priority=\"High\", estimated_hours=3),\n#     Task(title=\"Write docs\", priority=\"Low\", estimated_hours=5)\n# ]\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"en/tutorials/03-type-parsing/#optional-fields","title":"Optional Fields","text":"<pre><code>from typing import Optional\n\nclass Product(BaseModel):\n    name: str\n    price: float\n    discount: Optional[float] = None\n    description: Optional[str] = None\n\n@agent\nasync def extract_product(text: str) -&gt; Product:\n    \"\"\"Extract product info from: {{ text }}\n    Return as JSON. discount and description are optional.\"\"\"\n    pass\n\nresult = await extract_product(\"Laptop $999\")\n# result: Product(name=\"Laptop\", price=999.0, discount=None, description=None)\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#union-types","title":"Union Types","text":"<pre><code>from typing import Union\n\n@agent\nasync def parse_value(text: str) -&gt; Union[int, str]:\n    \"\"\"Parse the value from: {{ text }}\n    Return as number if numeric, otherwise as string.\"\"\"\n    pass\n\nresult1 = await parse_value(\"42\")        # returns int: 42\nresult2 = await parse_value(\"hello\")     # returns str: \"hello\"\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#enums","title":"Enums","text":"<pre><code>from enum import Enum\n\nclass Priority(str, Enum):\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n\nclass Issue(BaseModel):\n    title: str\n    priority: Priority\n\n@agent\nasync def extract_issue(text: str) -&gt; Issue:\n    \"\"\"Extract issue from: {{ text }}\n    Priority must be: low, medium, or high.\"\"\"\n    pass\n\nresult = await extract_issue(\"Fix login bug - high priority\")\n# result: Issue(title=\"Fix login bug\", priority=Priority.HIGH)\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/03-type-parsing/#1-clear-return-format-instructions","title":"1. Clear Return Format Instructions","text":"<pre><code># \u2705 Good: Explicit format\n@agent\nasync def extract_data(text: str) -&gt; Person:\n    \"\"\"Extract person from: {{ text }}\n    Return as JSON: {\"name\": str, \"age\": int, \"email\": str}\"\"\"\n    pass\n\n# \u274c Bad: Unclear format\n@agent\nasync def extract_data(text: str) -&gt; Person:\n    \"\"\"Get person from: {{ text }}\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#2-use-field-descriptions","title":"2. Use Field Descriptions","text":"<pre><code># \u2705 Good: Descriptive fields\nclass Report(BaseModel):\n    summary: str = Field(description=\"Executive summary, 2-3 sentences\")\n    findings: List[str] = Field(description=\"Key findings, bullet points\")\n    score: int = Field(description=\"Overall score 0-100\")\n\n# \u274c Bad: No descriptions\nclass Report(BaseModel):\n    summary: str\n    findings: List[str]\n    score: int\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#3-validate-constraints","title":"3. Validate Constraints","text":"<pre><code>from pydantic import validator, Field\n\nclass Temperature(BaseModel):\n    celsius: float = Field(ge=-273.15, description=\"Temperature in Celsius\")\n\n    @validator('celsius')\n    def validate_temp(cls, v):\n        if v &lt; -273.15:\n            raise ValueError('Temperature below absolute zero')\n        return v\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#4-handle-errors-gracefully","title":"4. Handle Errors Gracefully","text":"<pre><code>from pydantic import ValidationError\n\n@agent\nasync def extract_safe(text: str) -&gt; Optional[Person]:\n    \"\"\"Extract person from: {{ text }}\n    Return as JSON or null if not found.\"\"\"\n    pass\n\ntry:\n    result = await extract_safe(\"No person here\")\nexcept ValidationError as e:\n    print(f\"Validation failed: {e}\")\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#error-handling","title":"Error Handling","text":""},{"location":"en/tutorials/03-type-parsing/#validation-errors","title":"Validation Errors","text":"<pre><code>from pydantic import ValidationError\n\n@agent\nasync def parse_age(text: str) -&gt; int:\n    \"\"\"Extract age from: {{ text }}. Return only the number.\"\"\"\n    pass\n\ntry:\n    result = await parse_age(\"Alice is twenty-five\")\n    # LLM returns \"twenty-five\" instead of 25\nexcept ValidationError as e:\n    print(f\"Failed to parse: {e}\")\n    # Handle error: retry, use default, etc.\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#missing-fields","title":"Missing Fields","text":"<pre><code>class Contact(BaseModel):\n    name: str\n    email: str\n    phone: str  # Required\n\n@agent\nasync def extract_contact(text: str) -&gt; Contact:\n    \"\"\"Extract contact from: {{ text }}\n    Return JSON with: name, email, phone.\"\"\"\n    pass\n\n# If LLM omits phone, ValidationError is raised\ntry:\n    result = await extract_contact(\"John, john@example.com\")\nexcept ValidationError as e:\n    print(\"Missing required field:\", e)\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#type-mismatches","title":"Type Mismatches","text":"<pre><code>@agent\nasync def get_count(text: str) -&gt; int:\n    \"\"\"Count items in: {{ text }}. Return only the number.\"\"\"\n    pass\n\n# If LLM returns \"five\" instead of 5\ntry:\n    result = await get_count(\"five items\")\nexcept ValidationError:\n    # Retry with more explicit instructions\n    @agent\n    async def get_count_strict(text: str) -&gt; int:\n        \"\"\"Count items in: {{ text }}.\n        Return ONLY a numeric digit, no words.\"\"\"\n        pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#common-patterns","title":"Common Patterns","text":""},{"location":"en/tutorials/03-type-parsing/#progressive-extraction","title":"Progressive Extraction","text":"<pre><code># Step 1: Extract basic info\n@agent\nasync def extract_basic(text: str) -&gt; Dict[str, str]:\n    \"\"\"Extract key-value pairs from: {{ text }}\"\"\"\n    pass\n\n# Step 2: Parse into model\nbasic = await extract_basic(text)\nperson = Person(**basic)\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#fallback-values","title":"Fallback Values","text":"<pre><code>class Config(BaseModel):\n    timeout: int = 30  # Default value\n    retries: int = 3\n    debug: bool = False\n\n@agent\nasync def parse_config(text: str) -&gt; Config:\n    \"\"\"Parse config from: {{ text }}\n    Use defaults for missing values.\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#multi-step-validation","title":"Multi-Step Validation","text":"<pre><code>class ValidatedData(BaseModel):\n    data: str\n\n    @validator('data')\n    def clean_data(cls, v):\n        # Clean and validate\n        return v.strip().lower()\n\n@agent\nasync def extract_and_validate(text: str) -&gt; ValidatedData:\n    \"\"\"Extract data from: {{ text }}\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#practice-exercises","title":"Practice Exercises","text":""},{"location":"en/tutorials/03-type-parsing/#exercise-1-contact-extractor","title":"Exercise 1: Contact Extractor","text":"<p>Create a model for contact information:</p> <pre><code>class Contact(BaseModel):\n    # TODO: Add fields for name, email, phone, company\n    pass\n\n@agent\nasync def extract_contact(text: str) -&gt; Contact:\n    \"\"\"# TODO: Write prompt to extract contact info\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#exercise-2-product-list-parser","title":"Exercise 2: Product List Parser","text":"<p>Parse a list of products:</p> <pre><code>class Product(BaseModel):\n    # TODO: Add fields for name, price, stock\n    pass\n\n@agent\nasync def parse_products(text: str) -&gt; List[Product]:\n    \"\"\"# TODO: Write prompt to parse product list\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#exercise-3-nested-organization","title":"Exercise 3: Nested Organization","text":"<p>Create a nested structure:</p> <pre><code>class Employee(BaseModel):\n    # TODO: name, role, salary\n    pass\n\nclass Department(BaseModel):\n    # TODO: name, employees list, budget\n    pass\n\n@agent\nasync def parse_org(text: str) -&gt; Department:\n    \"\"\"# TODO: Write prompt to parse organization\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/03-type-parsing/#llm-returns-wrong-format","title":"LLM Returns Wrong Format","text":"<pre><code># Problem: LLM returns \"The age is 25\" instead of just \"25\"\n\n# Solution: Be more explicit\n@agent\nasync def get_age(name: str) -&gt; int:\n    \"\"\"What is {{ name }}'s age?\n    IMPORTANT: Return ONLY the numeric age, nothing else.\n    Example: 25\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#validation-fails-repeatedly","title":"Validation Fails Repeatedly","text":"<pre><code># Problem: LLM returns data that fails validation\n\n# Solution: Relax constraints or provide examples\nclass Person(BaseModel):\n    age: int = Field(ge=0, le=150, description=\"Age between 0-150\")\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    \"\"\"Extract person from: {{ text }}\n    Return JSON: {\"name\": \"string\", \"age\": number between 0-150}\n    Example: {\"name\": \"Alice\", \"age\": 25}\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial 04: Code Execution - Execute Python code with AI</li> <li>API Reference: Type Parsing - Complete parsing documentation</li> <li>Pydantic Documentation - Learn more about Pydantic</li> </ul>"},{"location":"en/tutorials/03-type-parsing/#additional-resources","title":"Additional Resources","text":"<ul> <li>Type Hints Cheat Sheet</li> <li>Pydantic Field Types</li> </ul>"},{"location":"en/tutorials/04-code-execution/","title":"Tutorial 04: Code Execution","text":"<p>Learn how to safely execute Python code generated by AI agents.</p>"},{"location":"en/tutorials/04-code-execution/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How to use the <code>execute_code</code> agent</li> <li>Security constraints and sandboxing</li> <li>Working with execution results</li> <li>Building code-generating workflows</li> <li>Best practices for code execution</li> </ul>"},{"location":"en/tutorials/04-code-execution/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Tutorial 01: Basic Agent</li> <li>Understanding of Python basics</li> <li>Familiarity with security concepts (helpful)</li> </ul>"},{"location":"en/tutorials/04-code-execution/#why-code-execution","title":"Why Code Execution?","text":"<p>Sometimes the best way to solve a problem is to write and execute code. Kagura provides a safe way to let AI agents generate and run Python code:</p> <pre><code>from kagura.agents import execute_code\n\nresult = await execute_code(\"Calculate the factorial of 10\")\n\nif result[\"success\"]:\n    print(result[\"result\"])  # 3628800\n    print(result[\"code\"])    # Shows the generated code\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#basic-usage","title":"Basic Usage","text":""},{"location":"en/tutorials/04-code-execution/#simple-calculations","title":"Simple Calculations","text":"<pre><code>from kagura.agents import execute_code\n\n# Mathematical operations\nresult = await execute_code(\"What is 2^10?\")\nprint(result[\"result\"])  # 1024\n\n# Data processing\nresult = await execute_code(\"Sum the numbers from 1 to 100\")\nprint(result[\"result\"])  # 5050\n\n# String operations\nresult = await execute_code(\"Reverse the string 'hello'\")\nprint(result[\"result\"])  # \"olleh\"\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#understanding-the-result","title":"Understanding the Result","text":"<p>The <code>execute_code</code> function returns a dictionary:</p> <pre><code>result = {\n    \"success\": True,         # Whether execution succeeded\n    \"result\": 3628800,       # The value of the `result` variable\n    \"code\": \"...\",          # The generated Python code\n    \"error\": None           # Error message if failed\n}\n</code></pre> <p>Important: The executed code must set a variable named <code>result</code>:</p> <pre><code># \u2705 Good: Sets result variable\nresult = await execute_code(\"Calculate 5 * 5\")\n# Generated code: result = 5 * 5\n\n# \u274c Bad: Doesn't set result\nresult = await execute_code(\"Print hello world\")\n# No result variable \u2192 result[\"result\"] is None\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#data-processing","title":"Data Processing","text":""},{"location":"en/tutorials/04-code-execution/#working-with-lists","title":"Working with Lists","text":"<pre><code># Filter data\nresult = await execute_code(\"\"\"\nFind all even numbers in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\"\"\")\nprint(result[\"result\"])  # [2, 4, 6, 8, 10]\n\n# Transform data\nresult = await execute_code(\"\"\"\nSquare each number in [1, 2, 3, 4, 5]\n\"\"\")\nprint(result[\"result\"])  # [1, 4, 9, 16, 25]\n\n# Aggregate data\nresult = await execute_code(\"\"\"\nCalculate the average of [10, 20, 30, 40, 50]\n\"\"\")\nprint(result[\"result\"])  # 30.0\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#working-with-dictionaries","title":"Working with Dictionaries","text":"<pre><code># Extract data\nresult = await execute_code(\"\"\"\nFrom this data: {'name': 'Alice', 'age': 25, 'city': 'NYC'}\nExtract the age\n\"\"\")\nprint(result[\"result\"])  # 25\n\n# Transform data\nresult = await execute_code(\"\"\"\nConvert this data to uppercase keys:\n{'name': 'Alice', 'role': 'engineer'}\n\"\"\")\nprint(result[\"result\"])  # {'NAME': 'Alice', 'ROLE': 'engineer'}\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#json-processing","title":"JSON Processing","text":"<pre><code>import json\n\n# Parse and analyze JSON\njson_data = json.dumps({\n    \"users\": [\n        {\"name\": \"Alice\", \"score\": 95},\n        {\"name\": \"Bob\", \"score\": 87},\n        {\"name\": \"Charlie\", \"score\": 92}\n    ]\n})\n\nresult = await execute_code(f\"\"\"\nParse this JSON and find the average score:\n{json_data}\n\"\"\")\nprint(result[\"result\"])  # 91.33...\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#advanced-features","title":"Advanced Features","text":""},{"location":"en/tutorials/04-code-execution/#multi-step-calculations","title":"Multi-Step Calculations","text":"<pre><code>result = await execute_code(\"\"\"\n1. Create a list of numbers from 1 to 20\n2. Filter only prime numbers\n3. Calculate their sum\n\"\"\")\n\nprint(result[\"code\"])    # See the generated algorithm\nprint(result[\"result\"])  # Sum of primes\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#custom-algorithms","title":"Custom Algorithms","text":"<pre><code>result = await execute_code(\"\"\"\nImplement the Fibonacci sequence up to the 10th number\n\"\"\")\n\nprint(result[\"result\"])  # [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#data-analysis","title":"Data Analysis","text":"<pre><code>result = await execute_code(\"\"\"\nGiven these test scores: [78, 92, 85, 88, 95, 72, 90]\nCalculate:\n- Mean\n- Median\n- Mode (if exists)\nReturn as a dictionary\n\"\"\")\n\nprint(result[\"result\"])\n# {'mean': 85.71, 'median': 88, 'mode': None}\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#security","title":"Security","text":"<p>Kagura executes code in a sandboxed environment with strict security constraints.</p>"},{"location":"en/tutorials/04-code-execution/#allowed-modules","title":"Allowed Modules","text":"<pre><code># \u2705 Allowed: Safe standard library modules\nresult = await execute_code(\"\"\"\nimport math\nresult = math.sqrt(16)\n\"\"\")\n# Success: 4.0\n\nresult = await execute_code(\"\"\"\nimport json\nresult = json.dumps({'key': 'value'})\n\"\"\")\n# Success: '{\"key\": \"value\"}'\n\nresult = await execute_code(\"\"\"\nfrom datetime import datetime\nresult = datetime.now().year\n\"\"\")\n# Success: 2025\n</code></pre> <p>Allowed modules: - <code>math</code>, <code>random</code>, <code>statistics</code> - <code>json</code>, <code>re</code>, <code>string</code> - <code>datetime</code>, <code>collections</code>, <code>itertools</code> - <code>functools</code>, <code>operator</code>, <code>copy</code></p>"},{"location":"en/tutorials/04-code-execution/#forbidden-operations","title":"Forbidden Operations","text":"<pre><code># \u274c File system access\nresult = await execute_code(\"Read file config.txt\")\n# Error: Forbidden import: os\n\n# \u274c Network access\nresult = await execute_code(\"Fetch data from https://api.example.com\")\n# Error: Forbidden import: requests\n\n# \u274c System commands\nresult = await execute_code(\"Run shell command ls\")\n# Error: Forbidden import: subprocess\n\n# \u274c Code execution\nresult = await execute_code(\"Execute eval('1+1')\")\n# Error: Forbidden operation: eval\n</code></pre> <p>Forbidden modules/operations: - File I/O: <code>os</code>, <code>sys</code>, <code>io</code>, <code>pathlib</code>, <code>open()</code> - Network: <code>socket</code>, <code>urllib</code>, <code>requests</code> - Execution: <code>eval</code>, <code>exec</code>, <code>compile</code>, <code>__import__</code> - System: <code>subprocess</code>, <code>multiprocessing</code></p>"},{"location":"en/tutorials/04-code-execution/#timeout-protection","title":"Timeout Protection","text":"<pre><code>from kagura.core.executor import CodeExecutor\n\n# Default timeout: 5 seconds\nexecutor = CodeExecutor()\n\n# Custom timeout\nexecutor = CodeExecutor(timeout=10.0)\n\nresult = await executor.execute(\"\"\"\nimport time\ntime.sleep(15)  # Will timeout after 10 seconds\nresult = \"done\"\n\"\"\")\n\nprint(result.success)  # False\nprint(result.error)    # \"Execution timeout\"\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#custom-codeexecutor","title":"Custom CodeExecutor","text":"<p>For advanced use cases, use <code>CodeExecutor</code> directly:</p> <pre><code>from kagura.core.executor import CodeExecutor\n\n# Create executor with custom settings\nexecutor = CodeExecutor(\n    timeout=10.0,           # 10 second timeout\n    max_output_size=1000    # Limit output size\n)\n\n# Execute code\nresult = await executor.execute(\"\"\"\nresult = sum(range(1, 1001))\n\"\"\")\n\nprint(result.success)    # True\nprint(result.result)     # 500500\nprint(result.code)       # Generated code\nprint(result.error)      # None\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#execution-result-object","title":"Execution Result Object","text":"<pre><code>from kagura.core.executor import ExecutionResult\n\nresult = await executor.execute(\"result = 42\")\n\n# Result attributes\nprint(result.success)    # bool: True/False\nprint(result.result)     # Any: The result value\nprint(result.code)       # str: Executed code\nprint(result.error)      # Optional[str]: Error message\nprint(result.stdout)     # str: Standard output\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#building-code-workflows","title":"Building Code Workflows","text":""},{"location":"en/tutorials/04-code-execution/#plan-code-execute-pattern","title":"Plan-Code-Execute Pattern","text":"<pre><code>from kagura import agent\nfrom kagura.agents import execute_code\n\n@agent\nasync def plan_solution(problem: str) -&gt; str:\n    \"\"\"\n    Analyze this problem and describe the algorithm:\n    {{ problem }}\n\n    Provide step-by-step approach.\n    \"\"\"\n    pass\n\nasync def solve_with_code(problem: str):\n    # Step 1: Plan\n    plan = await plan_solution(problem)\n    print(f\"Plan: {plan}\")\n\n    # Step 2: Execute\n    result = await execute_code(problem)\n\n    # Step 3: Verify\n    if result[\"success\"]:\n        print(f\"Result: {result['result']}\")\n        print(f\"Code:\\n{result['code']}\")\n    else:\n        print(f\"Error: {result['error']}\")\n\n# Use it\nawait solve_with_code(\"Find all prime numbers between 1 and 50\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#iterative-refinement","title":"Iterative Refinement","text":"<pre><code>async def solve_with_retry(problem: str, max_retries: int = 3):\n    for attempt in range(max_retries):\n        result = await execute_code(problem)\n\n        if result[\"success\"]:\n            return result[\"result\"]\n\n        # If failed, try with more specific instructions\n        problem = f\"{problem}\\n\\nPrevious error: {result['error']}\\nPlease fix and try again.\"\n\n    raise Exception(f\"Failed after {max_retries} attempts\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#code-review-agent","title":"Code Review Agent","text":"<pre><code>@agent\nasync def review_code(code: str) -&gt; str:\n    \"\"\"\n    Review this Python code for:\n    - Correctness\n    - Efficiency\n    - Best practices\n\n    Code:\n    ```python\n    {{ code }}\n    ```\n    \"\"\"\n    pass\n\nasync def code_and_review(problem: str):\n    # Generate code\n    result = await execute_code(problem)\n\n    if result[\"success\"]:\n        # Review the code\n        review = await review_code(result[\"code\"])\n        print(f\"Review: {review}\")\n\n        return result[\"result\"]\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/04-code-execution/#1-clear-specifications","title":"1. Clear Specifications","text":"<pre><code># \u2705 Good: Clear requirements\nresult = await execute_code(\"\"\"\nCalculate the factorial of 10.\nStore the result in a variable named 'result'.\n\"\"\")\n\n# \u274c Bad: Vague request\nresult = await execute_code(\"Do factorial stuff\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#2-handle-errors","title":"2. Handle Errors","text":"<pre><code># \u2705 Good: Error handling\nresult = await execute_code(problem)\n\nif result[\"success\"]:\n    process_result(result[\"result\"])\nelse:\n    logger.error(f\"Code execution failed: {result['error']}\")\n    fallback_solution()\n\n# \u274c Bad: No error handling\nresult = await execute_code(problem)\nprocess_result(result[\"result\"])  # May fail!\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#3-validate-results","title":"3. Validate Results","text":"<pre><code># \u2705 Good: Validate output\nresult = await execute_code(\"Calculate sum of [1,2,3]\")\n\nif result[\"success\"]:\n    value = result[\"result\"]\n    if isinstance(value, (int, float)) and value &gt; 0:\n        use_result(value)\n    else:\n        raise ValueError(f\"Unexpected result: {value}\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#4-provide-context","title":"4. Provide Context","text":"<pre><code># \u2705 Good: Context and examples\nresult = await execute_code(f\"\"\"\nGiven this data: {json.dumps(data)}\nExtract all items where status is 'active'\nReturn as a list\n\nExample output: [item1, item2, ...]\n\"\"\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#5-use-appropriate-timeout","title":"5. Use Appropriate Timeout","text":"<pre><code># \u2705 Good: Adjust timeout based on task\nexecutor = CodeExecutor(timeout=1.0)   # Quick tasks\nresult = await executor.execute(\"result = 2 + 2\")\n\nexecutor = CodeExecutor(timeout=30.0)  # Complex tasks\nresult = await executor.execute(\"Analyze large dataset...\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#common-patterns","title":"Common Patterns","text":""},{"location":"en/tutorials/04-code-execution/#data-transformation-pipeline","title":"Data Transformation Pipeline","text":"<pre><code>async def transform_data(data: list, operations: list[str]):\n    \"\"\"Apply multiple transformations to data\"\"\"\n    current_data = data\n\n    for operation in operations:\n        result = await execute_code(f\"\"\"\nApply this operation to the data: {operation}\nData: {current_data}\n\"\"\")\n        if result[\"success\"]:\n            current_data = result[\"result\"]\n        else:\n            raise Exception(f\"Failed: {result['error']}\")\n\n    return current_data\n\n# Use it\ndata = [1, 2, 3, 4, 5]\noperations = [\n    \"Multiply each by 2\",\n    \"Filter numbers &gt; 5\",\n    \"Sum all numbers\"\n]\nresult = await transform_data(data, operations)\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#calculator-agent","title":"Calculator Agent","text":"<pre><code>@agent\nasync def calculate(expression: str) -&gt; float:\n    \"\"\"A calculator agent that evaluates expressions\"\"\"\n    result = await execute_code(f\"Calculate: {expression}\")\n\n    if result[\"success\"]:\n        return result[\"result\"]\n    else:\n        raise ValueError(f\"Calculation failed: {result['error']}\")\n\n# Use it\nanswer = await calculate(\"(5 + 3) * 2 - 10\")\nprint(answer)  # 6.0\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#data-analysis-agent","title":"Data Analysis Agent","text":"<pre><code>async def analyze_dataset(data: list[dict], query: str):\n    \"\"\"Analyze structured data with natural language\"\"\"\n    data_str = json.dumps(data)\n\n    result = await execute_code(f\"\"\"\nDataset: {data_str}\nQuery: {query}\n\nAnalyze the dataset and answer the query.\n\"\"\")\n\n    return result[\"result\"] if result[\"success\"] else None\n\n# Use it\nsales_data = [\n    {\"product\": \"A\", \"revenue\": 1000},\n    {\"product\": \"B\", \"revenue\": 1500},\n    {\"product\": \"C\", \"revenue\": 800}\n]\n\nresult = await analyze_dataset(\n    sales_data,\n    \"What is the total revenue?\"\n)\nprint(result)  # 3300\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#practice-exercises","title":"Practice Exercises","text":""},{"location":"en/tutorials/04-code-execution/#exercise-1-prime-number-finder","title":"Exercise 1: Prime Number Finder","text":"<pre><code># TODO: Create a function that finds prime numbers\nasync def find_primes(n: int):\n    \"\"\"Find all prime numbers up to n\"\"\"\n    result = await execute_code(f\"\"\"\n    Find all prime numbers up to {n}\n    Return as a list\n    \"\"\")\n    return result[\"result\"] if result[\"success\"] else []\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#exercise-2-data-aggregator","title":"Exercise 2: Data Aggregator","text":"<pre><code># TODO: Create a function that aggregates data\nasync def aggregate_sales(sales: list[dict]) -&gt; dict:\n    \"\"\"Calculate total, average, min, max from sales data\"\"\"\n    # Use execute_code to analyze the sales list\n    pass\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#exercise-3-text-analyzer","title":"Exercise 3: Text Analyzer","text":"<pre><code># TODO: Create a function that analyzes text\nasync def analyze_text(text: str) -&gt; dict:\n    \"\"\"\n    Analyze text and return:\n    - word_count\n    - unique_words\n    - most_common_word\n    - average_word_length\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/04-code-execution/#result-is-none","title":"Result is None","text":"<pre><code># Problem: result[\"result\"] is None\n\n# Cause: Code doesn't set 'result' variable\nresult = await execute_code(\"print(42)\")  # Only prints\n\n# Solution: Ask for explicit result\nresult = await execute_code(\"Calculate 42 and store in result variable\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#timeout-errors","title":"Timeout Errors","text":"<pre><code># Problem: Execution timeout\n\n# Cause: Complex operation or infinite loop\nresult = await execute_code(\"Calculate factorial of 100000\")\n\n# Solution: Increase timeout or simplify\nexecutor = CodeExecutor(timeout=30.0)\nresult = await executor.execute(\"Calculate factorial of 100\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#security-errors","title":"Security Errors","text":"<pre><code># Problem: Forbidden import error\n\n# Cause: Trying to use restricted module\nresult = await execute_code(\"Read file data.txt\")\n\n# Solution: Use allowed modules or provide data\nresult = await execute_code(f\"Process this data: {data}\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial 05: Interactive REPL - Interactive development environment</li> <li>API Reference: Code Execution - Complete executor documentation</li> <li>Examples: Code Generator - Full example</li> </ul>"},{"location":"en/tutorials/04-code-execution/#additional-resources","title":"Additional Resources","text":"<ul> <li>Python Security Best Practices</li> <li>AST Module Documentation</li> </ul>"},{"location":"en/tutorials/05-repl/","title":"Tutorial 5: Using the Interactive REPL","text":"<p>Learn how to use Kagura AI's interactive REPL for rapid prototyping and testing.</p>"},{"location":"en/tutorials/05-repl/#what-is-the-repl","title":"What is the REPL?","text":"<p>REPL stands for Read-Eval-Print Loop - an interactive environment where you can: - Define agents on the fly - Test them immediately - Iterate quickly without writing files - Experiment with different prompts and models</p>"},{"location":"en/tutorials/05-repl/#starting-the-repl","title":"Starting the REPL","text":"<pre><code>kagura repl\n</code></pre> <p>You'll see the welcome screen:</p> <pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Kagura AI REPL                       \u2502\n\u2502 Python-First AI Agent Framework      \u2502\n\u2502                                      \u2502\n\u2502 Type /help for commands, /exit to    \u2502\n\u2502 quit                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n&gt;&gt;&gt;\n</code></pre>"},{"location":"en/tutorials/05-repl/#environment-setup","title":"Environment Setup","text":""},{"location":"en/tutorials/05-repl/#api-keys-with-env-file","title":"API Keys with .env File","text":"<p>The REPL automatically loads environment variables from a <code>.env</code> file in your project directory. This is the recommended way to manage API keys:</p> <p>Step 1: Create a <code>.env</code> file in your project root:</p> <pre><code># .env\nOPENAI_API_KEY=sk-...\nANTHROPIC_API_KEY=sk-ant-...\nGOOGLE_API_KEY=...\n</code></pre> <p>Step 2: Start the REPL (the <code>.env</code> file is loaded automatically):</p> <pre><code>kagura repl\n</code></pre> <p>That's it! No need to manually export environment variables.</p> <p>Note: Copy <code>.env.example</code> to <code>.env</code> to get started: <pre><code>cp .env.example .env\n# Edit .env and add your API keys\n</code></pre></p>"},{"location":"en/tutorials/05-repl/#command-history","title":"Command History","text":"<p>The REPL automatically saves your command history to <code>~/.kagura_history</code>. This means: - Up/Down arrows work to navigate your previous commands - History persists across REPL sessions - Up to 1000 commands are saved</p> <p>This makes it easy to: - Rerun previous commands - Edit and retry agent definitions - Resume work from previous sessions</p>"},{"location":"en/tutorials/05-repl/#basic-usage","title":"Basic Usage","text":""},{"location":"en/tutorials/05-repl/#import-and-define","title":"Import and Define","text":"<pre><code>&gt;&gt;&gt; from kagura import agent\n&gt;&gt;&gt;\n&gt;&gt;&gt; @agent\n... async def hello(name: str) -&gt; str:\n...     '''Say hello to {{ name }}'''\n...     pass\n...\nAgent 'hello' defined\n</code></pre>"},{"location":"en/tutorials/05-repl/#call-the-agent","title":"Call the Agent","text":"<pre><code>&gt;&gt;&gt; await hello(\"World\")\nHello, World! How can I help you today?\n</code></pre> <p>That's it! No files, no boilerplate - just define and run.</p>"},{"location":"en/tutorials/05-repl/#repl-commands","title":"REPL Commands","text":"<p>Commands start with <code>/</code>:</p>"},{"location":"en/tutorials/05-repl/#help-show-help","title":"/help - Show Help","text":"<pre><code>&gt;&gt;&gt; /help\nAvailable Commands:\n  /help      - Show this help message\n  /agents    - List all defined agents\n  /exit      - Exit REPL\n  /clear     - Clear screen\n  /model     - Show or set default model\n  /temp      - Show or set default temperature\n</code></pre>"},{"location":"en/tutorials/05-repl/#agents-list-agents","title":"/agents - List Agents","text":"<pre><code>&gt;&gt;&gt; /agents\nDefined Agents:\n  hello(name: str) -&gt; str\n  translate(text: str, lang: str) -&gt; str\n</code></pre>"},{"location":"en/tutorials/05-repl/#model-change-model","title":"/model - Change Model","text":"<pre><code>&gt;&gt;&gt; /model\nCurrent model: gpt-4o-mini\n\n&gt;&gt;&gt; /model gpt-4o\nModel changed to: gpt-4o\n</code></pre>"},{"location":"en/tutorials/05-repl/#temp-change-temperature","title":"/temp - Change Temperature","text":"<pre><code>&gt;&gt;&gt; /temp\nCurrent temperature: 0.7\n\n&gt;&gt;&gt; /temp 1.2\nTemperature changed to: 1.2\n</code></pre>"},{"location":"en/tutorials/05-repl/#clear-clear-screen","title":"/clear - Clear Screen","text":"<pre><code>&gt;&gt;&gt; /clear\n# Screen clears\n</code></pre>"},{"location":"en/tutorials/05-repl/#exit-exit-repl","title":"/exit - Exit REPL","text":"<pre><code>&gt;&gt;&gt; /exit\nGoodbye!\n</code></pre>"},{"location":"en/tutorials/05-repl/#multi-line-input","title":"Multi-line Input","text":"<p>The REPL automatically detects multi-line statements:</p> <pre><code>&gt;&gt;&gt; from pydantic import BaseModel\n&gt;&gt;&gt;\n&gt;&gt;&gt; class Person(BaseModel):\n...     name: str\n...     age: int\n...     occupation: str\n...\n&gt;&gt;&gt;\n&gt;&gt;&gt; @agent\n... async def extract_person(text: str) -&gt; Person:\n...     '''Extract person info from: {{ text }}'''\n...     pass\n...\nAgent 'extract_person' defined\n</code></pre>"},{"location":"en/tutorials/05-repl/#practical-workflow","title":"Practical Workflow","text":""},{"location":"en/tutorials/05-repl/#1-quick-testing","title":"1. Quick Testing","text":"<p>Test ideas quickly:</p> <pre><code>&gt;&gt;&gt; @agent\n... async def v1(text: str) -&gt; str:\n...     '''Summarize: {{ text }}'''\n...     pass\n...\n&gt;&gt;&gt; await v1(\"Long text here...\")\nSummary here...\n\n&gt;&gt;&gt; @agent\n... async def v2(text: str) -&gt; str:\n...     '''Summarize in bullet points: {{ text }}'''\n...     pass\n...\n&gt;&gt;&gt; await v2(\"Long text here...\")\n- Point 1\n- Point 2\n</code></pre>"},{"location":"en/tutorials/05-repl/#2-iterative-refinement","title":"2. Iterative Refinement","text":"<p>Refine your prompts:</p> <pre><code>&gt;&gt;&gt; @agent\n... async def summarize_v1(text: str) -&gt; str:\n...     '''Summarize: {{ text }}'''\n...     pass\n...\n&gt;&gt;&gt; result1 = await summarize_v1(\"Long article...\")\n&gt;&gt;&gt; # Not quite right, let's try again\n\n&gt;&gt;&gt; @agent\n... async def summarize_v2(text: str) -&gt; str:\n...     '''Provide a concise summary in 2-3 sentences: {{ text }}'''\n...     pass\n...\n&gt;&gt;&gt; result2 = await summarize_v2(\"Long article...\")\n&gt;&gt;&gt; # Better!\n</code></pre>"},{"location":"en/tutorials/05-repl/#3-debugging","title":"3. Debugging","text":"<p>Inspect results:</p> <pre><code>&gt;&gt;&gt; result = await extract_person(\"Alice is 30 years old and works as an engineer\")\n&gt;&gt;&gt; print(result)\nPerson(name='Alice', age=30, occupation='engineer')\n\n&gt;&gt;&gt; print(type(result))\n&lt;class '__main__.Person'&gt;\n\n&gt;&gt;&gt; print(result.model_dump())\n{'name': 'Alice', 'age': 30, 'occupation': 'engineer'}\n</code></pre>"},{"location":"en/tutorials/05-repl/#4-composition","title":"4. Composition","text":"<p>Chain agents together:</p> <pre><code>&gt;&gt;&gt; @agent\n... async def extract_topic(text: str) -&gt; str:\n...     '''Extract the main topic from: {{ text }}'''\n...     pass\n...\n&gt;&gt;&gt; @agent\n... async def elaborate(topic: str) -&gt; str:\n...     '''Elaborate on: {{ topic }}'''\n...     pass\n...\n&gt;&gt;&gt; topic = await extract_topic(\"Quantum computing is revolutionary...\")\n&gt;&gt;&gt; await elaborate(topic)\nQuantum computing is a revolutionary technology...\n</code></pre>"},{"location":"en/tutorials/05-repl/#advanced-features","title":"Advanced Features","text":""},{"location":"en/tutorials/05-repl/#using-code-execution","title":"Using Code Execution","text":"<pre><code>&gt;&gt;&gt; from kagura.agents import execute_code\n&gt;&gt;&gt;\n&gt;&gt;&gt; result = await execute_code(\"Calculate fibonacci(15)\")\n&gt;&gt;&gt; result[\"result\"]\n610\n</code></pre>"},{"location":"en/tutorials/05-repl/#trying-different-models","title":"Trying Different Models","text":"<pre><code>&gt;&gt;&gt; @agent(model=\"gpt-4o\")\n... async def advanced(query: str) -&gt; str:\n...     '''Answer with deep analysis: {{ query }}'''\n...     pass\n...\n&gt;&gt;&gt; @agent(model=\"gpt-4o-mini\")\n... async def simple(query: str) -&gt; str:\n...     '''Answer briefly: {{ query }}'''\n...     pass\n...\n</code></pre>"},{"location":"en/tutorials/05-repl/#custom-temperature","title":"Custom Temperature","text":"<pre><code>&gt;&gt;&gt; @agent(temperature=0.1)  # Very deterministic\n... async def factual(query: str) -&gt; str:\n...     '''Provide factual answer: {{ query }}'''\n...     pass\n...\n&gt;&gt;&gt; @agent(temperature=1.5)  # More creative\n... async def creative(topic: str) -&gt; str:\n...     '''Write a creative story about: {{ topic }}'''\n...     pass\n...\n</code></pre>"},{"location":"en/tutorials/05-repl/#tips-and-tricks","title":"Tips and Tricks","text":""},{"location":"en/tutorials/05-repl/#1-use-variables","title":"1. Use Variables","text":"<p>Store results for reuse:</p> <pre><code>&gt;&gt;&gt; text = \"Long article text here...\"\n&gt;&gt;&gt; summary = await summarize(text)\n&gt;&gt;&gt; keywords = await extract_keywords(summary)\n</code></pre>"},{"location":"en/tutorials/05-repl/#2-quick-imports","title":"2. Quick Imports","text":"<p>Import common modules at the start:</p> <pre><code>&gt;&gt;&gt; from kagura import agent\n&gt;&gt;&gt; from pydantic import BaseModel\n&gt;&gt;&gt; from typing import List, Optional\n</code></pre>"},{"location":"en/tutorials/05-repl/#3-test-error-handling","title":"3. Test Error Handling","text":"<pre><code>&gt;&gt;&gt; try:\n...     result = await my_agent(\"test\")\n... except Exception as e:\n...     print(f\"Error: {e}\")\n</code></pre>"},{"location":"en/tutorials/05-repl/#4-save-working-code","title":"4. Save Working Code","text":"<p>Once you have working code, copy it to a <code>.py</code> file:</p> <pre><code># From REPL:\n&gt;&gt;&gt; @agent\n... async def working_agent(x: str) -&gt; str:\n...     '''Process {{ x }}'''\n...     pass\n\n# Copy to agent.py:\nfrom kagura import agent\n\n@agent\nasync def working_agent(x: str) -&gt; str:\n    '''Process {{ x }}'''\n    pass\n</code></pre>"},{"location":"en/tutorials/05-repl/#common-workflows","title":"Common Workflows","text":""},{"location":"en/tutorials/05-repl/#workflow-1-prompt-engineering","title":"Workflow 1: Prompt Engineering","text":"<pre><code># Start REPL\n$ kagura repl\n\n# Test different prompts\n&gt;&gt;&gt; @agent\n... async def v1(text: str) -&gt; str:\n...     '''{{ text }}'''\n...     pass\n&gt;&gt;&gt; await v1(\"Summarize this\")\n\n&gt;&gt;&gt; @agent\n... async def v2(text: str) -&gt; str:\n...     '''Provide a detailed summary of: {{ text }}'''\n...     pass\n&gt;&gt;&gt; await v2(\"Summarize this\")\n\n# Find the best prompt, save to file\n</code></pre>"},{"location":"en/tutorials/05-repl/#workflow-2-model-comparison","title":"Workflow 2: Model Comparison","text":"<pre><code>&gt;&gt;&gt; @agent(model=\"gpt-4o-mini\")\n... async def fast(q: str) -&gt; str:\n...     '''Answer: {{ q }}'''\n...     pass\n\n&gt;&gt;&gt; @agent(model=\"gpt-4o\")\n... async def accurate(q: str) -&gt; str:\n...     '''Answer: {{ q }}'''\n...     pass\n\n&gt;&gt;&gt; await fast(\"Explain quantum computing\")\n&gt;&gt;&gt; await accurate(\"Explain quantum computing\")\n# Compare outputs\n</code></pre>"},{"location":"en/tutorials/05-repl/#workflow-3-data-extraction-testing","title":"Workflow 3: Data Extraction Testing","text":"<pre><code>&gt;&gt;&gt; from pydantic import BaseModel\n&gt;&gt;&gt; from typing import List\n\n&gt;&gt;&gt; class Item(BaseModel):\n...     name: str\n...     price: float\n\n&gt;&gt;&gt; @agent\n... async def extract_items(text: str) -&gt; List[Item]:\n...     '''Extract items and prices from: {{ text }}'''\n...     pass\n\n&gt;&gt;&gt; test_text = \"Apple $1.50, Banana $0.75\"\n&gt;&gt;&gt; await extract_items(test_text)\n[Item(name='Apple', price=1.5), Item(name='Banana', price=0.75)]\n</code></pre>"},{"location":"en/tutorials/05-repl/#keyboard-shortcuts","title":"Keyboard Shortcuts","text":"<ul> <li>\u2191/\u2193: Navigate command history (persistent across sessions, saved to <code>~/.kagura_history</code>)</li> <li>Tab: Auto-complete (when available)</li> <li>Ctrl+C: Cancel current input</li> <li>Ctrl+D: Exit REPL (saves history on exit)</li> </ul>"},{"location":"en/tutorials/05-repl/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/05-repl/#import-errors","title":"Import Errors","text":"<pre><code>&gt;&gt;&gt; from kagura import agent\nModuleNotFoundError: No module named 'kagura'\n</code></pre> <p>Solution: Ensure Kagura AI is installed in the current environment: <pre><code>pip install kagura-ai\n</code></pre></p>"},{"location":"en/tutorials/05-repl/#api-key-errors","title":"API Key Errors","text":"<pre><code>&gt;&gt;&gt; await hello(\"test\")\nAuthenticationError: API key not found\n</code></pre> <p>Solution 1 (Recommended): Create a <code>.env</code> file: <pre><code># Create .env file\necho \"OPENAI_API_KEY=your-key-here\" &gt; .env\nkagura repl\n</code></pre></p> <p>Solution 2: Export environment variable: <pre><code>export OPENAI_API_KEY=\"your-key-here\"\nkagura repl\n</code></pre></p>"},{"location":"en/tutorials/05-repl/#memory-issues","title":"Memory Issues","text":"<p>If the REPL becomes slow: - Exit and restart: <code>/exit</code> - Clear large variables: <code>del big_variable</code></p>"},{"location":"en/tutorials/05-repl/#best-practices","title":"Best Practices","text":"<ol> <li>Start Simple: Begin with basic agents, then add complexity</li> <li>Test Incrementally: Test each change before moving on</li> <li>Save Working Code: Copy successful agents to files</li> <li>Use Variables: Store reusable data in variables</li> <li>Clean Up: Delete large variables when done</li> </ol>"},{"location":"en/tutorials/05-repl/#example-session","title":"Example Session","text":"<p>Complete example of a REPL session:</p> <pre><code>$ kagura repl\n\n&gt;&gt;&gt; from kagura import agent\n&gt;&gt;&gt; from pydantic import BaseModel\n\n&gt;&gt;&gt; class Task(BaseModel):\n...     title: str\n...     priority: int\n\n&gt;&gt;&gt; @agent\n... async def extract_task(text: str) -&gt; Task:\n...     '''Extract task from: {{ text }}'''\n...     pass\n...\nAgent 'extract_task' defined\n\n&gt;&gt;&gt; task = await extract_task(\"Fix the login bug (high priority)\")\n&gt;&gt;&gt; print(task)\nTask(title='Fix the login bug', priority=3)\n\n&gt;&gt;&gt; @agent\n... async def create_issue(task: Task) -&gt; str:\n...     '''Create a GitHub issue for task: {{ task.title }} (priority: {{ task.priority }})'''\n...     pass\n...\nAgent 'create_issue' defined\n\n&gt;&gt;&gt; issue = await create_issue(task)\n&gt;&gt;&gt; print(issue)\nGitHub Issue:\nTitle: Fix the login bug\nPriority: High (3)\nDescription: This is a high-priority bug that needs immediate attention...\n\n&gt;&gt;&gt; /exit\nGoodbye!\n</code></pre>"},{"location":"en/tutorials/05-repl/#summary","title":"Summary","text":"<p>You learned: - \u2713 How to start and use the REPL - \u2713 REPL commands (/help, /agents, /model, etc.) - \u2713 Multi-line input for complex definitions - \u2713 Practical workflows for testing and iteration - \u2713 Tips for efficient REPL usage</p> <p>The REPL is your playground for experimentation. Use it to: - Test ideas quickly - Refine prompts - Compare models - Debug agents</p> <p>Happy coding! \ud83c\udf89</p>"},{"location":"en/tutorials/05-repl/#next-steps","title":"Next Steps","text":"<ul> <li>API Reference: CLI - Detailed CLI documentation</li> <li>Examples - More code examples</li> <li>FAQ - Common questions</li> </ul>"},{"location":"en/tutorials/06-mcp-integration/","title":"MCP Integration","text":""},{"location":"en/tutorials/06-mcp-integration/#overview","title":"Overview","text":"<p>Kagura AI supports MCP (Model Context Protocol), enabling your agents to be used as tools in Claude Desktop, Claude Code, Cline, and other MCP-compatible applications.</p> <p>With MCP integration, you can: - Expose Kagura agents as MCP tools - Use agents from Claude Desktop/Code directly - Share agents across MCP-compatible applications - Build agent ecosystems with standard protocols</p>"},{"location":"en/tutorials/06-mcp-integration/#what-is-mcp","title":"What is MCP?","text":"<p>Model Context Protocol (MCP) is an open protocol developed by Anthropic that standardizes how AI applications connect to external tools and data sources.</p>"},{"location":"en/tutorials/06-mcp-integration/#installation","title":"Installation","text":"<p>Install Kagura AI with MCP support:</p> <pre><code>pip install kagura-ai[mcp]\n</code></pre> <p>Or with uv:</p> <pre><code>uv add \"kagura-ai[mcp]\"\n</code></pre> <p>This installs additional dependencies: - <code>mcp&gt;=1.0.0</code> - MCP SDK - <code>jsonschema&gt;=4.20.0</code> - Schema validation</p>"},{"location":"en/tutorials/06-mcp-integration/#quick-start","title":"Quick Start","text":""},{"location":"en/tutorials/06-mcp-integration/#1-create-an-agent","title":"1. Create an Agent","text":"<p>Create a simple agent in <code>my_agents.py</code>:</p> <pre><code>from kagura import agent\n\n@agent\nasync def analyze_code(code: str, language: str = \"python\") -&gt; str:\n    \"\"\"\n    Analyze code quality and suggest improvements.\n\n    code: Source code to analyze\n    language: Programming language (default: python)\n    \"\"\"\n    pass\n</code></pre> <p>That's it! The agent is automatically registered and ready to use via MCP.</p>"},{"location":"en/tutorials/06-mcp-integration/#2-start-mcp-server","title":"2. Start MCP Server","text":"<p>Start the Kagura MCP server:</p> <pre><code>kagura mcp serve\n</code></pre> <p>This starts a stdio-based MCP server that listens for requests.</p>"},{"location":"en/tutorials/06-mcp-integration/#3-configure-claude-desktop","title":"3. Configure Claude Desktop","text":"<p>Add Kagura to your Claude Desktop configuration:</p> <p>macOS: <code>~/Library/Application Support/Claude/claude_desktop_config.json</code> Windows: <code>%APPDATA%\\Claude\\claude_desktop_config.json</code> Linux: <code>~/.config/Claude/claude_desktop_config.json</code></p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n</code></pre> <p>Note: Replace <code>OPENAI_API_KEY</code> with your actual API key, or use <code>ANTHROPIC_API_KEY</code> if using Claude models.</p>"},{"location":"en/tutorials/06-mcp-integration/#4-restart-claude-desktop","title":"4. Restart Claude Desktop","text":"<ol> <li>Quit Claude Desktop completely</li> <li>Restart Claude Desktop</li> <li>Your Kagura agents are now available as tools!</li> </ol>"},{"location":"en/tutorials/06-mcp-integration/#5-use-your-agent-in-claude-desktop","title":"5. Use Your Agent in Claude Desktop","text":"<p>In Claude Desktop, simply ask:</p> <pre><code>Can you analyze this Python code for me?\n\ndef calculate(x):\n    return x * 2 + 3\n</code></pre> <p>Claude will automatically use your <code>analyze_code</code> agent via MCP.</p>"},{"location":"en/tutorials/06-mcp-integration/#configuration-options","title":"Configuration Options","text":""},{"location":"en/tutorials/06-mcp-integration/#custom-server-name","title":"Custom Server Name","text":"<pre><code>kagura mcp serve --name my-custom-server\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#environment-variables","title":"Environment Variables","text":"<p>Set API keys and other environment variables in the configuration:</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"${OPENAI_API_KEY}\",\n        \"MODEL\": \"gpt-4o-mini\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#multiple-agent-files","title":"Multiple Agent Files","text":"<p>If you have agents in multiple files, import them before starting the server:</p> <pre><code># startup.py\nimport my_agents\nimport more_agents\n\n# Agents are automatically registered on import\n</code></pre> <p>Then configure Claude Desktop to run your startup script:</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"python\",\n      \"args\": [\"-c\", \"import startup; from kagura.cli.main import cli; cli(['mcp', 'serve'])\"]\n    }\n  }\n}\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#managing-agents","title":"Managing Agents","text":""},{"location":"en/tutorials/06-mcp-integration/#list-registered-agents","title":"List Registered Agents","text":"<p>See all agents available via MCP:</p> <pre><code>kagura mcp list\n</code></pre> <p>Output: <pre><code>Registered agents (1):\n\n  \u2022 analyze_code\n    Analyze code quality and suggest improvements\n</code></pre></p>"},{"location":"en/tutorials/06-mcp-integration/#agent-naming-convention","title":"Agent Naming Convention","text":"<p>MCP tool names are prefixed with <code>kagura_</code>: - Agent function: <code>analyze_code</code> - MCP tool name: <code>kagura_analyze_code</code></p> <p>This prevents naming conflicts with other MCP tools.</p>"},{"location":"en/tutorials/06-mcp-integration/#advanced-usage","title":"Advanced Usage","text":""},{"location":"en/tutorials/06-mcp-integration/#multiple-agents","title":"Multiple Agents","text":"<p>Create multiple specialized agents:</p> <pre><code>from kagura import agent\n\n@agent\nasync def review_code(code: str) -&gt; str:\n    \"\"\"Review code and provide feedback\"\"\"\n    pass\n\n@agent\nasync def generate_tests(code: str, framework: str = \"pytest\") -&gt; str:\n    \"\"\"Generate unit tests for the code\"\"\"\n    pass\n\n@agent\nasync def explain_code(code: str, audience: str = \"beginner\") -&gt; str:\n    \"\"\"Explain code for different audiences\"\"\"\n    pass\n</code></pre> <p>All three agents are automatically available in Claude Desktop.</p>"},{"location":"en/tutorials/06-mcp-integration/#complex-input-types","title":"Complex Input Types","text":"<p>Use Pydantic models for structured inputs:</p> <pre><code>from kagura import agent\nfrom pydantic import BaseModel\n\nclass CodeReviewRequest(BaseModel):\n    code: str\n    language: str\n    focus_areas: list[str]\n\n@agent\nasync def detailed_review(request: CodeReviewRequest) -&gt; dict:\n    \"\"\"Perform detailed code review\"\"\"\n    return {\n        \"score\": 8.5,\n        \"issues\": [...],\n        \"suggestions\": [...]\n    }\n</code></pre> <p>The Pydantic model is automatically converted to JSON Schema for MCP.</p>"},{"location":"en/tutorials/06-mcp-integration/#error-handling","title":"Error Handling","text":"<p>Agents should handle errors gracefully:</p> <pre><code>@agent\nasync def safe_analysis(code: str) -&gt; str:\n    \"\"\"Analyze code with error handling\"\"\"\n    try:\n        # Analysis logic\n        return \"Analysis complete\"\n    except Exception as e:\n        return f\"Error during analysis: {str(e)}\"\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#integration-with-other-mcp-clients","title":"Integration with Other MCP Clients","text":"<p>Kagura MCP works with any MCP-compatible client:</p>"},{"location":"en/tutorials/06-mcp-integration/#claude-code-vs-code-extension","title":"Claude Code (VS Code Extension)","text":"<p>Add to <code>.vscode/settings.json</code>:</p> <pre><code>{\n  \"mcp.servers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"]\n    }\n  }\n}\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#cline-vs-code-extension","title":"Cline (VS Code Extension)","text":"<p>Similar configuration in Cline settings.</p>"},{"location":"en/tutorials/06-mcp-integration/#custom-mcp-clients","title":"Custom MCP Clients","text":"<p>Use the MCP Python SDK to connect:</p> <pre><code>from mcp import ClientSession\nimport asyncio\n\nasync def test_kagura_mcp():\n    async with ClientSession() as session:\n        # Connect to Kagura MCP server\n        await session.initialize()\n\n        # List tools\n        tools = await session.list_tools()\n        print(f\"Available tools: {[t.name for t in tools]}\")\n\n        # Call agent\n        result = await session.call_tool(\n            \"kagura_analyze_code\",\n            {\"code\": \"def hello(): print('hi')\"}\n        )\n        print(result)\n\nasyncio.run(test_kagura_mcp())\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#debugging","title":"Debugging","text":""},{"location":"en/tutorials/06-mcp-integration/#enable-verbose-logging","title":"Enable Verbose Logging","text":"<pre><code>kagura -v mcp serve\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#check-agent-registration","title":"Check Agent Registration","text":"<pre><code>kagura mcp list\n</code></pre> <p>If your agent doesn't appear: 1. Ensure the file is imported 2. Check the <code>@agent</code> decorator is applied 3. Verify no import errors</p>"},{"location":"en/tutorials/06-mcp-integration/#test-without-claude-desktop","title":"Test Without Claude Desktop","text":"<p>Use <code>mcp</code> CLI tool to test directly:</p> <pre><code># Install MCP CLI\nnpm install -g @modelcontextprotocol/cli\n\n# Test Kagura MCP server\nmcp call kagura_analyze_code '{\"code\": \"def test(): pass\"}'\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/06-mcp-integration/#1-clear-descriptions","title":"1. Clear Descriptions","text":"<p>Write clear docstrings - they become tool descriptions in Claude:</p> <pre><code>@agent\nasync def analyze_code(code: str, language: str = \"python\") -&gt; str:\n    \"\"\"\n    Analyze code quality and suggest improvements.\n\n    This agent examines code structure, identifies potential issues,\n    and provides actionable suggestions for improvement.\n\n    code: Source code to analyze\n    language: Programming language (python, javascript, etc.)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#2-type-hints","title":"2. Type Hints","text":"<p>Use type hints for automatic schema generation:</p> <pre><code>@agent\nasync def process_data(\n    data: list[dict[str, Any]],\n    max_items: int = 100,\n    include_metadata: bool = False\n) -&gt; dict[str, Any]:\n    \"\"\"Process data with options\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#3-default-values","title":"3. Default Values","text":"<p>Provide sensible defaults for optional parameters:</p> <pre><code>@agent\nasync def translate(\n    text: str,\n    target_language: str = \"English\",\n    tone: str = \"neutral\"\n) -&gt; str:\n    \"\"\"Translate text\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#4-structured-output","title":"4. Structured Output","text":"<p>Return structured data when appropriate:</p> <pre><code>@agent\nasync def analyze_sentiment(text: str) -&gt; dict:\n    \"\"\"\n    Analyze sentiment of text\n\n    Returns:\n        {\n            \"sentiment\": \"positive\" | \"negative\" | \"neutral\",\n            \"confidence\": float,\n            \"keywords\": list[str]\n        }\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/06-mcp-integration/#agent-not-appearing-in-claude-desktop","title":"Agent Not Appearing in Claude Desktop","text":"<ol> <li>Check configuration file location</li> <li>macOS: <code>~/Library/Application Support/Claude/claude_desktop_config.json</code></li> <li>Windows: <code>%APPDATA%\\Claude\\claude_desktop_config.json</code></li> <li> <p>Linux: <code>~/.config/Claude/claude_desktop_config.json</code></p> </li> <li> <p>Verify JSON syntax <pre><code># Test JSON validity\ncat ~/Library/Application\\ Support/Claude/claude_desktop_config.json | python -m json.tool\n</code></pre></p> </li> <li> <p>Check server logs <pre><code>kagura -v mcp serve 2&gt; mcp_server.log\n</code></pre></p> </li> <li> <p>Restart Claude Desktop completely</p> </li> <li>Quit application</li> <li>Restart</li> <li>Check MCP indicator in status bar</li> </ol>"},{"location":"en/tutorials/06-mcp-integration/#authentication-errors","title":"Authentication Errors","text":"<p>Make sure API keys are set:</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"sk-...\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#permission-errors","title":"Permission Errors","text":"<p>On Unix systems, ensure <code>kagura</code> is executable:</p> <pre><code>which kagura\nchmod +x $(which kagura)\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#next-steps","title":"Next Steps","text":"<ul> <li>API Reference - MCP API documentation</li> <li>CLI Reference - <code>kagura mcp</code> commands</li> <li>MCP Specification - Learn more about MCP</li> </ul>"},{"location":"en/tutorials/06-mcp-integration/#example-projects","title":"Example Projects","text":"<p>See <code>examples/mcp_integration/</code> for complete examples: - Code analysis agent - Multi-agent workflow - Custom tool integration</p>"},{"location":"en/tutorials/07-shell-integration/","title":"Shell Integration","text":""},{"location":"en/tutorials/07-shell-integration/#overview","title":"Overview","text":"<p>Kagura AI provides secure shell command execution through built-in functions and the <code>ShellExecutor</code> class. This enables automation of system tasks, Git operations, and file management.</p>"},{"location":"en/tutorials/07-shell-integration/#built-in-functions","title":"Built-in Functions","text":""},{"location":"en/tutorials/07-shell-integration/#shell-commands","title":"Shell Commands","text":"<p>Execute shell commands securely:</p> <pre><code>from kagura.builtin import shell\n\n# Basic commands\noutput = await shell(\"ls -la\")\nprint(output)\n\n# With working directory\noutput = await shell(\"pwd\", working_dir=\"/tmp\")\n</code></pre>"},{"location":"en/tutorials/07-shell-integration/#git-operations","title":"Git Operations","text":"<p>Automate Git workflows:</p> <pre><code>from kagura.builtin import git_commit, git_push, git_status, git_create_pr\n\n# Check status\nstatus = await git_status()\nprint(status)\n\n# Commit changes\nawait git_commit(\"feat: add new feature\", files=[\"src/main.py\"])\n\n# Or commit all changes\nawait git_commit(\"fix: bug fix\", all=True)\n\n# Push to remote\nawait git_push()\n\n# Create pull request (requires GitHub CLI)\npr_url = await git_create_pr(\n    title=\"feat: implement shell integration\",\n    body=\"This PR adds shell execution capabilities\"\n)\n</code></pre>"},{"location":"en/tutorials/07-shell-integration/#file-operations","title":"File Operations","text":"<p>Search and analyze files:</p> <pre><code>from kagura.builtin import file_search, grep_content\n\n# Search for Python test files\ntest_files = await file_search(\n    pattern=\"test\",\n    directory=\"./tests\",\n    file_type=\"*.py\"\n)\n\n# Search for TODOs in files\nresults = await grep_content(\"TODO\", test_files)\nfor file, matches in results.items():\n    print(f\"{file}: {len(matches)} TODOs\")\n</code></pre>"},{"location":"en/tutorials/07-shell-integration/#security","title":"Security","text":"<p>Shell execution is protected by:</p> <ol> <li>Whitelist: Only approved commands are allowed</li> <li>Blacklist: Dangerous commands are blocked</li> <li>Timeout: Commands have 30-second timeout by default</li> <li>Working Directory: Commands run in isolated directories</li> </ol> <p>Default allowed commands: - Git: <code>git</code>, <code>gh</code> - File operations: <code>ls</code>, <code>cat</code>, <code>find</code>, <code>grep</code>, <code>mkdir</code>, <code>rm</code>, <code>cp</code>, <code>mv</code> - Package managers: <code>npm</code>, <code>pip</code>, <code>uv</code>, <code>poetry</code>, <code>yarn</code> - Build tools: <code>make</code>, <code>cargo</code>, <code>go</code> - Testing: <code>pytest</code>, <code>jest</code>, <code>vitest</code></p>"},{"location":"en/tutorials/07-shell-integration/#advanced-usage","title":"Advanced Usage","text":""},{"location":"en/tutorials/07-shell-integration/#custom-shellexecutor","title":"Custom ShellExecutor","text":"<p>For more control, use <code>ShellExecutor</code> directly:</p> <pre><code>from kagura.core.shell import ShellExecutor\nfrom pathlib import Path\n\nexecutor = ShellExecutor(\n    allowed_commands=[\"git\", \"npm\"],  # Restrict to specific commands\n    timeout=60,  # Custom timeout\n    working_dir=Path(\"./my-project\")\n)\n\nresult = await executor.exec(\"git status\")\nif result.success:\n    print(result.stdout)\nelse:\n    print(f\"Error: {result.stderr}\")\n</code></pre>"},{"location":"en/tutorials/07-shell-integration/#error-handling","title":"Error Handling","text":"<pre><code>from kagura.builtin import shell\nfrom kagura.core.shell import SecurityError\n\ntry:\n    output = await shell(\"my-command\")\nexcept SecurityError as e:\n    print(f\"Command blocked: {e}\")\nexcept RuntimeError as e:\n    print(f\"Command failed: {e}\")\nexcept TimeoutError as e:\n    print(f\"Command timed out: {e}\")\n</code></pre>"},{"location":"en/tutorials/07-shell-integration/#examples","title":"Examples","text":""},{"location":"en/tutorials/07-shell-integration/#automated-deployment","title":"Automated Deployment","text":"<pre><code>from kagura.builtin import shell, git_commit, git_push\n\nasync def deploy(version: str):\n    \"\"\"Deploy application\"\"\"\n\n    # Run tests\n    test_result = await shell(\"pytest tests/\")\n    if \"FAILED\" in test_result:\n        raise RuntimeError(\"Tests failed\")\n\n    # Build\n    await shell(\"uv build\")\n\n    # Commit and push\n    await git_commit(f\"chore: release v{version}\")\n    await shell(f\"git tag v{version}\")\n    await git_push()\n    await shell(\"git push --tags\")\n\n    print(f\"\u2713 Deployed v{version}\")\n\n# Usage\nimport asyncio\nasyncio.run(deploy(\"2.1.0\"))\n</code></pre>"},{"location":"en/tutorials/07-shell-integration/#code-quality-check","title":"Code Quality Check","text":"<pre><code>from kagura.builtin import file_search, grep_content, shell\n\nasync def code_review():\n    \"\"\"Run automated code review\"\"\"\n    issues = {}\n\n    # Find Python files\n    py_files = await file_search(\"*.py\", directory=\"src/\")\n\n    # Check for TODOs\n    todos = await grep_content(\"TODO\", py_files)\n    if todos:\n        issues[\"todos\"] = todos\n\n    # Run linter\n    ruff_output = await shell(\"ruff check src/\")\n    if ruff_output:\n        issues[\"lint\"] = ruff_output\n\n    # Run type checker\n    pyright_output = await shell(\"pyright src/\")\n    if \"error\" in pyright_output.lower():\n        issues[\"types\"] = pyright_output\n\n    return issues\n\n# Usage\nimport asyncio\nresults = asyncio.run(code_review())\nprint(f\"Found {len(results)} issue types\")\n</code></pre>"},{"location":"en/tutorials/07-shell-integration/#see-also","title":"See Also","text":"<ul> <li>Shell API Reference</li> <li>ShellExecutor Documentation</li> </ul>"},{"location":"en/tutorials/08-memory-management/","title":"Memory Management Tutorial","text":"<p>Learn how to build agents with memory capabilities using Kagura AI's memory management system.</p>"},{"location":"en/tutorials/08-memory-management/#introduction","title":"Introduction","text":"<p>Kagura AI provides a three-tier memory system:</p> <ol> <li>Working Memory: Temporary data during execution</li> <li>Context Memory: Conversation history</li> <li>Persistent Memory: Long-term storage</li> </ol> <p>All three are accessed through the unified <code>MemoryManager</code> interface.</p>"},{"location":"en/tutorials/08-memory-management/#quick-start","title":"Quick Start","text":""},{"location":"en/tutorials/08-memory-management/#basic-memory-usage","title":"Basic Memory Usage","text":"<pre><code>from kagura.core.memory import MemoryManager\n\n# Create memory manager\nmemory = MemoryManager(agent_name=\"my_assistant\")\n\n# Store and recall persistent data\nmemory.remember(\"user_name\", \"Alice\")\nname = memory.recall(\"user_name\")  # \"Alice\"\n\n# Track conversation\nmemory.add_message(\"user\", \"Hello!\")\nmemory.add_message(\"assistant\", \"Hi there!\")\n\n# Get conversation context\ncontext = memory.get_llm_context()\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#agent-with-memory","title":"Agent with Memory","text":"<pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n@agent(enable_memory=True)\nasync def greeter(name: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Greet {{ name }} personally\"\"\"\n\n    # Remember this person\n    memory.remember(f\"greeted_{name}\", True)\n\n    # Check if we've met before\n    met_before = memory.recall(f\"greeted_{name}\")\n\n    if met_before:\n        return f\"Welcome back, {name}!\"\n    else:\n        return f\"Nice to meet you, {name}!\"\n\n# First time\nresult = await greeter(\"Alice\")  # \"Nice to meet you, Alice!\"\n\n# Second time\nresult = await greeter(\"Alice\")  # \"Welcome back, Alice!\"\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#working-memory","title":"Working Memory","text":"<p>Temporary storage that's cleared after execution.</p>"},{"location":"en/tutorials/08-memory-management/#use-cases","title":"Use Cases","text":"<ul> <li>Tracking loop iterations</li> <li>Storing intermediate results</li> <li>Temporary configuration</li> </ul>"},{"location":"en/tutorials/08-memory-management/#example","title":"Example","text":"<pre><code>from kagura.core.memory import MemoryManager\n\nmemory = MemoryManager()\n\n# Store temporary data\nmemory.set_temp(\"retry_count\", 0)\nmemory.set_temp(\"current_task\", \"data_processing\")\n\n# Retrieve\ncount = memory.get_temp(\"retry_count\")  # 0\ntask = memory.get_temp(\"current_task\")  # \"data_processing\"\n\n# Check existence\nif memory.has_temp(\"retry_count\"):\n    count = memory.get_temp(\"retry_count\")\n    memory.set_temp(\"retry_count\", count + 1)\n\n# Delete\nmemory.delete_temp(\"current_task\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#context-memory","title":"Context Memory","text":"<p>Manages conversation history with automatic pruning.</p>"},{"location":"en/tutorials/08-memory-management/#message-roles","title":"Message Roles","text":"<ul> <li><code>\"user\"</code>: User messages</li> <li><code>\"assistant\"</code>: Agent responses</li> <li><code>\"system\"</code>: System prompts</li> </ul>"},{"location":"en/tutorials/08-memory-management/#basic-usage","title":"Basic Usage","text":"<pre><code>memory = MemoryManager(max_messages=100)\n\n# Add messages\nmemory.add_message(\"user\", \"What is AI?\")\nmemory.add_message(\"assistant\", \"AI stands for Artificial Intelligence...\")\n\n# Get all messages\nmessages = memory.get_context()\n\n# Get last N messages\nrecent = memory.get_context(last_n=5)\n\n# Get last user message\nlast_user = memory.get_last_message(role=\"user\")\nprint(last_user.content)  # \"What is AI?\"\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#llm-integration","title":"LLM Integration","text":"<pre><code># Get context for LLM API\nllm_messages = memory.get_llm_context()\n\n# Format: [{\"role\": \"user\", \"content\": \"...\"}, ...]\nfor msg in llm_messages:\n    print(f\"{msg['role']}: {msg['content']}\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#auto-pruning","title":"Auto-Pruning","text":"<p>Context memory automatically prunes old messages when exceeding the limit:</p> <pre><code>memory = MemoryManager(max_messages=3)\n\nmemory.add_message(\"user\", \"Message 1\")\nmemory.add_message(\"assistant\", \"Message 2\")\nmemory.add_message(\"user\", \"Message 3\")\n# 3 messages stored\n\nmemory.add_message(\"assistant\", \"Message 4\")\n# Only last 3 kept: Message 2, 3, 4\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#metadata","title":"Metadata","text":"<p>Attach metadata to messages:</p> <pre><code>memory.add_message(\n    \"assistant\",\n    \"The answer is 42\",\n    metadata={\n        \"confidence\": 0.95,\n        \"source\": \"knowledge_base\",\n        \"timestamp\": \"2025-01-01T00:00:00Z\"\n    }\n)\n\nmessages = memory.get_context()\nprint(messages[0].metadata[\"confidence\"])  # 0.95\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#persistent-memory","title":"Persistent Memory","text":"<p>Long-term storage using SQLite.</p>"},{"location":"en/tutorials/08-memory-management/#basic-operations","title":"Basic Operations","text":"<pre><code>from pathlib import Path\n\nmemory = MemoryManager(\n    agent_name=\"my_agent\",\n    persist_dir=Path(\"./data\")\n)\n\n# Store\nmemory.remember(\"api_key\", \"sk-...\")\nmemory.remember(\"user_prefs\", {\"theme\": \"dark\", \"lang\": \"en\"})\n\n# Recall\napi_key = memory.recall(\"api_key\")\nprefs = memory.recall(\"user_prefs\")\n\n# Delete\nmemory.forget(\"api_key\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#search","title":"Search","text":"<p>Search using SQL LIKE patterns:</p> <pre><code># Store multiple items\nmemory.remember(\"user_name\", \"Alice\")\nmemory.remember(\"user_email\", \"alice@example.com\")\nmemory.remember(\"user_age\", 25)\nmemory.remember(\"product_name\", \"Widget\")\n\n# Search for user-related items\nresults = memory.search_memory(\"user\")\n# Returns: user_name, user_email, user_age\n\nfor item in results:\n    print(f\"{item['key']}: {item['value']}\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#agent-scoping","title":"Agent Scoping","text":"<p>Memories can be scoped to specific agents:</p> <pre><code># Agent 1\nmemory1 = MemoryManager(agent_name=\"agent1\")\nmemory1.remember(\"config\", {\"mode\": \"fast\"})\n\n# Agent 2\nmemory2 = MemoryManager(agent_name=\"agent2\")\nmemory2.remember(\"config\", {\"mode\": \"accurate\"})\n\n# Each agent has separate memories\nconfig1 = memory1.recall(\"config\")  # {\"mode\": \"fast\"}\nconfig2 = memory2.recall(\"config\")  # {\"mode\": \"accurate\"}\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#maintenance","title":"Maintenance","text":"<pre><code># Prune old memories (older than 30 days)\ndeleted = memory.prune_old(older_than_days=30)\nprint(f\"Deleted {deleted} old memories\")\n\n# Count memories\ncount = memory.persistent.count(agent_name=\"my_agent\")\nprint(f\"{count} memories stored\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#session-management","title":"Session Management","text":"<p>Save and restore complete agent state.</p>"},{"location":"en/tutorials/08-memory-management/#saving-sessions","title":"Saving Sessions","text":"<pre><code>memory = MemoryManager(agent_name=\"assistant\")\n\n# Have a conversation\nmemory.add_message(\"user\", \"What is machine learning?\")\nmemory.add_message(\"assistant\", \"Machine learning is...\")\n\n# Store temporary data\nmemory.set_temp(\"conversation_step\", 5)\n\n# Save everything\nmemory.save_session(\"ml_discussion\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#loading-sessions","title":"Loading Sessions","text":"<pre><code># Later... create new memory manager\nnew_memory = MemoryManager(agent_name=\"assistant\")\n\n# Restore session\nif new_memory.load_session(\"ml_discussion\"):\n    print(\"Session restored!\")\n\n    # Context is restored\n    messages = new_memory.get_context()\n    print(f\"Restored {len(messages)} messages\")\n\n    # Session ID is restored\n    session_id = new_memory.get_session_id()\nelse:\n    print(\"Session not found\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#agent-integration","title":"Agent Integration","text":""},{"location":"en/tutorials/08-memory-management/#enable-memory","title":"Enable Memory","text":"<p>Use <code>enable_memory=True</code> in the <code>@agent</code> decorator:</p> <pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n@agent(enable_memory=True)\nasync def chatbot(message: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Chat: {{ message }}\"\"\"\n\n    # Memory is automatically injected\n    memory.add_message(\"user\", message)\n\n    # Use memory for personalization\n    user_name = memory.recall(\"user_name\")\n    if user_name:\n        response = f\"Hello {user_name}! You said: {message}\"\n    else:\n        response = f\"Hello! You said: {message}\"\n\n    memory.add_message(\"assistant\", response)\n    return response\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#custom-configuration","title":"Custom Configuration","text":"<pre><code>from pathlib import Path\n\n@agent(\n    enable_memory=True,\n    persist_dir=Path(\"./agent_data\"),\n    max_messages=50\n)\nasync def my_agent(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Process: {{ query }}\"\"\"\n    # Custom persist directory and message limit\n    pass\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#practical-examples","title":"Practical Examples","text":""},{"location":"en/tutorials/08-memory-management/#personal-assistant","title":"Personal Assistant","text":"<pre><code>@agent(enable_memory=True)\nasync def personal_assistant(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Answer: {{ query }}\"\"\"\n\n    memory.add_message(\"user\", query)\n\n    # Learn user preferences\n    if \"my favorite color is\" in query.lower():\n        color = query.split(\"my favorite color is\")[-1].strip()\n        memory.remember(\"favorite_color\", color)\n\n    if \"my name is\" in query.lower():\n        name = query.split(\"my name is\")[-1].strip()\n        memory.remember(\"user_name\", name)\n\n    # Use learned information\n    name = memory.recall(\"user_name\") or \"there\"\n    fav_color = memory.recall(\"favorite_color\") or \"unknown\"\n\n    response = f\"Hi {name}! Your favorite color is {fav_color}.\"\n    memory.add_message(\"assistant\", response)\n\n    return response\n\n# Usage\nawait personal_assistant(\"Hi, my name is Alice\")\nawait personal_assistant(\"my favorite color is blue\")\nawait personal_assistant(\"what's my name?\")\n# \"Hi Alice! Your favorite color is blue.\"\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#multi-turn-conversation","title":"Multi-Turn Conversation","text":"<pre><code>@agent(enable_memory=True, max_messages=20)\nasync def conversational_agent(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Continue conversation: {{ query }}\n\n    Previous context:\n    {% for msg in context %}\n    {{ msg.role }}: {{ msg.content }}\n    {% endfor %}\n    \"\"\"\n\n    # Get recent context for prompt\n    context = memory.get_context(last_n=5)\n\n    # Add current message\n    memory.add_message(\"user\", query)\n\n    # Response would come from LLM\n    response = \"...\"  # LLM processes with full context\n\n    memory.add_message(\"assistant\", response)\n    return response\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#task-tracker","title":"Task Tracker","text":"<pre><code>@agent(enable_memory=True)\nasync def task_tracker(command: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Manage tasks: {{ command }}\"\"\"\n\n    if command.startswith(\"add\"):\n        task = command[4:].strip()\n        tasks = memory.recall(\"tasks\") or []\n        tasks.append(task)\n        memory.remember(\"tasks\", tasks)\n        return f\"Added task: {task}\"\n\n    elif command == \"list\":\n        tasks = memory.recall(\"tasks\") or []\n        if not tasks:\n            return \"No tasks\"\n        return \"Tasks:\\n\" + \"\\n\".join(f\"- {t}\" for t in tasks)\n\n    elif command.startswith(\"done\"):\n        task = command[5:].strip()\n        tasks = memory.recall(\"tasks\") or []\n        if task in tasks:\n            tasks.remove(task)\n            memory.remember(\"tasks\", tasks)\n            return f\"Completed: {task}\"\n        return \"Task not found\"\n\n    return \"Unknown command\"\n\n# Usage\nawait task_tracker(\"add Write documentation\")\nawait task_tracker(\"add Review code\")\nawait task_tracker(\"list\")\n# \"Tasks:\\n- Write documentation\\n- Review code\"\nawait task_tracker(\"done Write documentation\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/08-memory-management/#1-use-appropriate-memory-types","title":"1. Use Appropriate Memory Types","text":"<ul> <li>Working Memory: Temporary state, loop counters, intermediate results</li> <li>Context Memory: Conversation history, user interactions</li> <li>Persistent Memory: User preferences, learned facts, configuration</li> </ul>"},{"location":"en/tutorials/08-memory-management/#2-set-reasonable-limits","title":"2. Set Reasonable Limits","text":"<pre><code># For chat applications\nmemory = MemoryManager(max_messages=50)  # Keep last 50 messages\n\n# For long-running agents\nmemory = MemoryManager(max_messages=200)  # More context\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#3-clean-up-old-data","title":"3. Clean Up Old Data","text":"<pre><code># Periodically prune old memories\nif datetime.now().day == 1:  # First day of month\n    deleted = memory.prune_old(older_than_days=90)\n    print(f\"Pruned {deleted} old memories\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#4-use-agent-scoping","title":"4. Use Agent Scoping","text":"<pre><code># Separate memories for different agents\ntranslator = MemoryManager(agent_name=\"translator\")\nsummarizer = MemoryManager(agent_name=\"summarizer\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#5-add-metadata","title":"5. Add Metadata","text":"<pre><code>memory.remember(\n    \"api_key\",\n    \"sk-...\",\n    metadata={\n        \"created\": \"2025-01-01\",\n        \"expires\": \"2026-01-01\",\n        \"environment\": \"production\"\n    }\n)\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/08-memory-management/#memory-not-persisting","title":"Memory Not Persisting","text":"<p>Ensure <code>persist_dir</code> exists:</p> <pre><code>from pathlib import Path\n\npersist_dir = Path(\"./data\")\npersist_dir.mkdir(exist_ok=True)\n\nmemory = MemoryManager(persist_dir=persist_dir)\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#context-too-large","title":"Context Too Large","text":"<p>Reduce <code>max_messages</code>:</p> <pre><code>memory = MemoryManager(max_messages=20)\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#agent-specific-memories","title":"Agent-Specific Memories","text":"<p>Always use <code>agent_name</code>:</p> <pre><code>memory = MemoryManager(agent_name=\"my_unique_agent\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#next-steps","title":"Next Steps","text":"<ul> <li>Memory Management API Reference</li> <li>Code Execution Tutorial</li> <li>Shell Integration Tutorial</li> </ul>"},{"location":"en/tutorials/09-agent-routing/","title":"Agent Routing Tutorial","text":"<p>Learn how to use agent routing to automatically select the best agent for user requests.</p>"},{"location":"en/tutorials/09-agent-routing/#what-is-agent-routing","title":"What is Agent Routing?","text":"<p>Agent routing automatically selects the most appropriate agent based on user input, eliminating the need to manually choose which agent to call.</p> <p>Benefits: - \ud83c\udfaf Automatic agent selection - \ud83d\ude80 Simplified user experience - \ud83d\udd04 Easy to add new agents - \ud83c\udf10 Multilingual support</p>"},{"location":"en/tutorials/09-agent-routing/#quick-start","title":"Quick Start","text":""},{"location":"en/tutorials/09-agent-routing/#step-1-install-kagura-ai","title":"Step 1: Install Kagura AI","text":"<pre><code>pip install kagura-ai\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#step-2-define-agents","title":"Step 2: Define Agents","text":"<pre><code>from kagura import agent\n\n@agent\nasync def code_reviewer(code: str) -&gt; str:\n    '''Review code quality and suggest improvements.\n    Code: {{ code }}'''\n    pass\n\n@agent\nasync def translator(text: str, target_lang: str = \"en\") -&gt; str:\n    '''Translate text to target language.\n    Text: {{ text }}\n    Target: {{ target_lang }}'''\n    pass\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#step-3-create-router","title":"Step 3: Create Router","text":"<pre><code>from kagura.routing import AgentRouter\n\nrouter = AgentRouter()\n\n# Register agents with intent keywords\nrouter.register(\n    code_reviewer,\n    intents=[\"review\", \"check\", \"analyze\"],\n    description=\"Reviews code for quality and bugs\"\n)\n\nrouter.register(\n    translator,\n    intents=[\"translate\", \"\u7ffb\u8a33\", \"translation\"],\n    description=\"Translates text between languages\"\n)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#step-4-use-automatic-routing","title":"Step 4: Use Automatic Routing","text":"<pre><code># The router automatically selects the right agent!\nresult = await router.route(\"Please review this code\")\n# \u2192 code_reviewer is selected\n\nresult = await router.route(\"Translate 'Hello' to Japanese\")\n# \u2192 translator is selected\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#basic-usage","title":"Basic Usage","text":""},{"location":"en/tutorials/09-agent-routing/#registering-agents","title":"Registering Agents","text":"<p>Agents are registered with intent keywords that help the router identify them:</p> <pre><code>from kagura import agent\nfrom kagura.routing import AgentRouter\n\n@agent\nasync def python_expert(question: str) -&gt; str:\n    '''Python programming expert: {{ question }}'''\n    pass\n\nrouter = AgentRouter()\n\nrouter.register(\n    python_expert,\n    intents=[\n        \"python\",      # Programming language\n        \"decorator\",   # Python-specific concepts\n        \"asyncio\",\n        \"pip\"\n    ],\n    description=\"Answers Python programming questions\"\n)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#routing-requests","title":"Routing Requests","text":"<pre><code># These will all route to python_expert\nawait router.route(\"How do I use Python decorators?\")\nawait router.route(\"Explain asyncio in Python\")\nawait router.route(\"What's the best way to use pip?\")\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#confidence-threshold","title":"Confidence Threshold","text":"<p>The router calculates a confidence score for each agent. You can control the minimum required confidence:</p> <pre><code>router = AgentRouter(confidence_threshold=0.5)\n</code></pre> <p>How Confidence Works:</p> <pre><code># Agent has intents: [\"review\", \"check\", \"analyze\"]\nuser_input = \"review and check code\"\n\n# Scoring:\n# - \"review\" \u2713 matched\n# - \"check\"  \u2713 matched\n# - \"analyze\" \u2717 not matched\n# Score = 2/3 = 0.67 \u2192 Above threshold (0.5) \u2192 Agent selected\n</code></pre> <p>Lower threshold = more lenient matching Higher threshold = stricter matching</p> <pre><code># Lenient (more matches)\nrouter = AgentRouter(confidence_threshold=0.3)\n\n# Strict (fewer matches, higher accuracy)\nrouter = AgentRouter(confidence_threshold=0.7)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#fallback-agent","title":"Fallback Agent","text":"<p>Always provide a fallback agent for requests that don't match any registered agent:</p> <pre><code>@agent\nasync def general_assistant(query: str) -&gt; str:\n    '''General purpose assistant: {{ query }}'''\n    pass\n\nrouter = AgentRouter(\n    fallback_agent=general_assistant,\n    confidence_threshold=0.4\n)\n\n# If no agent matches or confidence is low, fallback is used\nresult = await router.route(\"What's the weather today?\")\n# \u2192 general_assistant (fallback) handles this\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#multilingual-support","title":"Multilingual Support","text":"<p>Add intent keywords in multiple languages:</p> <pre><code>router.register(\n    translator,\n    intents=[\n        # English\n        \"translate\", \"translation\",\n        # Japanese\n        \"\u7ffb\u8a33\", \"\u8a33\u3057\u3066\",\n        # Spanish\n        \"traducir\", \"traducci\u00f3n\",\n        # Korean\n        \"\ubc88\uc5ed\"\n    ],\n    description=\"Multilingual translator\"\n)\n\n# Works with any language\nawait router.route(\"\u3053\u306e\u6587\u7ae0\u3092\u7ffb\u8a33\u3057\u3066\")  # Japanese\nawait router.route(\"Traducir este texto\")  # Spanish\nawait router.route(\"\uc774\uac83\uc744 \ubc88\uc5ed\ud574\uc8fc\uc138\uc694\")  # Korean\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#checking-matched-agents","title":"Checking Matched Agents","text":"<p>See which agents match and their confidence scores:</p> <pre><code>matches = router.get_matched_agents(\"review my code\", top_k=3)\n\nfor agent, score in matches:\n    print(f\"{agent.__name__}: {score:.2f}\")\n\n# Output:\n# code_reviewer: 0.67\n# quality_checker: 0.33\n# general_assistant: 0.00\n</code></pre> <p>This is useful for: - Debugging routing issues - Tuning confidence thresholds - Understanding why an agent was selected</p>"},{"location":"en/tutorials/09-agent-routing/#semantic-routing-advanced","title":"Semantic Routing (Advanced)","text":"<p>Semantic routing uses embedding-based similarity matching for more intelligent routing. Instead of keyword matching, it understands the meaning of user queries.</p>"},{"location":"en/tutorials/09-agent-routing/#installation","title":"Installation","text":"<pre><code>pip install kagura-ai[ai]\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from kagura import agent\nfrom kagura.routing import AgentRouter\n\n@agent\nasync def code_reviewer(code: str) -&gt; str:\n    '''Review code: {{ code }}'''\n    pass\n\n@agent\nasync def translator(text: str, lang: str = \"en\") -&gt; str:\n    '''Translate: {{ text }} to {{ lang }}'''\n    pass\n\n# Create semantic router\nrouter = AgentRouter(strategy=\"semantic\")\n\n# Register with sample queries (not keywords!)\nrouter.register(\n    code_reviewer,\n    samples=[\n        \"Can you review this code?\",\n        \"Check my implementation\",\n        \"Look at this function\",\n        \"\u3053\u306e\u30b3\u30fc\u30c9\u3092\u30ec\u30d3\u30e5\u30fc\u3057\u3066\"  # Japanese\n    ]\n)\n\nrouter.register(\n    translator,\n    samples=[\n        \"Translate this text\",\n        \"Convert to Japanese\",\n        \"What does this mean in French?\",\n        \"\u7ffb\u8a33\u3057\u3066\"  # Japanese\n    ]\n)\n\n# Semantic matching understands meaning!\nawait router.route(\"Could you look at my Python script?\")\n# \u2192 code_reviewer (understands \"look at\" \u2248 \"review\")\n\nawait router.route(\"\u82f1\u8a9e\u3067\u4f55\u3066\u8a00\u3046\uff1f\")\n# \u2192 translator (understands Japanese intent)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#benefits-of-semantic-routing","title":"Benefits of Semantic Routing","text":"<p>\u2705 Understands synonyms: \"check\", \"review\", \"analyze\" all match \u2705 Cross-language: Matches meaning across languages \u2705 Context-aware: Understands similar phrases \u2705 No keyword tuning: Just provide natural examples</p>"},{"location":"en/tutorials/09-agent-routing/#intent-vs-semantic-comparison","title":"Intent vs Semantic Comparison","text":"Feature Intent (Keyword) Semantic (Embedding) Speed \u26a1 Very fast (&lt;1ms) \ud83d\udc22 Slower (~50-200ms) Cost \ud83d\udcb0 Free \ud83d\udcb5 API calls required Accuracy \u2713 Good for exact keywords \u2713\u2713 Better for natural language Setup Simple keywords Sample queries needed Offline \u2705 Yes \u274c No (needs API) <p>When to use Intent: - High-volume routing - Offline applications - Clear keyword patterns - Cost-sensitive applications</p> <p>When to use Semantic: - Natural language queries - Multilingual support - Complex intent understanding - User-facing chatbots</p>"},{"location":"en/tutorials/09-agent-routing/#configuration","title":"Configuration","text":"<pre><code># OpenAI encoder (default)\nrouter = AgentRouter(\n    strategy=\"semantic\",\n    encoder=\"openai\"\n)\n\n# Cohere encoder\nrouter = AgentRouter(\n    strategy=\"semantic\",\n    encoder=\"cohere\"\n)\n\n# With fallback and threshold\nrouter = AgentRouter(\n    strategy=\"semantic\",\n    fallback_agent=general_assistant,\n    confidence_threshold=0.7,\n    encoder=\"openai\"\n)\n</code></pre> <p>Environment Variables:</p> <pre><code># For OpenAI\nexport OPENAI_API_KEY=\"sk-...\"\n\n# For Cohere\nexport COHERE_API_KEY=\"...\"\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#practical-examples","title":"Practical Examples","text":""},{"location":"en/tutorials/09-agent-routing/#example-1-customer-support-bot","title":"Example 1: Customer Support Bot","text":"<pre><code>from kagura import agent\nfrom kagura.routing import AgentRouter\n\n# Define specialized agents\n@agent\nasync def billing_agent(query: str) -&gt; str:\n    '''Handle billing inquiries: {{ query }}'''\n    pass\n\n@agent\nasync def technical_agent(query: str) -&gt; str:\n    '''Handle technical issues: {{ query }}'''\n    pass\n\n@agent\nasync def general_agent(query: str) -&gt; str:\n    '''General customer support: {{ query }}'''\n    pass\n\n# Create router\nrouter = AgentRouter(\n    fallback_agent=general_agent,\n    confidence_threshold=0.4\n)\n\n# Register agents\nrouter.register(\n    billing_agent,\n    intents=[\"billing\", \"payment\", \"invoice\", \"charge\", \"subscription\"],\n    description=\"Handles billing and payment questions\"\n)\n\nrouter.register(\n    technical_agent,\n    intents=[\"technical\", \"bug\", \"error\", \"crash\", \"not working\"],\n    description=\"Handles technical support issues\"\n)\n\n# Use in chat loop\nasync def customer_support_chat():\n    print(\"Customer Support Bot (type 'exit' to quit)\")\n\n    while True:\n        query = input(\"\\nCustomer: \")\n        if query.lower() == \"exit\":\n            break\n\n        response = await router.route(query)\n        print(f\"Support: {response}\")\n\n# Run\nawait customer_support_chat()\n\n# Example conversation:\n# Customer: I was charged twice for my subscription\n# Support: [billing_agent handles this]\n#\n# Customer: The app keeps crashing on startup\n# Support: [technical_agent handles this]\n#\n# Customer: What are your business hours?\n# Support: [general_agent handles this]\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#example-2-development-assistant","title":"Example 2: Development Assistant","text":"<pre><code>@agent\nasync def code_generator(description: str) -&gt; str:\n    '''Generate code from description: {{ description }}'''\n    pass\n\n@agent\nasync def code_reviewer(code: str) -&gt; str:\n    '''Review code quality: {{ code }}'''\n    pass\n\n@agent\nasync def bug_finder(code: str) -&gt; str:\n    '''Find bugs in code: {{ code }}'''\n    pass\n\n@agent\nasync def documenter(code: str) -&gt; str:\n    '''Generate documentation: {{ code }}'''\n    pass\n\nrouter = AgentRouter(confidence_threshold=0.3)\n\nrouter.register(code_generator, intents=[\"generate\", \"create\", \"write\"])\nrouter.register(code_reviewer, intents=[\"review\", \"check\", \"assess\"])\nrouter.register(bug_finder, intents=[\"bug\", \"error\", \"issue\", \"debug\"])\nrouter.register(documenter, intents=[\"document\", \"docs\", \"comment\"])\n\n# Automatic task routing\nawait router.route(\"Generate a function to sort a list\")\n# \u2192 code_generator\n\nawait router.route(\"Check this code for issues\")\n# \u2192 code_reviewer\n\nawait router.route(\"Find bugs in this code\")\n# \u2192 bug_finder\n\nawait router.route(\"Add documentation to this function\")\n# \u2192 documenter\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#example-3-educational-platform","title":"Example 3: Educational Platform","text":"<pre><code>@agent\nasync def math_tutor(question: str) -&gt; str:\n    '''Math tutor: {{ question }}'''\n    pass\n\n@agent\nasync def physics_tutor(question: str) -&gt; str:\n    '''Physics tutor: {{ question }}'''\n    pass\n\n@agent\nasync def chemistry_tutor(question: str) -&gt; str:\n    '''Chemistry tutor: {{ question }}'''\n    pass\n\n@agent\nasync def general_tutor(question: str) -&gt; str:\n    '''General education tutor: {{ question }}'''\n    pass\n\nrouter = AgentRouter(\n    fallback_agent=general_tutor,\n    confidence_threshold=0.4\n)\n\nrouter.register(\n    math_tutor,\n    intents=[\"math\", \"algebra\", \"calculus\", \"geometry\", \"trigonometry\"],\n    description=\"Mathematics tutor\"\n)\n\nrouter.register(\n    physics_tutor,\n    intents=[\"physics\", \"mechanics\", \"thermodynamics\", \"electricity\"],\n    description=\"Physics tutor\"\n)\n\nrouter.register(\n    chemistry_tutor,\n    intents=[\"chemistry\", \"molecule\", \"reaction\", \"element\"],\n    description=\"Chemistry tutor\"\n)\n\n# Smart subject routing\nawait router.route(\"How do I solve quadratic equations?\")\n# \u2192 math_tutor\n\nawait router.route(\"Explain Newton's laws of motion\")\n# \u2192 physics_tutor\n\nawait router.route(\"What is a covalent bond?\")\n# \u2192 chemistry_tutor\n\nawait router.route(\"How do I study effectively?\")\n# \u2192 general_tutor (fallback)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#managing-agents","title":"Managing Agents","text":""},{"location":"en/tutorials/09-agent-routing/#list-registered-agents","title":"List Registered Agents","text":"<pre><code>agents = router.list_agents()\nprint(f\"Registered agents: {', '.join(agents)}\")\n# Registered agents: code_reviewer, translator, data_analyzer\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#get-agent-information","title":"Get Agent Information","text":"<pre><code>info = router.get_agent_info(\"code_reviewer\")\nprint(f\"Description: {info['description']}\")\nprint(f\"Intents: {info['intents']}\")\n\n# Output:\n# Description: Reviews code for quality and bugs\n# Intents: ['review', 'check', 'analyze']\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#error-handling","title":"Error Handling","text":""},{"location":"en/tutorials/09-agent-routing/#no-agent-found","title":"No Agent Found","text":"<pre><code>from kagura.routing import NoAgentFoundError\n\ntry:\n    result = await router.route(\"Unknown request\")\nexcept NoAgentFoundError as e:\n    print(f\"No agent found for: {e.user_input}\")\n    # Handle the error gracefully\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#with-fallback-recommended","title":"With Fallback (Recommended)","text":"<pre><code>@agent\nasync def fallback(query: str) -&gt; str:\n    '''Fallback handler: {{ query }}'''\n    pass\n\nrouter = AgentRouter(fallback_agent=fallback)\n\n# No exception raised - fallback is used automatically\nresult = await router.route(\"Any request\")\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/09-agent-routing/#1-use-specific-intent-keywords","title":"1. Use Specific Intent Keywords","text":"<pre><code># \u2705 Good: Specific, distinctive keywords\nrouter.register(\n    code_reviewer,\n    intents=[\"review\", \"code quality\", \"static analysis\"]\n)\n\n# \u274c Bad: Generic, overlapping keywords\nrouter.register(\n    code_reviewer,\n    intents=[\"help\", \"check\", \"look\"]\n)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#2-provide-agent-descriptions","title":"2. Provide Agent Descriptions","text":"<pre><code># \u2705 Good: Clear description\nrouter.register(\n    translator,\n    intents=[\"translate\"],\n    description=\"Translates text between 50+ languages\"\n)\n\n# \u274c Bad: No description\nrouter.register(translator, intents=[\"translate\"])\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#3-test-edge-cases","title":"3. Test Edge Cases","text":"<pre><code># Test ambiguous inputs\ntest_cases = [\n    \"review and translate\",  # Matches multiple agents\n    \"\",  # Empty input\n    \"xyz123\",  # Random input\n    \"\u3053\u3093\u306b\u3061\u306f\",  # Unicode\n]\n\nfor test in test_cases:\n    try:\n        matches = router.get_matched_agents(test)\n        print(f\"{test}: {len(matches)} matches\")\n    except Exception as e:\n        print(f\"{test}: Error - {e}\")\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#4-monitor-confidence-scores","title":"4. Monitor Confidence Scores","text":"<pre><code># Log routing decisions\nmatches = router.get_matched_agents(user_input, top_k=1)\nif matches:\n    agent, score = matches[0]\n    print(f\"Selected: {agent.__name__} (confidence: {score:.2f})\")\n\n    if score &lt; 0.5:\n        print(\"Warning: Low confidence routing\")\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#5-always-use-fallback","title":"5. Always Use Fallback","text":"<pre><code># \u2705 Good: Always have a fallback\nrouter = AgentRouter(fallback_agent=general_agent)\n\n# \u274c Bad: No fallback (exceptions for unmatched inputs)\nrouter = AgentRouter()\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/09-agent-routing/#agent-not-being-selected","title":"Agent Not Being Selected","text":"<p>Problem: Expected agent is not selected</p> <p>Solution: Check intent keywords and scoring</p> <pre><code># Debug: Check matched agents\nmatches = router.get_matched_agents(user_input, top_k=5)\nfor agent, score in matches:\n    print(f\"{agent.__name__}: {score:.2f}\")\n\n# If score is too low, add more intent keywords\nrouter.register(\n    my_agent,\n    intents=[\"original\", \"keywords\", \"plus\", \"more\", \"variants\"]\n)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#fallback-always-used","title":"Fallback Always Used","text":"<p>Problem: Fallback agent is always selected</p> <p>Solution: Lower confidence threshold or add more intent keywords</p> <pre><code># Option 1: Lower threshold\nrouter = AgentRouter(\n    fallback_agent=fallback,\n    confidence_threshold=0.2  # More lenient\n)\n\n# Option 2: Add more intents\nrouter.register(\n    my_agent,\n    intents=[\"many\", \"different\", \"keyword\", \"variations\"]\n)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#multiple-agents-match","title":"Multiple Agents Match","text":"<p>Problem: Multiple agents have similar scores</p> <p>Solution: Make intents more specific</p> <pre><code># Before: Generic intents\nrouter.register(agent1, intents=[\"check\", \"analyze\"])\nrouter.register(agent2, intents=[\"check\", \"review\"])\n\n# After: Specific intents\nrouter.register(agent1, intents=[\"performance check\", \"load analysis\"])\nrouter.register(agent2, intents=[\"code review\", \"quality review\"])\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#next-steps","title":"Next Steps","text":"<ul> <li>Phase 2: Semantic routing with embedding-based matching</li> <li>Phase 3: Agent chaining and conditional routing</li> <li>Integration: Use with Chat REPL for conversational AI</li> </ul>"},{"location":"en/tutorials/09-agent-routing/#see-also","title":"See Also","text":"<ul> <li>Agent Routing API Reference</li> <li>Agent Decorator Guide</li> <li>RFC-016: Agent Routing System</li> </ul>"},{"location":"en/tutorials/10-chat-repl/","title":"Chat REPL Tutorial","text":"<p>The Chat REPL provides an interactive chat interface for conversing with AI directly from your terminal, without needing to define agents beforehand.</p>"},{"location":"en/tutorials/10-chat-repl/#quick-start","title":"Quick Start","text":""},{"location":"en/tutorials/10-chat-repl/#starting-chat-session","title":"Starting Chat Session","text":"<pre><code>kagura chat\n</code></pre> <p>You'll see a welcome screen:</p> <pre><code>\u256d\u2500 Kagura AI Chat \u2500\u256e\n\u2502 Welcome to        \u2502\n\u2502 Kagura Chat!      \u2502\n\u2502                   \u2502\n\u2502 Commands:         \u2502\n\u2502  /help      Help  \u2502\n\u2502  /translate Text  \u2502\n\u2502  /summarize Text  \u2502\n\u2502  /review    Code  \u2502\n\u2502  /exit      Exit  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"en/tutorials/10-chat-repl/#basic-conversation","title":"Basic Conversation","text":"<p>Simply type your message and press Enter:</p> <pre><code>[You] &gt; What is Python?\n\n[AI]\nPython is a high-level, interpreted programming language known for its\nreadability and versatility. It's widely used for web development, data\nscience, automation, and more.\n</code></pre> <p>The AI maintains conversation context, so you can have multi-turn dialogues:</p> <pre><code>[You] &gt; What are its main features?\n\n[AI]\nPython's main features include:\n1. **Simple syntax** - Easy to read and write\n2. **Dynamic typing** - No need to declare variable types\n3. **Extensive libraries** - Rich ecosystem of packages\n4. **Cross-platform** - Runs on Windows, macOS, Linux\n5. **Community support** - Large, active developer community\n</code></pre>"},{"location":"en/tutorials/10-chat-repl/#preset-commands","title":"Preset Commands","text":""},{"location":"en/tutorials/10-chat-repl/#translation-translate","title":"Translation (<code>/translate</code>)","text":"<p>Translate text to another language:</p> <pre><code>[You] &gt; /translate Hello World to ja\n\n\u256d\u2500 Translation \u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u3053\u3093\u306b\u3061\u306f\u4e16\u754c      \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>Default target language is Japanese:</p> <pre><code>[You] &gt; /translate Good morning\n\n\u256d\u2500 Translation \u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u304a\u306f\u3088\u3046\u3054\u3056\u3044\u307e\u3059  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"en/tutorials/10-chat-repl/#summarization-summarize","title":"Summarization (<code>/summarize</code>)","text":"<p>Summarize long text:</p> <pre><code>[You] &gt; /summarize Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to natural intelligence displayed by animals including humans. AI research has been defined as the field of study of intelligent agents, which refers to any system that perceives its environment and takes actions that maximize its chance of achieving its goals.\n\n\u256d\u2500 Summary \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 AI is machine intelligence that studies        \u2502\n\u2502 intelligent agents capable of perceiving their \u2502\n\u2502 environment and taking goal-oriented actions.  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"en/tutorials/10-chat-repl/#code-review-review","title":"Code Review (<code>/review</code>)","text":"<p>Review code for issues and improvements:</p> <pre><code>[You] &gt; /review\n\nPaste your code (press Enter twice to finish):\ndef divide(a, b):\n    return a / b\n\n&lt;press Enter twice&gt;\n\n\n[Code Review]\n\n## Issues Found\n\n1. **Division by Zero** - No check for `b == 0`\n2. **Missing Type Hints** - Function parameters lack type annotations\n3. **No Docstring** - Missing documentation\n\n## Suggestions\n\n```python\ndef divide(a: float, b: float) -&gt; float:\n    \"\"\"\n    Divide two numbers.\n\n    Args:\n        a: Numerator\n        b: Denominator\n\n    Returns:\n        Result of division\n\n    Raises:\n        ValueError: If b is zero\n    \"\"\"\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n</code></pre>"},{"location":"en/tutorials/10-chat-repl/#best-practices","title":"Best Practices","text":"<ul> <li>Always validate inputs</li> <li>Add type hints for better code clarity</li> <li>Document function behavior <pre><code>## Session Management\n\n### Saving Sessions\n\nSave your conversation for later:\n</code></pre> [You] &gt; /save my_session</li> </ul> <p>Session saved to: /home/user/.kagura/sessions/my_session.json <pre><code>Auto-generate session name with timestamp:\n</code></pre> [You] &gt; /save</p> <p>Session saved to: /home/user/.kagura/sessions/2025-10-10_14-30-15.json <pre><code>### Loading Sessions\n\nResume a previous conversation:\n</code></pre> [You] &gt; /load my_session</p> <p>Session loaded: my_session (12 messages) <pre><code>All context and history will be restored.\n\n### Clearing History\n\nClear the current conversation:\n</code></pre> [You] &gt; /clear</p> <p>Conversation history cleared. <pre><code>## Advanced Usage\n\n### Using Different Models\n\nSpecify a different LLM model:\n\n```bash\nkagura chat --model gpt-4o\n</code></pre></p> <p>Available models: - <code>gpt-4o-mini</code> (default, fastest) - <code>gpt-4o</code> (most capable) - <code>claude-3-5-sonnet-20241022</code> (Anthropic Claude) - <code>gemini/gemini-2.0-flash-exp</code> (Google Gemini)</p>"},{"location":"en/tutorials/10-chat-repl/#command-reference","title":"Command Reference","text":"Command Description Example <code>/help</code> Show help message <code>/help</code> <code>/translate</code> Translate text <code>/translate Hello to es</code> <code>/summarize</code> Summarize text <code>/summarize &lt;long text&gt;</code> <code>/review</code> Review code <code>/review</code> <code>/save [name]</code> Save session <code>/save my_session</code> <code>/load &lt;name&gt;</code> Load session <code>/load my_session</code> <code>/clear</code> Clear history <code>/clear</code> <code>/exit</code> or <code>/quit</code> Exit chat <code>/exit</code>"},{"location":"en/tutorials/10-chat-repl/#tips-tricks","title":"Tips &amp; Tricks","text":""},{"location":"en/tutorials/10-chat-repl/#1-paste-code-directly","title":"1. Paste Code Directly","text":"<p>You can paste code directly into the chat:</p> <pre><code>[You] &gt; Review this code:\n```python\ndef factorial(n):\n    if n == 0:\n        return 1\n    return n * factorial(n - 1)\n</code></pre> <p>[AI] This recursive factorial implementation is correct but... <pre><code>### 2. Multi-Turn Conversations\n\nThe chat maintains context across multiple exchanges:\n</code></pre> [You] &gt; Explain recursion</p> <p>[AI] Recursion is when a function calls itself...</p> <p>[You] &gt; Can you give an example in Python?</p> <p>[AI] Sure! Here's a recursive function... <pre><code>### 3. Quick Translations\n\nFor quick translations without typing the full command:\n</code></pre> [You] &gt; Translate \"thank you\" to French</p> <p>[AI] \"merci\" <pre><code>### 4. Session Organization\n\nOrganize sessions by topic:\n\n```bash\n/save python_learning\n/save work_project\n/save research_notes\n</code></pre></p>"},{"location":"en/tutorials/10-chat-repl/#example-workflows","title":"Example Workflows","text":""},{"location":"en/tutorials/10-chat-repl/#learning-a-new-concept","title":"Learning a New Concept","text":"<pre><code>[You] &gt; What is async/await in Python?\n\n[AI]\nAsync/await is Python's syntax for asynchronous programming...\n\n[You] &gt; Show me an example\n\n[AI]\n```python\nimport asyncio\n\nasync def fetch_data():\n    await asyncio.sleep(1)\n    return \"data\"\n</code></pre> <p>[You] &gt; How is this different from threading?</p> <p>[AI] Async/await uses cooperative multitasking...</p> <p>[You] &gt; /save async_learning <pre><code>### Code Review Workflow\n</code></pre> [You] &gt; /review</p> <p> <p>[AI]  <p>[You] &gt; Can you fix the issues you found?</p> <p>[AI]  <p>[You] &gt; /save code_review_2025-10-10 <pre><code>### Translation Workflow\n</code></pre> [You] &gt; /translate \"Hello, how are you?\" to ja</p> <p>\u256d\u2500 Translation \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 \u3053\u3093\u306b\u3061\u306f\u3001\u304a\u5143\u6c17\u3067\u3059\u304b\uff1f  \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</p> <p>[You] &gt; /translate \"I am fine, thank you\" to ja</p> <p>\u256d\u2500 Translation \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 \u5143\u6c17\u3067\u3059\u3001\u3042\u308a\u304c\u3068\u3046        \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f <pre><code>## Keyboard Shortcuts\n\n- **Ctrl+C** - Cancel current input / Exit\n- **Ctrl+D** - Exit chat (EOF)\n- **Up/Down Arrow** - Navigate command history\n- **Enter** - Submit message\n\n## Next Steps\n\n- Learn about [Custom Agents](./01-quick-start.md)\n- Explore [Agent Routing](./09-agent-routing.md)\n- Try [MCP Integration](./06-mcp-integration.md)\n\n## Troubleshooting\n\n### Chat doesn't start\n\nEnsure you have a valid API key:\n\n```bash\nexport OPENAI_API_KEY=your_key_here\n</code></pre></p>"},{"location":"en/tutorials/10-chat-repl/#slow-responses","title":"Slow responses","text":"<p>Try using a faster model:</p> <pre><code>kagura chat --model gpt-4o-mini\n</code></pre>"},{"location":"en/tutorials/10-chat-repl/#session-not-found","title":"Session not found","text":"<p>List available sessions:</p> <pre><code>ls ~/.kagura/sessions/\n</code></pre>"},{"location":"en/tutorials/10-chat-repl/#further-reading","title":"Further Reading","text":"<ul> <li>Chat API Reference</li> <li>Memory Management</li> <li>Preset Agents</li> </ul>"},{"location":"en/tutorials/11-tools/","title":"Tools Tutorial","text":"<p>The @tool decorator allows you to convert regular Python functions into tools that can be used by AI agents or exposed via MCP.</p>"},{"location":"en/tutorials/11-tools/#what-are-tools","title":"What are Tools?","text":"<p>Tools are non-LLM functions that provide deterministic, reliable functionality to your agents:</p> <ul> <li>Calculations: Math, tax, conversions</li> <li>Data Access: Database queries, API calls</li> <li>File Operations: Read, write, process files</li> <li>System Operations: Execute commands, manage resources</li> </ul> <p>Unlike <code>@agent</code> (which calls an LLM), <code>@tool</code> functions execute pure Python code.</p>"},{"location":"en/tutorials/11-tools/#quick-start","title":"Quick Start","text":""},{"location":"en/tutorials/11-tools/#basic-tool","title":"Basic Tool","text":"<pre><code>from kagura import tool\n\n@tool\ndef calculate_tax(amount: float, rate: float = 0.1) -&gt; float:\n    \"\"\"Calculate tax amount\"\"\"\n    return amount * rate\n\n# Call directly\ntax = calculate_tax(100.0, 0.15)  # 15.0\n</code></pre>"},{"location":"en/tutorials/11-tools/#using-tools-with-agents","title":"Using Tools with Agents","text":"<pre><code>from kagura import agent, tool\n\n@tool\ndef get_exchange_rate(from_currency: str, to_currency: str) -&gt; float:\n    \"\"\"Get currency exchange rate (simplified)\"\"\"\n    rates = {\n        (\"USD\", \"EUR\"): 0.85,\n        (\"EUR\", \"USD\"): 1.18,\n        (\"USD\", \"JPY\"): 110.0,\n    }\n    return rates.get((from_currency, to_currency), 1.0)\n\n@agent\nasync def currency_assistant(query: str) -&gt; str:\n    \"\"\"\n    Help with currency conversions.\n\n    Available tools:\n    - get_exchange_rate(from_currency, to_currency): Get exchange rate\n\n    Query: {{ query }}\n    \"\"\"\n    pass\n\n# Use\nresult = await currency_assistant(\"Convert 100 USD to EUR\")\n# AI will suggest using get_exchange_rate(\"USD\", \"EUR\") = 0.85\n# Then calculate: 100 * 0.85 = 85 EUR\n</code></pre>"},{"location":"en/tutorials/11-tools/#tool-features","title":"Tool Features","text":""},{"location":"en/tutorials/11-tools/#1-type-validation","title":"1. Type Validation","text":"<p>Tools automatically validate argument types:</p> <pre><code>@tool\ndef divide(a: float, b: float) -&gt; float:\n    \"\"\"Divide two numbers\"\"\"\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n\n# Valid\nresult = divide(10.0, 2.0)  # 5.0\n\n# Invalid - raises TypeError\ndivide(10.0)  # Missing argument\ndivide(10.0, 2.0, 3.0)  # Too many arguments\n</code></pre>"},{"location":"en/tutorials/11-tools/#2-default-parameters","title":"2. Default Parameters","text":"<pre><code>@tool\ndef greet(name: str, greeting: str = \"Hello\") -&gt; str:\n    \"\"\"Greet someone\"\"\"\n    return f\"{greeting}, {name}!\"\n\ngreet(\"Alice\")  # \"Hello, Alice!\"\ngreet(\"Bob\", \"Hi\")  # \"Hi, Bob!\"\ngreet(name=\"Charlie\", greeting=\"Hey\")  # \"Hey, Charlie!\"\n</code></pre>"},{"location":"en/tutorials/11-tools/#3-custom-names","title":"3. Custom Names","text":"<pre><code>@tool(name=\"tax_calculator\")\ndef calc_tax(amount: float) -&gt; float:\n    \"\"\"Calculate 10% tax\"\"\"\n    return amount * 0.1\n\n# Registered as \"tax_calculator\" instead of \"calc_tax\"\n</code></pre>"},{"location":"en/tutorials/11-tools/#4-documentation","title":"4. Documentation","text":"<p>Docstrings are preserved for MCP integration:</p> <pre><code>@tool\ndef search_database(query: str, limit: int = 10) -&gt; list:\n    \"\"\"\n    Search database for records matching query.\n\n    Args:\n        query: Search query string\n        limit: Maximum number of results\n\n    Returns:\n        List of matching records\n    \"\"\"\n    # Implementation here\n    return []\n</code></pre>"},{"location":"en/tutorials/11-tools/#tool-registry","title":"Tool Registry","text":"<p>All tools are automatically registered in the global <code>tool_registry</code>:</p> <pre><code>from kagura.core.tool_registry import tool_registry\n\n# List all tools\nprint(tool_registry.list_names())\n# ['calculate_tax', 'get_exchange_rate', 'divide', ...]\n\n# Get a specific tool\ntax_tool = tool_registry.get(\"calculate_tax\")\nresult = tax_tool(100.0, 0.15)  # 15.0\n\n# Get all tools\nall_tools = tool_registry.get_all()\nfor name, func in all_tools.items():\n    print(f\"{name}: {func.__doc__}\")\n</code></pre>"},{"location":"en/tutorials/11-tools/#examples","title":"Examples","text":""},{"location":"en/tutorials/11-tools/#example-1-calculator-tools","title":"Example 1: Calculator Tools","text":"<pre><code>from kagura import tool\n\n@tool\ndef add(a: float, b: float) -&gt; float:\n    \"\"\"Add two numbers\"\"\"\n    return a + b\n\n@tool\ndef subtract(a: float, b: float) -&gt; float:\n    \"\"\"Subtract b from a\"\"\"\n    return a - b\n\n@tool\ndef multiply(a: float, b: float) -&gt; float:\n    \"\"\"Multiply two numbers\"\"\"\n    return a * b\n\n@tool\ndef divide(a: float, b: float) -&gt; float:\n    \"\"\"Divide a by b\"\"\"\n    if b == 0:\n        raise ValueError(\"Division by zero\")\n    return a / b\n\n# Use directly\nprint(add(5, 3))       # 8.0\nprint(multiply(4, 7))  # 28.0\n</code></pre>"},{"location":"en/tutorials/11-tools/#example-2-string-processing-tools","title":"Example 2: String Processing Tools","text":"<pre><code>@tool\ndef count_words(text: str) -&gt; int:\n    \"\"\"Count words in text\"\"\"\n    return len(text.split())\n\n@tool\ndef to_uppercase(text: str) -&gt; str:\n    \"\"\"Convert text to uppercase\"\"\"\n    return text.upper()\n\n@tool\ndef extract_emails(text: str) -&gt; list[str]:\n    \"\"\"Extract email addresses from text\"\"\"\n    import re\n    pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n    return re.findall(pattern, text)\n\n# Use\ntext = \"Contact: alice@example.com or bob@test.org\"\nemails = extract_emails(text)\nprint(emails)  # ['alice@example.com', 'bob@test.org']\n</code></pre>"},{"location":"en/tutorials/11-tools/#example-3-data-processing-tools","title":"Example 3: Data Processing Tools","text":"<pre><code>@tool\ndef filter_dict(data: dict, keys: list[str]) -&gt; dict:\n    \"\"\"Filter dictionary to only include specified keys\"\"\"\n    return {k: v for k, v in data.items() if k in keys}\n\n@tool\ndef merge_dicts(*dicts: dict) -&gt; dict:\n    \"\"\"Merge multiple dictionaries\"\"\"\n    result = {}\n    for d in dicts:\n        result.update(d)\n    return result\n\n@tool\ndef get_nested_value(data: dict, path: str, default=None):\n    \"\"\"Get value from nested dictionary using dot notation\"\"\"\n    keys = path.split('.')\n    value = data\n    for key in keys:\n        if isinstance(value, dict):\n            value = value.get(key, default)\n        else:\n            return default\n    return value\n\n# Use\ndata = {\"user\": {\"name\": \"Alice\", \"age\": 30, \"email\": \"alice@example.com\"}}\nname = get_nested_value(data, \"user.name\")  # \"Alice\"\n</code></pre>"},{"location":"en/tutorials/11-tools/#example-4-file-tools","title":"Example 4: File Tools","text":"<pre><code>import json\nfrom pathlib import Path\n\n@tool\ndef read_json_file(filepath: str) -&gt; dict:\n    \"\"\"Read and parse JSON file\"\"\"\n    with open(filepath) as f:\n        return json.load(f)\n\n@tool\ndef write_json_file(filepath: str, data: dict) -&gt; None:\n    \"\"\"Write data to JSON file\"\"\"\n    with open(filepath, 'w') as f:\n        json.dump(data, f, indent=2)\n\n@tool\ndef list_files(directory: str, extension: str = \"*\") -&gt; list[str]:\n    \"\"\"List files in directory with optional extension filter\"\"\"\n    path = Path(directory)\n    if extension == \"*\":\n        return [str(f) for f in path.iterdir() if f.is_file()]\n    return [str(f) for f in path.glob(f\"*.{extension}\")]\n\n# Use\nfiles = list_files(\".\", \"py\")  # All .py files in current directory\n</code></pre>"},{"location":"en/tutorials/11-tools/#integration-with-mcp","title":"Integration with MCP","text":"<p>Tools can be exposed via MCP for use in Claude Desktop:</p> <pre><code>from kagura import tool\n\n@tool\ndef weather_lookup(city: str) -&gt; dict:\n    \"\"\"Get current weather for a city\"\"\"\n    # Implementation\n    return {\n        \"city\": city,\n        \"temperature\": 72,\n        \"condition\": \"sunny\"\n    }\n\n# Automatically available in MCP\n# Run: kagura mcp start\n# Claude Desktop can now call weather_lookup\n</code></pre>"},{"location":"en/tutorials/11-tools/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/11-tools/#1-clear-documentation","title":"1. Clear Documentation","text":"<pre><code>@tool\ndef calculate_discount(price: float, discount_percent: float) -&gt; float:\n    \"\"\"\n    Calculate discounted price.\n\n    Args:\n        price: Original price\n        discount_percent: Discount percentage (e.g., 15 for 15%)\n\n    Returns:\n        Final price after discount\n\n    Example:\n        &gt;&gt;&gt; calculate_discount(100.0, 15.0)\n        85.0\n    \"\"\"\n    return price * (1 - discount_percent / 100)\n</code></pre>"},{"location":"en/tutorials/11-tools/#2-input-validation","title":"2. Input Validation","text":"<pre><code>@tool\ndef withdraw_money(account_id: str, amount: float) -&gt; dict:\n    \"\"\"Withdraw money from account\"\"\"\n    if amount &lt;= 0:\n        raise ValueError(\"Amount must be positive\")\n    if amount &gt; 10000:\n        raise ValueError(\"Exceeds daily limit\")\n\n    # Process withdrawal\n    return {\"success\": True, \"new_balance\": 5000 - amount}\n</code></pre>"},{"location":"en/tutorials/11-tools/#3-error-handling","title":"3. Error Handling","text":"<pre><code>@tool\ndef fetch_user_data(user_id: int) -&gt; dict:\n    \"\"\"Fetch user data from database\"\"\"\n    try:\n        # Database query\n        user = database.get_user(user_id)\n        if not user:\n            raise ValueError(f\"User {user_id} not found\")\n        return user\n    except DatabaseError as e:\n        raise RuntimeError(f\"Database error: {e}\") from e\n</code></pre>"},{"location":"en/tutorials/11-tools/#4-type-hints","title":"4. Type Hints","text":"<p>Always use type hints for better documentation and validation:</p> <pre><code>@tool\ndef process_order(\n    order_id: str,\n    items: list[dict],\n    shipping_address: dict,\n    priority: bool = False\n) -&gt; dict:\n    \"\"\"Process customer order\"\"\"\n    # Implementation\n    return {\n        \"order_id\": order_id,\n        \"status\": \"processing\",\n        \"estimated_delivery\": \"2025-10-15\"\n    }\n</code></pre>"},{"location":"en/tutorials/11-tools/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/11-tools/#tool-not-found-in-registry","title":"Tool not found in registry","text":"<pre><code>from kagura.core.tool_registry import tool_registry\n\n# Check if tool is registered\nif \"my_tool\" not in tool_registry.list_names():\n    print(\"Tool not found!\")\n    print(\"Available tools:\", tool_registry.list_names())\n</code></pre>"},{"location":"en/tutorials/11-tools/#type-validation-errors","title":"Type validation errors","text":"<pre><code>@tool\ndef strict_function(x: int) -&gt; int:\n    return x * 2\n\n# This will raise TypeError\nstrict_function(\"not an int\")  # Error!\nstrict_function(5, 10)  # Too many arguments!\n</code></pre>"},{"location":"en/tutorials/11-tools/#tool-name-conflicts","title":"Tool name conflicts","text":"<pre><code># This will raise ValueError\n@tool\ndef duplicate():\n    pass\n\n@tool\ndef duplicate():  # Error: already registered!\n    pass\n\n# Solution: Use custom names\n@tool(name=\"duplicate_v2\")\ndef duplicate():\n    pass\n</code></pre>"},{"location":"en/tutorials/11-tools/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Agent Routing</li> <li>Explore MCP Integration</li> <li>Try Chat REPL</li> </ul>"},{"location":"en/tutorials/11-tools/#further-reading","title":"Further Reading","text":"<ul> <li>Tools API Reference</li> <li>Tool Registry API</li> <li>MCP Tools Integration</li> </ul>"},{"location":"en/tutorials/12-workflows/","title":"Workflows Tutorial","text":"<p>The @workflow decorator allows you to create multi-agent orchestrations that coordinate multiple agents and tools to accomplish complex tasks.</p>"},{"location":"en/tutorials/12-workflows/#what-are-workflows","title":"What are Workflows?","text":"<p>Workflows are multi-agent orchestrations that combine agents and tools in a coordinated sequence:</p> <ul> <li>Coordination: Call multiple agents in sequence or parallel</li> <li>Data Flow: Pass results between agents</li> <li>Complex Tasks: Break down large problems into steps</li> <li>Reusability: Package multi-step processes</li> </ul> <p>Unlike <code>@agent</code> (which calls an LLM) and <code>@tool</code> (which executes pure Python), <code>@workflow</code> executes the function body to orchestrate agent calls.</p>"},{"location":"en/tutorials/12-workflows/#quick-start","title":"Quick Start","text":""},{"location":"en/tutorials/12-workflows/#basic-workflow","title":"Basic Workflow","text":"<pre><code>from kagura import workflow, agent\n\n@agent\nasync def search_agent(query: str) -&gt; str:\n    \"\"\"Search for information about {{ query }}\"\"\"\n    ...\n\n@agent\nasync def summarize_agent(text: str) -&gt; str:\n    \"\"\"Summarize: {{ text }}\"\"\"\n    ...\n\n@workflow\nasync def research_workflow(topic: str) -&gt; dict:\n    \"\"\"Research a topic using multiple agents\"\"\"\n    # Step 1: Search for information\n    search_results = await search_agent(topic)\n\n    # Step 2: Summarize findings\n    summary = await summarize_agent(search_results)\n\n    return {\n        \"topic\": topic,\n        \"findings\": search_results,\n        \"summary\": summary\n    }\n\n# Use\nresult = await research_workflow(\"AI safety\")\n</code></pre>"},{"location":"en/tutorials/12-workflows/#workflow-features","title":"Workflow Features","text":""},{"location":"en/tutorials/12-workflows/#1-sequential-execution","title":"1. Sequential Execution","text":"<p>Execute agents in a specific order:</p> <pre><code>@workflow\nasync def content_pipeline(topic: str) -&gt; dict:\n    \"\"\"Create content through multiple stages\"\"\"\n    # Research phase\n    research = await research_agent(topic)\n\n    # Writing phase\n    draft = await writing_agent(research)\n\n    # Editing phase\n    final = await editing_agent(draft)\n\n    return {\n        \"topic\": topic,\n        \"draft\": draft,\n        \"final\": final\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#2-parallel-execution","title":"2. Parallel Execution","text":"<p>Run agents concurrently using <code>asyncio.gather</code>:</p> <pre><code>import asyncio\n\n@workflow\nasync def multi_source_research(topic: str) -&gt; dict:\n    \"\"\"Research from multiple sources in parallel\"\"\"\n    # Execute in parallel\n    results = await asyncio.gather(\n        academic_search_agent(topic),\n        news_search_agent(topic),\n        social_media_agent(topic)\n    )\n\n    academic, news, social = results\n\n    # Combine results\n    combined = await synthesis_agent(\n        f\"Academic: {academic}\\nNews: {news}\\nSocial: {social}\"\n    )\n\n    return {\n        \"academic\": academic,\n        \"news\": news,\n        \"social\": social,\n        \"synthesis\": combined\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#3-conditional-logic","title":"3. Conditional Logic","text":"<p>Use branching logic based on results:</p> <pre><code>@workflow\nasync def smart_analysis(text: str) -&gt; dict:\n    \"\"\"Analyze text with conditional processing\"\"\"\n    # Classify content type\n    content_type = await classifier_agent(text)\n\n    # Different processing based on type\n    if content_type == \"technical\":\n        analysis = await technical_analyzer(text)\n    elif content_type == \"creative\":\n        analysis = await creative_analyzer(text)\n    else:\n        analysis = await general_analyzer(text)\n\n    return {\n        \"type\": content_type,\n        \"analysis\": analysis\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#4-error-handling","title":"4. Error Handling","text":"<p>Handle failures gracefully:</p> <pre><code>@workflow\nasync def robust_workflow(query: str) -&gt; dict:\n    \"\"\"Workflow with error handling\"\"\"\n    try:\n        primary_result = await primary_agent(query)\n    except Exception as e:\n        # Fallback to secondary agent\n        primary_result = await fallback_agent(query)\n\n    # Validate result\n    if not primary_result:\n        raise ValueError(\"No results found\")\n\n    return {\n        \"query\": query,\n        \"result\": primary_result\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#workflow-registry","title":"Workflow Registry","text":"<p>All workflows are automatically registered in the global <code>workflow_registry</code>:</p> <pre><code>from kagura.core.workflow_registry import workflow_registry\n\n# List all workflows\nprint(workflow_registry.list_names())\n# ['research_workflow', 'content_pipeline', ...]\n\n# Get a specific workflow\nworkflow = workflow_registry.get(\"research_workflow\")\nresult = await workflow(\"AI safety\")\n\n# Get all workflows\nall_workflows = workflow_registry.get_all()\nfor name, func in all_workflows.items():\n    print(f\"{name}: {func.__doc__}\")\n</code></pre>"},{"location":"en/tutorials/12-workflows/#examples","title":"Examples","text":""},{"location":"en/tutorials/12-workflows/#example-1-document-processing-workflow","title":"Example 1: Document Processing Workflow","text":"<pre><code>@workflow\nasync def process_document(file_path: str) -&gt; dict:\n    \"\"\"Complete document processing pipeline\"\"\"\n    # Extract text\n    text = await extract_text_tool(file_path)\n\n    # Analyze sentiment\n    sentiment = await sentiment_agent(text)\n\n    # Extract key points\n    key_points = await extraction_agent(text)\n\n    # Generate summary\n    summary = await summarization_agent(text)\n\n    # Categorize\n    category = await categorization_agent(text)\n\n    return {\n        \"file\": file_path,\n        \"sentiment\": sentiment,\n        \"key_points\": key_points,\n        \"summary\": summary,\n        \"category\": category\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#example-2-customer-support-workflow","title":"Example 2: Customer Support Workflow","text":"<pre><code>@workflow\nasync def customer_support_workflow(ticket: dict) -&gt; dict:\n    \"\"\"Handle customer support ticket\"\"\"\n    # Classify urgency\n    urgency = await urgency_classifier(ticket[\"description\"])\n\n    # Route based on urgency\n    if urgency == \"high\":\n        # Immediate escalation\n        response = await senior_support_agent(ticket)\n    else:\n        # Standard processing\n        response = await support_agent(ticket)\n\n    # Generate follow-up\n    follow_up = await follow_up_agent(response)\n\n    return {\n        \"ticket_id\": ticket[\"id\"],\n        \"urgency\": urgency,\n        \"response\": response,\n        \"follow_up\": follow_up\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#example-3-data-analysis-workflow","title":"Example 3: Data Analysis Workflow","text":"<pre><code>@workflow\nasync def data_analysis_workflow(dataset: str) -&gt; dict:\n    \"\"\"Analyze dataset with multiple techniques\"\"\"\n    # Load and validate data\n    data = await data_loader_tool(dataset)\n\n    # Statistical analysis\n    stats = await statistical_agent(data)\n\n    # Pattern detection\n    patterns = await pattern_detection_agent(data)\n\n    # Visualization\n    viz = await visualization_agent(data, patterns)\n\n    # Report generation\n    report = await report_agent(\n        f\"Stats: {stats}\\nPatterns: {patterns}\"\n    )\n\n    return {\n        \"dataset\": dataset,\n        \"statistics\": stats,\n        \"patterns\": patterns,\n        \"visualization\": viz,\n        \"report\": report\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#example-4-content-creation-workflow","title":"Example 4: Content Creation Workflow","text":"<pre><code>@workflow\nasync def content_creation_workflow(\n    topic: str,\n    target_audience: str\n) -&gt; dict:\n    \"\"\"Create content tailored to audience\"\"\"\n    # Research topic\n    research = await research_agent(f\"{topic} for {target_audience}\")\n\n    # Generate outline\n    outline = await outline_agent(research)\n\n    # Write content sections in parallel\n    sections = await asyncio.gather(\n        intro_writer_agent(outline[0]),\n        body_writer_agent(outline[1]),\n        conclusion_writer_agent(outline[2])\n    )\n\n    # Combine sections\n    full_content = \"\\n\\n\".join(sections)\n\n    # Edit for audience\n    edited = await editor_agent(\n        f\"Edit for {target_audience}: {full_content}\"\n    )\n\n    # SEO optimization\n    seo_optimized = await seo_agent(edited, topic)\n\n    return {\n        \"topic\": topic,\n        \"audience\": target_audience,\n        \"research\": research,\n        \"outline\": outline,\n        \"content\": seo_optimized\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#integration-with-agents-and-tools","title":"Integration with Agents and Tools","text":""},{"location":"en/tutorials/12-workflows/#combining-agents-and-tools","title":"Combining Agents and Tools","text":"<pre><code>from kagura import workflow, agent, tool\n\n@tool\ndef calculate_metrics(data: list) -&gt; dict:\n    \"\"\"Calculate statistical metrics\"\"\"\n    return {\n        \"mean\": sum(data) / len(data),\n        \"max\": max(data),\n        \"min\": min(data)\n    }\n\n@agent\nasync def insights_agent(metrics: dict) -&gt; str:\n    \"\"\"Generate insights from {{ metrics }}\"\"\"\n    ...\n\n@workflow\nasync def analytics_workflow(data: list) -&gt; dict:\n    \"\"\"Analyze data and generate insights\"\"\"\n    # Use tool for calculations\n    metrics = calculate_metrics(data)\n\n    # Use agent for insights\n    insights = await insights_agent(metrics)\n\n    return {\n        \"metrics\": metrics,\n        \"insights\": insights\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/12-workflows/#1-clear-workflow-structure","title":"1. Clear Workflow Structure","text":"<pre><code>@workflow\nasync def well_structured_workflow(input_data: str) -&gt; dict:\n    \"\"\"\n    Process data through multiple stages.\n\n    Stages:\n    1. Validation\n    2. Processing\n    3. Analysis\n    4. Reporting\n    \"\"\"\n    # Stage 1: Validation\n    validated = await validation_agent(input_data)\n\n    # Stage 2: Processing\n    processed = await processing_agent(validated)\n\n    # Stage 3: Analysis\n    analyzed = await analysis_agent(processed)\n\n    # Stage 4: Reporting\n    report = await reporting_agent(analyzed)\n\n    return {\n        \"validated\": validated,\n        \"processed\": processed,\n        \"analyzed\": analyzed,\n        \"report\": report\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#2-error-recovery","title":"2. Error Recovery","text":"<pre><code>@workflow\nasync def resilient_workflow(task: str) -&gt; dict:\n    \"\"\"Workflow with retry logic\"\"\"\n    max_retries = 3\n\n    for attempt in range(max_retries):\n        try:\n            result = await unreliable_agent(task)\n            break\n        except Exception as e:\n            if attempt == max_retries - 1:\n                # Final fallback\n                result = await fallback_agent(task)\n            else:\n                # Retry with backoff\n                await asyncio.sleep(2 ** attempt)\n\n    return {\"task\": task, \"result\": result}\n</code></pre>"},{"location":"en/tutorials/12-workflows/#3-progress-tracking","title":"3. Progress Tracking","text":"<pre><code>@workflow\nasync def tracked_workflow(items: list) -&gt; dict:\n    \"\"\"Track progress through workflow\"\"\"\n    results = []\n    total = len(items)\n\n    for i, item in enumerate(items, 1):\n        print(f\"Processing {i}/{total}: {item}\")\n        result = await processing_agent(item)\n        results.append(result)\n\n    return {\n        \"total\": total,\n        \"processed\": len(results),\n        \"results\": results\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#4-modular-design","title":"4. Modular Design","text":"<pre><code># Define reusable sub-workflows\n@workflow\nasync def data_prep_workflow(raw_data: str) -&gt; dict:\n    \"\"\"Reusable data preparation\"\"\"\n    cleaned = await cleaning_agent(raw_data)\n    normalized = await normalization_agent(cleaned)\n    return {\"cleaned\": cleaned, \"normalized\": normalized}\n\n@workflow\nasync def main_workflow(input_data: str) -&gt; dict:\n    \"\"\"Main workflow using sub-workflows\"\"\"\n    # Reuse data prep\n    prepared = await data_prep_workflow(input_data)\n\n    # Continue with analysis\n    analysis = await analysis_agent(prepared[\"normalized\"])\n\n    return {\n        \"prepared\": prepared,\n        \"analysis\": analysis\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/12-workflows/#workflow-not-found-in-registry","title":"Workflow not found in registry","text":"<pre><code>from kagura.core.workflow_registry import workflow_registry\n\n# Check if workflow is registered\nif \"my_workflow\" not in workflow_registry.list_names():\n    print(\"Workflow not found!\")\n    print(\"Available workflows:\", workflow_registry.list_names())\n</code></pre>"},{"location":"en/tutorials/12-workflows/#workflow-name-conflicts","title":"Workflow name conflicts","text":"<pre><code># This will raise ValueError\n@workflow\ndef duplicate():\n    pass\n\n@workflow\ndef duplicate():  # Error: already registered!\n    pass\n\n# Solution: Use custom names\n@workflow(name=\"duplicate_v2\")\nasync def duplicate():\n    pass\n</code></pre>"},{"location":"en/tutorials/12-workflows/#asyncawait-issues","title":"Async/await issues","text":"<pre><code># \u274c Wrong: Forgot await\n@workflow\nasync def broken_workflow(query: str) -&gt; str:\n    result = search_agent(query)  # Missing await!\n    return result\n\n# \u2705 Correct: Always await agent calls\n@workflow\nasync def correct_workflow(query: str) -&gt; str:\n    result = await search_agent(query)\n    return result\n</code></pre>"},{"location":"en/tutorials/12-workflows/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about MCP Integration</li> <li>Explore Agent Routing</li> <li>Try Chat REPL</li> </ul>"},{"location":"en/tutorials/12-workflows/#further-reading","title":"Further Reading","text":"<ul> <li>Workflows API Reference</li> <li>Workflow Registry API</li> <li>MCP Workflows Integration</li> </ul>"},{"location":"en/tutorials/13-agent-builder/","title":"Tutorial 13: Agent Builder","text":"<p>Learn how to use the AgentBuilder fluent API to create complex agents with integrated features.</p>"},{"location":"en/tutorials/13-agent-builder/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed (<code>pip install kagura-ai</code>)</li> <li>Completion of Tutorial 1: Basic Agent</li> <li>OpenAI API key (or other LLM provider)</li> </ul>"},{"location":"en/tutorials/13-agent-builder/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand the AgentBuilder fluent API pattern - Build agents with memory, tools, and hooks - Configure LLM generation parameters - Create reusable agent configurations</p>"},{"location":"en/tutorials/13-agent-builder/#what-is-agentbuilder","title":"What is AgentBuilder?","text":"<p><code>AgentBuilder</code> is a fluent API that simplifies creating complex agents with multiple features. Instead of manually wiring together memory, tools, hooks, and routing, you can use method chaining to build agents declaratively.</p>"},{"location":"en/tutorials/13-agent-builder/#before-agentbuilder","title":"Before AgentBuilder","text":"<pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n# Manually configure everything\nmemory = MemoryManager(agent_name=\"my_agent\", enable_rag=True)\n\n@agent(model=\"gpt-4o-mini\", temperature=0.7)\nasync def my_agent(prompt: str) -&gt; str:\n    '''Process: {{ prompt }}'''\n    pass\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#with-agentbuilder","title":"With AgentBuilder","text":"<pre><code>from kagura import AgentBuilder\n\n# Declarative configuration\nagent = (\n    AgentBuilder(\"my_agent\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(type=\"rag\", enable_rag=True)\n    .with_context(temperature=0.7)\n    .build()\n)\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#step-1-basic-agent-creation","title":"Step 1: Basic Agent Creation","text":"<p>Create a file called <code>builder_demo.py</code>:</p> <pre><code>import asyncio\nfrom kagura import AgentBuilder\n\n\nasync def main():\n    # Create a basic agent with AgentBuilder\n    agent = (\n        AgentBuilder(\"greeter\")\n        .with_model(\"gpt-4o-mini\")\n        .build()\n    )\n\n    result = await agent(\"Say hello!\")\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Run it:</p> <pre><code>python builder_demo.py\n</code></pre> <p>Explanation: 1. <code>AgentBuilder(\"greeter\")</code> - Initialize builder with agent name 2. <code>.with_model(\"gpt-4o-mini\")</code> - Set the LLM model 3. <code>.build()</code> - Build the final agent</p>"},{"location":"en/tutorials/13-agent-builder/#step-2-adding-memory","title":"Step 2: Adding Memory","text":"<p>Let's add memory so the agent can remember conversation history:</p> <pre><code>agent = (\n    AgentBuilder(\"assistant\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(\n        type=\"working\",\n        max_messages=50,\n        enable_rag=False\n    )\n    .build()\n)\n\n# Agent can now access conversation history\nresult = await agent(\"My name is Alice\")\nprint(result)  # \"Nice to meet you, Alice!\"\n\nresult = await agent(\"What's my name?\")\nprint(result)  # \"Your name is Alice.\"\n</code></pre> <p>Memory Types: - <code>\"working\"</code> - In-memory storage (fast, temporary) - <code>\"context\"</code> - Conversation context (for LLM context window) - <code>\"persistent\"</code> - SQLite storage (survives restarts) - <code>\"rag\"</code> - Vector-based semantic search (requires ChromaDB)</p>"},{"location":"en/tutorials/13-agent-builder/#step-3-rag-semantic-memory","title":"Step 3: RAG (Semantic Memory)","text":"<p>For semantic search over conversation history:</p> <pre><code>agent = (\n    AgentBuilder(\"smart_assistant\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(\n        type=\"rag\",\n        enable_rag=True,\n        max_messages=100\n    )\n    .build()\n)\n\n# Store various facts\nawait agent(\"Python is a programming language created by Guido van Rossum\")\nawait agent(\"I love hiking in the mountains\")\nawait agent(\"My favorite food is sushi\")\n\n# Semantic search finds relevant context\nresult = await agent(\"Tell me about programming\")\n# Agent recalls: \"Python is a programming language...\"\n\nresult = await agent(\"What do I like to eat?\")\n# Agent recalls: \"My favorite food is sushi\"\n</code></pre> <p>Note: RAG requires ChromaDB installation: <pre><code>pip install chromadb\n</code></pre></p>"},{"location":"en/tutorials/13-agent-builder/#step-4-adding-tools","title":"Step 4: Adding Tools","text":"<p>Tools extend agents with external capabilities:</p> <pre><code>def search_web(query: str) -&gt; str:\n    \"\"\"Search the web for information.\"\"\"\n    # Simulate web search\n    return f\"Search results for: {query}\"\n\n\ndef calculate(expression: str) -&gt; float:\n    \"\"\"Evaluate a mathematical expression.\"\"\"\n    return eval(expression)  # Note: Use safely in production!\n\n\nagent = (\n    AgentBuilder(\"researcher\")\n    .with_model(\"gpt-4o-mini\")\n    .with_tools([search_web, calculate])\n    .build()\n)\n\n# Agent can now use tools\nresult = await agent(\"What is 15 * 23?\")\n# Agent calls calculate(\"15 * 23\") and returns: \"345\"\n\nresult = await agent(\"Search for Python tutorials\")\n# Agent calls search_web(\"Python tutorials\")\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#step-5-pre-and-post-hooks","title":"Step 5: Pre and Post Hooks","text":"<p>Hooks let you inject logic before and after agent execution:</p> <pre><code>def log_input(*args, **kwargs):\n    \"\"\"Log agent input.\"\"\"\n    print(f\"[PRE] Input: {args}, {kwargs}\")\n\n\ndef log_output(result):\n    \"\"\"Log agent output.\"\"\"\n    print(f\"[POST] Output: {result}\")\n\n\nagent = (\n    AgentBuilder(\"monitored_agent\")\n    .with_model(\"gpt-4o-mini\")\n    .with_hooks(\n        pre=[log_input],\n        post=[log_output]\n    )\n    .build()\n)\n\nresult = await agent(\"Hello!\")\n# Console output:\n# [PRE] Input: ('Hello!',), {}\n# [POST] Output: Hi there! How can I help you?\n</code></pre> <p>Use Cases for Hooks: - Logging and monitoring - Input validation - Output sanitization - Rate limiting - Caching</p>"},{"location":"en/tutorials/13-agent-builder/#step-6-llm-generation-parameters","title":"Step 6: LLM Generation Parameters","text":"<p>Control how the LLM generates responses:</p> <pre><code># More deterministic (factual tasks)\nfactual_agent = (\n    AgentBuilder(\"fact_checker\")\n    .with_model(\"gpt-4o-mini\")\n    .with_context(\n        temperature=0.2,\n        max_tokens=500\n    )\n    .build()\n)\n\n# More creative (story generation)\ncreative_agent = (\n    AgentBuilder(\"storyteller\")\n    .with_model(\"gpt-4o-mini\")\n    .with_context(\n        temperature=1.5,\n        max_tokens=1000,\n        top_p=0.9\n    )\n    .build()\n)\n</code></pre> <p>Common Parameters: - <code>temperature</code> (0.0-2.0): Randomness (lower = more deterministic) - <code>max_tokens</code>: Maximum response length - <code>top_p</code> (0.0-1.0): Nucleus sampling threshold - <code>frequency_penalty</code>: Discourage repetition - <code>presence_penalty</code>: Encourage new topics</p>"},{"location":"en/tutorials/13-agent-builder/#complete-example-multi-feature-agent","title":"Complete Example: Multi-Feature Agent","text":"<p>Here's an agent with all features combined:</p> <pre><code>import asyncio\nfrom pathlib import Path\nfrom kagura import AgentBuilder\n\n\ndef web_search(query: str) -&gt; str:\n    \"\"\"Search the web.\"\"\"\n    return f\"Results for: {query}\"\n\n\ndef log_execution(result):\n    \"\"\"Log each execution.\"\"\"\n    print(f\"[LOG] Agent returned: {result}\")\n\n\nasync def main():\n    # Build a powerful multi-feature agent\n    agent = (\n        AgentBuilder(\"advanced_assistant\")\n        .with_model(\"gpt-4o-mini\")\n        .with_memory(\n            type=\"persistent\",\n            persist_dir=Path.home() / \".kagura\" / \"agents\",\n            max_messages=100,\n            enable_rag=True\n        )\n        .with_tools([web_search])\n        .with_hooks(\n            post=[log_execution]\n        )\n        .with_context(\n            temperature=0.7,\n            max_tokens=800\n        )\n        .build()\n    )\n\n    # Test the agent\n    result = await agent(\"Search for Python tutorials\")\n    print(f\"Response: {result}\")\n\n    result = await agent(\"What did I just ask you?\")\n    print(f\"Response: {result}\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#agent-configuration-object","title":"Agent Configuration Object","text":"<p>You can also work with configuration separately:</p> <pre><code>from kagura import AgentBuilder\nfrom kagura.builder import AgentConfiguration, MemoryConfig\n\n# Create configuration\nconfig = AgentConfiguration(\n    name=\"my_agent\",\n    model=\"gpt-4o-mini\"\n)\n\n# Build agent from config\nbuilder = AgentBuilder(config.name)\nbuilder._config = config\nagent = builder.build()\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/13-agent-builder/#1-descriptive-agent-names","title":"1. Descriptive Agent Names","text":"<pre><code># Good\nAgentBuilder(\"customer_support_chatbot\")\nAgentBuilder(\"data_analysis_assistant\")\n\n# Less clear\nAgentBuilder(\"agent1\")\nAgentBuilder(\"my_agent\")\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#2-choose-appropriate-memory-type","title":"2. Choose Appropriate Memory Type","text":"<pre><code># Short conversations - working memory\nAgentBuilder(\"quick_qa\").with_memory(type=\"working\")\n\n# Long-term knowledge - RAG\nAgentBuilder(\"knowledge_base\").with_memory(type=\"rag\", enable_rag=True)\n\n# Persistent storage - persistent memory\nAgentBuilder(\"assistant\").with_memory(\n    type=\"persistent\",\n    persist_dir=Path.home() / \".kagura\"\n)\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#3-model-selection","title":"3. Model Selection","text":"<pre><code># Fast, cheap tasks\n.with_model(\"gpt-4o-mini\")\n\n# Complex reasoning\n.with_model(\"gpt-4o\")\n.with_model(\"claude-3-5-sonnet-20241022\")\n\n# Local models\n.with_model(\"ollama/llama3.2\")\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#4-method-chaining-formatting","title":"4. Method Chaining Formatting","text":"<pre><code># Good - readable\nagent = (\n    AgentBuilder(\"name\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(type=\"rag\")\n    .with_tools([tool1, tool2])\n    .build()\n)\n\n# Less readable\nagent = AgentBuilder(\"name\").with_model(\"gpt-4o-mini\").with_memory(type=\"rag\").with_tools([tool1, tool2]).build()\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#common-patterns","title":"Common Patterns","text":""},{"location":"en/tutorials/13-agent-builder/#pattern-1-chatbot-with-memory","title":"Pattern 1: Chatbot with Memory","text":"<pre><code>chatbot = (\n    AgentBuilder(\"chatbot\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(type=\"context\", max_messages=20)\n    .with_context(temperature=0.8)\n    .build()\n)\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#pattern-2-researcher-with-tools","title":"Pattern 2: Researcher with Tools","text":"<pre><code>researcher = (\n    AgentBuilder(\"researcher\")\n    .with_model(\"gpt-4o\")\n    .with_tools([web_search, summarize, extract_facts])\n    .with_context(temperature=0.3)\n    .build()\n)\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#pattern-3-monitored-agent","title":"Pattern 3: Monitored Agent","text":"<pre><code>monitored = (\n    AgentBuilder(\"monitored\")\n    .with_model(\"gpt-4o-mini\")\n    .with_hooks(\n        pre=[validate_input, rate_limit],\n        post=[log_output, cache_result]\n    )\n    .build()\n)\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#common-mistakes","title":"Common Mistakes","text":""},{"location":"en/tutorials/13-agent-builder/#1-forgetting-build","title":"1. Forgetting <code>.build()</code>","text":"<pre><code># Wrong - returns AgentBuilder, not an agent\nagent = AgentBuilder(\"name\").with_model(\"gpt-4o-mini\")\n\n# Correct\nagent = AgentBuilder(\"name\").with_model(\"gpt-4o-mini\").build()\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#2-enabling-rag-without-chromadb","title":"2. Enabling RAG Without ChromaDB","text":"<pre><code># This will fail if chromadb is not installed\nagent = (\n    AgentBuilder(\"agent\")\n    .with_memory(enable_rag=True)\n    .build()\n)\n\n# Install first:\n# pip install chromadb\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#3-incompatible-memory-and-rag","title":"3. Incompatible Memory and RAG","text":"<pre><code># RAG should use \"rag\" or \"persistent\" memory type\nagent = (\n    AgentBuilder(\"agent\")\n    .with_memory(type=\"working\", enable_rag=True)  # Conflict!\n    .build()\n)\n\n# Better\nagent = (\n    AgentBuilder(\"agent\")\n    .with_memory(type=\"rag\", enable_rag=True)\n    .build()\n)\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#practice-exercises","title":"Practice Exercises","text":""},{"location":"en/tutorials/13-agent-builder/#exercise-1-build-a-knowledge-assistant","title":"Exercise 1: Build a Knowledge Assistant","text":"<p>Create an agent that: - Uses GPT-4o-mini - Has RAG-enabled memory - Logs all interactions</p> <pre><code># Your code here\nknowledge_assistant = (\n    AgentBuilder(\"knowledge_assistant\")\n    # Add configurations\n    .build()\n)\n\n# Test it\nawait knowledge_assistant(\"Python is a programming language\")\nawait knowledge_assistant(\"What did I tell you about Python?\")\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#exercise-2-tool-equipped-researcher","title":"Exercise 2: Tool-Equipped Researcher","text":"<p>Create an agent with: - GPT-4o model - Web search and calculator tools - Low temperature (0.2) for accuracy</p> <pre><code># Your code here\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#exercise-3-multi-agent-system","title":"Exercise 3: Multi-Agent System","text":"<p>Build two agents with different configurations and have them work together:</p> <pre><code># Analyst (factual)\nanalyst = AgentBuilder(\"analyst\")...\n\n# Storyteller (creative)\nstoryteller = AgentBuilder(\"storyteller\")...\n\n# Workflow\nfacts = await analyst(\"Analyze: quantum computing\")\nstory = await storyteller(f\"Write a story about: {facts}\")\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"en/tutorials/13-agent-builder/#1-fluent-api-pattern","title":"1. Fluent API Pattern","text":"<p>Method chaining for readable configuration: <pre><code>builder.method1().method2().method3()\n</code></pre></p>"},{"location":"en/tutorials/13-agent-builder/#2-declarative-agent-configuration","title":"2. Declarative Agent Configuration","text":"<p>Specify what you want, not how to build it: <pre><code>AgentBuilder(\"name\").with_feature().build()\n</code></pre></p>"},{"location":"en/tutorials/13-agent-builder/#3-feature-integration","title":"3. Feature Integration","text":"<p>Combine memory, tools, and hooks seamlessly: <pre><code>.with_memory().with_tools().with_hooks()\n</code></pre></p>"},{"location":"en/tutorials/13-agent-builder/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial 14: Agent Testing - Learn to test your agents</li> <li>Tutorial 15: Observability - Monitor agent performance</li> <li>API Reference: Builder - Complete API documentation</li> </ul>"},{"location":"en/tutorials/13-agent-builder/#summary","title":"Summary","text":"<p>You learned: - \u2713 How to use AgentBuilder's fluent API - \u2713 How to add memory (working, persistent, RAG) - \u2713 How to integrate tools and hooks - \u2713 How to configure LLM generation parameters - \u2713 Best practices for agent configuration</p> <p>Continue to Tutorial 14: Agent Testing to learn how to test your agents!</p>"},{"location":"en/tutorials/13-multimodal-rag/","title":"Tutorial 13: Multimodal RAG - Search Images, Audio, Videos &amp; PDFs","text":"<p>Learn how to create AI agents that can search and understand multimodal content (images, audio, video, PDFs) from your directories using Retrieval-Augmented Generation (RAG).</p>"},{"location":"en/tutorials/13-multimodal-rag/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed with web support: <code>pip install kagura-ai[web]</code></li> <li>Google API key (for Gemini API)</li> <li>ChromaDB installed (included with multimodal extra)</li> </ul>"},{"location":"en/tutorials/13-multimodal-rag/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand what Multimodal RAG is and why it's useful - Set up a directory for multimodal content indexing - Create agents that can search across text, images, audio, videos, and PDFs - Build a documentation assistant that understands diagrams and screenshots</p>"},{"location":"en/tutorials/13-multimodal-rag/#what-is-multimodal-rag","title":"What is Multimodal RAG?","text":"<p>RAG (Retrieval-Augmented Generation) enhances AI agents by giving them access to external knowledge. Multimodal RAG extends this to work with:</p> <ul> <li>Images (PNG, JPG, GIF, WEBP)</li> <li>Audio (MP3, WAV, M4A)</li> <li>Video (MP4, MOV, AVI)</li> <li>PDFs (documents with text and images)</li> <li>Text files (MD, TXT, Python code, etc.)</li> </ul> <p>Instead of just searching text, your agent can: - Find relevant diagrams and screenshots - Transcribe and search audio recordings - Extract information from video content - Process PDF documentation</p>"},{"location":"en/tutorials/13-multimodal-rag/#step-1-set-up-your-environment","title":"Step 1: Set Up Your Environment","text":"<p>Set your Google API key (required for processing multimodal content):</p> <pre><code>export GOOGLE_API_KEY=\"your-gemini-api-key\"\n</code></pre> <p>Install Kagura AI with web support (includes multimodal features):</p> <pre><code>pip install kagura-ai[web]\n</code></pre> <p>This installs: - <code>google-generativeai</code> - For Gemini API (multimodal processing) - <code>chromadb</code> - Vector database for semantic search (included in <code>ai</code> extra) - <code>pillow</code> - Image processing</p>"},{"location":"en/tutorials/13-multimodal-rag/#step-2-prepare-your-content-directory","title":"Step 2: Prepare Your Content Directory","text":"<p>Create a project directory with mixed content:</p> <pre><code>mkdir my_project\ncd my_project\n\n# Create some documentation\necho \"# Authentication\\nOur app uses OAuth 2.0\" &gt; auth.md\n\n# Create a docs folder\nmkdir docs\necho \"User guide content here\" &gt; docs/guide.txt\n\n# Add some images (diagrams, screenshots, etc.)\nmkdir images\n# Add your actual images here\n</code></pre> <p>Your directory structure: <pre><code>my_project/\n\u251c\u2500\u2500 auth.md           # Text documentation\n\u251c\u2500\u2500 docs/\n\u2502   \u2514\u2500\u2500 guide.txt     # More docs\n\u2514\u2500\u2500 images/\n    \u251c\u2500\u2500 diagram.png   # Architecture diagram\n    \u2514\u2500\u2500 screenshot.jpg # UI screenshot\n</code></pre></p>"},{"location":"en/tutorials/13-multimodal-rag/#step-3-create-your-first-rag-agent","title":"Step 3: Create Your First RAG Agent","text":"<p>Create <code>rag_agent.py</code>:</p> <pre><code>import asyncio\nfrom pathlib import Path\nfrom kagura import agent\n\n\n@agent(\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./my_project\")\n)\nasync def docs_assistant(query: str, rag) -&gt; str:\n    '''Answer the question: {{ query }}\n\n    Use rag.query(query) to search documentation.\n    Include relevant details from the search results.'''\n    pass\n\n\nasync def main():\n    # First call: Builds index (may take a moment)\n    result = await docs_assistant(\"How does authentication work?\")\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Let's break this down:</p> <ol> <li><code>enable_multimodal_rag=True</code> - Enables RAG functionality</li> <li><code>rag_directory=Path(\"./my_project\")</code> - Directory to index</li> <li><code>rag</code> parameter - Auto-injected MultimodalRAG instance</li> <li><code>rag.query(query)</code> - Search for relevant content</li> </ol>"},{"location":"en/tutorials/13-multimodal-rag/#step-4-run-your-rag-agent","title":"Step 4: Run Your RAG Agent","text":"<p>Execute the script:</p> <pre><code>python rag_agent.py\n</code></pre> <p>First run: <pre><code>Building index from /path/to/my_project\nIndex built: 5 files (3 text, 2 multimodal)\nOur app uses OAuth 2.0 for authentication...\n</code></pre></p> <p>Subsequent runs: Much faster (uses cached index)</p> <p>\ud83c\udf89 Your agent can now search across all your documentation!</p>"},{"location":"en/tutorials/13-multimodal-rag/#how-it-works-behind-the-scenes","title":"How It Works: Behind the Scenes","text":""},{"location":"en/tutorials/13-multimodal-rag/#index-building","title":"Index Building","text":"<p>When you first call the agent:</p> <ol> <li>Directory Scanning: Recursively scans <code>my_project/</code></li> <li>File Type Detection: Identifies text, images, audio, video, PDFs</li> <li>Content Processing:</li> <li>Text files: Read directly</li> <li>Images: Analyzed with Gemini Vision API (describes content)</li> <li>Audio: Transcribed to text</li> <li>Video: Frames extracted and analyzed</li> <li>PDFs: Text and images extracted</li> <li>Vector Indexing: Stores in ChromaDB for semantic search</li> <li>Caching: Results cached for faster subsequent access</li> </ol>"},{"location":"en/tutorials/13-multimodal-rag/#query-time","title":"Query Time","text":"<p>When you search:</p> <ol> <li>Semantic Search: Finds relevant content using vector similarity</li> <li>Context Injection: Results available to the agent</li> <li>LLM Response: Agent synthesizes answer using search results</li> </ol>"},{"location":"en/tutorials/13-multimodal-rag/#step-5-advanced-usage-manual-search","title":"Step 5: Advanced Usage - Manual Search","text":"<p>You can manually control the search and response:</p> <pre><code>@agent(\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./my_project\")\n)\nasync def smart_assistant(query: str, rag) -&gt; str:\n    '''You are a helpful documentation assistant.\n\n    First, search for relevant information using: rag.query(\"{{ query }}\", n_results=3)\n    Then answer based on the search results: {{ query }}\n\n    If no relevant results found, say \"I couldn't find information about that.\"'''\n    pass\n</code></pre> <p>How this works: - The prompt tells the LLM to use <code>rag.query()</code> - The LLM calls it during generation (via tool calling) - Results are incorporated into the response</p>"},{"location":"en/tutorials/13-multimodal-rag/#step-6-building-the-index-explicitly","title":"Step 6: Building the Index Explicitly","text":"<p>For large directories, build the index ahead of time:</p> <pre><code>from pathlib import Path\nfrom kagura.core.memory import MultimodalRAG\nimport asyncio\n\n\nasync def build_index():\n    # Initialize RAG\n    rag = MultimodalRAG(\n        directory=Path(\"./my_project\"),\n        collection_name=\"my_docs\"\n    )\n\n    # Build index\n    stats = await rag.build_index(max_concurrent=3)\n\n    print(f\"Indexed {stats['total_files']} files\")\n    print(f\"  - Text: {stats['text_files']}\")\n    print(f\"  - Multimodal: {stats['multimodal_files']}\")\n    print(f\"  - Failed: {stats['failed_files']}\")\n    print(f\"Cache hit rate: {stats['cache_hit_rate']:.2%}\")\n\n\nasyncio.run(build_index())\n</code></pre> <p>Output: <pre><code>Building index from ./my_project\nIndexed 15 files\n  - Text: 10\n  - Multimodal: 5\n  - Failed: 0\nCache hit rate: 0.00%\n</code></pre></p>"},{"location":"en/tutorials/13-multimodal-rag/#step-7-search-by-file-type","title":"Step 7: Search by File Type","text":"<p>Filter results by content type:</p> <pre><code>from kagura.loaders.file_types import FileType\n\n# Search only images\nresults = rag.query(\"architecture diagram\", file_type=FileType.IMAGE)\n\n# Search only text\nresults = rag.query(\"authentication\", file_type=FileType.TEXT)\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#step-8-incremental-updates","title":"Step 8: Incremental Updates","text":"<p>Update the index when files change:</p> <pre><code># Add new files to my_project/\n# Then update incrementally (faster than full rebuild)\nstats = await rag.incremental_update()\nprint(f\"Updated {stats['total_files']} new/modified files\")\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#configuration-options","title":"Configuration Options","text":""},{"location":"en/tutorials/13-multimodal-rag/#rag-parameters","title":"RAG Parameters","text":"<pre><code>@agent(\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./docs\"),        # Required\n    rag_cache_size_mb=100,                # Cache size (default: 100MB)\n    persist_dir=Path(\"./.kagura\")         # ChromaDB storage location\n)\nasync def my_agent(query: str, rag) -&gt; str:\n    pass\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#multimodalrag-options","title":"MultimodalRAG Options","text":"<pre><code>from kagura.core.memory import MultimodalRAG\n\nrag = MultimodalRAG(\n    directory=Path(\"./project\"),\n    collection_name=\"my_docs\",         # ChromaDB collection name\n    persist_dir=Path(\"./.kagura\"),     # Storage directory\n    cache_size_mb=100,                 # File cache size\n    respect_gitignore=True,            # Honor .gitignore/.kaguraignore\n)\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#step-9-gitignore-support","title":"Step 9: Gitignore Support","text":"<p>Create <code>.kaguraignore</code> to exclude files:</p> <pre><code># .kaguraignore\nnode_modules/\n*.log\n.env\n__pycache__/\n</code></pre> <p>Files matching these patterns are automatically excluded from indexing.</p>"},{"location":"en/tutorials/13-multimodal-rag/#complete-example-documentation-assistant","title":"Complete Example: Documentation Assistant","text":"<p>Here's a full example with proper error handling:</p> <pre><code>import asyncio\nfrom pathlib import Path\nfrom kagura import agent\nfrom kagura.core.memory import MultimodalRAG\n\n\n@agent(\n    model=\"gpt-4o-mini\",\n    temperature=0.7,\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./my_project\")\n)\nasync def docs_bot(query: str, rag: MultimodalRAG) -&gt; str:\n    '''You are a documentation assistant.\n\n    Search relevant documentation: rag.query(\"{{ query }}\", n_results=5)\n    Answer based on results: {{ query }}\n\n    If you can't find relevant info, say so clearly.'''\n    pass\n\n\nasync def main():\n    print(\"Documentation Assistant\")\n    print(\"=\" * 40)\n\n    # Build index first (optional, but recommended)\n    print(\"Building knowledge base...\")\n\n    queries = [\n        \"How does authentication work?\",\n        \"Show me the architecture diagram\",\n        \"What's in the user guide?\",\n    ]\n\n    for query in queries:\n        print(f\"\\nQ: {query}\")\n        result = await docs_bot(query)\n        print(f\"A: {result}\\n\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#use-cases","title":"Use Cases","text":""},{"location":"en/tutorials/13-multimodal-rag/#1-technical-documentation","title":"1. Technical Documentation","text":"<pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./docs\"))\nasync def tech_support(question: str, rag) -&gt; str:\n    '''Answer technical questions using docs, diagrams, and screenshots.\n    Question: {{ question }}'''\n    pass\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#2-meeting-notes-search","title":"2. Meeting Notes Search","text":"<pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./meetings\"))\nasync def meeting_search(topic: str, rag) -&gt; str:\n    '''Search meeting recordings and notes for: {{ topic }}\n    Include timestamps and speakers.'''\n    pass\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#3-design-system-assistant","title":"3. Design System Assistant","text":"<pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./design_system\"))\nasync def design_helper(component: str, rag) -&gt; str:\n    '''Find design specs and screenshots for: {{ component }}'''\n    pass\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#performance-tips","title":"Performance Tips","text":""},{"location":"en/tutorials/13-multimodal-rag/#1-cache-sizing","title":"1. Cache Sizing","text":"<pre><code># For large projects\nrag_cache_size_mb=500  # 500MB cache\n\n# For small projects\nrag_cache_size_mb=50   # 50MB cache\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#2-concurrency-control","title":"2. Concurrency Control","text":"<pre><code># Build index with controlled concurrency\nawait rag.build_index(max_concurrent=5)  # Process 5 files at once\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#3-incremental-updates","title":"3. Incremental Updates","text":"<pre><code># Instead of full rebuild\nawait rag.build_index(force_rebuild=True)  # Slow\n\n# Use incremental update\nawait rag.incremental_update()             # Fast\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/13-multimodal-rag/#issue-google-api-key-not-found","title":"Issue: \"Google API key not found\"","text":"<p>Solution: Set the environment variable: <pre><code>export GOOGLE_API_KEY=\"your-key\"\n</code></pre></p>"},{"location":"en/tutorials/13-multimodal-rag/#issue-importerror-no-module-named-chromadb","title":"Issue: \"ImportError: No module named 'chromadb'\"","text":"<p>Solution: Install with web support (includes multimodal): <pre><code>pip install kagura-ai[web]\n</code></pre></p>"},{"location":"en/tutorials/13-multimodal-rag/#issue-index-build-is-slow","title":"Issue: Index build is slow","text":"<p>Solutions: 1. Reduce concurrency: <code>max_concurrent=2</code> 2. Exclude large files with <code>.kaguraignore</code> 3. Use smaller cache: <code>rag_cache_size_mb=50</code></p>"},{"location":"en/tutorials/13-multimodal-rag/#issue-out-of-memory","title":"Issue: Out of memory","text":"<p>Solutions: 1. Reduce cache size: <code>rag_cache_size_mb=50</code> 2. Process in batches with <code>incremental_update()</code> 3. Exclude large video files</p>"},{"location":"en/tutorials/13-multimodal-rag/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"en/tutorials/13-multimodal-rag/#1-multimodal-rag","title":"1. Multimodal RAG","text":"<p>Search and understand multiple content types: - Text, images, audio, video, PDFs - Automatic processing with Gemini API - Semantic vector search with ChromaDB</p>"},{"location":"en/tutorials/13-multimodal-rag/#2-agent-integration","title":"2. @agent Integration","text":"<pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./docs\"))\nasync def my_agent(query: str, rag: MultimodalRAG) -&gt; str:\n    pass\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#3-directory-scanning","title":"3. Directory Scanning","text":"<ul> <li>Recursive scanning with <code>.gitignore</code> support</li> <li>Automatic file type detection</li> <li>Parallel processing for speed</li> </ul>"},{"location":"en/tutorials/13-multimodal-rag/#4-caching-performance","title":"4. Caching &amp; Performance","text":"<ul> <li>File content caching (configurable size)</li> <li>Incremental updates (only new/modified files)</li> <li>Vector index persistence (no re-indexing on restart)</li> </ul>"},{"location":"en/tutorials/13-multimodal-rag/#next-steps","title":"Next Steps","text":"<p>Now that you understand Multimodal RAG:</p> <ol> <li>Combine with Memory - Use <code>enable_memory=True</code> for conversational RAG</li> <li>Add Tools - Combine RAG with custom tools for enhanced capabilities</li> <li>Deploy - Use RAG agents in production applications</li> </ol>"},{"location":"en/tutorials/13-multimodal-rag/#practice-exercises","title":"Practice Exercises","text":""},{"location":"en/tutorials/13-multimodal-rag/#exercise-1-image-search-agent","title":"Exercise 1: Image Search Agent","text":"<p>Create an agent that searches only images:</p> <pre><code>from kagura.loaders.file_types import FileType\n\n@agent(enable_multimodal_rag=True, rag_directory=Path(\"./images\"))\nasync def image_search(query: str, rag) -&gt; str:\n    '''Find images matching: {{ query }}\n    Use: rag.query(query, file_type=FileType.IMAGE)'''\n    pass\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#exercise-2-code-documentation","title":"Exercise 2: Code Documentation","text":"<p>Index a codebase and answer questions:</p> <pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./src\"))\nasync def code_qa(question: str, rag) -&gt; str:\n    '''Answer questions about the codebase: {{ question }}'''\n    pass\n\n# Test\nprint(await code_qa(\"How does the authentication module work?\"))\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#exercise-3-meeting-minutes-bot","title":"Exercise 3: Meeting Minutes Bot","text":"<p>Search meeting recordings and notes:</p> <pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./meetings\"))\nasync def meeting_bot(topic: str, rag) -&gt; str:\n    '''Summarize discussions about: {{ topic }}\n    Include meeting dates and key decisions.'''\n    pass\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#summary","title":"Summary","text":"<p>You learned: - \u2713 What Multimodal RAG is and its benefits - \u2713 How to set up content directories for indexing - \u2713 How to create RAG-enabled agents with <code>@agent</code> - \u2713 How to search across text, images, audio, video, PDFs - \u2713 Performance optimization and troubleshooting</p> <p>Continue exploring with Tutorial 14: Advanced Memory Management!</p>"},{"location":"en/tutorials/14-testing/","title":"Tutorial 14: Agent Testing","text":"<p>Learn how to test AI agents using Kagura's testing framework, designed to handle the non-deterministic nature of LLM outputs.</p>"},{"location":"en/tutorials/14-testing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed (<code>pip install kagura-ai</code>)</li> <li>pytest installed (<code>pip install pytest</code>)</li> <li>Completion of Tutorial 1: Basic Agent</li> </ul>"},{"location":"en/tutorials/14-testing/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand testing challenges with AI agents - Use AgentTestCase for agent testing - Write assertions for LLM behavior - Mock LLM responses for deterministic testing - Measure performance and cost</p>"},{"location":"en/tutorials/14-testing/#the-challenge-of-testing-ai-agents","title":"The Challenge of Testing AI Agents","text":"<p>Unlike traditional functions, AI agents are non-deterministic:</p> <pre><code># Traditional function - predictable\ndef add(a, b):\n    return a + b\n\nassert add(2, 3) == 5  # Always passes\n\n# AI agent - non-deterministic\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\nresult = await hello(\"Alice\")\n# Could be: \"Hello, Alice!\"\n# Could be: \"Hi Alice! How are you?\"\n# Could be: \"Hello there, Alice! Nice to meet you!\"\n</code></pre> <p>Solution: Test for patterns, not exact matches.</p>"},{"location":"en/tutorials/14-testing/#step-1-basic-test-setup","title":"Step 1: Basic Test Setup","text":"<p>Create a file called <code>test_agents.py</code>:</p> <pre><code>import pytest\nfrom kagura import agent\nfrom kagura.testing import AgentTestCase\n\n\n# Define agent to test\n@agent\nasync def greeter(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\n\n# Create test class\nclass TestGreeter(AgentTestCase):\n    agent = greeter\n\n    @pytest.mark.asyncio\n    async def test_basic_greeting(self):\n        \"\"\"Test that agent produces a greeting.\"\"\"\n        result = await self.agent(\"Alice\")\n\n        # Assert response is not empty\n        self.assert_not_empty(result)\n\n        # Assert response contains the name\n        self.assert_contains(result, \"Alice\")\n</code></pre> <p>Run the test:</p> <pre><code>pytest test_agents.py -v\n</code></pre>"},{"location":"en/tutorials/14-testing/#step-2-content-assertions","title":"Step 2: Content Assertions","text":"<p>AgentTestCase provides many assertion methods:</p>"},{"location":"en/tutorials/14-testing/#assert_contains","title":"assert_contains","text":"<pre><code>@pytest.mark.asyncio\nasync def test_contains_name(self):\n    result = await self.agent(\"Bob\")\n    self.assert_contains(result, \"Bob\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#assert_contains_any","title":"assert_contains_any","text":"<pre><code>@pytest.mark.asyncio\nasync def test_greeting_style(self):\n    result = await self.agent(\"Charlie\")\n\n    # Accept any common greeting\n    self.assert_contains_any(result, [\n        \"Hello\",\n        \"Hi\",\n        \"Hey\",\n        \"Greetings\"\n    ])\n</code></pre>"},{"location":"en/tutorials/14-testing/#assert_not_contains","title":"assert_not_contains","text":"<pre><code>@pytest.mark.asyncio\nasync def test_no_profanity(self):\n    result = await self.agent(\"Test\")\n    self.assert_not_contains(result, \"bad_word\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#assert_matches_pattern","title":"assert_matches_pattern","text":"<pre><code>@pytest.mark.asyncio\nasync def test_email_format(self):\n    @agent\n    async def email_extractor(text: str) -&gt; str:\n        '''Extract email from: {{ text }}'''\n        pass\n\n    result = await email_extractor(\"Contact: alice@example.com\")\n\n    # Use regex pattern\n    self.assert_matches_pattern(result, r'\\w+@\\w+\\.\\w+')\n</code></pre>"},{"location":"en/tutorials/14-testing/#step-3-language-detection","title":"Step 3: Language Detection","text":"<p>Test multilingual agents:</p> <pre><code>@agent\nasync def translator(text: str, target_lang: str) -&gt; str:\n    '''Translate \"{{ text }}\" to {{ target_lang }}'''\n    pass\n\n\nclass TestTranslator(AgentTestCase):\n    agent = translator\n\n    @pytest.mark.asyncio\n    async def test_japanese_translation(self):\n        result = await self.agent(\"Hello\", target_lang=\"Japanese\")\n\n        # Requires: pip install langdetect\n        self.assert_language(result, \"ja\")\n\n    @pytest.mark.asyncio\n    async def test_french_translation(self):\n        result = await self.agent(\"Hello\", target_lang=\"French\")\n        self.assert_language(result, \"fr\")\n</code></pre> <p>Note: Requires <code>langdetect</code>: <pre><code>pip install langdetect\n</code></pre></p>"},{"location":"en/tutorials/14-testing/#step-4-llm-behavior-assertions","title":"Step 4: LLM Behavior Assertions","text":"<p>Test LLM call characteristics:</p>"},{"location":"en/tutorials/14-testing/#assert_llm_calls","title":"assert_llm_calls","text":"<pre><code>@pytest.mark.asyncio\nasync def test_single_llm_call(self):\n    with self.record_llm_calls():\n        result = await self.agent(\"Test\")\n\n    # Assert exactly one LLM call was made\n    self.assert_llm_calls(count=1)\n\n\n@pytest.mark.asyncio\nasync def test_correct_model(self):\n    with self.record_llm_calls():\n        result = await self.agent(\"Test\")\n\n    # Assert specific model was used\n    self.assert_llm_calls(model=\"gpt-4o-mini\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#assert_token_usage","title":"assert_token_usage","text":"<pre><code>@pytest.mark.asyncio\nasync def test_token_budget(self):\n    with self.record_llm_calls():\n        result = await self.agent(\"Test\")\n\n    # Assert token usage within limit\n    self.assert_token_usage(max_tokens=500)\n</code></pre>"},{"location":"en/tutorials/14-testing/#assert_tool_calls","title":"assert_tool_calls","text":"<pre><code>def search_web(query: str) -&gt; str:\n    return f\"Results for: {query}\"\n\n\n@agent(tools=[search_web])\nasync def researcher(query: str) -&gt; str:\n    '''Search for: {{ query }}'''\n    pass\n\n\nclass TestResearcher(AgentTestCase):\n    agent = researcher\n\n    @pytest.mark.asyncio\n    async def test_uses_search_tool(self):\n        result = await self.agent(\"Python tutorials\")\n\n        # Assert search tool was called\n        self.assert_tool_calls([\"search_web\"])\n</code></pre>"},{"location":"en/tutorials/14-testing/#step-5-performance-testing","title":"Step 5: Performance Testing","text":""},{"location":"en/tutorials/14-testing/#test-execution-duration","title":"Test Execution Duration","text":"<pre><code>@pytest.mark.asyncio\nasync def test_response_time(self):\n    with self.measure_time() as timer:\n        result = await self.agent(\"Test\")\n\n    # Assert response within 5 seconds\n    self.assert_duration(5.0)\n</code></pre>"},{"location":"en/tutorials/14-testing/#test-cost-budget","title":"Test Cost Budget","text":"<pre><code>@pytest.mark.asyncio\nasync def test_cost_budget(self):\n    with self.record_llm_calls():\n        result = await self.agent(\"Test\")\n\n    # Assert cost under $0.01\n    self.assert_cost(0.01)\n</code></pre>"},{"location":"en/tutorials/14-testing/#step-6-mocking-llm-responses","title":"Step 6: Mocking LLM Responses","text":"<p>For fast, deterministic testing, mock LLM responses:</p> <pre><code>@pytest.mark.asyncio\nasync def test_with_mock_llm(self):\n    with self.mock_llm(\"Mocked response\"):\n        result = await self.agent(\"Test\")\n\n    # Now we can assert exact match\n    assert result == \"Mocked response\"\n</code></pre>"},{"location":"en/tutorials/14-testing/#use-case-test-error-handling","title":"Use Case: Test Error Handling","text":"<pre><code>@agent\nasync def safe_agent(query: str) -&gt; str:\n    '''Process: {{ query }}'''\n    pass\n\n\nclass TestSafeAgent(AgentTestCase):\n    agent = safe_agent\n\n    @pytest.mark.asyncio\n    async def test_handles_empty_response(self):\n        with self.mock_llm(\"\"):\n            result = await self.agent(\"Test\")\n\n            # Agent should handle empty response gracefully\n            # (Implementation-dependent)\n</code></pre>"},{"location":"en/tutorials/14-testing/#step-7-structured-output-testing","title":"Step 7: Structured Output Testing","text":"<p>Test agents that return Pydantic models:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    '''Extract person info from: {{ text }}'''\n    pass\n\n\nclass TestPersonExtractor(AgentTestCase):\n    agent = extract_person\n\n    @pytest.mark.asyncio\n    async def test_extracts_person(self):\n        result = await self.agent(\n            \"Alice is 30 years old and works as a software engineer\"\n        )\n\n        # Assert result is valid Person model\n        self.assert_valid_model(result, Person)\n\n        # Assert specific field values\n        self.assert_field_value(result, \"name\", \"Alice\")\n        self.assert_field_value(result, \"age\", 30)\n        self.assert_field_value(result, \"occupation\", \"software engineer\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#step-8-mocking-tools","title":"Step 8: Mocking Tools","text":"<p>Test agents with tools without executing real tools:</p> <pre><code>def expensive_api_call(query: str) -&gt; dict:\n    \"\"\"Simulate expensive API call.\"\"\"\n    # Real implementation would call external API\n    pass\n\n\n@agent(tools=[expensive_api_call])\nasync def api_agent(query: str) -&gt; str:\n    '''Query API: {{ query }}'''\n    pass\n\n\nclass TestAPIAgent(AgentTestCase):\n    agent = api_agent\n\n    @pytest.mark.asyncio\n    async def test_with_mocked_tool(self):\n        mock_data = {\"result\": \"mocked data\"}\n\n        with self.mock_tool(\"expensive_api_call\", return_value=mock_data):\n            result = await self.agent(\"test query\")\n\n            # Agent receives mocked data instead of real API call\n            self.assert_not_empty(result)\n</code></pre>"},{"location":"en/tutorials/14-testing/#complete-example-comprehensive-test-suite","title":"Complete Example: Comprehensive Test Suite","text":"<pre><code>import pytest\nfrom pydantic import BaseModel\nfrom kagura import agent\nfrom kagura.testing import AgentTestCase\n\n\n# Agent definition\n@agent(model=\"gpt-4o-mini\", temperature=0.7)\nasync def sentiment_analyzer(text: str) -&gt; str:\n    '''Analyze sentiment (positive/negative/neutral) of: {{ text }}'''\n    pass\n\n\n# Test suite\nclass TestSentimentAnalyzer(AgentTestCase):\n    agent = sentiment_analyzer\n\n    @pytest.mark.asyncio\n    async def test_positive_sentiment(self):\n        \"\"\"Test positive sentiment detection.\"\"\"\n        result = await self.agent(\"I love this product!\")\n\n        self.assert_not_empty(result)\n        self.assert_contains_any(result, [\"positive\", \"Positive\"])\n\n    @pytest.mark.asyncio\n    async def test_negative_sentiment(self):\n        \"\"\"Test negative sentiment detection.\"\"\"\n        result = await self.agent(\"This is terrible.\")\n\n        self.assert_not_empty(result)\n        self.assert_contains_any(result, [\"negative\", \"Negative\"])\n\n    @pytest.mark.asyncio\n    async def test_neutral_sentiment(self):\n        \"\"\"Test neutral sentiment detection.\"\"\"\n        result = await self.agent(\"It's okay.\")\n\n        self.assert_not_empty(result)\n        self.assert_contains_any(result, [\"neutral\", \"Neutral\"])\n\n    @pytest.mark.asyncio\n    async def test_uses_correct_model(self):\n        \"\"\"Test correct model is used.\"\"\"\n        with self.record_llm_calls():\n            result = await self.agent(\"Test\")\n\n        self.assert_llm_calls(count=1, model=\"gpt-4o-mini\")\n\n    @pytest.mark.asyncio\n    async def test_performance(self):\n        \"\"\"Test response time.\"\"\"\n        with self.measure_time():\n            result = await self.agent(\"Test\")\n\n        self.assert_duration(5.0)\n\n    @pytest.mark.asyncio\n    async def test_token_efficiency(self):\n        \"\"\"Test token usage.\"\"\"\n        with self.record_llm_calls():\n            result = await self.agent(\"Test\")\n\n        self.assert_token_usage(max_tokens=200)\n\n    @pytest.mark.asyncio\n    async def test_deterministic_with_mock(self):\n        \"\"\"Test with mocked LLM response.\"\"\"\n        with self.mock_llm(\"Positive sentiment detected\"):\n            result = await self.agent(\"Test\")\n\n        assert result == \"Positive sentiment detected\"\n</code></pre> <p>Run the suite:</p> <pre><code>pytest test_agents.py -v\n</code></pre>"},{"location":"en/tutorials/14-testing/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/14-testing/#1-test-patterns-not-exact-text","title":"1. Test Patterns, Not Exact Text","text":"<pre><code># Good\nself.assert_contains_any(result, [\"hello\", \"hi\", \"greetings\"])\n\n# Bad\nassert result == \"Hello, World!\"  # Too brittle\n</code></pre>"},{"location":"en/tutorials/14-testing/#2-use-mocks-for-fast-tests","title":"2. Use Mocks for Fast Tests","text":"<pre><code># Fast (mocked)\nwith self.mock_llm(\"Mocked\"):\n    result = await self.agent(\"Test\")\n\n# Slow (real LLM call)\nresult = await self.agent(\"Test\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#3-test-edge-cases","title":"3. Test Edge Cases","text":"<pre><code>@pytest.mark.asyncio\nasync def test_empty_input(self):\n    result = await self.agent(\"\")\n    # Handle edge case\n\n@pytest.mark.asyncio\nasync def test_very_long_input(self):\n    long_text = \"word \" * 1000\n    result = await self.agent(long_text)\n    # Handle long input\n</code></pre>"},{"location":"en/tutorials/14-testing/#4-parametrize-tests","title":"4. Parametrize Tests","text":"<pre><code>@pytest.mark.asyncio\n@pytest.mark.parametrize(\"text,expected\", [\n    (\"I love it\", \"positive\"),\n    (\"I hate it\", \"negative\"),\n    (\"It's okay\", \"neutral\"),\n])\nasync def test_sentiment(self, text, expected):\n    result = await self.agent(text)\n    self.assert_contains(result.lower(), expected)\n</code></pre>"},{"location":"en/tutorials/14-testing/#common-testing-patterns","title":"Common Testing Patterns","text":""},{"location":"en/tutorials/14-testing/#pattern-1-golden-test","title":"Pattern 1: Golden Test","text":"<p>Store expected output and compare:</p> <pre><code>@pytest.mark.asyncio\nasync def test_golden_output(self):\n    with self.mock_llm(\"Expected output\"):\n        result = await self.agent(\"Test\")\n\n    # Load golden output from file\n    with open(\"golden_output.txt\") as f:\n        expected = f.read()\n\n    assert result == expected\n</code></pre>"},{"location":"en/tutorials/14-testing/#pattern-2-regression-test","title":"Pattern 2: Regression Test","text":"<p>Ensure behavior doesn't change:</p> <pre><code>@pytest.mark.asyncio\nasync def test_no_regression(self):\n    # Use fixed mock to ensure consistent behavior\n    with self.mock_llm(\"Previous version output\"):\n        result = await self.agent(\"Test\")\n\n    # Test should always pass\n    self.assert_not_empty(result)\n</code></pre>"},{"location":"en/tutorials/14-testing/#pattern-3-integration-test","title":"Pattern 3: Integration Test","text":"<p>Test multiple agents together:</p> <pre><code>@pytest.mark.asyncio\nasync def test_agent_pipeline(self):\n    @agent\n    async def analyzer(text: str) -&gt; str:\n        '''Analyze: {{ text }}'''\n        pass\n\n    @agent\n    async def summarizer(text: str) -&gt; str:\n        '''Summarize: {{ text }}'''\n        pass\n\n    # Test pipeline\n    analysis = await analyzer(\"Long text...\")\n    summary = await summarizer(analysis)\n\n    self.assert_not_empty(summary)\n</code></pre>"},{"location":"en/tutorials/14-testing/#common-mistakes","title":"Common Mistakes","text":""},{"location":"en/tutorials/14-testing/#1-testing-exact-llm-output","title":"1. Testing Exact LLM Output","text":"<pre><code># Wrong - LLM output varies\nassert result == \"Hello, World!\"\n\n# Correct - Test pattern\nself.assert_contains(result, \"World\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#2-not-using-mocks","title":"2. Not Using Mocks","text":"<pre><code># Slow - Real LLM calls in every test\nresult = await self.agent(\"Test\")\n\n# Fast - Mocked responses\nwith self.mock_llm(\"Mocked\"):\n    result = await self.agent(\"Test\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#3-missing-pytestmarkasyncio","title":"3. Missing @pytest.mark.asyncio","text":"<pre><code># Wrong - Async test without decorator\nasync def test_agent(self):\n    result = await self.agent(\"Test\")\n\n# Correct\n@pytest.mark.asyncio\nasync def test_agent(self):\n    result = await self.agent(\"Test\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#practice-exercises","title":"Practice Exercises","text":""},{"location":"en/tutorials/14-testing/#exercise-1-test-translation-agent","title":"Exercise 1: Test Translation Agent","text":"<p>Create tests for a translation agent:</p> <pre><code>@agent\nasync def translator(text: str, target_lang: str) -&gt; str:\n    '''Translate to {{ target_lang }}: {{ text }}'''\n    pass\n\n# Your tests here:\nclass TestTranslator(AgentTestCase):\n    agent = translator\n\n    # TODO: Test Japanese translation\n    # TODO: Test French translation\n    # TODO: Test empty input\n    # TODO: Test performance\n</code></pre>"},{"location":"en/tutorials/14-testing/#exercise-2-test-with-multiple-assertions","title":"Exercise 2: Test with Multiple Assertions","text":"<p>Create a comprehensive test with multiple assertions:</p> <pre><code>@pytest.mark.asyncio\nasync def test_comprehensive(self):\n    with self.record_llm_calls():\n        with self.measure_time():\n            result = await self.agent(\"Test\")\n\n    # TODO: Add multiple assertions\n    # - Not empty\n    # - Contains specific text\n    # - LLM call count\n    # - Duration\n    # - Token usage\n</code></pre>"},{"location":"en/tutorials/14-testing/#exercise-3-mock-tool-testing","title":"Exercise 3: Mock Tool Testing","text":"<p>Test an agent with tools:</p> <pre><code>def calculator(expr: str) -&gt; float:\n    return eval(expr)\n\n@agent(tools=[calculator])\nasync def math_agent(question: str) -&gt; str:\n    '''Answer: {{ question }}'''\n    pass\n\n# TODO: Create tests with mocked calculator\n</code></pre>"},{"location":"en/tutorials/14-testing/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"en/tutorials/14-testing/#1-non-deterministic-testing","title":"1. Non-Deterministic Testing","text":"<p>Test patterns, not exact matches: <pre><code>self.assert_contains_any(result, [\"option1\", \"option2\"])\n</code></pre></p>"},{"location":"en/tutorials/14-testing/#2-llm-behavior-assertions","title":"2. LLM Behavior Assertions","text":"<p>Assert on LLM characteristics: <pre><code>self.assert_llm_calls(count=1, model=\"gpt-4o-mini\")\nself.assert_token_usage(max_tokens=500)\n</code></pre></p>"},{"location":"en/tutorials/14-testing/#3-mocking-for-determinism","title":"3. Mocking for Determinism","text":"<p>Use mocks for fast, predictable tests: <pre><code>with self.mock_llm(\"Fixed output\"):\n    result = await self.agent(\"Test\")\n</code></pre></p>"},{"location":"en/tutorials/14-testing/#4-performance-testing","title":"4. Performance Testing","text":"<p>Measure duration and cost: <pre><code>self.assert_duration(5.0)\nself.assert_cost(0.01)\n</code></pre></p>"},{"location":"en/tutorials/14-testing/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial 15: Observability - Monitor agent performance</li> <li>API Reference: Testing - Complete testing API</li> <li>Tutorial 13: Agent Builder - Build complex agents</li> </ul>"},{"location":"en/tutorials/14-testing/#summary","title":"Summary","text":"<p>You learned: - \u2713 How to test non-deterministic AI agents - \u2713 How to use AgentTestCase assertions - \u2713 How to mock LLM responses and tools - \u2713 How to test performance and cost - \u2713 How to test structured outputs</p> <p>Continue to Tutorial 15: Observability to learn agent monitoring!</p>"},{"location":"en/tutorials/15-observability/","title":"Tutorial 15: Observability &amp; Monitoring","text":"<p>Learn how to monitor agent execution telemetry, track performance, analyze costs, and debug issues using Kagura's observability tools.</p>"},{"location":"en/tutorials/15-observability/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed (<code>pip install kagura-ai</code>)</li> <li>Completion of Tutorial 1: Basic Agent</li> <li>Rich library (included with Kagura)</li> </ul>"},{"location":"en/tutorials/15-observability/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand agent telemetry and observability - Use the monitor CLI for live tracking - Analyze execution history and traces - Track performance metrics and costs - Build custom monitoring dashboards</p>"},{"location":"en/tutorials/15-observability/#what-is-observability","title":"What is Observability?","text":"<p>Observability means understanding what your agents are doing: - When did they run? - How long did they take? - What did they call (LLM, tools)? - How much did they cost? - Did they succeed or fail?</p> <p>Kagura automatically tracks telemetry for all agent executions.</p>"},{"location":"en/tutorials/15-observability/#step-1-enable-telemetry","title":"Step 1: Enable Telemetry","text":"<p>Telemetry is enabled by default. All agent executions are automatically recorded to:</p> <pre><code>~/.kagura/telemetry.db\n</code></pre> <p>No configuration needed!</p>"},{"location":"en/tutorials/15-observability/#step-2-live-monitoring","title":"Step 2: Live Monitoring","text":"<p>The simplest way to monitor agents is the <code>kagura monitor</code> command:</p> <pre><code># Start live monitoring\nkagura monitor\n</code></pre> <p>Output: <pre><code>\ud83d\udcca Kagura Agent Monitor\nTotal: 42 | Completed: 40 | Failed: 2\n\n\u250c\u2500 Recent Activity \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Time     Agent         Status      Duration  Cost     \u2502\n\u2502 14:32:15 translator    \u2713 COMPLETED 0.52s    $0.0003  \u2502\n\u2502 14:31:58 chatbot       \u2713 COMPLETED 1.23s    $0.0012  \u2502\n\u2502 14:30:41 researcher    \u2717 FAILED    2.11s    $0.0008  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#monitor-specific-agent","title":"Monitor Specific Agent","text":"<pre><code># Monitor only \"translator\" agent\nkagura monitor --agent translator\n</code></pre>"},{"location":"en/tutorials/15-observability/#custom-refresh-rate","title":"Custom Refresh Rate","text":"<pre><code># Update every 2 seconds\nkagura monitor --refresh 2.0\n</code></pre>"},{"location":"en/tutorials/15-observability/#step-3-execution-history","title":"Step 3: Execution History","text":"<p>View past executions:</p> <pre><code># List recent executions\nkagura monitor list\n\n# Filter by agent\nkagura monitor list --agent my_agent\n\n# Filter by status (completed/failed)\nkagura monitor list --status failed\n\n# Limit results\nkagura monitor list --limit 50\n</code></pre> <p>Output: <pre><code>\u250c\u2500 Execution History \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Time     Agent         Status      Duration  Cost     \u2502\n\u2502 14:32:15 translator    \u2713 COMPLETED 0.52s    $0.0003  \u2502\n\u2502 14:31:58 chatbot       \u2713 COMPLETED 1.23s    $0.0012  \u2502\n\u2502 14:30:41 researcher    \u2717 FAILED    2.11s    $0.0008  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#step-4-statistics","title":"Step 4: Statistics","text":"<p>Get aggregate statistics:</p> <pre><code># Overall statistics\nkagura monitor stats\n\n# Agent-specific stats\nkagura monitor stats --agent translator\n</code></pre> <p>Output: <pre><code>\ud83d\udcca Summary Statistics\n\nTotal Executions: 42\n  \u2022 Completed: 40\n  \u2022 Failed: 2\nAvg Duration: 1.34s\nTotal Cost: $0.0512\nTotal Tokens: 12,450\nLLM Calls: 45\nTool Calls: 12\n\nSuccess Rate: 95.2%\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#step-5-detailed-traces","title":"Step 5: Detailed Traces","text":"<p>View detailed execution traces:</p> <pre><code># Get execution ID from list\nkagura monitor list\n\n# View detailed trace\nkagura monitor trace exec_abc123\n</code></pre> <p>Output: <pre><code>\ud83d\udccd Execution Trace: translator (exec_abc123)\n\nExecution Info\n\u251c\u2500\u2500 Started: 14:32:15\n\u251c\u2500\u2500 Status: \u2713 COMPLETED\n\u251c\u2500\u2500 Duration: 0.52s\n\nMetrics\n\u251c\u2500\u2500 total_cost: $0.0003\n\u251c\u2500\u2500 total_tokens: 85\n\u251c\u2500\u2500 llm_calls: 1\n\u2514\u2500\u2500 tool_calls: 0\n\nEvents Timeline (3 events)\n\u251c\u2500\u2500 [0.00s] LLM Call (gpt-4o-mini) - 85 tokens, $0.0003, 0.48s\n\u251c\u2500\u2500 [0.48s] Memory Op (store) - 0.02s\n\u2514\u2500\u2500 [0.50s] Completion\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#step-6-cost-analysis","title":"Step 6: Cost Analysis","text":"<p>Track costs across agents:</p> <pre><code># Cost by agent\nkagura monitor cost\n\n# Cost by date\nkagura monitor cost --group-by date\n</code></pre> <p>Output (by agent): <pre><code>\u250c\u2500 Cost by Agent \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Agent          Calls  Tokens    Cost     \u2502\n\u2502 translator     23     5,123     $0.0234  \u2502\n\u2502 chatbot        15     4,892     $0.0189  \u2502\n\u2502 researcher     4      2,435     $0.0089  \u2502\n\u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502 Total          42     12,450    $0.0512  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nEstimated monthly cost: $1.54\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#step-7-programmatic-access","title":"Step 7: Programmatic Access","text":"<p>Use EventStore and Dashboard in your Python code:</p> <pre><code>from pathlib import Path\nfrom kagura.observability import EventStore, Dashboard\n\n# Load event store\nstore = EventStore(Path.home() / \".kagura\" / \"telemetry.db\")\n\n# Get recent executions\nexecutions = store.get_executions(agent_name=\"translator\", limit=10)\n\nfor exec in executions:\n    print(f\"{exec['agent_name']}: {exec['status']} - {exec['duration']:.2f}s\")\n\n# Get statistics\nstats = store.get_summary_stats(agent_name=\"translator\")\nprint(f\"Total: {stats['total_executions']}\")\nprint(f\"Avg Duration: {stats['avg_duration']:.2f}s\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#step-8-custom-dashboard","title":"Step 8: Custom Dashboard","text":"<p>Create a custom monitoring dashboard:</p> <pre><code>from kagura.observability import EventStore, Dashboard\n\n# Initialize\nstore = EventStore()\ndashboard = Dashboard(store)\n\n# Show live dashboard (refreshes every 1 second)\ndashboard.show_live(agent_name=\"my_agent\", refresh_rate=1.0)\n\n# Show execution list\ndashboard.show_list(agent_name=\"my_agent\", limit=20)\n\n# Show statistics\ndashboard.show_stats(agent_name=\"my_agent\")\n\n# Show specific trace\ndashboard.show_trace(execution_id=\"exec_abc123\")\n\n# Show cost summary\ndashboard.show_cost_summary(group_by=\"agent\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#step-9-filtering-and-querying","title":"Step 9: Filtering and Querying","text":"<p>Filter executions programmatically:</p> <pre><code>import time\nfrom kagura.observability import EventStore\n\nstore = EventStore()\n\n# Get executions from last 24 hours\nsince = time.time() - 86400  # 24 hours ago\nrecent = store.get_executions(since=since)\n\n# Get failed executions only\nfailed = store.get_executions(status=\"failed\")\n\n# Get specific agent's executions\nagent_execs = store.get_executions(agent_name=\"translator\", limit=50)\n\n# Get single execution\nexecution = store.get_execution(\"exec_abc123\")\nif execution:\n    print(f\"Duration: {execution['duration']:.2f}s\")\n    print(f\"Status: {execution['status']}\")\n    print(f\"Error: {execution.get('error')}\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#step-10-cleanup-old-data","title":"Step 10: Cleanup Old Data","text":"<p>Manage telemetry database size:</p> <pre><code>import time\nfrom kagura.observability import EventStore\n\nstore = EventStore()\n\n# Delete executions older than 30 days\nthirty_days_ago = time.time() - (30 * 86400)\ndeleted = store.delete_old_executions(older_than=thirty_days_ago)\nprint(f\"Deleted {deleted} old executions\")\n\n# Clear all data (use with caution!)\n# store.clear_all()\n</code></pre>"},{"location":"en/tutorials/15-observability/#complete-example-monitoring-integration","title":"Complete Example: Monitoring Integration","text":"<pre><code>import asyncio\nfrom kagura import agent\nfrom kagura.observability import EventStore, Dashboard\n\n\n@agent(model=\"gpt-4o-mini\")\nasync def translator(text: str, target_lang: str) -&gt; str:\n    '''Translate \"{{ text }}\" to {{ target_lang }}'''\n    pass\n\n\nasync def main():\n    # Run agent multiple times\n    translations = [\n        (\"Hello\", \"French\"),\n        (\"Goodbye\", \"Japanese\"),\n        (\"Thank you\", \"Spanish\"),\n    ]\n\n    for text, lang in translations:\n        result = await translator(text, target_lang=lang)\n        print(f\"{text} \u2192 {lang}: {result}\")\n\n    # Analyze telemetry\n    store = EventStore()\n    dashboard = Dashboard(store)\n\n    print(\"\\n\" + \"=\" * 50)\n    print(\"TELEMETRY ANALYSIS\")\n    print(\"=\" * 50 + \"\\n\")\n\n    # Show statistics\n    dashboard.show_stats(agent_name=\"translator\")\n\n    # Show execution list\n    dashboard.show_list(agent_name=\"translator\", limit=10)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/tutorials/15-observability/#use-cases","title":"Use Cases","text":""},{"location":"en/tutorials/15-observability/#use-case-1-performance-monitoring","title":"Use Case 1: Performance Monitoring","text":"<p>Track agent performance over time:</p> <pre><code>store = EventStore()\n\n# Get last 100 executions\nexecutions = store.get_executions(limit=100)\n\n# Calculate average duration per agent\nfrom collections import defaultdict\n\nagent_durations = defaultdict(list)\nfor exec in executions:\n    agent_durations[exec['agent_name']].append(exec['duration'])\n\nfor agent, durations in agent_durations.items():\n    avg = sum(durations) / len(durations)\n    print(f\"{agent}: {avg:.2f}s average\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#use-case-2-cost-budget-alerts","title":"Use Case 2: Cost Budget Alerts","text":"<p>Monitor costs and alert when budget exceeded:</p> <pre><code>store = EventStore()\n\n# Get today's executions\nimport time\ntoday_start = time.time() - 86400\nexecutions = store.get_executions(since=today_start)\n\n# Calculate total cost\ntotal_cost = sum(\n    exec.get('metrics', {}).get('total_cost', 0.0)\n    for exec in executions\n)\n\n# Alert if over budget\nDAILY_BUDGET = 1.0  # $1.00\nif total_cost &gt; DAILY_BUDGET:\n    print(f\"\u26a0\ufe0f  ALERT: Daily cost ${total_cost:.2f} exceeds budget ${DAILY_BUDGET:.2f}\")\nelse:\n    print(f\"\u2713 Cost ${total_cost:.2f} within budget ${DAILY_BUDGET:.2f}\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#use-case-3-error-tracking","title":"Use Case 3: Error Tracking","text":"<p>Track and analyze failures:</p> <pre><code>store = EventStore()\n\n# Get all failed executions\nfailed = store.get_executions(status=\"failed\", limit=100)\n\n# Group by error type\nfrom collections import Counter\n\nerror_types = Counter(\n    exec.get('error', 'Unknown error')\n    for exec in failed\n)\n\nprint(\"Top 5 Error Types:\")\nfor error, count in error_types.most_common(5):\n    print(f\"  {count}x: {error}\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#use-case-4-custom-metrics-dashboard","title":"Use Case 4: Custom Metrics Dashboard","text":"<p>Build a real-time metrics dashboard:</p> <pre><code>import time\nfrom rich.console import Console\nfrom rich.table import Table\nfrom kagura.observability import EventStore\n\ndef show_realtime_metrics():\n    \"\"\"Display real-time metrics dashboard.\"\"\"\n    store = EventStore()\n    console = Console()\n\n    while True:\n        # Get recent executions\n        recent = store.get_executions(limit=50)\n\n        # Calculate metrics\n        total = len(recent)\n        completed = sum(1 for e in recent if e['status'] == 'completed')\n        failed = total - completed\n        avg_duration = sum(e['duration'] for e in recent) / total if total &gt; 0 else 0\n\n        # Create table\n        table = Table(title=\"Real-Time Metrics\")\n        table.add_column(\"Metric\", style=\"cyan\")\n        table.add_column(\"Value\", style=\"white\")\n\n        table.add_row(\"Total Executions\", str(total))\n        table.add_row(\"Completed\", str(completed))\n        table.add_row(\"Failed\", str(failed))\n        table.add_row(\"Avg Duration\", f\"{avg_duration:.2f}s\")\n\n        # Display\n        console.clear()\n        console.print(table)\n\n        time.sleep(2)  # Refresh every 2 seconds\n\n# show_realtime_metrics()\n</code></pre>"},{"location":"en/tutorials/15-observability/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/15-observability/#1-regular-monitoring","title":"1. Regular Monitoring","text":"<p>Check your agents regularly:</p> <pre><code># Daily health check\nkagura monitor stats\n\n# Weekly cost review\nkagura monitor cost\n</code></pre>"},{"location":"en/tutorials/15-observability/#2-set-up-alerts","title":"2. Set Up Alerts","text":"<p>Create scripts to alert on issues:</p> <pre><code>#!/bin/bash\n# daily_check.sh\n\n# Check for failed executions\nfailed_count=$(kagura monitor stats | grep \"Failed:\" | awk '{print $3}')\n\nif [ \"$failed_count\" -gt 10 ]; then\n  echo \"\u26a0\ufe0f  Alert: $failed_count failed executions\"\n  # Send notification (email, Slack, etc.)\nfi\n</code></pre>"},{"location":"en/tutorials/15-observability/#3-cost-tracking","title":"3. Cost Tracking","text":"<p>Track costs by project:</p> <pre><code># Tag agents by project\n@agent(model=\"gpt-4o-mini\")\nasync def project_a_agent(query: str) -&gt; str:\n    '''...'''\n    pass\n\n# Query costs by agent name prefix\nproject_a_execs = store.get_executions(agent_name=\"project_a_\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#4-performance-baselines","title":"4. Performance Baselines","text":"<p>Establish performance baselines:</p> <pre><code># Record baseline\nbaseline_duration = 2.0  # seconds\n\n# Check if performance degraded\nrecent = store.get_executions(agent_name=\"my_agent\", limit=10)\navg_recent = sum(e['duration'] for e in recent) / len(recent)\n\nif avg_recent &gt; baseline_duration * 1.5:\n    print(f\"\u26a0\ufe0f  Performance degraded: {avg_recent:.2f}s (baseline: {baseline_duration:.2f}s)\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#common-monitoring-patterns","title":"Common Monitoring Patterns","text":""},{"location":"en/tutorials/15-observability/#pattern-1-health-check","title":"Pattern 1: Health Check","text":"<pre><code>def health_check(agent_name: str) -&gt; dict:\n    \"\"\"Check agent health.\"\"\"\n    store = EventStore()\n    recent = store.get_executions(agent_name=agent_name, limit=20)\n\n    if not recent:\n        return {\"status\": \"unknown\", \"reason\": \"no executions\"}\n\n    failed = sum(1 for e in recent if e['status'] == 'failed')\n    failure_rate = failed / len(recent)\n\n    if failure_rate &gt; 0.5:\n        return {\"status\": \"unhealthy\", \"failure_rate\": failure_rate}\n    elif failure_rate &gt; 0.2:\n        return {\"status\": \"degraded\", \"failure_rate\": failure_rate}\n    else:\n        return {\"status\": \"healthy\", \"failure_rate\": failure_rate}\n</code></pre>"},{"location":"en/tutorials/15-observability/#pattern-2-performance-regression-detection","title":"Pattern 2: Performance Regression Detection","text":"<pre><code>def detect_regression(agent_name: str, threshold: float = 1.5) -&gt; bool:\n    \"\"\"Detect performance regression.\"\"\"\n    store = EventStore()\n\n    # Get baseline (last 100 executions)\n    baseline = store.get_executions(agent_name=agent_name, limit=100)\n    baseline_avg = sum(e['duration'] for e in baseline) / len(baseline)\n\n    # Get recent (last 10 executions)\n    recent = store.get_executions(agent_name=agent_name, limit=10)\n    recent_avg = sum(e['duration'] for e in recent) / len(recent)\n\n    # Check if recent is significantly slower\n    return recent_avg &gt; baseline_avg * threshold\n</code></pre>"},{"location":"en/tutorials/15-observability/#pattern-3-cost-tracking","title":"Pattern 3: Cost Tracking","text":"<pre><code>def get_cost_breakdown(since: float) -&gt; dict:\n    \"\"\"Get cost breakdown by agent.\"\"\"\n    store = EventStore()\n    executions = store.get_executions(since=since, limit=10000)\n\n    breakdown = {}\n    for exec in executions:\n        agent = exec['agent_name']\n        cost = exec.get('metrics', {}).get('total_cost', 0.0)\n\n        if agent not in breakdown:\n            breakdown[agent] = {\"cost\": 0.0, \"calls\": 0}\n\n        breakdown[agent][\"cost\"] += cost\n        breakdown[agent][\"calls\"] += 1\n\n    return breakdown\n</code></pre>"},{"location":"en/tutorials/15-observability/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/15-observability/#issue-no-telemetry-data","title":"Issue: No telemetry data","text":"<p>Solution: Check database location: <pre><code>ls ~/.kagura/telemetry.db\n</code></pre></p> <p>If missing, run an agent to initialize it.</p>"},{"location":"en/tutorials/15-observability/#issue-old-data-filling-disk","title":"Issue: Old data filling disk","text":"<p>Solution: Regularly clean old data: <pre><code>import time\nfrom kagura.observability import EventStore\n\nstore = EventStore()\nthirty_days_ago = time.time() - (30 * 86400)\nstore.delete_old_executions(older_than=thirty_days_ago)\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#issue-slow-queries","title":"Issue: Slow queries","text":"<p>Solution: Use indexes and filters: <pre><code># Efficient - uses indexes\nstore.get_executions(agent_name=\"my_agent\", limit=100)\n\n# Less efficient - scans all data\nall_execs = store.get_executions(limit=100000)\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"en/tutorials/15-observability/#1-automatic-telemetry","title":"1. Automatic Telemetry","text":"<p>All executions are tracked automatically: <pre><code># Just use agents - telemetry is automatic\nresult = await my_agent(\"query\")\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#2-cli-monitoring","title":"2. CLI Monitoring","text":"<p>Quick monitoring via CLI: <pre><code>kagura monitor        # Live view\nkagura monitor list   # History\nkagura monitor stats  # Statistics\nkagura monitor trace  # Detailed trace\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#3-programmatic-access","title":"3. Programmatic Access","text":"<p>Build custom monitoring: <pre><code>store = EventStore()\nexecutions = store.get_executions(...)\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#4-cost-tracking","title":"4. Cost Tracking","text":"<p>Monitor spending: <pre><code>kagura monitor cost\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#next-steps","title":"Next Steps","text":"<ul> <li>API Reference: Observability - Complete observability API</li> <li>Tutorial 13: Agent Builder - Build advanced agents</li> <li>Tutorial 14: Testing - Test your agents</li> </ul>"},{"location":"en/tutorials/15-observability/#summary","title":"Summary","text":"<p>You learned: - \u2713 How to monitor agents with CLI commands - \u2713 How to access telemetry programmatically - \u2713 How to track performance and costs - \u2713 How to build custom dashboards - \u2713 Best practices for observability</p> <p>You now have the tools to monitor, debug, and optimize your AI agents!</p>"}]}