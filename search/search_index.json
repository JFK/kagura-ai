{"config":{"lang":["en","ja"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"api/","title":"OpenAPI Specification","text":"<p>Kagura Memory API v4.0 - Complete OpenAPI Reference</p>"},{"location":"api/#overview","title":"\ud83d\udccb Overview","text":"<p>Kagura Memory API provides RESTful endpoints for memory management, graph operations, and system monitoring.</p> <p>OpenAPI Version: 3.1.0 API Version: 4.0.0</p>"},{"location":"api/#interactive-documentation","title":"\ud83d\udd17 Interactive Documentation","text":""},{"location":"api/#1-redocly-documentation-recommended","title":"1. Redocly Documentation (Recommended) \u2b50","text":"<p>Static HTML: index.html - Beautiful, interactive API explorer - Generated from <code>reference.yaml</code> using Redocly - No server required - open in browser - Build: <code>make build_docs</code></p>"},{"location":"api/#2-live-api-documentation-server-required","title":"2. Live API Documentation (Server Required)","text":"<p>When running the Kagura API server:</p> <p>Swagger UI: http://localhost:8000/docs - Interactive API testing - Try endpoints directly from browser - See request/response examples - Execute requests with authentication</p> <p>ReDoc: http://localhost:8000/redoc - Clean, readable API documentation - Search functionality - Code samples</p>"},{"location":"api/#3-openapi-yaml","title":"3. OpenAPI YAML","text":"<p>Spec File: reference.yaml - Source of truth for API specification - Use for client SDK generation - Import into Postman, Insomnia, etc.</p>"},{"location":"api/#openapi-specification-file","title":"\ud83d\udcc4 OpenAPI Specification File","text":"<p>File: <code>reference.yaml</code></p> <p>Download and use with your favorite tools:</p> <pre><code># Download spec\ncurl http://localhost:8000/openapi.json &gt; openapi.json\n\n# Generate client SDK\nnpx @openapitools/openapi-generator-cli generate \\\n  -i openapi.json \\\n  -g python \\\n  -o ./kagura-client\n\n# Validate spec\nnpx @stoplight/spectral-cli lint openapi.json\n</code></pre>"},{"location":"api/#api-endpoints","title":"\ud83c\udf10 API Endpoints","text":""},{"location":"api/#memory-operations","title":"Memory Operations","text":"Method Endpoint Description POST <code>/api/v1/memory</code> Create/update memory GET <code>/api/v1/memory</code> List memories GET <code>/api/v1/memory/{key}</code> Get memory by key PUT <code>/api/v1/memory/{key}</code> Update memory DELETE <code>/api/v1/memory/{key}</code> Delete memory"},{"location":"api/#search-recall","title":"Search &amp; Recall","text":"Method Endpoint Description GET <code>/api/v1/search</code> Full-text search POST <code>/api/v1/recall</code> Semantic search (RAG)"},{"location":"api/#graph-operations","title":"Graph Operations","text":"Method Endpoint Description POST <code>/api/v1/graph/interactions</code> Record AI-User interaction GET <code>/api/v1/graph/{node_id}/related</code> Get related nodes GET <code>/api/v1/graph/users/{user_id}/pattern</code> Analyze user pattern"},{"location":"api/#system","title":"System","text":"Method Endpoint Description GET <code>/</code> API root information GET <code>/api/v1/health</code> Health check GET <code>/api/v1/metrics</code> System metrics"},{"location":"api/#mcp-transport-phase-c","title":"MCP Transport (Phase C)","text":"Method Endpoint Description GET <code>/mcp</code> SSE streaming (server \u2192 client) POST <code>/mcp</code> JSON-RPC requests (client \u2192 server) DELETE <code>/mcp</code> Session termination"},{"location":"api/#authentication","title":"\ud83d\udd10 Authentication","text":""},{"location":"api/#headers","title":"Headers","text":"<p>X-User-ID (optional): <pre><code>X-User-ID: user_jfk\n</code></pre> Specifies which user's memory to access. Defaults to <code>default_user</code>.</p> <p>Authorization (optional, Phase C): <pre><code>Authorization: Bearer kagura_abc123xyz789...\n</code></pre> API Key for authentication. User ID is extracted from validated key.</p>"},{"location":"api/#schemas","title":"\ud83d\udce6 Schemas","text":""},{"location":"api/#memory","title":"Memory","text":"<p>MemoryCreate: <pre><code>type: object\nrequired: [key, value]\nproperties:\n  key: string\n  value: string\n  scope: string (working|persistent)\n  tags: array of strings\n  importance: number (0.0-1.0)\n  metadata: object\n</code></pre></p> <p>MemoryResponse: <pre><code>type: object\nproperties:\n  key: string\n  value: string\n  scope: string\n  tags: array\n  importance: number\n  created_at: string (datetime)\n  updated_at: string (datetime)\n</code></pre></p>"},{"location":"api/#search","title":"Search","text":"<p>RecallRequest: <pre><code>type: object\nrequired: [query]\nproperties:\n  query: string\n  k: integer (default: 5)\n  scope: string (all|working|persistent)\n</code></pre></p> <p>RecallResponse: <pre><code>type: object\nproperties:\n  results: array\n    items:\n      key: string\n      value: string\n      score: number\n</code></pre></p>"},{"location":"api/#graph","title":"Graph","text":"<p>InteractionCreate: <pre><code>type: object\nrequired: [user_id, query, response]\nproperties:\n  user_id: string\n  query: string\n  response: string\n  metadata: object\n  ai_platform: string (optional)\n</code></pre></p> <p>UserPattern: <pre><code>type: object\nproperties:\n  user_id: string\n  total_interactions: integer\n  topics: object (topic \u2192 count)\n  platforms: object (platform \u2192 count)\n  learning_trajectory: array\n</code></pre></p>"},{"location":"api/#tools-sdks","title":"\ud83d\udee0\ufe0f Tools &amp; SDKs","text":""},{"location":"api/#official-tools","title":"Official Tools","text":"<p>Python (httpx): <pre><code>import httpx\n\nasync with httpx.AsyncClient() as client:\n    response = await client.post(\n        \"http://localhost:8000/api/v1/memory\",\n        json={\"key\": \"test\", \"value\": \"data\"},\n        headers={\"X-User-ID\": \"user_jfk\"}\n    )\n</code></pre></p> <p>cURL: <pre><code>curl -X POST http://localhost:8000/api/v1/memory \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-User-ID: user_jfk\" \\\n  -d '{\"key\":\"test\",\"value\":\"data\",\"scope\":\"persistent\"}'\n</code></pre></p>"},{"location":"api/#client-sdk-generation","title":"Client SDK Generation","text":"<p>Generate clients for any language using OpenAPI Generator:</p> <pre><code># Python\nopenapi-generator-cli generate -i reference.yaml -g python -o ./client-python\n\n# TypeScript/Axios\nopenapi-generator-cli generate -i reference.yaml -g typescript-axios -o ./client-ts\n\n# Go\nopenapi-generator-cli generate -i reference.yaml -g go -o ./client-go\n\n# Rust\nopenapi-generator-cli generate -i reference.yaml -g rust -o ./client-rust\n</code></pre>"},{"location":"api/#related-documentation","title":"\ud83d\udcda Related Documentation","text":"<ul> <li>API Reference Guide - Human-readable API guide</li> <li>REST API Usage - Usage examples and patterns</li> <li>MCP over HTTP/SSE - MCP protocol endpoint</li> <li>Getting Started</li> </ul>"},{"location":"api/#keeping-spec-updated","title":"\ud83d\udd04 Keeping Spec Updated","text":"<p>The OpenAPI spec can be regenerated from the running server:</p> <pre><code># Start server\nuvicorn kagura.api.server:app --port 8000\n\n# Download current spec\ncurl http://localhost:8000/openapi.json &gt; docs/api/reference.json\n\n# Convert to YAML (optional)\npython -c \"import json, yaml; print(yaml.dump(json.load(open('docs/api/reference.json'))))\" &gt; docs/api/reference.yaml\n</code></pre> <p>Last Updated: 2025-10-27 API Version: 4.0.0 OpenAPI Version: 3.1.0</p>"},{"location":"","title":"Kagura AI","text":"<p>Universal AI Memory Platform</p> <p>Own your memory. Bring it to every AI.</p> <p>MCP-native memory infrastructure that connects Claude Desktop, ChatGPT, Gemini, and all your AI platforms with shared context and memory.</p>"},{"location":"#what-is-kagura-ai-v40","title":"What is Kagura AI v4.0?","text":"<p>A universal memory layer that makes every AI remember your preferences, context, and history across all platforms.</p> <pre><code>Morning: ChatGPT helps you plan your day\n         \u2193 (remembers your preferences)\n\nAfternoon: Claude Desktop writes code with you\n           \u2193 (knows your coding style)\n\nEvening: Gemini analyzes your documents\n         \u2193 (recalls your project context)\n</code></pre> <p>One memory. Every AI.</p>"},{"location":"#why-kagura-ai","title":"Why Kagura AI?","text":""},{"location":"#for-individuals","title":"For Individuals","text":"<ul> <li>\ud83d\udd12 Privacy-first: Local storage or self-hosted</li> <li>\ud83d\udeab No vendor lock-in: Complete data export anytime</li> <li>\ud83e\udde0 Smart recall: Vector search + Knowledge graph</li> <li>\ud83c\udf10 Universal: Works with Claude, ChatGPT, Gemini, Cursor, Cline</li> </ul>"},{"location":"#for-developers","title":"For Developers","text":"<ul> <li>\ud83d\udcbb MCP-native: 31 tools via Model Context Protocol</li> <li>\ud83d\udd0c Easy integration: <code>kagura mcp install</code> for Claude Desktop</li> <li>\ud83d\udee0\ufe0f REST API: FastAPI server with OpenAPI</li> <li>\ud83d\udce6 Production-ready: Docker, authentication, monitoring</li> </ul>"},{"location":"#for-teams-coming-soon","title":"For Teams (Coming Soon)","text":"<ul> <li>\ud83d\udc65 Shared knowledge: Team-wide memory</li> <li>\ud83d\udd10 Enterprise features: SSO, BYOK, audit logs</li> <li>\ud83d\udcc8 Analytics: Track team AI usage patterns</li> </ul>"},{"location":"#core-features","title":"Core Features","text":""},{"location":"#1-universal-memory","title":"1. Universal Memory","text":"<p>Store once, access from any AI:</p> <pre><code># Via MCP tool (works in Claude Desktop, ChatGPT, etc.)\nmemory_store(\n    user_id=\"jfk\",\n    agent_name=\"global\",\n    key=\"coding_style\",\n    value=\"Always use type hints in Python\",\n    scope=\"persistent\",\n    tags='[\"python\", \"best-practices\"]'\n)\n</code></pre>"},{"location":"#2-mcp-integration","title":"2. MCP Integration","text":"<p>Claude Desktop (local, all 31 tools): <pre><code>kagura mcp install  # Auto-configure\n# All tools available: memory, files, web, shell, etc.\n</code></pre></p> <p>ChatGPT Connector (remote, 24 safe tools): <pre><code>docker compose up -d\n# Connect ChatGPT to http://localhost:8000/mcp\n# Safe tools only (no file ops, no shell)\n</code></pre></p>"},{"location":"#3-knowledge-graph","title":"3. Knowledge Graph","text":"<p>Track relationships and patterns: - AI-User interaction history - Memory relationships - Learning patterns analysis - Topic clustering</p>"},{"location":"#4-complete-data-portability","title":"4. Complete Data Portability","text":"<pre><code># Export everything\nkagura memory export --output ./backup\n\n# Import anywhere\nkagura memory import --input ./backup\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#option-1-claude-desktop-user","title":"Option 1: Claude Desktop User","text":"<pre><code>pip install kagura-ai[full]\nkagura mcp install\n# Restart Claude Desktop - Done!\n</code></pre> <p>Claude Desktop Setup \u2192</p>"},{"location":"#option-2-chatgpt-user","title":"Option 2: ChatGPT User","text":"<pre><code>docker compose up -d\n# Configure ChatGPT Connector: http://localhost:8000/mcp\n</code></pre> <p>ChatGPT Connector Setup \u2192</p>"},{"location":"#option-3-self-hosted-production","title":"Option 3: Self-Hosted Production","text":"<pre><code>git clone https://github.com/JFK/kagura-ai.git\ncd kagura-ai\ncp .env.example .env  # Configure DOMAIN, POSTGRES_PASSWORD\ndocker compose -f docker-compose.prod.yml up -d\n</code></pre> <p>Self-Hosting Guide \u2192</p>"},{"location":"#available-tools-mcp","title":"Available Tools (MCP)","text":"<p>Memory (6 tools): - memory_store, memory_recall, memory_search - memory_list, memory_delete, memory_feedback</p> <p>Graph (3 tools): - memory_record_interaction - memory_get_related - memory_get_user_pattern</p> <p>Web/API (10+ tools): - web_search, web_scrape - youtube_summarize, get_youtube_transcript - brave_web_search, fact_check_claim</p> <p>File Operations (local only): - file_read, file_write, dir_list</p> <p>System: - shell_exec (local only) - telemetry_stats, telemetry_cost</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Getting Started - 10-minute setup</li> <li>API Reference - REST API + MCP tools</li> <li>Architecture - System design</li> <li>Self-Hosting - Production deployment</li> <li>Memory Export/Import - Backup guide</li> </ul>"},{"location":"#community","title":"Community","text":"<ul> <li>GitHub - Source code &amp; issues</li> <li>PyPI - Package downloads</li> <li>Examples - Usage examples</li> </ul>"},{"location":"#status-v400-phase-c-complete","title":"Status: v4.0.0 (Phase C Complete)","text":"<p>Recently Completed: - \u2705 Phase A: MCP-First Foundation - \u2705 Phase B: Graph Memory - \u2705 Phase C: Remote MCP Server + Export/Import</p> <p>Features: - \u2705 31 MCP tools - \u2705 REST API (FastAPI) - \u2705 MCP over HTTP/SSE (ChatGPT Connector) - \u2705 API Key authentication - \u2705 Memory export/import (JSONL) - \u2705 Production Docker setup</p> <p>Coming Next: v4.0.0 stable release</p> <p>Built with \u2764\ufe0f for universal AI memory</p>"},{"location":"api-reference/","title":"API Reference - Kagura v4.0","text":"<p>REST API &amp; MCP Tools Documentation</p> <p>Comprehensive reference for Kagura's REST API and MCP tools.</p>"},{"location":"api-reference/#table-of-contents","title":"\ud83d\udcda Table of Contents","text":"<ol> <li>REST API - HTTP endpoints</li> <li>MCP over HTTP/SSE - ChatGPT Connector</li> <li>MCP Tools - Claude Desktop, stdio</li> <li>Authentication - API Keys</li> <li>OpenAPI Specification</li> </ol>"},{"location":"api-reference/#rest-api","title":"\ud83c\udf10 REST API","text":"<p>Base URL: <code>http://localhost:8000</code> (default)</p> <p>Interactive Docs: http://localhost:8000/docs</p>"},{"location":"api-reference/#authentication","title":"Authentication","text":"<p>v4.0.0: Optional API Key authentication</p> <pre><code># With API key\ncurl -H \"Authorization: Bearer kagura_abc123...\" \\\n     http://localhost:8000/api/v1/memory\n\n# Without (uses default_user)\ncurl http://localhost:8000/api/v1/memory\n</code></pre> <p>Headers: - <code>Authorization: Bearer &lt;api_key&gt;</code> - Optional API key - <code>X-User-ID: &lt;user_id&gt;</code> - Optional user identifier</p>"},{"location":"api-reference/#memory-operations","title":"Memory Operations","text":""},{"location":"api-reference/#post-apiv1memory","title":"POST /api/v1/memory","text":"<p>Create or update a memory.</p> <p>Request: <pre><code>{\n  \"key\": \"python_tips\",\n  \"value\": \"Always use type hints\",\n  \"scope\": \"persistent\",\n  \"tags\": [\"python\"],\n  \"importance\": 0.8\n}\n</code></pre></p> <p>Response (201 Created): <pre><code>{\n  \"key\": \"python_tips\",\n  \"value\": \"Always use type hints\",\n  \"scope\": \"persistent\",\n  \"tags\": [\"python\"],\n  \"importance\": 0.8\n}\n</code></pre></p>"},{"location":"api-reference/#get-apiv1memorykey","title":"GET /api/v1/memory/{key}","text":"<p>Retrieve a memory by key.</p> <p>Response (200 OK): <pre><code>{\n  \"key\": \"python_tips\",\n  \"value\": \"Always use type hints\",\n  \"scope\": \"persistent\"\n}\n</code></pre></p>"},{"location":"api-reference/#delete-apiv1memorykey","title":"DELETE /api/v1/memory/{key}","text":"<p>Delete a memory.</p> <p>Response (204 No Content)</p>"},{"location":"api-reference/#search-recall","title":"Search &amp; Recall","text":""},{"location":"api-reference/#post-apiv1recall","title":"POST /api/v1/recall","text":"<p>Semantic search using RAG.</p> <p>Request: <pre><code>{\n  \"query\": \"Python coding tips\",\n  \"k\": 5,\n  \"scope\": \"all\"\n}\n</code></pre></p> <p>Response (200 OK): <pre><code>{\n  \"results\": [\n    {\"key\": \"python_tips\", \"value\": \"...\", \"score\": 0.95}\n  ]\n}\n</code></pre></p>"},{"location":"api-reference/#get-apiv1search","title":"GET /api/v1/search","text":"<p>Full-text search.</p> <p>Query params: - <code>q</code>: Search query - <code>limit</code>: Max results (default: 10)</p>"},{"location":"api-reference/#graph-operations","title":"Graph Operations","text":""},{"location":"api-reference/#post-apiv1graphinteraction","title":"POST /api/v1/graph/interaction","text":"<p>Record AI-User interaction.</p> <p>Request: <pre><code>{\n  \"user_id\": \"jfk\",\n  \"query\": \"How do I use async?\",\n  \"response\": \"...\",\n  \"metadata\": {\"topic\": \"python\"}\n}\n</code></pre></p>"},{"location":"api-reference/#get-apiv1graphpatternuser_id","title":"GET /api/v1/graph/pattern/{user_id}","text":"<p>Analyze user patterns.</p> <p>Response: <pre><code>{\n  \"user_id\": \"jfk\",\n  \"total_interactions\": 150,\n  \"topics\": {\"python\": 45, \"docker\": 20},\n  \"learning_trajectory\": [...]\n}\n</code></pre></p>"},{"location":"api-reference/#system-endpoints","title":"System Endpoints","text":""},{"location":"api-reference/#get-apiv1health","title":"GET /api/v1/health","text":"<p>Health check.</p> <p>Response: <pre><code>{\n  \"status\": \"healthy\",\n  \"services\": {\n    \"database\": \"healthy\",\n    \"redis\": \"healthy\"\n  }\n}\n</code></pre></p>"},{"location":"api-reference/#get-apiv1metrics","title":"GET /api/v1/metrics","text":"<p>System metrics.</p> <p>Response: <pre><code>{\n  \"memories_count\": 150,\n  \"graph_nodes\": 87,\n  \"graph_edges\": 42,\n  \"storage_size_mb\": 12.5\n}\n</code></pre></p>"},{"location":"api-reference/#mcp-over-httpsse","title":"\ud83d\udd0c MCP over HTTP/SSE","text":"<p>Endpoint: <code>/mcp</code></p> <p>Protocol: MCP (Model Context Protocol) over HTTP/SSE</p> <p>Methods: - <code>GET /mcp</code> - SSE streaming (server \u2192 client) - <code>POST /mcp</code> - JSON-RPC requests (client \u2192 server) - <code>DELETE /mcp</code> - Session termination</p> <p>Authentication: <pre><code>curl -H \"Authorization: Bearer kagura_abc123...\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}' \\\n     http://localhost:8000/mcp\n</code></pre></p> <p>See: MCP over HTTP/SSE Guide</p>"},{"location":"api-reference/#mcp-tools","title":"\ud83d\udee0\ufe0f MCP Tools","text":"<p>Available via: Claude Desktop, stdio transport, HTTP/SSE</p>"},{"location":"api-reference/#remote-mcp-vs-local-mcp","title":"Remote MCP vs Local MCP","text":"Feature Remote MCP (HTTP/SSE) Local MCP (stdio) Platforms ChatGPT, Claude Chat (future) Claude Desktop, Claude Code, Cursor Transport HTTP/SSE over network stdio (stdin/stdout) File Access \u274c No \u2705 Yes Available Tools 49/56 tools 56/56 tools (all) Authentication API Key required Local only (no auth)"},{"location":"api-reference/#remote-mcp-tools-4956","title":"Remote MCP Tools (49/56)","text":"<p>These tools work with both Remote and Local MCP:</p>"},{"location":"api-reference/#available-for-remote-mcp","title":"\u2705 Available for Remote MCP","text":"<p>Memory Tools (13): - <code>memory_store</code>, <code>memory_recall</code>, <code>memory_search</code>, <code>memory_list</code>, <code>memory_delete</code> - <code>memory_feedback</code>, <code>memory_fetch</code>, <code>memory_search_ids</code>, <code>memory_stats</code> - <code>memory_get_related</code>, <code>memory_get_user_pattern</code>, <code>memory_record_interaction</code></p> <p>Web Search (5): - <code>brave_web_search</code>, <code>brave_image_search</code>, <code>brave_video_search</code>, <code>brave_news_search</code> - <code>web_scrape</code></p> <p>YouTube (4): - <code>get_youtube_transcript</code>, <code>get_youtube_metadata</code>, <code>youtube_summarize</code>, <code>youtube_fact_check</code></p> <p>Coding (14): - <code>coding_start_session</code>, <code>coding_end_session</code>, <code>coding_track_file_change</code> - <code>coding_record_error</code>, <code>coding_search_errors</code>, <code>coding_record_decision</code> - <code>coding_analyze_patterns</code>, <code>coding_analyze_file_dependencies</code> - <code>coding_analyze_refactor_impact</code>, <code>coding_suggest_refactor_order</code> - <code>coding_get_project_context</code>, <code>coding_get_issue_context</code> - <code>coding_link_github_issue</code>, <code>coding_generate_pr_description</code></p> <p>GitHub (6): - <code>github_exec</code>, <code>github_issue_list</code>, <code>github_issue_view</code> - <code>github_pr_view</code>, <code>github_pr_create</code>, <code>github_pr_merge</code></p> <p>Multimodal (2): - <code>multimodal_index</code>, <code>multimodal_search</code></p> <p>Other (5): - <code>arxiv_search</code>, <code>fact_check_claim</code>, <code>telemetry_stats</code>, <code>telemetry_cost</code>, <code>route_query</code></p>"},{"location":"api-reference/#local-only-tools-7","title":"\u274c Local-Only Tools (7)","text":"<p>These tools only work with Local MCP (require file system access):</p> <ul> <li><code>file_read</code> - Read files from disk</li> <li><code>file_write</code> - Write files to disk</li> <li><code>dir_list</code> - List directory contents</li> <li><code>shell_exec</code> - Execute shell commands</li> <li><code>media_open_image</code> - Open image in OS app</li> <li><code>media_open_audio</code> - Open audio in OS app</li> <li><code>media_open_video</code> - Open video in OS app</li> </ul> <p>Note: File upload for Remote MCP is planned for v4.1 (Issue #462)</p>"},{"location":"api-reference/#memory-tools","title":"Memory Tools","text":""},{"location":"api-reference/#memory_store","title":"memory_store","text":"<p>Store information in memory.</p> <p>Parameters: - <code>user_id</code> (string, required) - User identifier - <code>agent_name</code> (string, required) - Agent name (\"global\" for cross-thread) - <code>key</code> (string, required) - Memory key - <code>value</code> (string, required) - Value to store - <code>scope</code> (string) - \"working\" or \"persistent\" (default: \"working\") - <code>tags</code> (string) - JSON array of tags (e.g., '[\"python\"]') - <code>importance</code> (number) - 0.0-1.0 (default: 0.5)</p> <p>Example: <pre><code>{\n  \"user_id\": \"jfk\",\n  \"agent_name\": \"global\",\n  \"key\": \"pref_language\",\n  \"value\": \"Python\",\n  \"scope\": \"persistent\",\n  \"tags\": \"[\\\"preferences\\\"]\",\n  \"importance\": 0.8\n}\n</code></pre></p>"},{"location":"api-reference/#memory_recall","title":"memory_recall","text":"<p>Search memories semantically.</p> <p>Parameters: - <code>user_id</code> (string, required) - <code>agent_name</code> (string, required) - <code>query</code> (string, required) - Search query - <code>k</code> (number) - Number of results (default: 5) - <code>scope</code> (string) - \"working\", \"persistent\", or \"all\"</p>"},{"location":"api-reference/#memory_search","title":"memory_search","text":"<p>Full-text + semantic search.</p> <p>Parameters: - <code>user_id</code>, <code>agent_name</code> (required) - <code>query</code> (string, required) - <code>limit</code> (number) - Max results</p>"},{"location":"api-reference/#memory_list","title":"memory_list","text":"<p>List all memories.</p>"},{"location":"api-reference/#memory_delete","title":"memory_delete","text":"<p>Delete a memory with audit logging.</p>"},{"location":"api-reference/#memory_feedback","title":"memory_feedback","text":"<p>Provide feedback on memory usefulness.</p> <p>Parameters: - <code>user_id</code>, <code>agent_name</code> (required) - <code>node_id</code> (string) - Memory to rate - <code>label</code> (string) - \"useful\", \"irrelevant\", or \"outdated\" - <code>weight</code> (number) - -1.0 to 1.0</p>"},{"location":"api-reference/#graph-tools","title":"Graph Tools","text":""},{"location":"api-reference/#memory_record_interaction","title":"memory_record_interaction","text":"<p>Record AI-User interaction.</p> <p>Parameters: - <code>user_id</code> (required) - <code>query</code>, <code>response</code> (required) - <code>metadata</code> (object) - Optional metadata</p>"},{"location":"api-reference/#memory_get_related","title":"memory_get_related","text":"<p>Get related memories via graph.</p> <p>Parameters: - <code>user_id</code>, <code>agent_name</code> (required) - <code>key</code> (string) - Starting memory - <code>depth</code> (number) - Traversal depth (default: 2)</p>"},{"location":"api-reference/#memory_get_user_pattern","title":"memory_get_user_pattern","text":"<p>Analyze user's interaction patterns.</p>"},{"location":"api-reference/#webapi-tools-safe-for-remote","title":"Web/API Tools (Safe for Remote)","text":"<ul> <li><code>brave_web_search</code> - Brave Search integration (replaces deprecated <code>web_search</code>)</li> <li><code>brave_local_search</code> - Brave Local Search for businesses/places</li> <li><code>brave_news_search</code> - Brave News Search</li> <li><code>brave_image_search</code> - Brave Image Search</li> <li><code>brave_video_search</code> - Brave Video Search</li> <li><code>web_scrape</code> - Scrape web pages</li> <li><code>youtube_summarize</code> - Summarize YouTube videos</li> <li><code>get_youtube_transcript</code> - Get video transcript</li> </ul>"},{"location":"api-reference/#file-tools-local-only","title":"File Tools (Local Only)","text":"<p>\u26d4 Blocked remotely for security: - <code>file_read</code> - Read local files - <code>file_write</code> - Write local files - <code>dir_list</code> - List directory contents - <code>shell_exec</code> - Execute shell commands</p> <p>Note: These tools are only available via local stdio MCP server (<code>kagura mcp serve</code>), NOT via HTTP/SSE (<code>/mcp</code> endpoint).</p>"},{"location":"api-reference/#authentication_1","title":"\ud83d\udd10 Authentication","text":""},{"location":"api-reference/#api-key-management","title":"API Key Management","text":"<pre><code># Create API key\nkagura api create-key --name \"my-key\"\n\n# List keys\nkagura api list-keys\n\n# Revoke key\nkagura api revoke-key --name \"my-key\"\n</code></pre>"},{"location":"api-reference/#using-api-keys","title":"Using API Keys","text":"<p>REST API: <pre><code>curl -H \"Authorization: Bearer kagura_abc123...\" \\\n     http://localhost:8000/api/v1/memory\n</code></pre></p> <p>MCP over HTTP/SSE: <pre><code>curl -H \"Authorization: Bearer kagura_abc123...\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\"}' \\\n     http://localhost:8000/mcp\n</code></pre></p> <p>User ID Extraction: - API keys are associated with <code>user_id</code> - Authenticated requests automatically use the key's <code>user_id</code> - Fallback to <code>default_user</code> if no authentication</p>"},{"location":"api-reference/#openapi-specification","title":"\ud83d\udcc4 OpenAPI Specification","text":"<p>Interactive Docs: http://localhost:8000/docs</p> <p>OpenAPI JSON: http://localhost:8000/openapi.json</p> <p>Download: <pre><code>curl http://localhost:8000/openapi.json &gt; openapi.json\n</code></pre></p>"},{"location":"api-reference/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>MCP Setup Guide - Claude Desktop</li> <li>MCP over HTTP/SSE - ChatGPT Connector</li> <li>Self-Hosting Guide - Production deployment</li> <li>Memory Export/Import - Backup and migration</li> <li>Architecture - System design</li> </ul> <p>Last Updated: 2025-10-27 Version: 4.0.0 API Version: v1</p>"},{"location":"architecture/","title":"Architecture - Kagura v4.0","text":"<p>Universal AI Memory Platform - System Design</p> <p>This document describes the architecture of Kagura v4.0 after Phase C completion.</p>"},{"location":"architecture/#high-level-overview","title":"\ud83c\udfd7\ufe0f High-Level Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  AI Platforms (MCP Clients)                     \u2502\n\u2502      Claude Desktop \u2022 ChatGPT \u2022 Gemini \u2022 Cursor \u2022 Cline         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 stdio (local)                    HTTP/SSE (remote)\u2502\n       \u2502                                                   \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  MCP Server        \u2502                    \u2502  MCP over HTTP/SSE    \u2502\n\u2502  (Local)           \u2502                    \u2502  (/mcp endpoint)      \u2502\n\u2502                    \u2502                    \u2502                       \u2502\n\u2502  All 31 tools \u2705   \u2502                    \u2502  24 safe tools only   \u2502\n\u2502  File ops \u2705       \u2502                    \u2502  File ops \u274c          \u2502\n\u2502  Shell exec \u2705     \u2502                    \u2502  Shell exec \u274c        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                                   \u2502\n       \u2502              Internal Python API                  \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502         Memory Manager                   \u2502\n          \u2502   (src/kagura/core/memory/manager.py)    \u2502\n          \u2502                                          \u2502\n          \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n          \u2502  \u2502 Working  \u2502 Context   \u2502 Persistent  \u2502 \u2502\n          \u2502  \u2502 Memory   \u2502 Memory    \u2502 Memory      \u2502 \u2502\n          \u2502  \u2502(In-Mem)  \u2502(Messages) \u2502(SQLite)     \u2502 \u2502\n          \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n          \u2502                                          \u2502\n          \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n          \u2502  \u2502  RAG (ChromaDB)                    \u2502 \u2502\n          \u2502  \u2502  \u2022 Working RAG                     \u2502 \u2502\n          \u2502  \u2502  \u2022 Persistent RAG                  \u2502 \u2502\n          \u2502  \u2502  \u2022 Semantic search                 \u2502 \u2502\n          \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n          \u2502                                          \u2502\n          \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n          \u2502  \u2502  Graph Memory (NetworkX)           \u2502 \u2502\n          \u2502  \u2502  \u2022 Relationships                   \u2502 \u2502\n          \u2502  \u2502  \u2022 Interaction history             \u2502 \u2502\n          \u2502  \u2502  \u2022 User patterns                   \u2502 \u2502\n          \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                  \u2502    Storage      \u2502\n                  \u2502  \u2022 SQLite       \u2502\n                  \u2502  \u2022 ChromaDB     \u2502\n                  \u2502  \u2022 Pickle files \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#phase-c-architecture-remote-mcp-server","title":"\ud83c\udd95 Phase C Architecture (Remote MCP Server)","text":""},{"location":"architecture/#remote-access-flow","title":"Remote Access Flow","text":"<pre><code>ChatGPT                         Your Server\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ChatGPT \u2502  HTTPS/SSE          \u2502    Caddy     \u2502\n\u2502Connector\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 (Port 443)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                       \u2502\n                               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                               \u2502  Kagura API   \u2502\n                               \u2502  (Port 8000)  \u2502\n                               \u2502               \u2502\n                               \u2502  /mcp         \u2502\u25c4\u2500 HTTP/SSE\n                               \u2502  /api/v1/*    \u2502\u25c4\u2500 REST\n                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                       \u2502\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                              \u2502 Memory Manager  \u2502\n                              \u2502  + Graph        \u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                       \u2502\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                              \u2502 PostgreSQL      \u2502\n                              \u2502 + pgvector      \u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#security-layers","title":"Security Layers","text":"<pre><code>1. API Key Authentication\n   \u251c\u2500 SHA256 hashed storage\n   \u251c\u2500 Optional expiration\n   \u2514\u2500 Audit trail (last_used_at)\n\n2. Tool Access Control\n   \u251c\u2500 Local context: All 31 tools \u2705\n   \u251c\u2500 Remote context: 24 safe tools only\n   \u2514\u2500 Dangerous tools filtered:\n      \u2022 file_read, file_write\n      \u2022 shell_exec\n      \u2022 media_open_*\n\n3. Network Security\n   \u251c\u2500 Caddy reverse proxy\n   \u251c\u2500 Automatic HTTPS (Let's Encrypt)\n   \u251c\u2500 CORS configuration\n   \u2514\u2500 Security headers (HSTS, XSS)\n</code></pre>"},{"location":"architecture/#component-details","title":"\ud83d\udce6 Component Details","text":""},{"location":"architecture/#1-mcp-server-srckaguramcp","title":"1. MCP Server (src/kagura/mcp/)","text":"<p>stdio Transport (local): - File: <code>src/kagura/cli/mcp.py</code> - Command: <code>kagura mcp serve</code> - Context: <code>local</code> (all tools available) - Clients: Claude Desktop, Cursor, Cline</p> <p>HTTP/SSE Transport (remote): - File: <code>src/kagura/api/routes/mcp_transport.py</code> - Endpoint: <code>/mcp</code> - Context: <code>remote</code> (safe tools only) - Clients: ChatGPT Connector, web browsers</p> <p>Tool Permissions: - File: <code>src/kagura/mcp/permissions.py</code> - Logic: <code>is_tool_allowed(tool_name, context)</code> - Default: Deny unknown tools (fail-safe)</p>"},{"location":"architecture/#2-memory-manager-srckaguracorememory","title":"2. Memory Manager (src/kagura/core/memory/)","text":"<p>Components: - <code>manager.py</code> - Main coordinator - <code>working.py</code> - In-memory temporary storage - <code>persistent.py</code> - SQLite-based long-term storage - <code>rag.py</code> - ChromaDB vector search - <code>export.py</code> - JSONL export/import</p> <p>Storage Scopes: - Working: Session-only, cleared after use - Persistent: Survives restarts, SQLite storage - Both: Indexed in RAG for semantic search</p>"},{"location":"architecture/#3-graph-memory-srckaguracoregraph","title":"3. Graph Memory (src/kagura/core/graph/)","text":"<p>Implementation: NetworkX-based</p> <p>Node Types: - <code>user</code> - User profiles - <code>topic</code> - Discussion topics - <code>memory</code> - Memory references - <code>interaction</code> - AI-User interactions</p> <p>Edge Types: - <code>related_to</code> - Related memories - <code>depends_on</code> - Dependencies - <code>learned_from</code> - Learning relationships - <code>works_on</code> - User activities</p> <p>Storage: Pickle files (<code>~/.local/share/kagura/graph.pkl</code>)</p>"},{"location":"architecture/#4-rest-api-srckaguraapi","title":"4. REST API (src/kagura/api/)","text":"<p>Framework: FastAPI</p> <p>Endpoints: - <code>/api/v1/memory</code> - Memory CRUD - <code>/api/v1/recall</code> - Semantic search - <code>/api/v1/search</code> - Full-text search - <code>/api/v1/graph/*</code> - Graph operations - <code>/api/v1/health</code> - Health check - <code>/api/v1/metrics</code> - System metrics - <code>/mcp</code> - MCP over HTTP/SSE \u2b50 NEW</p> <p>Authentication: - File: <code>src/kagura/api/auth.py</code> - Method: Bearer token (API keys) - Storage: SQLite (<code>~/.local/share/kagura/api_keys.db</code>) - Hashing: SHA256</p>"},{"location":"architecture/#data-flow","title":"\ud83d\udd04 Data Flow","text":""},{"location":"architecture/#memory-store-flow","title":"Memory Store Flow","text":"<pre><code>1. MCP Client (Claude/ChatGPT)\n   \u2514\u2500\u25ba MCP Tool Call: memory_store(...)\n\n2. MCP Server (stdio or HTTP/SSE)\n   \u2514\u2500\u25ba Route to tool_registry\n\n3. Built-in Tool (src/kagura/mcp/builtin/memory.py)\n   \u2514\u2500\u25ba Call MemoryManager.store()\n\n4. Memory Manager\n   \u251c\u2500\u25ba Working memory (if scope=\"working\")\n   \u251c\u2500\u25ba Persistent memory (if scope=\"persistent\")\n   \u2514\u2500\u25ba RAG indexing (both scopes)\n\n5. Storage\n   \u251c\u2500\u25ba SQLite (persistent)\n   \u251c\u2500\u25ba ChromaDB (vectors)\n   \u2514\u2500\u25ba In-memory dict (working)\n</code></pre>"},{"location":"architecture/#memory-recall-flow","title":"Memory Recall Flow","text":"<pre><code>1. MCP Tool Call: memory_recall(query=\"Python tips\", k=5)\n\n2. Memory Manager\n   \u2514\u2500\u25ba Query RAG (vector similarity)\n\n3. RAG Search\n   \u251c\u2500\u25ba Embed query (text-embedding-3-small)\n   \u251c\u2500\u25ba Search ChromaDB collections\n   \u2514\u2500\u25ba Return top-k results\n\n4. Return to client\n   \u2514\u2500\u25ba Formatted results with scores\n</code></pre>"},{"location":"architecture/#security-architecture","title":"\ud83d\udd10 Security Architecture","text":""},{"location":"architecture/#authentication-flow","title":"Authentication Flow","text":"<pre><code>1. Client Request\n   \u2514\u2500\u25ba Authorization: Bearer kagura_abc123...\n\n2. API Gateway (/mcp or /api/v1/*)\n   \u2514\u2500\u25ba Extract Bearer token\n\n3. API Key Manager (src/kagura/api/auth.py)\n   \u251c\u2500\u25ba Hash provided key (SHA256)\n   \u251c\u2500\u25ba Query api_keys.db\n   \u251c\u2500\u25ba Check expiration &amp; revocation\n   \u2514\u2500\u25ba Extract user_id\n\n4. Request Processing\n   \u2514\u2500\u25ba Use authenticated user_id for memory operations\n</code></pre>"},{"location":"architecture/#tool-filtering-remote-context","title":"Tool Filtering (Remote Context)","text":"<pre><code>1. create_mcp_server(context=\"remote\")\n\n2. handle_list_tools()\n   \u251c\u2500\u25ba Get all registered tools (31 total)\n   \u251c\u2500\u25ba Filter by TOOL_PERMISSIONS\n   \u2514\u2500\u25ba Return safe tools only (24)\n\n3. Client sees:\n   \u2705 memory_* tools\n   \u2705 web_* tools\n   \u274c file_* tools (blocked)\n   \u274c shell_exec (blocked)\n</code></pre>"},{"location":"architecture/#data-model","title":"\ud83d\udcbe Data Model","text":""},{"location":"architecture/#memory-record","title":"Memory Record","text":"<pre><code>{\n    \"key\": str,                  # Unique identifier\n    \"value\": Any,                # Stored data (JSON serializable)\n    \"user_id\": str,              # Owner (v4.0+)\n    \"agent_name\": str,           # Agent scope\n    \"scope\": \"working|persistent\",\n    \"tags\": List[str],           # Categorization\n    \"importance\": float,         # 0.0-1.0\n    \"created_at\": datetime,\n    \"updated_at\": datetime,\n    \"metadata\": Dict[str, Any]   # Additional metadata\n}\n</code></pre>"},{"location":"architecture/#graph-node","title":"Graph Node","text":"<pre><code>{\n    \"id\": str,                   # Node identifier\n    \"type\": str,                 # Node type (user, topic, memory, interaction)\n    \"data\": Dict[str, Any],      # Node attributes\n}\n</code></pre>"},{"location":"architecture/#graph-edge","title":"Graph Edge","text":"<pre><code>{\n    \"src\": str,                  # Source node ID\n    \"dst\": str,                  # Destination node ID\n    \"type\": str,                 # Relationship type\n    \"weight\": float,             # 0.0-1.0\n}\n</code></pre>"},{"location":"architecture/#deployment-architecture","title":"\ud83d\udcca Deployment Architecture","text":""},{"location":"architecture/#local-development","title":"Local Development","text":"<pre><code>Developer Machine\n\u251c\u2500\u2500 SQLite (~/.local/share/kagura/memory.db)\n\u251c\u2500\u2500 ChromaDB (~/.local/share/kagura/chromadb/)\n\u251c\u2500\u2500 Graph pickle (~/.local/share/kagura/graph.pkl)\n\u2514\u2500\u2500 API Keys (~/.local/share/kagura/api_keys.db)\n</code></pre>"},{"location":"architecture/#production-deployment","title":"Production Deployment","text":"<pre><code>Docker Stack (docker-compose.prod.yml)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            Caddy (Port 443)             \u2502\n\u2502     Automatic HTTPS, Reverse Proxy      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       Kagura API (Port 8000)            \u2502\n\u2502    FastAPI + MCP over HTTP/SSE          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                      \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   PostgreSQL    \u2502   \u2502     Redis       \u2502\n\u2502   + pgvector    \u2502   \u2502   (Caching)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nVolumes:\n\u251c\u2500\u2500 postgres_data  - Database persistence\n\u251c\u2500\u2500 redis_data     - Redis persistence\n\u251c\u2500\u2500 kagura_data    - Memory exports, etc.\n\u2514\u2500\u2500 caddy_data     - SSL certificates\n</code></pre>"},{"location":"architecture/#exportimport-system","title":"\ud83d\udd04 Export/Import System","text":""},{"location":"architecture/#export-format-jsonl","title":"Export Format (JSONL)","text":"<pre><code>backup/\n\u251c\u2500\u2500 memories.jsonl      # All memory records\n\u251c\u2500\u2500 graph.jsonl         # Graph nodes &amp; edges\n\u2514\u2500\u2500 metadata.json       # Export metadata\n</code></pre> <p>Example record: <pre><code>{\"type\":\"memory\",\"scope\":\"persistent\",\"key\":\"python_tips\",\"value\":\"Use type hints\",\"user_id\":\"jfk\",\"agent_name\":\"global\",\"tags\":[\"python\"],\"importance\":0.8,\"exported_at\":\"2025-10-27T10:00:00Z\"}\n</code></pre></p>"},{"location":"architecture/#design-principles","title":"\ud83d\udcd0 Design Principles","text":""},{"location":"architecture/#1-mcp-first","title":"1. MCP-First","text":"<p>All functionality exposed via MCP tools first, then REST API.</p>"},{"location":"architecture/#2-multi-user-from-day-1","title":"2. Multi-User from Day 1","text":"<p>All operations scoped by <code>user_id</code> (Phase C foundation).</p>"},{"location":"architecture/#3-security-by-default","title":"3. Security by Default","text":"<p>Remote access auto-filtered for safety.</p>"},{"location":"architecture/#4-data-portability","title":"4. Data Portability","text":"<p>Complete export/import in human-readable JSONL.</p>"},{"location":"architecture/#5-fail-safe","title":"5. Fail-Safe","text":"<p>Unknown tools denied by default in remote context.</p>"},{"location":"architecture/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>Getting Started</li> <li>MCP Setup Guide</li> <li>MCP over HTTP/SSE</li> <li>Self-Hosting Guide</li> <li>API Reference</li> </ul> <p>Last Updated: 2025-10-27 Version: 4.0.0 Phase: C Complete</p>"},{"location":"chat-integration-tips/","title":"\u30c1\u30e3\u30c3\u30c8\u7d71\u5408\u306e\u30d2\u30f3\u30c8\u3068\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":"<p>ChatGPT\u3001Claude Chat\u3001\u305d\u306e\u4ed6\u306eAI\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3067Kagura AI\u3092\u6700\u5927\u9650\u306b\u6d3b\u7528\u3059\u308b</p> <p>\u3053\u306e\u30ac\u30a4\u30c9\u306f\u3001Remote MCP (Model Context Protocol) \u3092\u4f7f\u7528\u3057\u3066\u30c1\u30e3\u30c3\u30c8\u30d9\u30fc\u30b9\u306eAI\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3068\u7d71\u5408\u3059\u308b\u969b\u306b\u3001Kagura AI\u3092\u6700\u5927\u9650\u306b\u6d3b\u7528\u3059\u308b\u305f\u3081\u306e\u3082\u306e\u3067\u3059\u3002</p>"},{"location":"chat-integration-tips/#_2","title":"\ud83d\udccb \u6982\u8981","text":""},{"location":"chat-integration-tips/#kagura-ai","title":"Kagura AI\u3068\u306f?","text":"<p>Kagura AI\u306f\u3001Claude\u3001ChatGPT\u3001Gemini\u3001\u305d\u3057\u3066\u3059\u3079\u3066\u306eAI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u9593\u3067\u4f1a\u8a71\u3068\u30ca\u30ec\u30c3\u30b8\u3092\u5171\u6709\u3067\u304d\u308b\u3001\u30e6\u30cb\u30d0\u30fc\u30b5\u30eb\u30e1\u30e2\u30ea\u30fc\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3067\u3059\u3002</p> <p>\u4e3b\u306a\u6a5f\u80fd: - \ud83e\udde0 \u30e6\u30cb\u30d0\u30fc\u30b5\u30eb\u30e1\u30e2\u30ea\u30fc: \u3059\u3079\u3066\u306eAI\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u9593\u3067\u60c5\u5831\u3092\u4fdd\u5b58\u30fb\u547c\u3073\u51fa\u3057 - \ud83d\udd0d \u30b9\u30de\u30fc\u30c8\u691c\u7d22: \u30d9\u30af\u30c8\u30eb\u57cb\u3081\u8fbc\u307f + BM25\u306b\u3088\u308b\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u691c\u7d22 - \ud83d\udcca \u30ca\u30ec\u30c3\u30b8\u30b0\u30e9\u30d5: \u30e1\u30e2\u30ea\u30fc\u9593\u306e\u95a2\u4fc2\u3092\u8ffd\u8de1 - \ud83c\udf10 Web\u7d71\u5408: Web\u3001YouTube\u3001arXiv\u3092\u76f4\u63a5\u691c\u7d22 - \ud83c\udfa8 \u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb: \u753b\u50cf\u3001PDF\u3001\u97f3\u58f0\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u5316\u3068\u691c\u7d22 - \ud83d\udcbb \u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30b5\u30dd\u30fc\u30c8: \u30d5\u30a1\u30a4\u30eb\u5909\u66f4\u3001\u30a8\u30e9\u30fc\u3001\u8a2d\u8a08\u6c7a\u5b9a\u3092\u8ffd\u8de1</p>"},{"location":"chat-integration-tips/#remote-mcp-vs-local-mcp","title":"Remote MCP vs Local MCP","text":"\u6a5f\u80fd Remote MCP Local MCP \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0 ChatGPT\u3001Claude Chat\u3001Gemini Claude Desktop\u3001Claude Code\u3001Cursor \u30c8\u30e9\u30f3\u30b9\u30dd\u30fc\u30c8 HTTP/SSE stdio \u30d5\u30a1\u30a4\u30eb\u30a2\u30af\u30bb\u30b9 \u274c \u306a\u3057 \u2705 \u3042\u308a \u30e1\u30e2\u30ea\u30fc\u30c4\u30fc\u30eb \u2705 \u5168\u3066 (49/56) \u2705 \u5168\u3066 (56/56) \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3 API Key\u5fc5\u9808 \u30ed\u30fc\u30ab\u30eb\u306e\u307f <p>\u3053\u306e\u30ac\u30a4\u30c9\u306fRemote MCP (ChatGPT\u3001Claude Chat\u306a\u3069) \u306b\u7126\u70b9\u3092\u5f53\u3066\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"chat-integration-tips/#_3","title":"\u26a1 \u30af\u30a4\u30c3\u30af\u30b9\u30bf\u30fc\u30c8","text":""},{"location":"chat-integration-tips/#step-1-kagura-remote-mcp","title":"Step 1: Kagura Remote MCP\u30b5\u30fc\u30d0\u30fc\u3092\u8d77\u52d5","text":"<pre><code># Kagura\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\npip install kagura-ai[full]\n\n# Remote MCP\u30b5\u30fc\u30d0\u30fc\u3092\u8d77\u52d5\ndocker compose -f docker-compose.prod.yml up -d\n\n# \u307e\u305f\u306f\u958b\u767a\u30e2\u30fc\u30c9\nuvicorn kagura.api.server:app --host 0.0.0.0 --port 8080\n</code></pre>"},{"location":"chat-integration-tips/#step-2-ai","title":"Step 2: AI\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3092\u8a2d\u5b9a","text":"<p>ChatGPT (MCP over HTTP/SSE\u7d4c\u7531): 1. ChatGPT\u8a2d\u5b9a \u2192 \u30c4\u30fc\u30eb \u3092\u958b\u304f 2. MCP\u30b5\u30fc\u30d0\u30fc\u3092\u8ffd\u52a0: <code>https://your-domain.com/mcp</code> 3. API Key\u3092\u8ffd\u52a0 (\u30aa\u30d7\u30b7\u30e7\u30f3\u3001\u672c\u756a\u74b0\u5883\u3067\u306f\u63a8\u5968)</p> <p>Claude Chat (\u5c06\u6765\u30b5\u30dd\u30fc\u30c8\u4e88\u5b9a): - Anthropic\u306f2026\u5e74\u306bClaude Chat\u5411\u3051MCP\u30b5\u30dd\u30fc\u30c8\u3092\u767a\u8868</p> <p>\u53c2\u7167: MCP over HTTP/SSE \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u30ac\u30a4\u30c9</p>"},{"location":"chat-integration-tips/#step-3","title":"Step 3: \u8a66\u3057\u3066\u307f\u3088\u3046!","text":"<p>AI\u30c1\u30e3\u30c3\u30c8\u3067\u4ee5\u4e0b\u306e\u30d7\u30ed\u30f3\u30d7\u30c8\u3092\u8a66\u3057\u3066\u304f\u3060\u3055\u3044:</p> <pre><code>\"\u3053\u3093\u306b\u3061\u306f! memory_stats \u3092\u5b9f\u884c\u3057\u3066Kagura\u306e\u30b9\u30c6\u30fc\u30bf\u30b9\u3092\u8868\u793a\u3067\u304d\u307e\u3059\u304b?\"\n\n\"\u79c1\u306e\u304a\u6c17\u306b\u5165\u308a\u306e\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u8a00\u8a9e\u306fPython\u3067\u3042\u308b\u3053\u3068\u3092\u899a\u3048\u3066\u304a\u3044\u3066\"\n\n\"Python 3.13\u306e\u30ea\u30ea\u30fc\u30b9\u30ce\u30fc\u30c8\u3092Web\u3067\u691c\u7d22\u3057\u3066\"\n\n\"\u79c1\u306e\u597d\u307f\u306b\u3064\u3044\u3066\u4f55\u3092\u899a\u3048\u3066\u3044\u307e\u3059\u304b?\"\n</code></pre>"},{"location":"chat-integration-tips/#remote-mcp-4956","title":"\ud83e\uddf0 Remote MCP\u30c4\u30fc\u30eb (49/56)","text":""},{"location":"chat-integration-tips/#_4","title":"\u2705 \u5229\u7528\u53ef\u80fd\u306a\u30c4\u30fc\u30eb","text":""},{"location":"chat-integration-tips/#13","title":"\u30e1\u30e2\u30ea\u30fc\u30c4\u30fc\u30eb (13\u30c4\u30fc\u30eb)","text":"\u30c4\u30fc\u30eb \u8aac\u660e \u4f7f\u7528\u4f8b <code>memory_store</code> \u60c5\u5831\u3092\u4fdd\u5b58 \"X\u3092\u899a\u3048\u3066\u304a\u3044\u3066\" <code>memory_recall</code> \u30ad\u30fc\u3067\u53d6\u5f97 \"Y\u306b\u3064\u3044\u3066\u4f55\u3068\u8a00\u3044\u307e\u3057\u305f\u304b?\" <code>memory_search</code> \u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u691c\u7d22 \"Z\u306b\u95a2\u3059\u308b\u30e1\u30e2\u30ea\u30fc\u3092\u691c\u7d22\" <code>memory_list</code> \u5168\u30e1\u30e2\u30ea\u30fc\u3092\u30ea\u30b9\u30c8 \"\u4f55\u3092\u899a\u3048\u3066\u3044\u307e\u3059\u304b?\" <code>memory_delete</code> \u60c5\u5831\u3092\u5fd8\u308c\u308b \"X\u306b\u3064\u3044\u3066\u5fd8\u308c\u3066\" <code>memory_feedback</code> \u6709\u7528/\u53e4\u3044\u3068\u30de\u30fc\u30af \u81ea\u52d5 <code>memory_fetch</code> \u7279\u5b9a\u306e\u30e1\u30e2\u30ea\u30fc\u3092\u53d6\u5f97 \u5185\u90e8\u4f7f\u7528 <code>memory_search_ids</code> ID\u306e\u307f\u3067\u691c\u7d22 \u4f4e\u30c8\u30fc\u30af\u30f3\u691c\u7d22 <code>memory_stats</code> \u30e1\u30e2\u30ea\u30fc\u7d71\u8a08\u3092\u53d6\u5f97 \"\u30e1\u30e2\u30ea\u30fc\u7d71\u8a08\u3092\u8868\u793a\" <code>memory_get_related</code> \u95a2\u9023\u30e1\u30e2\u30ea\u30fc\u3092\u53d6\u5f97 \u30b0\u30e9\u30d5\u30c8\u30e9\u30d0\u30fc\u30b5\u30eb <code>memory_get_user_pattern</code> \u30e6\u30fc\u30b6\u30fc\u30d1\u30bf\u30fc\u30f3\u3092\u5206\u6790 \"\u79c1\u306e\u8208\u5473\u306f\u4f55?\" <code>memory_record_interaction</code> \u30a4\u30f3\u30bf\u30e9\u30af\u30b7\u30e7\u30f3\u3092\u8ffd\u8de1 \u81ea\u52d5"},{"location":"chat-integration-tips/#web-5","title":"Web\u691c\u7d22\u30c4\u30fc\u30eb (5\u30c4\u30fc\u30eb)","text":"\u30c4\u30fc\u30eb \u8aac\u660e <code>brave_web_search</code> \u4e00\u822c\u7684\u306aWeb\u691c\u7d22 <code>brave_image_search</code> \u753b\u50cf\u691c\u7d22 <code>brave_video_search</code> \u52d5\u753b\u691c\u7d22 <code>brave_news_search</code> \u30cb\u30e5\u30fc\u30b9\u691c\u7d22 <code>web_scrape</code> Web\u30da\u30fc\u30b8\u3092\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0 <p>\u6ce8: <code>BRAVE_API_KEY</code> \u74b0\u5883\u5909\u6570\u304c\u5fc5\u8981</p>"},{"location":"chat-integration-tips/#1","title":"\u30a2\u30ab\u30c7\u30df\u30c3\u30af\u691c\u7d22 (1\u30c4\u30fc\u30eb)","text":"\u30c4\u30fc\u30eb \u8aac\u660e <code>arxiv_search</code> arXiv\u3067\u5b66\u8853\u8ad6\u6587\u3092\u691c\u7d22"},{"location":"chat-integration-tips/#youtube-4","title":"YouTube\u30c4\u30fc\u30eb (4\u30c4\u30fc\u30eb)","text":"\u30c4\u30fc\u30eb \u8aac\u660e \u4f8b <code>get_youtube_transcript</code> \u52d5\u753b\u306e\u6587\u5b57\u8d77\u3053\u3057\u3092\u53d6\u5f97 \"\u3053\u306e\u52d5\u753b\u3092\u6587\u5b57\u8d77\u3053\u3057\u3057\u3066\" <code>get_youtube_metadata</code> \u52d5\u753b\u60c5\u5831\u3092\u53d6\u5f97 \"\u52d5\u753b\u306e\u8a73\u7d30\u3092\u53d6\u5f97\" <code>youtube_summarize</code> \u52d5\u753b\u3092\u8981\u7d04 \"\u3053\u306eYouTube\u52d5\u753b\u3092\u8981\u7d04\u3057\u3066\" <code>youtube_fact_check</code> \u4e3b\u5f35\u3092\u691c\u8a3c \"\u3053\u306e\u52d5\u753b\u306e\u4e3b\u5f35\u3092\u4e8b\u5b9f\u78ba\u8a8d\u3057\u3066\""},{"location":"chat-integration-tips/#2","title":"\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u30c4\u30fc\u30eb (2\u30c4\u30fc\u30eb)","text":"\u30c4\u30fc\u30eb \u8aac\u660e \u6ce8\u610f <code>multimodal_index</code> \u753b\u50cf/PDF/\u97f3\u58f0\u3092\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u5316 Gemini API\u5fc5\u9808 <code>multimodal_search</code> \u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u5316\u3055\u308c\u305f\u30b3\u30f3\u30c6\u30f3\u30c4\u3092\u691c\u7d22 Gemini API\u5fc5\u9808 <p>\u6ce8: Remote MCP\u7d4c\u7531\u306e\u30d5\u30a1\u30a4\u30eb\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u306fv4.1\u3067\u63d0\u4f9b\u4e88\u5b9a (Issue #462)</p>"},{"location":"chat-integration-tips/#14","title":"\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30c4\u30fc\u30eb (14\u30c4\u30fc\u30eb)","text":"\u30c4\u30fc\u30eb \u8aac\u660e <code>coding_start_session</code> \u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u958b\u59cb <code>coding_end_session</code> \u30bb\u30c3\u30b7\u30e7\u30f3\u7d42\u4e86 + AI\u8981\u7d04 <code>coding_track_file_change</code> \u30d5\u30a1\u30a4\u30eb\u5909\u66f4\u3092\u8ffd\u8de1 <code>coding_record_error</code> \u30b9\u30bf\u30c3\u30af\u30c8\u30ec\u30fc\u30b9\u4ed8\u304d\u3067\u30a8\u30e9\u30fc\u3092\u8a18\u9332 <code>coding_search_errors</code> \u904e\u53bb\u306e\u985e\u4f3c\u30a8\u30e9\u30fc\u3092\u691c\u7d22 <code>coding_record_decision</code> \u8a2d\u8a08\u6c7a\u5b9a\u3092\u8a18\u9332 <code>coding_analyze_patterns</code> \u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u8a2d\u5b9a\u3092\u5206\u6790 <code>coding_analyze_file_dependencies</code> AST\u30d9\u30fc\u30b9\u306e\u4f9d\u5b58\u95a2\u4fc2\u5206\u6790 <code>coding_analyze_refactor_impact</code> \u30ea\u30d5\u30a1\u30af\u30bf\u30ea\u30f3\u30b0\u5f71\u97ff\u8a55\u4fa1 <code>coding_suggest_refactor_order</code> \u5b89\u5168\u306a\u30ea\u30d5\u30a1\u30af\u30bf\u30ea\u30f3\u30b0\u9806\u5e8f <code>coding_get_project_context</code> \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u6982\u8981\u3092\u53d6\u5f97 <code>coding_get_issue_context</code> GitHub issue\u8a73\u7d30\u3092\u53d6\u5f97 <code>coding_link_github_issue</code> \u30bb\u30c3\u30b7\u30e7\u30f3\u3092issue\u306b\u30ea\u30f3\u30af <code>coding_generate_pr_description</code> AI\u751f\u6210PR\u8aac\u660e"},{"location":"chat-integration-tips/#github-6","title":"GitHub\u30c4\u30fc\u30eb (6\u30c4\u30fc\u30eb)","text":"\u30c4\u30fc\u30eb \u8aac\u660e <code>github_exec</code> \u5b89\u5168\u306aGitHub CLI\u5b9f\u884c <code>github_issue_list</code> issue\u3092\u30ea\u30b9\u30c8 <code>github_issue_view</code> issue\u8a73\u7d30\u3092\u8868\u793a <code>github_pr_view</code> PR\u8a73\u7d30\u3092\u8868\u793a <code>github_pr_create</code> PR\u3092\u4f5c\u6210 <code>github_pr_merge</code> PR\u3092\u30de\u30fc\u30b8 <p>\u6ce8: <code>gh</code> CLI\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3068\u8a8d\u8a3c\u304c\u5fc5\u8981</p>"},{"location":"chat-integration-tips/#2_1","title":"\u30c6\u30ec\u30e1\u30c8\u30ea\u30fc\u30c4\u30fc\u30eb (2\u30c4\u30fc\u30eb)","text":"\u30c4\u30fc\u30eb \u8aac\u660e <code>telemetry_stats</code> \u4f7f\u7528\u7d71\u8a08\u3092\u53d6\u5f97 <code>telemetry_cost</code> \u30b3\u30b9\u30c8\u30b5\u30de\u30ea\u30fc\u3092\u53d6\u5f97"},{"location":"chat-integration-tips/#2_2","title":"\u305d\u306e\u4ed6\u306e\u30c4\u30fc\u30eb (2\u30c4\u30fc\u30eb)","text":"\u30c4\u30fc\u30eb \u8aac\u660e <code>fact_check_claim</code> Web\u691c\u7d22\u3092\u4f7f\u7528\u3057\u3066\u4e3b\u5f35\u3092\u691c\u8a3c <code>route_query</code> \u9069\u5207\u306a\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306b\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0 (\u30d7\u30ec\u30fc\u30b9\u30db\u30eb\u30c0\u30fc)"},{"location":"chat-integration-tips/#7","title":"\u274c \u30ed\u30fc\u30ab\u30eb\u5c02\u7528\u30c4\u30fc\u30eb (7\u30c4\u30fc\u30eb)","text":"<p>\u3053\u308c\u3089\u306e\u30c4\u30fc\u30eb\u306fLocal MCP\u3067\u306e\u307f\u52d5\u4f5c\u3057\u307e\u3059 (Claude Desktop\u3001Claude Code\u3001Cursor):</p> \u30c4\u30fc\u30eb \u306a\u305c\u30ed\u30fc\u30ab\u30eb\u5c02\u7528? \u4ee3\u66ff\u624b\u6bb5 <code>file_read</code> \u76f4\u63a5\u30d5\u30a1\u30a4\u30eb\u30b7\u30b9\u30c6\u30e0\u30a2\u30af\u30bb\u30b9 \u30b3\u30f3\u30c6\u30f3\u30c4\u3092\u30b3\u30d4\u30fc&amp;\u30da\u30fc\u30b9\u30c8 <code>file_write</code> \u76f4\u63a5\u30d5\u30a1\u30a4\u30eb\u30b7\u30b9\u30c6\u30e0\u30a2\u30af\u30bb\u30b9 \u51fa\u529b\u3092\u30b3\u30d4\u30fc&amp;\u30da\u30fc\u30b9\u30c8 <code>dir_list</code> \u76f4\u63a5\u30d5\u30a1\u30a4\u30eb\u30b7\u30b9\u30c6\u30e0\u30a2\u30af\u30bb\u30b9 \u624b\u52d5\u3067\u30d5\u30a1\u30a4\u30eb\u3092\u30ea\u30b9\u30c8 <code>shell_exec</code> \u30b7\u30a7\u30eb\u30b3\u30de\u30f3\u30c9\u5b9f\u884c GitHub CLI\u306f <code>github_exec</code> \u3092\u4f7f\u7528 <code>media_open_image</code> OS\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u958b\u304f \u8a72\u5f53\u306a\u3057 <code>media_open_audio</code> OS\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u958b\u304f \u8a72\u5f53\u306a\u3057 <code>media_open_video</code> OS\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u958b\u304f \u8a72\u5f53\u306a\u3057 <p>\u5c06\u6765: Remote MCP\u7d4c\u7531\u306e\u30d5\u30a1\u30a4\u30eb\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u306fv4.1\u3067\u8a08\u753b\u4e2d (Issue #462)</p>"},{"location":"chat-integration-tips/#_5","title":"\ud83d\udca1 \u63a8\u5968\u30ef\u30fc\u30af\u30d5\u30ed\u30fc","text":""},{"location":"chat-integration-tips/#1_1","title":"\u30d1\u30bf\u30fc\u30f31: \u5c0f\u3055\u306a\u30c7\u30fc\u30bf (\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306b\u4fdd\u6301) \ud83d\udd35","text":"<p>\u3044\u3064\u4f7f\u3046\u304b: \u73fe\u5728\u306e\u4f1a\u8a71\u3067\u306e\u307f\u5fc5\u8981\u306a\u5c11\u91cf\u306e\u60c5\u5831</p> <p>\u65b9\u6cd5: <pre><code>\u30e6\u30fc\u30b6\u30fc: \"Python 3.13\u306f2024\u5e7410\u67087\u65e5\u306b\u30ea\u30ea\u30fc\u30b9\u3055\u308c\u307e\u3057\u305f\"\nAI: [\u4f1a\u8a71\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306b\u4fdd\u6301\u3001\u4fdd\u5b58\u306a\u3057]\n</code></pre></p> <p>\u30e1\u30ea\u30c3\u30c8: \u9ad8\u901f\u3001\u30aa\u30fc\u30d0\u30fc\u30d8\u30c3\u30c9\u306a\u3057 \u30c7\u30e1\u30ea\u30c3\u30c8: \u4f1a\u8a71\u7d42\u4e86\u5f8c\u306b\u5931\u308f\u308c\u308b</p>"},{"location":"chat-integration-tips/#2_3","title":"\u30d1\u30bf\u30fc\u30f32: \u91cd\u8981\u306a\u30c7\u30fc\u30bf (\u6c38\u7d9a\u7684\u30e1\u30e2\u30ea\u30fc) \u2b50 \u63a8\u5968","text":"<p>\u3044\u3064\u4f7f\u3046\u304b: \u9577\u671f\u7684\u306b\u899a\u3048\u3066\u304a\u304d\u305f\u3044\u60c5\u5831</p> <p>\u65b9\u6cd5: <pre><code>\u30e6\u30fc\u30b6\u30fc: \"\u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3067\u306fDjango\u3088\u308a\u3082FastAPI\u3092\u597d\u3080\u3053\u3068\u3092\u899a\u3048\u3066\u304a\u3044\u3066\u3002\n       \u3053\u308c\u306f\u91cd\u8981\u3067\u6c38\u7d9a\u7684\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\"\n\nAI: [scope=\"persistent\"\u3067memory_store\u3092\u4f7f\u7528]\n</code></pre></p> <p>\u5f8c\u3067: <pre><code>\u30e6\u30fc\u30b6\u30fc: \"\u65b0\u3057\u3044\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u306f\u3069\u306e\u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u3092\u4f7f\u3046\u3079\u304d\u3067\u3059\u304b?\"\nAI: [memory_recall/search\u3092\u4f7f\u7528\u3057\u3066\u8a2d\u5b9a\u3092\u53d6\u5f97]\n</code></pre></p> <p>\u30e1\u30ea\u30c3\u30c8: - \u4f1a\u8a71\u3092\u8d85\u3048\u3066\u5b58\u7d9a - \u3059\u3079\u3066\u306eAI\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3067\u52d5\u4f5c - \u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u306b\u691c\u7d22\u53ef\u80fd</p> <p>\u30c7\u30e1\u30ea\u30c3\u30c8: \u899a\u3048\u3066\u304a\u304f\u305f\u3081\u306e\u660e\u793a\u7684\u306a\u6307\u793a\u304c\u5fc5\u8981</p> <p>\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9: - \"\u899a\u3048\u3066\"\u3001\"\u4fdd\u5b58\"\u3001\"\u6c38\u7d9a\u5316\"\u306a\u3069\u306e\u30ad\u30fc\u30ef\u30fc\u30c9\u3092\u4f7f\u7528 - \u660e\u793a\u7684\u306b: \"\u3053\u308c\u306f\u91cd\u8981\u3067\u3059\" - \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u8ffd\u52a0: \"\u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u7528\"</p>"},{"location":"chat-integration-tips/#3-rag","title":"\u30d1\u30bf\u30fc\u30f33: \u5927\u304d\u306a\u30c7\u30fc\u30bf (\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30ebRAG) \ud83d\ude80","text":"<p>\u3044\u3064\u4f7f\u3046\u304b: \u5927\u304d\u306a\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3001\u753b\u50cf\u3001\u8907\u6570\u30d5\u30a1\u30a4\u30eb</p> <p>\u65b9\u6cd5 (Gemini API\u5fc5\u9808): <pre><code>\u30e6\u30fc\u30b6\u30fc: \"./photos\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u5185\u306e\u3059\u3079\u3066\u306e\u753b\u50cf\u3092\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u5316\u3057\u3066\"\nAI: [multimodal_index\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"\u72ac\u304c\u5199\u3063\u3066\u3044\u308b\u5199\u771f\u3092\u691c\u7d22\u3057\u3066\"\nAI: [multimodal_search\u3092\u4f7f\u7528]\n</code></pre></p> <p>\u30e1\u30ea\u30c3\u30c8: - \u5927\u898f\u6a21\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u51e6\u7406 - \u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u753b\u50cf\u691c\u7d22 - \u591a\u8a00\u8a9e\u30b5\u30dd\u30fc\u30c8</p> <p>\u30c7\u30e1\u30ea\u30c3\u30c8: - Gemini API\u30ad\u30fc\u304c\u5fc5\u8981 - Remote MCP\u7d4c\u7531\u306e\u30d5\u30a1\u30a4\u30eb\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u306f\u307e\u3060\u5229\u7528\u4e0d\u53ef (v4.1\u3067\u63d0\u4f9b\u4e88\u5b9a)</p> <p>\u73fe\u5728\u306e\u56de\u907f\u7b56: \u30d5\u30a1\u30a4\u30eb\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u5316\u306b\u306fLocal MCP (Claude Desktop) \u3092\u4f7f\u7528</p>"},{"location":"chat-integration-tips/#_6","title":"\ud83d\udcdd \u30d7\u30ed\u30f3\u30d7\u30c8\u4f8b (\u30b3\u30d4\u30fc&amp;\u30da\u30fc\u30b9\u30c8)","text":""},{"location":"chat-integration-tips/#_7","title":"\u30e1\u30e2\u30ea\u30fc\u64cd\u4f5c","text":"<p>\u4fdd\u5b58: <pre><code>\"\u79c1\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u7de0\u5207\u306f2025\u5e7412\u670831\u65e5\u3067\u3042\u308b\u3053\u3068\u3092\u899a\u3048\u3066\u304a\u3044\u3066\u3002\u3053\u308c\u306f\u91cd\u8981\u3067\u3059\u3002\"\n\n\"\u3053\u306e\u60c5\u5831\u3092\u4fdd\u5b58: \u79c1\u306fAcme Corp\u3067Python\u958b\u767a\u8005\u3068\u3057\u3066\u50cd\u3044\u3066\u3044\u307e\u3059\"\n\n\"\u79c1\u306e\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30b9\u30bf\u30a4\u30eb\u306e\u8a2d\u5b9a\u3092\u899a\u3048\u3066\u304a\u3044\u3066: \u5e38\u306b\u578b\u30d2\u30f3\u30c8\u3068docstring\u3092\u4f7f\u7528\"\n</code></pre></p> <p>\u691c\u7d22: <pre><code>\"\u79c1\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u7de0\u5207\u306b\u3064\u3044\u3066\u4f55\u3092\u899a\u3048\u3066\u3044\u307e\u3059\u304b?\"\n\n\"\u79c1\u306e\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u8a2d\u5b9a\u306b\u95a2\u9023\u3059\u308b\u3059\u3079\u3066\u306e\u30e1\u30e2\u30ea\u30fc\u3092\u691c\u7d22\"\n\n\"\u79c1\u306b\u3064\u3044\u3066\u4f55\u3092\u77e5\u3063\u3066\u3044\u307e\u3059\u304b?\"\n\n\"'python'\u3067\u30bf\u30b0\u4ed8\u3051\u3055\u308c\u305f\u3059\u3079\u3066\u306e\u30e1\u30e2\u30ea\u30fc\u3092\u8868\u793a\"\n</code></pre></p> <p>\u524a\u9664: <pre><code>\"\u79c1\u306e\u53e4\u3044JavaScript\u306e\u8a2d\u5b9a\u306b\u3064\u3044\u3066\u5fd8\u308c\u3066\"\n\n\"\u79c1\u306e\u524d\u8077\u306b\u3064\u3044\u3066\u306e\u30e1\u30e2\u30ea\u30fc\u3092\u524a\u9664\"\n</code></pre></p> <p>\u7d71\u8a08: <pre><code>\"\u79c1\u306b\u3064\u3044\u3066\u306e\u30e1\u30e2\u30ea\u30fc\u306f\u3044\u304f\u3064\u3042\u308a\u307e\u3059\u304b?\"\n\n\"\u30e1\u30e2\u30ea\u30fc\u7d71\u8a08\u3092\u8868\u793a\"\n\n\"\u79c1\u306e\u6700\u3082\u4e00\u822c\u7684\u306a\u30c8\u30d4\u30c3\u30af\u306f\u4f55\u3067\u3059\u304b?\"\n</code></pre></p>"},{"location":"chat-integration-tips/#web","title":"Web\u691c\u7d22","text":"<p>\u6700\u65b0\u30cb\u30e5\u30fc\u30b9: <pre><code>\"Python\u306e\u6700\u65b0\u30d0\u30fc\u30b8\u30e7\u30f3\u306f\u4f55\u3067\u3059\u304b? Web\u3092\u691c\u7d22\u3057\u3066\u3002\"\n\n\"FastAPI\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u306b\u95a2\u3059\u308b\u6700\u8fd1\u306e\u30cb\u30e5\u30fc\u30b9\u3092\u691c\u7d22\"\n\n\"Python 3.13\u306e\u30ea\u30ea\u30fc\u30b9\u30ce\u30fc\u30c8\u3092\u691c\u7d22\"\n</code></pre></p> <p>\u6bd4\u8f03: <pre><code>\"FastAPI\u3068Django\u3092\u6bd4\u8f03\u3002\u9577\u6240\u3068\u77ed\u6240\u3092Web\u3067\u691c\u7d22\u3057\u3066\u3002\"\n\n\"PostgreSQL\u3068MySQL\u3092\u6bd4\u8f03\u3059\u308b\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3092\u691c\u7d22\"\n</code></pre></p> <p>\u753b\u50cf: <pre><code>\"'\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u56f3'\u306e\u753b\u50cf\u3092\u691c\u7d22\"\n\n\"VSCode\u30c6\u30fc\u30de\u306e\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8\u3092\u691c\u7d22\"\n</code></pre></p>"},{"location":"chat-integration-tips/#youtube","title":"YouTube","text":"<p>\u8981\u7d04: <pre><code>\"\u3053\u306eYouTube\u52d5\u753b\u3092\u8981\u7d04\u3057\u3066: https://www.youtube.com/watch?v=xxxxx\"\n\n\"\u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u52d5\u753b\u304b\u3089\u8981\u70b9\u3092\u6559\u3048\u3066: [URL]\"\n</code></pre></p> <p>\u30d5\u30a1\u30af\u30c8\u30c1\u30a7\u30c3\u30af: <pre><code>\"\u3053\u306e\u52d5\u753b\u3067\u4e3b\u5f35\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u3092\u4e8b\u5b9f\u78ba\u8a8d\u3057\u3066: [URL]\"\n\n\"[URL]\u3067\u8a00\u53ca\u3055\u308c\u3066\u3044\u308b\u7d71\u8a08\u304c\u6b63\u78ba\u304b\u691c\u8a3c\u3057\u3066\"\n</code></pre></p> <p>\u6587\u5b57\u8d77\u3053\u3057: <pre><code>\"\u3053\u306e\u52d5\u753b\u306e\u6587\u5b57\u8d77\u3053\u3057\u3092\u53d6\u5f97: [URL]\"\n\n\"\u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u304b\u3089\u30b3\u30fc\u30c9\u4f8b\u3092\u62bd\u51fa: [URL]\"\n</code></pre></p>"},{"location":"chat-integration-tips/#_8","title":"\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0","text":"<p>\u30bb\u30c3\u30b7\u30e7\u30f3\u958b\u59cb: <pre><code>\"\u30e6\u30fc\u30b6\u30fc\u8a8d\u8a3c\u306e\u5b9f\u88c5\u306e\u305f\u3081\u306e\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u958b\u59cb\"\n\n\"Issue #123\u3067\u306e\u4f5c\u696d\u306e\u8ffd\u8de1\u3092\u958b\u59cb\"\n</code></pre></p> <p>\u5909\u66f4\u306e\u8ffd\u8de1: <pre><code>\"auth.py\u3092\u4fee\u6b63\u3057\u3066OAuth2\u30b5\u30dd\u30fc\u30c8\u3092\u8ffd\u52a0\u3057\u307e\u3057\u305f\"\n\n\"\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u63a5\u7d9a\u306e\u30d0\u30b0\u3092\u4fee\u6b63\u3057\u305f\u3053\u3068\u3092\u8a18\u9332\"\n</code></pre></p> <p>\u30a8\u30e9\u30fc\u306e\u8a18\u9332: <pre><code>\"\u3053\u306e\u30a8\u30e9\u30fc\u3092\u8a18\u9332: [\u30b9\u30bf\u30c3\u30af\u30c8\u30ec\u30fc\u30b9\u3092\u8cbc\u308a\u4ed8\u3051]\"\n\n\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8\u4ed8\u304d\u3067\u3053\u306eTypeScript\u30a8\u30e9\u30fc\u3092\u8a18\u9332\"\n</code></pre></p> <p>\u904e\u53bb\u306e\u30a8\u30e9\u30fc\u3092\u691c\u7d22: <pre><code>\"\u3053\u306e'Connection refused'\u30a8\u30e9\u30fc\u3092\u4ee5\u524d\u898b\u305f\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u304b?\"\n\n\"\u904e\u53bb\u306e\u30bb\u30c3\u30b7\u30e7\u30f3\u304b\u3089\u985e\u4f3c\u306e\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30de\u30a4\u30b0\u30ec\u30fc\u30b7\u30e7\u30f3\u30a8\u30e9\u30fc\u3092\u691c\u7d22\"\n</code></pre></p> <p>\u30bb\u30c3\u30b7\u30e7\u30f3\u7d42\u4e86: <pre><code>\"\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u7d42\u4e86\u3057\u3066\u8981\u7d04\u3092\u751f\u6210\"\n\n\"\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u7d42\u4e86\u3057\u3066PR\u8aac\u660e\u3092\u4f5c\u6210\"\n</code></pre></p>"},{"location":"chat-integration-tips/#github","title":"GitHub","text":"<p>Issue\u306e\u30ea\u30b9\u30c8: <pre><code>\"JFK/kagura-ai\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u30aa\u30fc\u30d7\u30f3\u306aissue\u3092\u30ea\u30b9\u30c8\"\n\n\"'bug'\u3068'priority:high'\u306e\u30e9\u30d9\u30eb\u304c\u4ed8\u3044\u305fissue\u3092\u8868\u793a\"\n</code></pre></p> <p>\u8a73\u7d30\u8868\u793a: <pre><code>\"issue #463\u306e\u8a73\u7d30\u3092\u53d6\u5f97\"\n\n\"PR #472\u3092\u8868\u793a\"\n</code></pre></p> <p>\u5b89\u5168\u306a\u5b9f\u884c: <pre><code>\"\u5b9f\u884c: gh issue list --repo JFK/kagura-ai --state open\"\n\n\"\u5b9f\u884c: gh pr view 472\"\n</code></pre></p>"},{"location":"chat-integration-tips/#_9","title":"\ud83c\udf0d \u30af\u30ed\u30b9\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u30e1\u30e2\u30ea\u30fc","text":""},{"location":"chat-integration-tips/#user_id","title":"user_id\u7ba1\u7406","text":"<p>\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9: \u500b\u4eba\u7684\u306a\u30e1\u30e2\u30ea\u30fc\u306b\u306f\u5e38\u306b <code>user_id</code> \u3092\u6307\u5b9a</p> <pre><code># \u2705 \u826f\u3044\nmemory_store(\n    user_id=\"user_jfk\",\n    key=\"python_preference\",\n    value=\"Django\u3088\u308a\u3082FastAPI\u3092\u597d\u3080\"\n)\n\n# \u274c \u60aa\u3044 (\u30c7\u30d5\u30a9\u30eb\u30c8\u30e6\u30fc\u30b6\u30fc\u3092\u4f7f\u7528)\nmemory_store(\n    key=\"python_preference\",\n    value=\"Django\u3088\u308a\u3082FastAPI\u3092\u597d\u3080\"\n)\n</code></pre> <p>\u30d7\u30ed\u30f3\u30d7\u30c8\u4f8b: <pre><code>\"user_id='john_doe'\u7528\u306b\u3053\u308c\u3092\u899a\u3048\u3066: \u30c0\u30fc\u30af\u30e2\u30fc\u30c9\u3092\u597d\u307f\u307e\u3059\"\n</code></pre></p>"},{"location":"chat-integration-tips/#agent_name","title":"agent_name\u30b9\u30b3\u30fc\u30d4\u30f3\u30b0","text":"<p><code>agent_name</code>\u3067\u30e1\u30e2\u30ea\u30fc\u30b9\u30b3\u30fc\u30d7\u3092\u5236\u5fa1:</p> <p>\u30b0\u30ed\u30fc\u30d0\u30eb\u30e1\u30e2\u30ea\u30fc (\u3059\u3079\u3066\u306e\u4f1a\u8a71\u3067\u5171\u6709): <pre><code>memory_store(\n    agent_name=\"global\",\n    key=\"coding_style\",\n    value=\"\u5e38\u306b\u578b\u30d2\u30f3\u30c8\u3092\u4f7f\u7528\"\n)\n</code></pre></p> <p>\u30b9\u30ec\u30c3\u30c9\u56fa\u6709\u30e1\u30e2\u30ea\u30fc (\u3053\u306e\u4f1a\u8a71\u306e\u307f): <pre><code>memory_store(\n    agent_name=\"thread_abc123\",\n    key=\"temp_data\",\n    value=\"...\"\n)\n</code></pre></p> <p>\u30d7\u30ed\u30f3\u30d7\u30c8\u4f8b: <pre><code>\"\u3053\u308c\u3092\u30b0\u30ed\u30fc\u30d0\u30eb\u306b\u899a\u3048\u3066: JavaScript\u3088\u308a\u3082Python\u3092\u597d\u3080\"\n\n\"\u3053\u306e\u4f1a\u8a71\u3060\u3051\u306e\u305f\u3081\u306b\u3053\u308c\u3092\u899a\u3048\u3066: \u73fe\u5728\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306f'kagura-ai'\"\n</code></pre></p>"},{"location":"chat-integration-tips/#_10","title":"\u30e1\u30e2\u30ea\u30fc\u30b9\u30b3\u30fc\u30d7","text":"<p>\u30ef\u30fc\u30ad\u30f3\u30b0\u30e1\u30e2\u30ea\u30fc (\u4e00\u6642\u7684\u3001\u30bb\u30c3\u30b7\u30e7\u30f3\u306e\u307f): <pre><code>memory_store(scope=\"working\", ...)\n</code></pre></p> <p>\u6c38\u7d9a\u7684\u30e1\u30e2\u30ea\u30fc (\u30c7\u30a3\u30b9\u30af\u306b\u4fdd\u5b58\u3001\u518d\u8d77\u52d5\u5f8c\u3082\u5b58\u7d9a): <pre><code>memory_store(scope=\"persistent\", ...)\n</code></pre></p> <p>\u30d7\u30ed\u30f3\u30d7\u30c8\u4f8b: <pre><code>\"\u3053\u308c\u3092\u6c38\u4e45\u306b\u899a\u3048\u3066: \u79c1\u306e\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\u306fjohn@example.com\u3067\u3059\"\n\n\"\u3053\u308c\u3092\u4e00\u6642\u7684\u306b\u4fdd\u5b58: \u73fe\u5728\u306e\u30bf\u30b9\u30af\u306f'\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u4f5c\u6210'\"\n</code></pre></p>"},{"location":"chat-integration-tips/#faq","title":"\u2753 \u3088\u304f\u3042\u308b\u8cea\u554f (FAQ)","text":""},{"location":"chat-integration-tips/#q","title":"Q: \u306a\u305c\u30d5\u30a1\u30a4\u30eb\u3092\u6dfb\u4ed8\u3067\u304d\u306a\u3044\u306e\u3067\u3059\u304b?","text":"<p>A: Remote MCP (ChatGPT\u3001Claude Chat) \u306f\u73fe\u5728\u3001\u30d5\u30a1\u30a4\u30eb\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u305b\u3093\u3002</p> <p>\u56de\u907f\u7b56: 1. \u30d5\u30a1\u30a4\u30eb\u306e\u5185\u5bb9\u3092\u30c1\u30e3\u30c3\u30c8\u306b\u76f4\u63a5\u30b3\u30d4\u30fc&amp;\u30da\u30fc\u30b9\u30c8 2. \u30d5\u30a1\u30a4\u30eb\u64cd\u4f5c\u306b\u306fLocal MCP (Claude Desktop\u3001Claude Code) \u3092\u4f7f\u7528 3. v4.1\u306e\u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9API\u3092\u5f85\u3064 (Issue #462)</p>"},{"location":"chat-integration-tips/#q_1","title":"Q: \u4f1a\u8a71\u304c\u7d42\u308f\u308b\u3068\u30e1\u30e2\u30ea\u30fc\u304c\u6d88\u3048\u3066\u3057\u307e\u3044\u307e\u3059\u3002\u306a\u305c\u3067\u3059\u304b?","text":"<p>A: <code>scope=\"working\"</code> (\u4e00\u6642\u30c7\u30fc\u30bf\u306e\u30c7\u30d5\u30a9\u30eb\u30c8) \u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002</p> <p>\u89e3\u6c7a\u7b56: \u660e\u793a\u7684\u306b\u6c38\u7d9a\u5316\u3092\u4f9d\u983c: <pre><code>\"\u3053\u308c\u3092\u6c38\u4e45\u306b\u899a\u3048\u3066: [\u3042\u306a\u305f\u306e\u30c7\u30fc\u30bf]\"\n</code></pre></p> <p>\u307e\u305f\u306f\u30d7\u30ed\u30f3\u30d7\u30c8\u3067\u6307\u5b9a: <pre><code>\"scope='persistent'\u3067\u3053\u308c\u3092\u4fdd\u5b58: [\u3042\u306a\u305f\u306e\u30c7\u30fc\u30bf]\"\n</code></pre></p>"},{"location":"chat-integration-tips/#q-ai","title":"Q: \u7570\u306a\u308bAI\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u9593\u3067\u30e1\u30e2\u30ea\u30fc\u3092\u5171\u6709\u3059\u308b\u306b\u306f?","text":"<p>A: <code>user_id</code>\u3092\u4e00\u8cab\u3057\u3066\u4f7f\u7528:</p> <ol> <li> <p>ChatGPT:    <pre><code>\"user_id='john'\u7528\u306b\u3053\u308c\u3092\u4fdd\u5b58: Python\u3092\u597d\u3080\"\n</code></pre></p> </li> <li> <p>Claude Chat (\u540c\u3058user_id):    <pre><code>\"user_id='john'\u306f\u3069\u306e\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u8a00\u8a9e\u3092\u597d\u307f\u307e\u3059\u304b?\"\n</code></pre></p> </li> </ol> <p>\u4e21\u65b9\u306eAI\u304c\u540c\u3058Kagura\u30e1\u30e2\u30ea\u30fc\u306b\u30a2\u30af\u30bb\u30b9\u3057\u307e\u3059!</p>"},{"location":"chat-integration-tips/#q_2","title":"Q: \u691c\u7d22\u7d50\u679c\u304c\u4e0d\u6b63\u78ba\u3067\u3059\u3002\u3069\u3046\u3059\u308c\u3070\u6539\u5584\u3067\u304d\u307e\u3059\u304b?","text":"<p>A: \u3088\u308a\u826f\u3044\u691c\u7d22\u306e\u305f\u3081\u306e\u30d2\u30f3\u30c8:</p> <ol> <li> <p>\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u691c\u7d22\u3092\u4f7f\u7528 (\u6b63\u78ba\u306a\u30ad\u30fc\u30ef\u30fc\u30c9\u3067\u306f\u306a\u304f):    <pre><code>\u2705 \"\u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u958b\u767a\u306b\u95a2\u3059\u308b\u30e1\u30e2\u30ea\u30fc\u3092\u691c\u7d22\"\n\u274c \"'FastAPI Django\u6bd4\u8f03'\u3092\u691c\u7d22\"\n</code></pre></p> </li> <li> <p>\u4fdd\u5b58\u6642\u306b\u30bf\u30b0\u3092\u8ffd\u52a0:    <pre><code>\"tags=['python', 'backend', 'framework']\u3067\u3053\u308c\u3092\u899a\u3048\u3066:\n FastAPI\u3092\u597d\u3080\"\n</code></pre></p> </li> <li> <p>\u30cf\u30a4\u30d6\u30ea\u30c3\u30c9\u691c\u7d22\u3092\u4f7f\u7528 (BM25 + \u30d9\u30af\u30c8\u30eb):    <pre><code>\"\u30cf\u30a4\u30d6\u30ea\u30c3\u30c9\u691c\u7d22\u3092\u4f7f\u7528\u3057\u3066'FastAPI'\u306e\u30e1\u30e2\u30ea\u30fc\u3092\u691c\u7d22\"\n</code></pre></p> </li> <li> <p>\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\u3092\u63d0\u4f9b:    <pre><code>\"\u30e1\u30e2\u30ea\u30fc[key]\u3092\u6709\u7528\u3068\u3057\u3066\u30de\u30fc\u30af\"\n\"\u3053\u306e\u30e1\u30e2\u30ea\u30fc\u306f\u53e4\u304f\u306a\u3063\u3066\u3044\u307e\u3059\"\n</code></pre></p> </li> </ol>"},{"location":"chat-integration-tips/#q_3","title":"Q: \u3069\u306e\u304f\u3089\u3044\u30b3\u30b9\u30c8\u304c\u304b\u304b\u308a\u307e\u3059\u304b?","text":"<p>A: Kagura AI\u306f\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u3067\u3001\u30bb\u30eb\u30d5\u30db\u30b9\u30c8\u306f\u7121\u6599\u3067\u3059\u3002</p> <p>\u30b3\u30b9\u30c8: - \u30bb\u30eb\u30d5\u30db\u30b9\u30c6\u30a3\u30f3\u30b0: \u7121\u6599 (\u30ed\u30fc\u30ab\u30eb\u306eChromaDB\u3092\u4f7f\u7528) - \u30af\u30e9\u30a6\u30c9\u30db\u30b9\u30c6\u30a3\u30f3\u30b0: \u30b5\u30fc\u30d0\u30fc\u30b3\u30b9\u30c8 (AWS\u3001DigitalOcean\u306a\u3069) - AI API:   - \u57cb\u3081\u8fbc\u307f\u7528\u306eOpenAI/Anthropic/Google API (\u30aa\u30d7\u30b7\u30e7\u30f3)   - Brave Search API (\u30aa\u30d7\u30b7\u30e7\u30f3\u3001\u7121\u6599\u5c64\u3042\u308a)   - \u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u7528\u306eGemini API (\u30aa\u30d7\u30b7\u30e7\u30f3)</p> <p>\u30b3\u30b9\u30c8\u8ffd\u8de1: <pre><code>\"\u30c6\u30ec\u30e1\u30c8\u30ea\u30fc\u30b3\u30b9\u30c8\u30b5\u30de\u30ea\u30fc\u3092\u8868\u793a\"\n</code></pre></p>"},{"location":"chat-integration-tips/#q_4","title":"Q: \u79c1\u306e\u30c7\u30fc\u30bf\u306f\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8\u3067\u3059\u304b?","text":"<p>A: \u306f\u3044! Kagura\u306f\u30d7\u30e9\u30a4\u30d0\u30b7\u30fc\u7b2c\u4e00\u3067\u3059:</p> <ul> <li>\u2705 \u30bb\u30eb\u30d5\u30db\u30b9\u30c8: \u30c7\u30fc\u30bf\u306f\u3042\u306a\u305f\u306e\u3082\u306e</li> <li>\u2705 \u30ed\u30fc\u30ab\u30eb\u30b9\u30c8\u30ec\u30fc\u30b8: \u3042\u306a\u305f\u306e\u30de\u30b7\u30f3\u4e0a\u306eSQLite + ChromaDB</li> <li>\u2705 \u30d9\u30f3\u30c0\u30fc\u30ed\u30c3\u30af\u30a4\u30f3\u306a\u3057: \u3044\u3064\u3067\u3082\u30a8\u30af\u30b9\u30dd\u30fc\u30c8 (JSONL\u5f62\u5f0f)</li> <li>\u2705 \u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9: \u30b3\u30fc\u30c9\u3092\u81ea\u5206\u3067\u76e3\u67fb\u53ef\u80fd</li> </ul> <p>\u30c7\u30fc\u30bf\u306e\u30a8\u30af\u30b9\u30dd\u30fc\u30c8: <pre><code>kagura memory export --output=./backup --format=jsonl\n</code></pre></p>"},{"location":"chat-integration-tips/#_11","title":"\ud83d\udd27 \u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"chat-integration-tips/#_12","title":"\u30e1\u30e2\u30ea\u30fc\u304c\u898b\u3064\u304b\u3089\u306a\u3044","text":"<p>\u75c7\u72b6: \"X\u306b\u3064\u3044\u3066\u306e\u30e1\u30e2\u30ea\u30fc\u304c\u3042\u308a\u307e\u305b\u3093\"</p> <p>\u539f\u56e0: 1. \u9593\u9055\u3063\u305f <code>user_id</code> 2. \u9593\u9055\u3063\u305f <code>agent_name</code> 3. \u30e1\u30e2\u30ea\u30fc\u304c <code>scope=\"working\"</code> \u3068\u3057\u3066\u4fdd\u5b58\u3055\u308c\u3001\u30bb\u30c3\u30b7\u30e7\u30f3\u304c\u7d42\u4e86\u3057\u305f</p> <p>\u30c7\u30d0\u30c3\u30b0: <pre><code>\"\u3059\u3079\u3066\u306e\u30e1\u30e2\u30ea\u30fc\u3092\u30ea\u30b9\u30c8\"\n\"\u30e1\u30e2\u30ea\u30fc\u7d71\u8a08\u3092\u8868\u793a\"\n\"\u30d5\u30a3\u30eb\u30bf\u30fc\u306a\u3057\u3067\u30e1\u30e2\u30ea\u30fc\u3092\u691c\u7d22\"\n</code></pre></p>"},{"location":"chat-integration-tips/#_13","title":"\u691c\u7d22\u7d50\u679c\u304c\u4f55\u3082\u8fd4\u3055\u306a\u3044","text":"<p>\u75c7\u72b6: <code>memory_search</code> \u304c\u7a7a\u306e\u7d50\u679c\u3092\u8fd4\u3059</p> <p>\u89e3\u6c7a\u7b56: 1. \u30e1\u30e2\u30ea\u30fc\u304c\u5b58\u5728\u3059\u308b\u304b\u78ba\u8a8d:    <pre><code>\"\u3059\u3079\u3066\u306e\u30e1\u30e2\u30ea\u30fc\u3092\u30ea\u30b9\u30c8\"\n</code></pre></p> <ol> <li> <p>\u7570\u306a\u308b\u691c\u7d22\u30af\u30a8\u30ea\u3092\u8a66\u3059:    <pre><code>\u2705 \"\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u306b\u95a2\u3059\u308b\u30e1\u30e2\u30ea\u30fc\u3092\u691c\u7d22\"\n\u274c \"\u6b63\u78ba\u306a\u30ad\u30fc'python_coding_style_2024'\u3067\u30e1\u30e2\u30ea\u30fc\u3092\u691c\u7d22\"\n</code></pre></p> </li> <li> <p>\u6b63\u78ba\u306a\u30ad\u30fc\u306b\u306f<code>memory_recall</code>\u3092\u4f7f\u7528:    <pre><code>\"key='python_preference'\u3067\u30e1\u30e2\u30ea\u30fc\u3092\u547c\u3073\u51fa\u3057\"\n</code></pre></p> </li> </ol>"},{"location":"chat-integration-tips/#api","title":"\u9ad8\u3044API\u30b3\u30b9\u30c8","text":"<p>\u75c7\u72b6: \u57cb\u3081\u8fbc\u307fAPI\u30b3\u30b9\u30c8\u304c\u9ad8\u3044</p> <p>\u89e3\u6c7a\u7b56: 1. \u30ed\u30fc\u30ab\u30eb\u57cb\u3081\u8fbc\u307f\u3092\u4f7f\u7528 (sentence-transformers):    <pre><code># API\u30b3\u30b9\u30c8\u306a\u3057\u3001\u30ed\u30fc\u30ab\u30eb\u3067\u5b9f\u884c\npip install kagura-ai[ai]\n</code></pre></p> <ol> <li>\u691c\u7d22\u983b\u5ea6\u3092\u6e1b\u3089\u3059:</li> <li><code>memory_search</code>\u306e\u4ee3\u308f\u308a\u306b<code>memory_recall</code> (\u6b63\u78ba\u306a\u30ad\u30fc) \u3092\u4f7f\u7528</li> <li> <p><code>memory_search_ids</code> (\u4f4e\u30c8\u30fc\u30af\u30f3\u30e2\u30fc\u30c9) \u3092\u4f7f\u7528</p> </li> <li> <p>\u30b3\u30b9\u30c8\u3092\u76e3\u8996:    <pre><code>\"\u30c6\u30ec\u30e1\u30c8\u30ea\u30fc\u30b3\u30b9\u30c8\u30b5\u30de\u30ea\u30fc\u3092\u8868\u793a\"\n</code></pre></p> </li> </ol>"},{"location":"chat-integration-tips/#remote-mcp","title":"Remote MCP\u63a5\u7d9a\u304c\u5931\u6557\u3059\u308b","text":"<p>\u75c7\u72b6: AI\u304cKagura\u306b\u63a5\u7d9a\u3067\u304d\u306a\u3044</p> <p>\u30c7\u30d0\u30c3\u30b0: 1. \u30b5\u30fc\u30d0\u30fc\u304c\u5b9f\u884c\u4e2d\u304b\u78ba\u8a8d:    <pre><code>curl http://localhost:8080/api/v1/health\n</code></pre></p> <ol> <li> <p>API key\u3092\u78ba\u8a8d (\u8a8d\u8a3c\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u5834\u5408):    <pre><code>curl -H \"Authorization: Bearer YOUR_KEY\" \\\n     http://localhost:8080/api/v1/health\n</code></pre></p> </li> <li> <p>\u30ed\u30b0\u3092\u78ba\u8a8d:    <pre><code>docker compose logs -f api\n</code></pre></p> </li> </ol> <p>\u53c2\u7167: \u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u30ac\u30a4\u30c9</p>"},{"location":"chat-integration-tips/#_14","title":"\ud83d\ude80 \u4e0a\u7d1a\u306e\u30d2\u30f3\u30c8","text":""},{"location":"chat-integration-tips/#1-graphmemory","title":"1. \u30ca\u30ec\u30c3\u30b8\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u306e\u305f\u3081\u306eGraphMemory","text":"<p>\u95a2\u9023\u30e1\u30e2\u30ea\u30fc\u3092\u30ea\u30f3\u30af: <pre><code>\"\u79c1\u306ePython\u8a2d\u5b9a\u30e1\u30e2\u30ea\u30fc\u3092FastAPI\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u30e1\u30e2\u30ea\u30fc\u3068\u30ea\u30f3\u30af\"\n\n\"'\u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u958b\u767a'\u306b\u95a2\u3059\u308b\u3059\u3079\u3066\u306e\u30e1\u30e2\u30ea\u30fc\u3092\u30ca\u30ec\u30c3\u30b8\u30b0\u30e9\u30d5\u306b\u63a5\u7d9a\"\n</code></pre></p> <p>\u95a2\u4fc2\u3092\u767a\u898b: <pre><code>\"\u79c1\u306ePython\u8a2d\u5b9a\u306b\u95a2\u9023\u3059\u308b\u30e1\u30e2\u30ea\u30fc\u306f\u4f55\u3067\u3059\u304b?\"\n\n\"2\u30db\u30c3\u30d7\u4ee5\u5185\u3067'FastAPI'\u306b\u63a5\u7d9a\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e\u6982\u5ff5\u3092\u691c\u7d22\"\n</code></pre></p>"},{"location":"chat-integration-tips/#2_4","title":"2. \u30d1\u30bf\u30fc\u30f3\u5206\u6790","text":"<p>\u30a4\u30f3\u30bf\u30e9\u30af\u30b7\u30e7\u30f3\u3092\u5206\u6790: <pre><code>\"\u904e\u53bb\u306e\u30bb\u30c3\u30b7\u30e7\u30f3\u304b\u3089\u79c1\u306e\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30d1\u30bf\u30fc\u30f3\u3092\u5206\u6790\"\n\n\"\u79c1\u306e\u6700\u3082\u4e00\u822c\u7684\u306a\u30c8\u30d4\u30c3\u30af\u306f\u4f55\u3067\u3059\u304b?\"\n\n\"\u79c1\u306e\u30a4\u30f3\u30bf\u30e9\u30af\u30b7\u30e7\u30f3\u7d71\u8a08\u3092\u8868\u793a\"\n</code></pre></p> <p>\u30a4\u30f3\u30b5\u30a4\u30c8\u3092\u53d6\u5f97: <pre><code>\"\u79c1\u304c\u6700\u3082\u3088\u304f\u4f7f\u3046\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u8a00\u8a9e\u306f\u4f55\u3067\u3059\u304b?\"\n\n\"\u79c1\u304c\u6700\u3082\u751f\u7523\u7684\u306a\u6642\u9593\u5e2f\u306f?\"\n</code></pre></p>"},{"location":"chat-integration-tips/#3","title":"3. \u30bb\u30c3\u30b7\u30e7\u30f3\u30b5\u30de\u30ea\u30fc","text":"<p>\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u8ffd\u8de1: <pre><code>\"Issue #123\u306e\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u958b\u59cb\"\n\n[... \u30b3\u30fc\u30c9\u3092\u4f5c\u696d ...]\n\n\"\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u7d42\u4e86\u3057\u3066\u30b3\u30b9\u30c8\u8ffd\u8de1\u4ed8\u304d\u306eAI\u8981\u7d04\u3092\u751f\u6210\"\n</code></pre></p> <p>PR\u8aac\u660e\u3092\u751f\u6210: <pre><code>\"\u73fe\u5728\u306e\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30bb\u30c3\u30b7\u30e7\u30f3\u304b\u3089PR\u8aac\u660e\u3092\u751f\u6210\"\n</code></pre></p>"},{"location":"chat-integration-tips/#4","title":"4. \u30d5\u30a1\u30af\u30c8\u30c1\u30a7\u30c3\u30af\u30ef\u30fc\u30af\u30d5\u30ed\u30fc","text":"<p>\u4e3b\u5f35\u3092\u691c\u8a3c: <pre><code>\"\u3053\u306e\u4e3b\u5f35\u3092\u4e8b\u5b9f\u78ba\u8a8d: Python 3.13\u306f3.12\u3088\u308a40%\u9ad8\u901f\"\n\n\"\u3053\u306eYouTube\u52d5\u753b\u306e\u7d71\u8a08\u3092\u691c\u8a3c: [URL]\"\n</code></pre></p> <p>\u30bd\u30fc\u30b9\u3092\u30af\u30ed\u30b9\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9: <pre><code>\"\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u6700\u9069\u5316\u306b\u95a2\u3059\u308b\u8ad6\u6587\u3092arXiv\u3067\u691c\u7d22\"\n\n\"\u6700\u8fd1\u306e\u30cb\u30e5\u30fc\u30b9\u8a18\u4e8b\u3068\u4e3b\u5f35\u3092\u6bd4\u8f03\"\n</code></pre></p>"},{"location":"chat-integration-tips/#_15","title":"\ud83d\udd17 \u95a2\u9023\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li>\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u30ac\u30a4\u30c9:</li> <li>MCP over HTTP/SSE (ChatGPT)</li> <li>Claude Desktop\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> <li> <p>Claude Code\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</p> </li> <li> <p>\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u56fa\u6709\u306e\u30ef\u30fc\u30af\u30d5\u30ed\u30fc:</p> </li> <li>ChatGPT\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u4f8b</li> <li> <p>Claude\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u4f8b</p> </li> <li> <p>\u6280\u8853\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9:</p> </li> <li>REST API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9</li> <li>\u30bb\u30eb\u30d5\u30db\u30b9\u30c6\u30a3\u30f3\u30b0\u30ac\u30a4\u30c9</li> <li> <p>\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u6982\u8981</p> </li> <li> <p>\u4e0a\u7d1a\u30c8\u30d4\u30c3\u30af:</p> </li> <li>\u30e1\u30e2\u30ea\u30fc\u30a8\u30af\u30b9\u30dd\u30fc\u30c8/\u30a4\u30f3\u30dd\u30fc\u30c8</li> <li>\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u30ac\u30a4\u30c9</li> </ul>"},{"location":"chat-integration-tips/#_16","title":"\ud83d\udcda \u8ffd\u52a0\u30ea\u30bd\u30fc\u30b9","text":""},{"location":"chat-integration-tips/#_17","title":"\u516c\u5f0f\u30ea\u30f3\u30af","text":"<ul> <li>GitHub\u30ea\u30dd\u30b8\u30c8\u30ea</li> <li>PyPI\u30d1\u30c3\u30b1\u30fc\u30b8</li> <li>Model Context Protocol</li> </ul>"},{"location":"chat-integration-tips/#_18","title":"\u30b3\u30df\u30e5\u30cb\u30c6\u30a3","text":"<ul> <li>GitHub Issues - \u30d0\u30b0\u30ec\u30dd\u30fc\u30c8\uff06\u6a5f\u80fd\u30ea\u30af\u30a8\u30b9\u30c8</li> <li>GitHub Discussions - Q&amp;A\uff06\u30b3\u30df\u30e5\u30cb\u30c6\u30a3</li> </ul> <p>Version: 4.0.0 Last updated: 2025-11-02</p>"},{"location":"coding-memory/","title":"Coding Memory - AI Coding Assistant Memory System","text":"<p>Status: Phase 1 Complete (v4.1.0) Target Users: AI Coding Assistants (Claude Code, Cursor, GitHub Copilot, etc.)</p>"},{"location":"coding-memory/#overview","title":"Overview","text":"<p>Coding Memory is a specialized memory system for AI coding assistants that maintains context across sessions, learns from error patterns, and tracks project evolution.</p>"},{"location":"coding-memory/#key-features","title":"Key Features","text":"<p>\u2705 Cross-Session Context - Remember coding decisions, errors, and patterns across sessions \u2705 Error Pattern Learning - Automatically suggest solutions based on past resolutions \u2705 Project Structure Understanding - Maintain comprehensive project context \u2705 Multimodal Support - Analyze error screenshots and architecture diagrams \u2705 Design Decision Tracking - Record and retrieve architectural decisions with rationale \u2705 Coding Session Management - Group related activities with AI-powered summaries \u2705 Plan Mode &amp; Approval Workflows - Cost estimation and approval before expensive operations \u2705 Multi-Provider Support - OpenAI (GPT-5), Google (Gemini 2.5), Anthropic (Claude) \u2705 Cost Tracking - Real-time cost monitoring and budget management</p>"},{"location":"coding-memory/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  CodingMemoryManager                        \u2502\n\u2502  (Extends base MemoryManager with coding features)         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Scope: user_id + project_id                                \u2502\n\u2502                                                              \u2502\n\u2502  Storage:                                                    \u2502\n\u2502  \u251c\u2500 Working Memory (active session)                        \u2502\n\u2502  \u251c\u2500 Persistent Memory (SQLite/PostgreSQL)                  \u2502\n\u2502  \u251c\u2500 RAG (ChromaDB) - Semantic search                       \u2502\n\u2502  \u2514\u2500 Graph (NetworkX) - Relationships                       \u2502\n\u2502                                                              \u2502\n\u2502  LLM Integration:                                           \u2502\n\u2502  \u251c\u2500 Session summarization (GPT-4/Claude)                   \u2502\n\u2502  \u251c\u2500 Error pattern analysis                                  \u2502\n\u2502  \u251c\u2500 Solution suggestions                                    \u2502\n\u2502  \u251c\u2500 Preference extraction                                   \u2502\n\u2502  \u2514\u2500 Context compression (RFC-024)                          \u2502\n\u2502                                                              \u2502\n\u2502  Vision Integration:                                        \u2502\n\u2502  \u251c\u2500 Error screenshot analysis                               \u2502\n\u2502  \u251c\u2500 Architecture diagram interpretation                     \u2502\n\u2502  \u2514\u2500 Code extraction from images                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"coding-memory/#mcp-tools","title":"MCP Tools","text":"<p>Kagura provides 14 MCP tools for coding assistants: - Phase 1: 8 tools (basic memory + sessions) - Phase 2: 3 tools (dependency analysis) - GitHub: 3 tools (issue/PR integration)</p>"},{"location":"coding-memory/#1-coding_track_file_change","title":"1. <code>coding_track_file_change</code>","text":"<p>Track file modifications with context.</p> <pre><code>await coding_track_file_change(\n    user_id=\"dev_john\",\n    project_id=\"api-service\",\n    file_path=\"src/auth.py\",\n    action=\"edit\",  # create, edit, delete, rename, refactor, test\n    diff=\"+ def validate_token(token: str) -&gt; bool:\\n+     ...\",\n    reason=\"Add JWT token validation for auth middleware\",\n    related_files='[\"src/middleware.py\"]',\n    line_range=\"42,57\"  # Optional\n)\n</code></pre>"},{"location":"coding-memory/#2-coding_record_error","title":"2. <code>coding_record_error</code>","text":"<p>Record errors with optional screenshots.</p> <pre><code>await coding_record_error(\n    user_id=\"dev_john\",\n    project_id=\"api-service\",\n    error_type=\"TypeError\",\n    message=\"can't compare offset-naive and offset-aware datetimes\",\n    stack_trace=\"Traceback:\\n  File 'auth.py', line 42...\",\n    file_path=\"src/auth.py\",\n    line_number=42,\n    solution=\"Use datetime.now(timezone.utc) consistently\",  # After fixing\n    screenshot=\"/path/to/error_screenshot.png\",  # Optional\n    tags='[\"datetime\", \"timezone\"]'\n)\n</code></pre>"},{"location":"coding-memory/#3-coding_record_decision","title":"3. <code>coding_record_decision</code>","text":"<p>Record design decisions with rationale.</p> <pre><code>await coding_record_decision(\n    user_id=\"dev_john\",\n    project_id=\"api-service\",\n    decision=\"Use JWT tokens for authentication\",\n    rationale=\"Stateless auth enables horizontal scaling. No session storage needed.\",\n    alternatives='[\"Session-based auth\", \"OAuth only\"]',\n    impact=\"Eliminates session store, requires key rotation strategy\",\n    tags='[\"architecture\", \"security\"]',\n    related_files='[\"src/auth.py\", \"src/middleware.py\"]',\n    confidence=0.9\n)\n</code></pre>"},{"location":"coding-memory/#4-coding_start_session","title":"4. <code>coding_start_session</code>","text":"<p>Start a tracked coding session.</p> <pre><code>session_id = await coding_start_session(\n    user_id=\"dev_john\",\n    project_id=\"api-service\",\n    description=\"Implement JWT authentication system\",\n    tags='[\"feature\", \"authentication\"]'\n)\n</code></pre>"},{"location":"coding-memory/#5-coding_end_session","title":"5. <code>coding_end_session</code>","text":"<p>End session with AI-generated summary.</p> <pre><code>result = await coding_end_session(\n    user_id=\"dev_john\",\n    project_id=\"api-service\",\n    summary=None,  # Let AI generate summary\n    success=True\n)\n\nprint(result['summary'])  # AI-generated comprehensive summary\n</code></pre>"},{"location":"coding-memory/#6-coding_search_errors","title":"6. <code>coding_search_errors</code>","text":"<p>Search past errors semantically.</p> <pre><code>similar_errors = await coding_search_errors(\n    user_id=\"dev_john\",\n    project_id=\"api-service\",\n    query=\"TypeError comparing datetime objects\",\n    k=5  # Return top 5 similar errors\n)\n</code></pre>"},{"location":"coding-memory/#7-coding_get_project_context","title":"7. <code>coding_get_project_context</code>","text":"<p>Get comprehensive project context.</p> <pre><code>context = await coding_get_project_context(\n    user_id=\"dev_john\",\n    project_id=\"api-service\",\n    focus=\"authentication\"  # Optional focus area\n)\n\nprint(context)  # Project summary, tech stack, recent changes, decisions, patterns\n</code></pre>"},{"location":"coding-memory/#8-coding_analyze_patterns","title":"8. <code>coding_analyze_patterns</code>","text":"<p>Analyze coding patterns and preferences.</p> <pre><code>patterns = await coding_analyze_patterns(\n    user_id=\"dev_john\",\n    project_id=\"api-service\"\n)\n\nprint(patterns)  # Language prefs, library choices, naming conventions, etc.\n</code></pre>"},{"location":"coding-memory/#usage-example-typical-session","title":"Usage Example: Typical Session","text":"<pre><code># 1. Start session\nsession_id = await coding_start_session(\n    user_id=\"dev_john\",\n    project_id=\"kagura-ai\",\n    description=\"Implement coding memory system\",\n    tags='[\"feature\", \"memory\"]'\n)\n\n# 2. Track file changes\nawait coding_track_file_change(\n    user_id=\"dev_john\",\n    project_id=\"kagura-ai\",\n    file_path=\"src/kagura/core/memory/coding_memory.py\",\n    action=\"create\",\n    diff=\"New file: CodingMemoryManager class\",\n    reason=\"Create coding-specialized memory manager\"\n)\n\n# 3. Record errors (if any)\nawait coding_record_error(\n    user_id=\"dev_john\",\n    project_id=\"kagura-ai\",\n    error_type=\"ImportError\",\n    message=\"No module named 'litellm'\",\n    stack_trace=\"...\",\n    file_path=\"src/kagura/llm/coding_analyzer.py\",\n    line_number=8,\n    solution=\"Added litellm to dependencies\"\n)\n\n# 4. Record design decisions\nawait coding_record_decision(\n    user_id=\"dev_john\",\n    project_id=\"kagura-ai\",\n    decision=\"Use LiteLLM for model abstraction\",\n    rationale=\"Unified interface for OpenAI, Anthropic, Google models\",\n    alternatives='[\"Direct API calls\", \"LangChain\"]',\n    impact=\"Easy model switching, better error handling\"\n)\n\n# 5. End session with AI summary\nresult = await coding_end_session(\n    user_id=\"dev_john\",\n    project_id=\"kagura-ai\",\n    success=True\n)\n\nprint(f\"Session completed in {result['duration_minutes']} minutes\")\nprint(f\"Summary:\\n{result['summary']}\")\n</code></pre>"},{"location":"coding-memory/#prompt-engineering","title":"Prompt Engineering","text":"<p>Coding Memory uses carefully crafted prompts for high-quality LLM outputs:</p>"},{"location":"coding-memory/#session-summary-prompt","title":"Session Summary Prompt","text":"<ul> <li>Few-shot examples for consistency</li> <li>Structured output (markdown with clear sections)</li> <li>Chain-of-thought reasoning for decisions</li> <li>Actionable recommendations</li> </ul>"},{"location":"coding-memory/#error-pattern-analysis-prompt","title":"Error Pattern Analysis Prompt","text":"<ul> <li>Pattern recognition focus</li> <li>Root cause analysis beyond symptoms</li> <li>Prevention strategies with code examples</li> <li>Quick fix step-by-step instructions</li> </ul>"},{"location":"coding-memory/#solution-suggestion-prompt","title":"Solution Suggestion Prompt","text":"<ul> <li>Case-based reasoning from past errors</li> <li>Confidence scoring (high/medium/low)</li> <li>Alternative approaches when applicable</li> <li>Debugging tips if solution fails</li> </ul> <p>See <code>src/kagura/llm/prompts.py</code> for complete prompt templates.</p>"},{"location":"coding-memory/#configuration","title":"Configuration","text":""},{"location":"coding-memory/#environment-variables","title":"Environment Variables","text":"<pre><code># Model Configuration\nexport CODING_MEMORY_MODEL=\"gpt-5-mini\"  # or \"gemini/gemini-2.5-flash\"\nexport CODING_MEMORY_VISION_MODEL=\"gpt-4o\"  # or \"gemini/gemini-2.0-flash-exp\"\n\n# Cost Management\nexport CODING_MEMORY_AUTO_APPROVE=\"false\"  # Require approval\nexport CODING_MEMORY_COST_THRESHOLD=\"0.10\"  # Ask approval if &gt; $0.10\n</code></pre>"},{"location":"coding-memory/#python-configuration","title":"Python Configuration","text":"<pre><code>from kagura.core.memory.coding_memory import CodingMemoryManager\n\n# Fast &amp; Affordable (Gemini) - RECOMMENDED\ncoding_mem = CodingMemoryManager(\n    user_id=\"dev_john\",\n    project_id=\"my-project\",\n    model=\"gemini/gemini-2.0-flash-exp\",  # Free during preview\n    vision_model=\"gemini/gemini-2.0-flash-exp\",  # DEFAULT: Free + excellent quality\n    auto_approve=False,  # Require approval\n    cost_threshold=0.05  # Ask if &gt; $0.05\n)\n\n# Balanced (GPT-5 + Gemini Vision)\ncoding_mem = CodingMemoryManager(\n    user_id=\"dev_john\",\n    project_id=\"my-project\",\n    model=\"gpt-5-mini\",  # Fast and affordable\n    vision_model=\"gemini/gemini-2.0-flash-exp\",  # DEFAULT: Free vision\n)\n\n# Premium (Claude + GPT-4o Vision)\ncoding_mem = CodingMemoryManager(\n    user_id=\"dev_john\",\n    project_id=\"my-project\",\n    model=\"claude-sonnet-4-5\",  # Best reasoning\n    vision_model=\"gpt-4o\",  # Best vision\n    auto_approve=True,  # Skip approvals (\u5bcc\u8c6a\u4ed5\u69d8)\n)\n</code></pre>"},{"location":"coding-memory/#kaguratoml-optional","title":"kagura.toml (Optional)","text":"<pre><code>[coding_memory]\nenabled = true\nmax_session_duration_hours = 24\nauto_summarize_on_end = true\nenable_pattern_learning = true\n\n[coding_memory.defaults]\nmodel = \"gpt-5-mini\"\nvision_model = \"gpt-4o\"\nauto_approve = false\ncost_threshold = 0.10\n\n[coding_memory.costs]\nmax_monthly_budget_usd = 500.0\nwarn_at_percentage = 80.0\n</code></pre>"},{"location":"coding-memory/#integration-with-claude-code","title":"Integration with Claude Code","text":"<ol> <li>Add to Claude Desktop config (<code>~/Library/Application Support/Claude/claude_desktop_config.json</code>):</li> </ol> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {\n        \"USER_ID\": \"dev_john\",\n        \"PROJECT_ID\": \"my-project\"\n      }\n    }\n  }\n}\n</code></pre> <ol> <li>Use tools in Claude Code:</li> </ol> <pre><code>User: I'm getting a TypeError when comparing datetimes\nClaude: Let me check if we've seen this before...\n[calls coding_search_errors]\nClaude: You've encountered this 3 times before! The solution is to use datetime.now(timezone.utc) consistently. Should I apply that fix?\n\nUser: Yes, and start tracking this session\nClaude: [calls coding_start_session]\nSession started! I'll track all changes.\n\n[After fixing...]\nUser: Fixed! End the session\nClaude: [calls coding_end_session]\nSession summary: Resolved datetime comparison TypeError (recurring pattern). Applied UTC timezone fix in src/auth.py. Recommend adding pre-commit hook to catch this pattern in future.\n</code></pre>"},{"location":"coding-memory/#plan-mode-cost-management","title":"Plan Mode &amp; Cost Management","text":""},{"location":"coding-memory/#approval-workflow","title":"Approval Workflow","text":"<p>When <code>auto_approve=False</code> (default), expensive operations require approval:</p> <pre><code># End session - shows cost estimate and asks approval\nresult = await coding_mem.end_coding_session(success=True)\n\n# Output:\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 \u26a0\ufe0f  Approval Required                    \u2502\n# \u2502                                          \u2502\n# \u2502 Generate AI-powered session summary     \u2502\n# \u2502                                          \u2502\n# \u2502 Estimated Cost: $0.25                   \u2502\n# \u2502 Input: ~3500 tokens, Model: gpt-5-mini \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n# Approve? [Y/n]:\n</code></pre>"},{"location":"coding-memory/#cost-threshold","title":"Cost Threshold","text":"<p>Only ask approval if cost exceeds threshold:</p> <pre><code>coding_mem = CodingMemoryManager(\n    user_id=\"dev_john\",\n    project_id=\"my-project\",\n    cost_threshold=0.50  # Only ask if &gt; $0.50\n)\n\n# Operations under $0.50 \u2192 auto-approved\n# Operations over $0.50 \u2192 ask for approval\n</code></pre>"},{"location":"coding-memory/#auto-approve-mode-batch-processing","title":"Auto-Approve Mode (Batch Processing)","text":"<p>For automated workflows or \"\u5bcc\u8c6a\u4ed5\u69d8\":</p> <pre><code>coding_mem = CodingMemoryManager(\n    user_id=\"dev_john\",\n    project_id=\"my-project\",\n    auto_approve=True  # Never ask, always execute\n)\n</code></pre>"},{"location":"coding-memory/#real-time-cost-tracking","title":"Real-Time Cost Tracking","text":"<pre><code># Check cumulative costs\nprint(f\"Total spent: ${coding_mem.coding_analyzer.total_cost:.2f}\")\nprint(f\"Total tokens: {coding_mem.coding_analyzer.total_tokens}\")\nprint(f\"LLM calls: {coding_mem.coding_analyzer.call_count}\")\n\n# Detailed breakdown\nfor call in coding_mem.coding_analyzer.call_costs:\n    print(f\"{call['timestamp']}: {call['model']} - ${call['cost']:.4f}\")\n</code></pre>"},{"location":"coding-memory/#cost-considerations","title":"Cost Considerations","text":""},{"location":"coding-memory/#model-comparison","title":"Model Comparison","text":"Provider Model Input ($/1M) Output ($/1M) Speed Quality OpenAI gpt-5-mini $0.15 $0.60 \u26a1\ufe0f\u26a1\ufe0f\u26a1\ufe0f \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f OpenAI gpt-5 $2.50 $10.00 \u26a1\ufe0f\u26a1\ufe0f \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f Google gemini-2.0-flash-exp Free Free \u26a1\ufe0f\u26a1\ufe0f\u26a1\ufe0f \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f Google gemini-2.5-flash $0.075 $0.30 \u26a1\ufe0f\u26a1\ufe0f\u26a1\ufe0f \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f Google gemini-2.5-pro $1.25 $5.00 \u26a1\ufe0f\u26a1\ufe0f \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f Anthropic claude-sonnet-4-5 $3.00 $15.00 \u26a1\ufe0f\u26a1\ufe0f \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f"},{"location":"coding-memory/#operation-cost-estimates","title":"Operation Cost Estimates","text":"Operation Tokens gpt-5-mini gemini-2.5-flash claude-sonnet-4-5 Session summary ~5000 $0.05 $0.02 $0.22 Error analysis ~3000 $0.03 $0.01 $0.13 Screenshot analysis ~2000 $0.02 Free $0.09 Pattern extraction ~7000 $0.08 $0.03 $0.31"},{"location":"coding-memory/#monthly-cost-estimates","title":"Monthly Cost Estimates","text":"<p>Budget-Conscious (Gemini): - 100 sessions \u00d7 $0.03 avg = ~$3-5/month</p> <p>Balanced (GPT-5-mini): - 100 sessions \u00d7 $0.05 avg = ~$5-10/month</p> <p>Premium (Claude): - 100 sessions \u00d7 $0.25 avg = ~$25-50/month</p> <p>\u5bcc\u8c6a\u4ed5\u69d8 (All Premium): - 500 sessions \u00d7 $0.30 avg = ~$150-200/month</p>"},{"location":"coding-memory/#cost-reduction-tips","title":"Cost Reduction Tips","text":"<ol> <li>Use Gemini for most operations - Free during preview, very affordable after</li> <li>Set cost thresholds - Only approve expensive operations</li> <li>Use fast models for summaries - gpt-5-mini is 94% cheaper than Claude</li> <li>Cache contexts - Reuse project context across sessions</li> <li>Batch operations - Analyze patterns weekly, not per session</li> </ol>"},{"location":"coding-memory/#multimodal-features","title":"Multimodal Features","text":""},{"location":"coding-memory/#error-screenshot-analysis","title":"Error Screenshot Analysis","text":"<pre><code>await coding_record_error(\n    user_id=\"dev_john\",\n    project_id=\"api-service\",\n    error_type=\"Unknown\",  # Vision AI will detect\n    message=\"See screenshot\",\n    stack_trace=\"\",\n    file_path=\"unknown\",\n    line_number=0,\n    screenshot=\"/path/to/screenshot.png\"  # Vision AI extracts: error type, message, location, code context\n)\n</code></pre> <p>Vision AI automatically extracts: - Error type and message - File path and line number - Stack trace key frames - Visible code context - Suggested root cause</p>"},{"location":"coding-memory/#architecture-diagram-analysis","title":"Architecture Diagram Analysis","text":"<pre><code>from kagura.llm.vision import VisionAnalyzer\n\nvision = VisionAnalyzer()\narch_info = await vision.analyze_architecture_diagram(\"docs/architecture.png\")\n\nprint(arch_info['components'])  # ['API Gateway', 'Auth Service', 'Database']\nprint(arch_info['architecture_pattern'])  # 'Microservices'\n</code></pre>"},{"location":"coding-memory/#best-practices","title":"Best Practices","text":""},{"location":"coding-memory/#1-always-provide-reason-for-changes","title":"1. Always Provide Reason for Changes","text":"<p>\u274c Bad: <pre><code>diff=\"Added function\",\nreason=\"Update\"\n</code></pre></p> <p>\u2705 Good: <pre><code>diff=\"+ def validate_token(token: str) -&gt; bool:\\n+     return jwt.decode(...)\",\nreason=\"Add JWT validation to support stateless auth. Needed for mobile app integration.\"\n</code></pre></p>"},{"location":"coding-memory/#2-record-errors-immediately","title":"2. Record Errors Immediately","text":"<p>Record errors when they occur, then update with solution after fixing:</p> <pre><code># When error occurs\nerror_id = await coding_record_error(...)\n\n# After fixing (update with solution)\nerror = await memory.recall(error_id)\nerror.solution = \"Fixed by using timezone-aware datetimes\"\nerror.resolved = True\nawait memory.store(error_id, error)\n</code></pre>"},{"location":"coding-memory/#3-use-sessions-for-coherent-work","title":"3. Use Sessions for Coherent Work","text":"<p>Group related changes into sessions:</p> <pre><code># Good: Feature implementation session\nawait coding_start_session(\n    description=\"Implement rate limiting for API endpoints\",\n    tags=[\"feature\", \"security\", \"performance\"]\n)\n# ... all changes tracked automatically ...\nawait coding_end_session()\n\n# Also good: Debugging session\nawait coding_start_session(\n    description=\"Debug memory leak in background task\",\n    tags=[\"bugfix\", \"performance\"]\n)\n</code></pre>"},{"location":"coding-memory/#4-leverage-semantic-search","title":"4. Leverage Semantic Search","text":"<p>Use natural language queries to find relevant past errors:</p> <pre><code># Instead of exact keywords, use descriptions\nawait coding_search_errors(\n    query=\"problem with async database queries not working\",\n    k=5\n)\n# Finds errors related to async/await, database operations, even if wording differs\n</code></pre>"},{"location":"coding-memory/#troubleshooting","title":"Troubleshooting","text":""},{"location":"coding-memory/#no-similar-errors-found","title":"\"No similar errors found\"","text":"<ul> <li>Need more historical data (record errors as you encounter them)</li> <li>RAG might not be enabled (check <code>enable_rag=True</code>)</li> <li>Check project_id scope (errors are project-specific)</li> </ul>"},{"location":"coding-memory/#insufficient-data-for-pattern-analysis","title":"\"Insufficient data for pattern analysis\"","text":"<ul> <li>Requires 10+ file changes for basic analysis</li> <li>30+ changes recommended for detailed insights</li> <li>Continue coding and tracking activities</li> </ul>"},{"location":"coding-memory/#session-already-active-error","title":"\"Session already active\" error","text":"<ul> <li>Only one session can be active at a time</li> <li>End current session before starting new one:</li> </ul> <pre><code>await coding_end_session(...)  # End current\nawait coding_start_session(...)  # Start new\n</code></pre>"},{"location":"coding-memory/#roadmap","title":"Roadmap","text":"<p>Phase 2: Graph Integration (Issue #464) - Automatic dependency graph from imports - Error \u2192 solution relationship tracking - Design decision \u2192 implementation links</p> <p>Phase 3: API &amp; CLI - REST API endpoints for non-MCP clients - CLI commands (<code>kagura coding start</code>, <code>kagura coding analyze-patterns</code>) - Export/import functionality</p> <p>Phase 4: Advanced Features - Cross-file refactoring recommendations - Proactive error prevention suggestions - Team-level pattern aggregation - Custom pattern definition</p>"},{"location":"coding-memory/#see-also","title":"See Also","text":"<ul> <li>CODING_MEMORY_DESIGN.md - Technical design</li> <li>RFC-024: Context Compression</li> <li>Issue #464 - Phase 1 implementation</li> <li>prompts.py - Prompt engineering</li> </ul> <p>Contributing: This is a new feature! Please report issues or suggest improvements at GitHub Issues.</p>"},{"location":"coding-memory/#9-coding_analyze_file_dependencies-phase-2","title":"9. <code>coding_analyze_file_dependencies</code> (Phase 2)","text":"<p>Analyze Python file dependencies using AST parsing.</p> <pre><code>await coding_analyze_file_dependencies(\n    user_id=\"dev_john\",\n    project_id=\"api-service\",\n    file_path=\"src/auth.py\"\n)\n\n# Output:\n# \ud83d\udcca Dependency Analysis: src/auth.py\n# \n# Imports (2 files):\n# - src/models/user.py\n# - src/utils/jwt.py\n#\n# Imported By (3 files):\n# - src/main.py\n# - src/api/auth.py\n# - src/middleware.py\n#\n# Import Depth: 3\n# \u2705 No Circular Dependencies\n</code></pre>"},{"location":"coding-memory/#10-coding_analyze_refactor_impact-phase-2","title":"10. <code>coding_analyze_refactor_impact</code> (Phase 2)","text":"<p>Analyze refactoring impact with risk assessment.</p> <pre><code>await coding_analyze_refactor_impact(\n    user_id=\"dev_john\",\n    project_id=\"api-service\",\n    file_path=\"src/models/user.py\"\n)\n\n# Output:\n# \ud83d\udd0d Refactoring Impact Analysis: src/models/user.py\n#\n# Risk Level: \ud83d\udea8 HIGH\n#\n# Affected Files (5):\n# - src/auth.py\n# - src/api/users.py\n# - src/api/posts.py\n# - src/middleware.py\n# - src/main.py\n#\n# Recommendations:\n# \u26a0\ufe0f  5 files depend on this - test thoroughly\n# Consider adding integration tests before refactoring\n</code></pre>"},{"location":"coding-memory/#11-coding_suggest_refactor_order-phase-2","title":"11. <code>coding_suggest_refactor_order</code> (Phase 2)","text":"<p>Suggest safe refactoring order using topological sort.</p> <pre><code>await coding_suggest_refactor_order(\n    user_id=\"dev_john\",\n    project_id=\"api-service\",\n    files='[\"src/main.py\", \"src/auth.py\", \"src/models/user.py\"]'\n)\n\n# Output:\n# \ud83d\udccb Suggested Refactoring Order:\n#\n# 1. src/models/user.py\n# 2. src/auth.py\n# 3. src/main.py\n#\n# \ud83d\udca1 Refactor in this order to minimize breaking changes.\n# Leaf dependencies (files with no internal imports) come first.\n</code></pre>"},{"location":"coding-memory/#phase-2-advanced-graph-features","title":"Phase 2: Advanced Graph Features","text":""},{"location":"coding-memory/#automatic-dependency-graph","title":"Automatic Dependency Graph","text":"<p>AST-Based Import Analysis: - Automatically parses Python <code>import</code> and <code>from ... import</code> statements - Builds dependency graph without manual configuration - Detects circular dependencies - Calculates import depth</p> <p>Usage: <pre><code># Analyze before refactoring\ndeps = await coding_mem.analyze_file_dependencies(\"src/auth.py\")\n\nif deps[\"circular_deps\"]:\n    print(f\"\u26a0\ufe0f  Circular dependency: {deps['circular_deps'][0]}\")\n\nprint(f\"This file is imported by {len(deps['imported_by'])} other files\")\n</code></pre></p>"},{"location":"coding-memory/#error-solution-linking","title":"Error \u2192 Solution Linking","text":"<p>Automatic Graph Links: <pre><code># Record error with solution\nerror_id = await coding_mem.record_error(\n    error_type=\"TypeError\",\n    message=\"datetime comparison failed\",\n    stack_trace=\"...\",\n    file_path=\"src/auth.py\",\n    line_number=42,\n    solution=\"Use datetime.now(timezone.utc) consistently\"\n)\n\n# Graph automatically creates:\n# - error node\n# - solution node\n# - error \u2192 solution edge (solved_by)\n\n# Later, retrieve solutions for similar errors\nsolutions = await coding_mem.get_solutions_for_error(error_id)\nfor sol in solutions:\n    print(f\"Solution: {sol['solution']} (confidence: {sol['confidence']})\")\n</code></pre></p>"},{"location":"coding-memory/#decision-implementation-linking","title":"Decision \u2192 Implementation Linking","text":"<p>Track Implementation Progress: <pre><code># Record decision\ndecision_id = await coding_mem.record_decision(\n    decision=\"Implement JWT authentication\",\n    rationale=\"Stateless auth for scaling\",\n    related_files=[\"src/auth.py\", \"src/middleware.py\", \"src/config.py\"]\n)\n\n# Implement in first file\nawait coding_mem.track_file_change(\n    file_path=\"src/auth.py\",\n    action=\"create\",\n    diff=\"...\",\n    reason=\"Implement JWT auth\",\n    implements_decision_id=decision_id  # Link to decision\n)\n\n# Check implementation status\nstatus = await coding_mem.get_decision_implementation_status(decision_id)\nprint(f\"Progress: {status['completion']:.0%}\")\n# \u2192 \"Progress: 33%\" (1 of 3 files implemented)\n\nprint(f\"Pending: {status['pending_files']}\")\n# \u2192 \"Pending: ['src/middleware.py', 'src/config.py']\"\n</code></pre></p>"},{"location":"coding-memory/#refactoring-workflow-example","title":"Refactoring Workflow Example","text":"<pre><code># 1. Analyze impact before refactoring\nimpact = await coding_mem.analyze_refactor_impact(\"src/models/user.py\")\n\nif impact[\"risk_level\"] == \"high\":\n    print(\"High risk refactoring!\")\n    print(f\"Affected files: {impact['affected_files']}\")\n\n    # Ask user confirmation\n    proceed = input(\"Continue? [y/N]: \")\n    if proceed.lower() != 'y':\n        exit()\n\n# 2. If refactoring multiple files, get safe order\nfiles_to_refactor = [\n    \"src/models/user.py\",\n    \"src/auth.py\",\n    \"src/api/users.py\"\n]\n\norder = await coding_mem.suggest_refactor_order(files_to_refactor)\nprint(f\"Refactor in this order: {order}\")\n\n# 3. Track each refactoring\nfor file in order:\n    await coding_mem.track_file_change(\n        file_path=file,\n        action=\"refactor\",\n        diff=\"...\",\n        reason=f\"Refactor {file} as part of user model update\"\n    )\n</code></pre>"},{"location":"coding-memory/#12-coding_link_github_issue-github-integration","title":"12. <code>coding_link_github_issue</code> (GitHub Integration)","text":"<p>Link current coding session to a GitHub issue.</p> <pre><code># Auto-detect from branch name (e.g., 464-feat-...)\nawait coding_link_github_issue(\n    user_id=\"dev_john\",\n    project_id=\"kagura-ai\"\n)\n\n# Or specify explicitly\nawait coding_link_github_issue(\n    user_id=\"dev_john\",\n    project_id=\"kagura-ai\",\n    issue_number=464\n)\n\n# Output:\n# \u2705 Linked session to GitHub issue #464\n# Title: feat(memory): Implement Coding-Specialized Memory System\n# URL: https://github.com/JFK/kagura-ai/issues/464\n# State: OPEN\n# Labels: enhancement, memory\n</code></pre>"},{"location":"coding-memory/#13-coding_generate_pr_description-github-integration","title":"13. <code>coding_generate_pr_description</code> (GitHub Integration)","text":"<p>Generate AI-powered PR description from session activities.</p> <pre><code>await coding_generate_pr_description(\n    user_id=\"dev_john\",\n    project_id=\"kagura-ai\"\n)\n\n# Output:\n# \ud83d\udcdd Generated PR Description:\n#\n# ## Summary\n# Implemented coding-specialized memory system with...\n#\n# ## Changes\n# - Added CodingMemoryManager for project-scoped memory\n# - Implemented 8 MCP tools for file/error/decision tracking\n# ...\n#\n# ## Testing\n# - Run pytest tests/core/memory/\n# - Verify RAG search functionality\n</code></pre>"},{"location":"coding-memory/#14-coding_get_issue_context-github-integration","title":"14. <code>coding_get_issue_context</code> (GitHub Integration)","text":"<p>Get GitHub issue details for coding context.</p> <pre><code>context = await coding_get_issue_context(464)\n\n# Output:\n# # Issue #464: feat(memory): Implement Coding-Specialized Memory System\n#\n# **URL:** https://github.com/JFK/kagura-ai/issues/464\n# **State:** OPEN\n# **Labels:** enhancement, memory\n# **Assignees:** JFK\n#\n# ## Description\n# Implement a coding-specialized memory system for AI coding assistants...\n</code></pre>"},{"location":"coding-memory/#github-integration-workflow","title":"GitHub Integration Workflow","text":""},{"location":"coding-memory/#complete-workflow-example","title":"Complete Workflow Example","text":"<pre><code># 1. Get issue context at start\nissue_context = await coding_get_issue_context(464)\nprint(issue_context)  # Understand requirements\n\n# 2. Start session\nsession_id = await coding_start_session(\n    user_id=\"dev_john\",\n    project_id=\"kagura-ai\",\n    description=\"Implement coding memory system (Issue #464)\",\n    tags='[\"feature\", \"memory\", \"issue-464\"]'\n)\n\n# 3. Auto-link to GitHub issue\nawait coding_link_github_issue(\n    user_id=\"dev_john\",\n    project_id=\"kagura-ai\"\n)\n# \u2192 Automatically detects issue #464 from branch name\n\n# 4. Do your work...\nawait coding_track_file_change(\n    file_path=\"src/kagura/core/memory/coding_memory.py\",\n    action=\"create\",\n    diff=\"...\",\n    reason=\"Implement CodingMemoryManager\"\n)\n\nawait coding_record_decision(\n    decision=\"Use project-scoped memory (user_id + project_id)\",\n    rationale=\"Isolate memories by project for better organization\",\n    tags=[\"architecture\"]\n)\n\n# 5. End session with AI summary\nresult = await coding_end_session(\n    user_id=\"dev_john\",\n    project_id=\"kagura-ai\",\n    success=True\n)\n\n# 6. Generate PR description\npr_desc = await coding_generate_pr_description(\n    user_id=\"dev_john\",\n    project_id=\"kagura-ai\"\n)\n\n# 7. Create PR with generated description\n# (manually copy pr_desc or save to file)\n# gh pr create --title \"feat(memory): Implement coding memory\" --body \"$pr_desc\"\n</code></pre>"},{"location":"coding-memory/#auto-detection-features","title":"Auto-Detection Features","text":"<p>Branch Name \u2192 Issue Number: <pre><code>Branch: \"464-featmemory-implement-coding-specialized-memory-system\"\n\u2192 Auto-detects: Issue #464\n</code></pre></p> <p>Session \u2192 GitHub Context: <pre><code>Session linked to Issue #464\n\u2192 Session summary includes:\n  - Issue title\n  - Issue labels\n  - Issue URL\n  - Automatically adds \"Closes #464\" to PR description\n</code></pre></p>"},{"location":"coding-memory/#benefits","title":"Benefits","text":"<ol> <li>Traceability: Code \u2192 Session \u2192 Issue \u2192 PR (\u5b8c\u5168\u306a\u8ffd\u8de1)</li> <li>Context Preservation: Issue\u8a73\u7d30\u304c\u30bb\u30c3\u30b7\u30e7\u30f3\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306b\u542b\u307e\u308c\u308b</li> <li>Automation: PR\u8aac\u660e\u6587\u81ea\u52d5\u751f\u6210</li> <li>Graph Relationships: Issue-Session-PR \u306e\u95a2\u4fc2\u304c\u30b0\u30e9\u30d5\u3067\u7ba1\u7406</li> <li>No Manual Work: Branch\u540d\u304b\u3089\u81ea\u52d5\u691c\u51fa\u3001\u624b\u52d5\u5165\u529b\u4e0d\u8981</li> </ol>"},{"location":"coding-memory/#requirements","title":"Requirements","text":""},{"location":"coding-memory/#for-github-integration","title":"For GitHub Integration","text":"<p>Required: - <code>gh</code> CLI installed and authenticated   <pre><code># Install gh CLI\nbrew install gh  # macOS\n# or download from: https://cli.github.com/\n\n# Authenticate\ngh auth login\n</code></pre></p> <p>Optional: - Git repository with GitHub remote - GitHub issue tracking enabled - Branch naming convention: <code>{issue_number}-{description}</code></p>"},{"location":"coding-memory/#troubleshooting_1","title":"Troubleshooting","text":"<p>\"Failed to fetch issue\": <pre><code># Check gh authentication\ngh auth status\n\n# Re-authenticate if needed\ngh auth login\n\n# Test manually\ngh issue view 464 --json title\n</code></pre></p> <p>\"Could not detect issue number\": - Branch name must start with digits: <code>464-feat-...</code> \u2705 - Invalid: <code>feat-464</code>, <code>feature-branch</code> \u274c - Rename branch: <code>git branch -m 464-feat-my-feature</code></p> <p>\"No active session\": - Start session first: <code>await coding_start_session(...)</code> - Then link to issue: <code>await coding_link_github_issue(...)</code></p>"},{"location":"getting-started/","title":"Getting Started with Kagura AI v4.0","text":"<p>Universal AI Memory Platform - 10-minute setup</p> <p>Kagura is a universal memory layer that connects all your AI platforms (Claude, ChatGPT, Gemini, etc.) with shared context and memory.</p>"},{"location":"getting-started/#what-is-kagura-v40","title":"\ud83d\udccb What is Kagura v4.0?","text":"<p>Kagura v4.0 = MCP-native Universal Memory</p> <ul> <li>For Claude Desktop: Local MCP server with all 31 tools</li> <li>For ChatGPT: HTTP/SSE connector with memory access</li> <li>For Teams: Self-hosted API with authentication</li> <li>For Developers: REST API + Python SDK</li> </ul>"},{"location":"getting-started/#quick-start-choose-your-path","title":"\ud83d\ude80 Quick Start (Choose Your Path)","text":""},{"location":"getting-started/#path-1-claude-desktop-user-recommended","title":"Path 1: Claude Desktop User (Recommended)","text":"<p>Setup time: 5 minutes</p> <pre><code># Install Kagura\npip install kagura-ai[full]\n\n# Auto-configure Claude Desktop\nkagura mcp install\n\n# Restart Claude Desktop\n# That's it! Kagura is now available in Claude\n</code></pre> <p>Try it in Claude Desktop: <pre><code>\"Remember: I prefer Python for backend development\"\n\"What do you know about my preferences?\"\n</code></pre></p> <p>See: MCP Setup Guide</p>"},{"location":"getting-started/#path-2-chatgpt-connector-user","title":"Path 2: ChatGPT Connector User","text":"<p>Setup time: 10 minutes</p> <ol> <li> <p>Start Kagura API:    <pre><code># Using Docker\ndocker compose up -d\n\n# Or local\npip install kagura-ai[api]\nuvicorn kagura.api.server:app --port 8000\n</code></pre></p> </li> <li> <p>Expose with ngrok (for testing):    <pre><code>ngrok http 8000\n# Get URL: https://abc123.ngrok.app\n</code></pre></p> </li> <li> <p>Configure ChatGPT:</p> </li> <li>Enable Developer Mode</li> <li>Add Connector:<ul> <li>URL: <code>https://abc123.ngrok.app/mcp</code></li> <li>Name: Kagura Memory</li> </ul> </li> </ol> <p>See: MCP over HTTP/SSE Guide</p>"},{"location":"getting-started/#path-3-self-hosted-production","title":"Path 3: Self-Hosted Production","text":"<p>Setup time: 30 minutes</p> <pre><code># Clone repository\ngit clone https://github.com/JFK/kagura-ai.git\ncd kagura-ai\n\n# Configure\ncp .env.example .env\nnano .env  # Set DOMAIN and POSTGRES_PASSWORD\n\n# Deploy\ndocker compose -f docker-compose.prod.yml up -d\n\n# Generate API key\ndocker compose -f docker-compose.prod.yml exec api \\\n  kagura api create-key --name \"production\"\n\n# Verify\ncurl https://your-domain.com/api/v1/health\n</code></pre> <p>See: Self-Hosting Guide</p>"},{"location":"getting-started/#key-features","title":"\ud83e\udde9 Key Features","text":""},{"location":"getting-started/#1-universal-memory","title":"1. Universal Memory","text":"<p>Store memories once, access from any AI:</p> <pre><code># Via MCP tool (Claude Desktop, ChatGPT, etc.)\nmemory_store(\n    user_id=\"jfk\",\n    agent_name=\"global\",\n    key=\"coding_style\",\n    value=\"Always use type hints in Python\",\n    scope=\"persistent\",\n    tags='[\"python\", \"best-practices\"]'\n)\n</code></pre>"},{"location":"getting-started/#2-graph-memory","title":"2. Graph Memory","text":"<p>Track relationships and patterns:</p> <pre><code># Record interaction\nmemory_record_interaction(\n    user_id=\"jfk\",\n    query=\"How do I write async functions?\",\n    response=\"...\",\n    metadata={\"topic\": \"python\", \"skill_level\": \"intermediate\"}\n)\n\n# Analyze patterns\nmemory_get_user_pattern(user_id=\"jfk\")\n</code></pre>"},{"location":"getting-started/#3-remote-access","title":"3. Remote Access","text":"<p>Access your memory from anywhere:</p> <ul> <li>ChatGPT Connector: HTTP/SSE transport</li> <li>API Keys: Secure authentication</li> <li>Tool Filtering: Automatic security (no file ops remotely)</li> </ul>"},{"location":"getting-started/#4-exportimport","title":"4. Export/Import","text":"<p>Own your data completely:</p> <pre><code># Backup\nkagura memory export --output ./backup\n\n# Restore\nkagura memory import --input ./backup\n</code></pre>"},{"location":"getting-started/#next-steps","title":"\ud83d\udcda Next Steps","text":""},{"location":"getting-started/#for-claude-desktop-users","title":"For Claude Desktop Users","text":"<ol> <li>Complete MCP Setup</li> <li>Try built-in tools: <code>kagura mcp tools</code></li> <li>Explore memory operations</li> </ol>"},{"location":"getting-started/#for-chatgpt-users","title":"For ChatGPT Users","text":"<ol> <li>Setup HTTP/SSE Connector</li> <li>Generate API key: <code>kagura api create-key</code></li> <li>Connect and test</li> </ol>"},{"location":"getting-started/#for-self-hosters","title":"For Self-Hosters","text":"<ol> <li>Follow Self-Hosting Guide</li> <li>Configure SSL/TLS with Caddy</li> <li>Set up backups</li> </ol>"},{"location":"getting-started/#for-developers","title":"For Developers","text":"<ol> <li>REST API Reference</li> <li>Architecture Overview</li> <li>Memory Export/Import</li> </ol>"},{"location":"getting-started/#available-commands","title":"\ud83d\udd0d Available Commands","text":"<pre><code># MCP Management\nkagura mcp serve           # Start MCP server (Claude Desktop)\nkagura mcp install         # Auto-configure Claude Desktop\nkagura mcp tools           # List available tools\nkagura mcp doctor          # Run diagnostics\nkagura mcp connect         # Configure remote connection\nkagura mcp test-remote     # Test remote API\n\n# API Key Management\nkagura api create-key      # Generate API key\nkagura api list-keys       # List all keys\nkagura api revoke-key      # Revoke key\n\n# Memory Management\nkagura memory export       # Export to JSONL\nkagura memory import       # Import from JSONL\n\n# System\nkagura --version           # Show version\n</code></pre>"},{"location":"getting-started/#support","title":"\ud83d\udcac Support","text":"<ul> <li>Documentation: https://kagura-ai.com/docs</li> <li>GitHub Issues: https://github.com/JFK/kagura-ai/issues</li> <li>Discussions: https://github.com/JFK/kagura-ai/discussions</li> </ul> <p>Version: 4.0.0 Protocol: MCP (Model Context Protocol) License: Apache 2.0</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.11 or higher</li> <li>pip or uv package manager</li> </ul>"},{"location":"installation/#install-from-pypi","title":"Install from PyPI","text":""},{"location":"installation/#using-pip","title":"Using pip","text":"<pre><code>pip install kagura-ai\n</code></pre>"},{"location":"installation/#using-uv-recommended","title":"Using uv (recommended)","text":"<pre><code>uv add kagura-ai\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<p>Check that Kagura AI is installed correctly:</p> <pre><code>kagura version\n</code></pre> <p>You should see output like:</p> <pre><code>Kagura AI v3.0\n</code></pre>"},{"location":"installation/#set-api-key","title":"Set API Key","text":"<p>Kagura AI uses LiteLLM, which supports multiple LLM providers. You need to set the appropriate API key for your chosen provider.</p> <p>\ud83d\udca1 Quick Start Tip</p> <p>The fastest way to get started with Gemini: 1. Visit Google AI Studio 2. Click \"Create API Key\" 3. Copy the key and set: <code>export GOOGLE_API_KEY=\"your-key\"</code></p> <p>No Google Cloud Console setup needed! OAuth2 is an advanced feature for specific use cases. See OAuth2 Authentication Guide for details.</p>"},{"location":"installation/#openai","title":"OpenAI","text":"<pre><code>export OPENAI_API_KEY=\"your-key-here\"\n</code></pre> <p>Or in Python: <pre><code>import os\nos.environ[\"OPENAI_API_KEY\"] = \"your-key-here\"\n</code></pre></p>"},{"location":"installation/#anthropic-claude","title":"Anthropic (Claude)","text":"<pre><code>export ANTHROPIC_API_KEY=\"your-key-here\"\n</code></pre>"},{"location":"installation/#google-gemini","title":"Google (Gemini)","text":"<pre><code>export GOOGLE_API_KEY=\"your-key-here\"\n</code></pre>"},{"location":"installation/#azure-openai","title":"Azure OpenAI","text":"<pre><code>export AZURE_API_KEY=\"your-key-here\"\nexport AZURE_API_BASE=\"https://your-endpoint.openai.azure.com/\"\nexport AZURE_API_VERSION=\"2023-05-15\"\n</code></pre>"},{"location":"installation/#test-your-installation","title":"Test Your Installation","text":"<p>Create a simple test file:</p> <pre><code># test_kagura.py\nfrom kagura import agent\n\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    async def main():\n        result = await hello(\"Kagura AI\")\n        print(result)\n\n    asyncio.run(main())\n</code></pre> <p>Run it:</p> <pre><code>python test_kagura.py\n</code></pre> <p>If successful, you should see a greeting message.</p>"},{"location":"installation/#development-installation","title":"Development Installation","text":"<p>For contributing to Kagura AI or running from source:</p>"},{"location":"installation/#clone-repository","title":"Clone Repository","text":"<pre><code>git clone https://github.com/JFK/kagura-ai.git\ncd kagura-ai\n</code></pre>"},{"location":"installation/#install-dependencies","title":"Install Dependencies","text":"<p>Using uv (recommended):</p> <pre><code>uv sync --dev\n</code></pre> <p>This will install: - All runtime dependencies - Development dependencies (pytest, pyright, ruff, etc.)</p>"},{"location":"installation/#run-tests","title":"Run Tests","text":"<pre><code>pytest\n</code></pre>"},{"location":"installation/#type-checking","title":"Type Checking","text":"<pre><code>pyright\n</code></pre>"},{"location":"installation/#code-formatting","title":"Code Formatting","text":"<pre><code>ruff check src/\n</code></pre>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>Kagura AI provides several optional feature presets to install only what you need.</p>"},{"location":"installation/#user-facing-presets","title":"\ud83d\udce6 User-Facing Presets","text":""},{"location":"installation/#ai-features-kagura-aiai","title":"AI Features (<code>kagura-ai[ai]</code>)","text":"<p>Core AI capabilities: Memory, Routing, Context Compression</p> <pre><code>pip install kagura-ai[ai]\n# or\nuv add \"kagura-ai[ai]\"\n</code></pre> <p>Includes: - <code>chromadb</code> - Vector storage for memory &amp; RAG - <code>semantic-router</code> - Semantic routing - <code>tiktoken</code> - Token counting for context compression</p> <p>Use cases: - Agents with long-term memory - Semantic routing between agents - Context-aware conversation management</p>"},{"location":"installation/#web-multimodal-kagura-aiweb","title":"Web &amp; Multimodal (<code>kagura-ai[web]</code>)","text":"<p>Web search, scraping, and multimodal (image/audio/video) processing</p> <pre><code>pip install kagura-ai[web]\n# or\nuv add \"kagura-ai[web]\"\n</code></pre> <p>Includes: - <code>google-generativeai</code> - Gemini API for multimodal - <code>pillow</code> - Image processing - <code>httpx</code> - HTTP client - <code>brave-search-python-client</code> - Brave Search API - <code>beautifulsoup4</code> - HTML parsing</p> <p>Use cases: - Web search agents - Image/audio/video analysis - Web scraping and data extraction</p>"},{"location":"installation/#oauth2-authentication-kagura-aiauth","title":"OAuth2 Authentication (<code>kagura-ai[auth]</code>)","text":"<p>OAuth2 authentication with Google/Gemini (advanced feature)</p> <pre><code>pip install kagura-ai[auth]\n# or\nuv add \"kagura-ai[auth]\"\n</code></pre> <p>Includes: - <code>google-auth</code> - Google authentication library - <code>google-auth-oauthlib</code> - OAuth2 flow - <code>google-auth-httplib2</code> - HTTP library - <code>cryptography</code> - Credential encryption</p> <p>Note: OAuth2 is an advanced feature. For most users, using API Keys is recommended as it's simpler. See OAuth2 Authentication Guide for when to use OAuth2.</p>"},{"location":"installation/#mcp-integration-kagura-aimcp","title":"MCP Integration (<code>kagura-ai[mcp]</code>)","text":"<p>Use Kagura agents with Claude Desktop, Claude Code, and other MCP clients</p> <pre><code>pip install kagura-ai[mcp]\n# or\nuv add \"kagura-ai[mcp]\"\n</code></pre> <p>Includes: - <code>mcp</code> - Model Context Protocol SDK - <code>jsonschema</code> - JSON Schema validation</p> <p>See MCP Integration Tutorial for setup guide.</p>"},{"location":"installation/#combined-presets-recommended","title":"\ud83c\udf81 Combined Presets (Recommended)","text":""},{"location":"installation/#full-features-kagura-aifull","title":"Full Features (<code>kagura-ai[full]</code>)","text":"<p>All user-facing features in one install</p> <pre><code>pip install kagura-ai[full]\n# or\nuv add \"kagura-ai[full]\"\n</code></pre> <p>Includes: <code>ai</code> + <code>web</code> + <code>auth</code> + <code>mcp</code></p> <p>Recommended for: Most users who want to explore all Kagura AI capabilities</p>"},{"location":"installation/#everything-kagura-aiall","title":"Everything (<code>kagura-ai[all]</code>)","text":"<p>All features including development tools</p> <pre><code>pip install kagura-ai[all]\n# or\nuv add \"kagura-ai[all]\"\n</code></pre> <p>Includes: <code>full</code> + <code>dev</code> + <code>docs</code></p> <p>Recommended for: Contributors and advanced users</p>"},{"location":"installation/#development-presets","title":"\ud83d\udee0\ufe0f Development Presets","text":""},{"location":"installation/#development-tools-kagura-aidev","title":"Development Tools (<code>kagura-ai[dev]</code>)","text":"<p>Testing and linting tools (included with <code>uv sync --dev</code>)</p> <pre><code>pip install kagura-ai[dev]\n# or\nuv add \"kagura-ai[dev]\"\n</code></pre> <p>Includes: - <code>pytest</code> - Testing framework - <code>pytest-asyncio</code> - Async test support - <code>pytest-cov</code> - Code coverage - <code>pytest-timeout</code> - Test timeout - <code>langdetect</code> - For agent testing - <code>pyright</code> - Type checker - <code>ruff</code> - Linter and formatter</p>"},{"location":"installation/#documentation-tools-kagura-aidocs","title":"Documentation Tools (<code>kagura-ai[docs]</code>)","text":"<p>Build documentation locally</p> <pre><code>pip install kagura-ai[docs]\n# or\nuv add \"kagura-ai[docs]\"\n</code></pre> <p>Includes: - <code>mkdocs</code> - Documentation generator - <code>mkdocs-material</code> - Material theme - <code>pymdown-extensions</code> - Markdown extensions</p> <p>Then run: <pre><code>mkdocs serve\n</code></pre></p> <p>Visit <code>http://localhost:8000</code> to view docs.</p>"},{"location":"installation/#installation-size-comparison","title":"\ud83d\udcca Installation Size Comparison","text":"Preset Dependencies Approximate Size Use Case <code>base</code> 8 packages ~50 MB Basic agents only <code>ai</code> +3 packages +150 MB AI features <code>web</code> +7 packages +200 MB Web &amp; Multimodal <code>auth</code> +4 packages +20 MB OAuth2 <code>mcp</code> +2 packages +10 MB MCP integration <code>full</code> +16 packages +380 MB All features <code>all</code> +23 packages +420 MB Everything"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#import-error","title":"Import Error","text":"<p>If you get import errors:</p> <pre><code>ImportError: cannot import name 'agent' from 'kagura'\n</code></pre> <p>Make sure you're using Python 3.11+:</p> <pre><code>python --version\n</code></pre>"},{"location":"installation/#api-key-not-found","title":"API Key Not Found","text":"<p>If you see authentication errors:</p> <pre><code>AuthenticationError: The api_key client option must be set\n</code></pre> <p>Set your API key as described above. The key must be set before importing kagura.</p>"},{"location":"installation/#type-errors","title":"Type Errors","text":"<p>If pyright shows errors in your IDE:</p> <ol> <li>Make sure your Python interpreter is set to 3.11+</li> <li>Ensure kagura-ai is installed in your environment</li> <li>Restart your IDE/language server</li> </ol>"},{"location":"installation/#upgrading","title":"Upgrading","text":""},{"location":"installation/#from-pypi","title":"From PyPI","text":"<pre><code>pip install --upgrade kagura-ai\n</code></pre> <p>or with uv:</p> <pre><code>uv add kagura-ai --upgrade\n</code></pre>"},{"location":"installation/#from-git","title":"From Git","text":"<pre><code>cd kagura-ai\ngit pull\nuv sync --dev\n</code></pre>"},{"location":"installation/#uninstalling","title":"Uninstalling","text":"<pre><code>pip uninstall kagura-ai\n</code></pre> <p>or with uv:</p> <pre><code>uv remove kagura-ai\n</code></pre>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start - Build your first agent</li> <li>API Reference - Detailed API documentation</li> <li>Examples - Example code</li> </ul>"},{"location":"mcp-claude-code-setup/","title":"MCP Setup Guide - Claude Code Integration","text":"<p>Connect Kagura to Claude Code in 2 minutes</p> <p>This guide shows how to integrate Kagura's universal memory with Claude Code (Anthropic's official CLI) using the Model Context Protocol (MCP).</p>"},{"location":"mcp-claude-code-setup/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<ul> <li>Kagura AI v4.0+ installed</li> <li>Claude Code CLI (Anthropic's official CLI tool)</li> </ul>"},{"location":"mcp-claude-code-setup/#quick-setup","title":"\u26a1 Quick Setup","text":""},{"location":"mcp-claude-code-setup/#step-1-install-kagura","title":"Step 1: Install Kagura","text":"<pre><code># Install with full dependencies\npip install kagura-ai[full]\n\n# Or install from source\ngit clone https://github.com/JFK/kagura-ai.git\ncd kagura-ai\nuv sync --all-extras\n</code></pre>"},{"location":"mcp-claude-code-setup/#step-2-add-mcp-server-to-claude-code","title":"Step 2: Add MCP Server to Claude Code","text":"<pre><code># Add Kagura as an MCP server\nclaude mcp add --transport stdio kagura -- kagura mcp serve\n</code></pre> <p>Output: <pre><code>Added stdio MCP server kagura with command: kagura mcp serve to local config\nFile modified: /home/user/.claude.json\n</code></pre></p>"},{"location":"mcp-claude-code-setup/#step-3-verify-connection","title":"Step 3: Verify Connection","text":"<pre><code># Check MCP server status\nclaude mcp list\n</code></pre> <p>Expected output: <pre><code>Checking MCP server health...\n\nkagura: kagura mcp serve - \u2713 Connected\n</code></pre></p> <p>That's it! Kagura is now connected to Claude Code.</p>"},{"location":"mcp-claude-code-setup/#available-tools","title":"\ud83e\udde0 Available Tools","text":"<p>Once integrated, Claude Code has access to 31 MCP tools across these categories:</p>"},{"location":"mcp-claude-code-setup/#core-memory-tools-4","title":"Core Memory Tools (4)","text":"Tool Purpose Example Usage <code>memory_store</code> Save information \"Remember that I prefer Python\" <code>memory_recall</code> Retrieve by key \"What's my Python preference?\" <code>memory_search</code> Semantic search \"Find memories about coding\" <code>memory_delete</code> Remove memory \"Forget about X\""},{"location":"mcp-claude-code-setup/#knowledge-graph-tools-3","title":"Knowledge Graph Tools (3)","text":"Tool Purpose <code>graph_add_node</code> Add concept <code>graph_link</code> Connect memories <code>graph_query</code> Multi-hop traversal"},{"location":"mcp-claude-code-setup/#search-tools-6","title":"Search Tools (6)","text":"Tool Purpose <code>search_memories</code> Hybrid search (BM25 + vector) <code>search_brave</code> Web search via Brave API <code>search_arxiv</code> Academic papers ... ..."},{"location":"mcp-claude-code-setup/#coding-tools-14","title":"Coding Tools (14)","text":"Tool Purpose <code>coding_store_file_change</code> Track file modifications <code>coding_store_error</code> Log errors <code>coding_store_design_decision</code> Document design choices <code>coding_summary</code> AI-powered session summary ... ..."},{"location":"mcp-claude-code-setup/#github-tools-6","title":"GitHub Tools (6)","text":"Tool Purpose <code>github_shell_exec</code> Safe shell execution <code>github_issue_*</code> Issue operations <code>github_pr_*</code> PR management <p>Full list: Run <code>kagura mcp tools</code> to see all 31 tools.</p>"},{"location":"mcp-claude-code-setup/#usage-examples","title":"\ud83c\udfaf Usage Examples","text":""},{"location":"mcp-claude-code-setup/#basic-memory-operations","title":"Basic Memory Operations","text":"<p>Store a memory: <pre><code>User: Remember that I prefer Python over JavaScript for backend projects\nClaude: [Uses memory_store tool]\n</code></pre></p> <p>Recall a memory: <pre><code>User: What programming languages do I prefer?\nClaude: [Uses memory_recall/search to retrieve the information]\n</code></pre></p>"},{"location":"mcp-claude-code-setup/#knowledge-graph","title":"Knowledge Graph","text":"<p>Link related memories: <pre><code>User: Connect my Python preference with FastAPI knowledge\nClaude: [Uses graph_link to create relationship]\n</code></pre></p> <p>Find related concepts: <pre><code>User: What's related to my coding preferences?\nClaude: [Uses graph_query for multi-hop traversal]\n</code></pre></p>"},{"location":"mcp-claude-code-setup/#coding-session","title":"Coding Session","text":"<p>Track file changes: <pre><code>Claude: [Automatically uses coding_store_file_change when editing files]\n</code></pre></p> <p>Summarize session: <pre><code>User: Summarize what we accomplished today\nClaude: [Uses coding_summary to analyze session history]\n</code></pre></p>"},{"location":"mcp-claude-code-setup/#advanced-configuration","title":"\ud83d\udd27 Advanced Configuration","text":""},{"location":"mcp-claude-code-setup/#remote-mode-safe-tools-only","title":"Remote Mode (Safe Tools Only)","text":"<p>If you want to connect to a remote Kagura API:</p> <pre><code># Configure remote connection\nkagura mcp connect\n\n# Add remote MCP server\nclaude mcp add --transport stdio kagura-remote -- kagura mcp serve --remote\n</code></pre>"},{"location":"mcp-claude-code-setup/#custom-server-name","title":"Custom Server Name","text":"<pre><code># Use custom name\nclaude mcp add --transport stdio my-kagura -- kagura mcp serve --name my-kagura\n</code></pre>"},{"location":"mcp-claude-code-setup/#environment-variables","title":"Environment Variables","text":"<p>Add API keys for optional features:</p> <pre><code># Add with environment variables\nclaude mcp add --transport stdio kagura \\\n  --env OPENAI_API_KEY=sk-... \\\n  --env BRAVE_API_KEY=... \\\n  -- kagura mcp serve\n</code></pre>"},{"location":"mcp-claude-code-setup/#troubleshooting","title":"\ud83d\udd0d Troubleshooting","text":""},{"location":"mcp-claude-code-setup/#kagura-command-not-found","title":"\"kagura command not found\"","text":"<p>Solution: Use full path</p> <pre><code># Find kagura path\nwhich kagura\n# Output: /home/user/.local/bin/kagura\n\n# Add with full path\nclaude mcp add --transport stdio kagura -- /home/user/.local/bin/kagura mcp serve\n</code></pre>"},{"location":"mcp-claude-code-setup/#check-configuration","title":"Check Configuration","text":"<p>View current configuration: <pre><code>claude mcp get kagura\n</code></pre></p> <p>Check logs: <pre><code># Kagura MCP server logs\nkagura mcp log\n</code></pre></p>"},{"location":"mcp-claude-code-setup/#remove-and-re-add","title":"Remove and Re-add","text":"<pre><code># Remove\nclaude mcp remove kagura\n\n# Re-add\nclaude mcp add --transport stdio kagura -- kagura mcp serve\n</code></pre>"},{"location":"mcp-claude-code-setup/#monitoring","title":"\ud83d\udcca Monitoring","text":""},{"location":"mcp-claude-code-setup/#view-tool-usage-statistics","title":"View Tool Usage Statistics","text":"<pre><code>kagura mcp stats\n</code></pre> <p>Example output: <pre><code>MCP Tool Usage Statistics\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal calls: 156\n\nTop tools:\n  memory_store: 45 calls\n  memory_search: 32 calls\n  coding_store_file_change: 28 calls\n  graph_link: 15 calls\n</code></pre></p>"},{"location":"mcp-claude-code-setup/#view-server-logs","title":"View Server Logs","text":"<pre><code># Real-time logs\nkagura mcp log --tail\n\n# Last 100 lines\nkagura mcp log --lines 100\n</code></pre>"},{"location":"mcp-claude-code-setup/#uninstall","title":"\ud83d\udeab Uninstall","text":"<p>To remove Kagura from Claude Code:</p> <pre><code>claude mcp remove kagura\n</code></pre> <p>This removes the configuration but does not delete your stored memories.</p> <p>To delete memories: <pre><code># Export first (backup)\nkagura memory export --output=./backup\n\n# Clear all memories\nrm -rf ~/.local/share/kagura/\nrm -rf ~/.cache/kagura/\n</code></pre></p>"},{"location":"mcp-claude-code-setup/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>MCP Setup (Claude Desktop) - Claude Desktop integration</li> <li>MCP over HTTP/SSE - Remote MCP setup</li> <li>Getting Started - Installation guide</li> <li>API Reference - REST API docs</li> </ul>"},{"location":"mcp-claude-code-setup/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"mcp-claude-code-setup/#claude-code-documentation","title":"Claude Code Documentation","text":"<ul> <li>Claude Code Official Docs</li> <li>MCP Protocol</li> </ul>"},{"location":"mcp-claude-code-setup/#kagura-documentation","title":"Kagura Documentation","text":"<ul> <li>GitHub Repository</li> <li>PyPI Package</li> </ul> <p>Version: 4.0.0 Last updated: 2025-11-02</p>"},{"location":"mcp-http-setup/","title":"MCP over HTTP/SSE Setup Guide","text":"<p>Kagura AI v4.0.0 - Universal AI Memory Platform</p> <p>This guide explains how to connect to Kagura Memory via HTTP/SSE transport using the MCP (Model Context Protocol).</p>"},{"location":"mcp-http-setup/#overview","title":"\ud83d\udccb Overview","text":"<p>Kagura AI provides an HTTP/SSE endpoint at <code>/mcp</code> that implements the MCP protocol, enabling:</p> <ul> <li>ChatGPT Connectors: Connect ChatGPT to Kagura memory</li> <li>Other HTTP-based MCP clients: Any MCP client that supports HTTP transport</li> <li>Remote access: Access Kagura memory from anywhere</li> </ul> <p>Supported Operations: - GET <code>/mcp</code> - SSE streaming (server \u2192 client messages) - POST <code>/mcp</code> - JSON-RPC requests (client \u2192 server messages) - DELETE <code>/mcp</code> - Session termination</p>"},{"location":"mcp-http-setup/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"mcp-http-setup/#1-start-kagura-api-server","title":"1. Start Kagura API Server","text":"<pre><code># Install Kagura with API extras\npip install kagura-ai[api]\n\n# Start the API server\nuvicorn kagura.api.server:app --host 0.0.0.0 --port 8000\n</code></pre> <p>The <code>/mcp</code> endpoint will be available at <code>http://localhost:8000/mcp</code>.</p>"},{"location":"mcp-http-setup/#2-connect-chatgpt-developer-mode","title":"2. Connect ChatGPT (Developer Mode)","text":"<p>Note: ChatGPT Connector support is currently in developer preview.</p>"},{"location":"mcp-http-setup/#step-1-enable-developer-mode","title":"Step 1: Enable Developer Mode","text":"<ol> <li>Open ChatGPT settings</li> <li>Navigate to: Settings \u2192 Connectors \u2192 Advanced \u2192 Developer Mode</li> <li>Enable Developer Mode</li> </ol>"},{"location":"mcp-http-setup/#step-2-add-kagura-connector","title":"Step 2: Add Kagura Connector","text":"<p>Add a custom connector with the following settings:</p> <pre><code>{\n  \"name\": \"Kagura Memory\",\n  \"url\": \"http://localhost:8000/mcp\",\n  \"description\": \"Universal AI Memory Platform\",\n  \"authentication\": \"none\"\n}\n</code></pre> <p>For remote access (using ngrok):</p> <pre><code># Expose local server\nngrok http 8000\n\n# Use the ngrok URL in ChatGPT\n# Example: https://abc123.ngrok.app/mcp\n</code></pre>"},{"location":"mcp-http-setup/#step-3-test-the-connection","title":"Step 3: Test the Connection","text":"<p>In ChatGPT, try:</p> <pre><code>\"Remember: I prefer Python for backend development\"\n\"What do you know about my preferences?\"\n</code></pre> <p>Kagura will store and recall your preferences across all AI platforms!</p>"},{"location":"mcp-http-setup/#advanced-configuration","title":"\ud83d\udd27 Advanced Configuration","text":""},{"location":"mcp-http-setup/#api-authentication-phase-c-task-2","title":"API Authentication (Phase C Task 2 \u2705)","text":"<p>Kagura API now supports API Key authentication for secure remote access.</p>"},{"location":"mcp-http-setup/#generate-api-key","title":"Generate API Key","text":"<pre><code># Create a new API key\nkagura api create-key --name \"chatgpt-connector\"\n\n# Output:\n# \u2713 API key created successfully!\n# \u26a0\ufe0f  Save this key securely - it won't be shown again:\n#\n#   kagura_abc123xyz789...\n</code></pre> <p>\u26a0\ufe0f Important: The API key is only shown once during creation. Save it securely!</p>"},{"location":"mcp-http-setup/#use-api-key-in-requests","title":"Use API Key in Requests","text":"<pre><code># Use in HTTP requests\ncurl -H \"Authorization: Bearer kagura_abc123xyz789...\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}' \\\n     http://localhost:8000/mcp\n</code></pre>"},{"location":"mcp-http-setup/#manage-api-keys","title":"Manage API Keys","text":"<pre><code># List all API keys\nkagura api list-keys\n\n# List keys for specific user\nkagura api list-keys --user-id user_alice\n\n# Revoke a key (keeps audit history)\nkagura api revoke-key --name \"old-key\"\n\n# Permanently delete a key\nkagura api delete-key --name \"unused-key\"\n</code></pre>"},{"location":"mcp-http-setup/#api-key-options","title":"API Key Options","text":"<pre><code># Create key with expiration (90 days)\nkagura api create-key --name \"temp-key\" --expires 90\n\n# Create key for specific user\nkagura api create-key --name \"alice-key\" --user-id user_alice\n</code></pre>"},{"location":"mcp-http-setup/#tool-access-control-phase-c-task-3","title":"Tool Access Control (Phase C Task 3 \u2705)","text":"<p>Kagura automatically filters dangerous tools when accessed remotely via HTTP/SSE.</p>"},{"location":"mcp-http-setup/#safe-vs-dangerous-tools","title":"Safe vs. Dangerous Tools","text":"<p>\u2705 Safe for Remote Access (allowed via <code>/mcp</code>): - Memory tools: <code>memory_store</code>, <code>memory_recall</code>, <code>memory_search</code>, etc. - Web/API tools: <code>web_search</code>, <code>brave_web_search</code>, <code>youtube_summarize</code>, etc. - Multimodal tools: <code>multimodal_index</code>, <code>multimodal_search</code> - Telemetry tools: <code>telemetry_stats</code>, <code>telemetry_cost</code></p> <p>\u26d4 Dangerous - Local Only (blocked via <code>/mcp</code>): - File operations: <code>file_read</code>, <code>file_write</code>, <code>dir_list</code> - Shell execution: <code>shell_exec</code> - Local app execution: <code>media_open_audio</code>, <code>media_open_image</code>, <code>media_open_video</code></p>"},{"location":"mcp-http-setup/#why-tool-filtering","title":"Why Tool Filtering?","text":"<p>Remote access to file operations or shell commands would allow: - Reading sensitive files (<code>/etc/passwd</code>, API keys, etc.) - Writing malicious files - Executing arbitrary commands on your server</p> <p>Solution: The <code>/mcp</code> endpoint automatically filters out dangerous tools.</p>"},{"location":"mcp-http-setup/#checking-tool-permissions","title":"Checking Tool Permissions","text":"<pre><code># List all available tools (via HTTP/SSE)\ncurl -X POST http://localhost:8000/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}'\n\n# file_read, shell_exec, etc. will NOT appear in the list\n</code></pre>"},{"location":"mcp-http-setup/#local-vs-remote-context","title":"Local vs. Remote Context","text":"<pre><code># Local MCP server (stdio) - ALL tools available\nkagura mcp serve  # Exposes all 31 tools\n\n# Remote HTTP/SSE server - Only safe tools\nuvicorn kagura.api.server:app  # Exposes ~24 safe tools\n</code></pre>"},{"location":"mcp-http-setup/#user-id-header","title":"User ID Header","text":"<p>Specify which user's memory to access:</p> <pre><code># Request with user ID\ncurl -H \"X-User-ID: user_alice\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}' \\\n     http://localhost:8000/mcp\n</code></pre> <p>Default: If no <code>X-User-ID</code> header is provided, <code>default_user</code> is used.</p>"},{"location":"mcp-http-setup/#cors-configuration","title":"CORS Configuration","text":"<p>For production deployments, configure CORS in <code>src/kagura/api/server.py</code>:</p> <pre><code>app.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"https://chat.openai.com\"],  # Specify origins\n    allow_credentials=True,\n    allow_methods=[\"GET\", \"POST\", \"DELETE\"],\n    allow_headers=[\"*\"],\n)\n</code></pre>"},{"location":"mcp-http-setup/#testing-the-endpoint","title":"\ud83e\uddea Testing the Endpoint","text":""},{"location":"mcp-http-setup/#1-health-check","title":"1. Health Check","text":"<pre><code>curl http://localhost:8000/\n# Expected: {\"name\":\"Kagura Memory API\",\"version\":\"4.0.0\",...}\n</code></pre>"},{"location":"mcp-http-setup/#2-mcp-protocol-test","title":"2. MCP Protocol Test","text":""},{"location":"mcp-http-setup/#initialize-session","title":"Initialize Session","text":"<pre><code>curl -X POST http://localhost:8000/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"jsonrpc\": \"2.0\",\n    \"id\": 1,\n    \"method\": \"initialize\",\n    \"params\": {\n      \"protocolVersion\": \"2024-11-05\",\n      \"capabilities\": {},\n      \"clientInfo\": {\"name\": \"test-client\", \"version\": \"1.0.0\"}\n    }\n  }'\n</code></pre>"},{"location":"mcp-http-setup/#list-available-tools","title":"List Available Tools","text":"<pre><code>curl -X POST http://localhost:8000/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"jsonrpc\": \"2.0\",\n    \"id\": 2,\n    \"method\": \"tools/list\",\n    \"params\": {}\n  }'\n</code></pre>"},{"location":"mcp-http-setup/#store-a-memory","title":"Store a Memory","text":"<pre><code>curl -X POST http://localhost:8000/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-User-ID: test_user\" \\\n  -d '{\n    \"jsonrpc\": \"2.0\",\n    \"id\": 3,\n    \"method\": \"tools/call\",\n    \"params\": {\n      \"name\": \"kagura_tool_memory_store\",\n      \"arguments\": {\n        \"user_id\": \"test_user\",\n        \"agent_name\": \"global\",\n        \"key\": \"my_preference\",\n        \"value\": \"I prefer Python for backend\",\n        \"scope\": \"persistent\",\n        \"tags\": \"[\\\"preferences\\\"]\",\n        \"importance\": 0.8\n      }\n    }\n  }'\n</code></pre>"},{"location":"mcp-http-setup/#remote-connection-management-phase-c-task-4","title":"\ud83d\udd0c Remote Connection Management (Phase C Task 4 \u2705)","text":"<p>Kagura provides CLI commands to configure and test remote MCP connections.</p>"},{"location":"mcp-http-setup/#configure-remote-connection","title":"Configure Remote Connection","text":"<pre><code># Configure connection to remote Kagura API\nkagura mcp connect \\\n  --api-base https://my-kagura.example.com \\\n  --api-key kagura_abc123xyz789...\n\n# With custom user ID\nkagura mcp connect \\\n  --api-base https://api.kagura.io \\\n  --api-key kagura_xyz... \\\n  --user-id user_alice\n</code></pre> <p>Config saved to: <code>~/.config/kagura/remote-config.json</code></p>"},{"location":"mcp-http-setup/#test-remote-connection","title":"Test Remote Connection","text":"<pre><code># Verify remote connection works\nkagura mcp test-remote\n\n# Output:\n# Testing Remote MCP Connection\n#\n# 1. Testing API health...\n#    \u2713 API server is reachable\n#\n# 2. Testing /mcp endpoint...\n#    \u2713 MCP endpoint is accessible\n#\n# 3. Testing authentication...\n#    \u2713 API key configured: ***xyz789\n#\n# \u2713 All tests passed!\n</code></pre>"},{"location":"mcp-http-setup/#usage-notes","title":"Usage Notes","text":"<ul> <li><code>kagura mcp serve --remote</code> is planned for future releases (stdio \u2192 HTTP proxy)</li> <li>For now, use direct HTTP/SSE connection from ChatGPT Connector</li> <li>The <code>connect</code> and <code>test-remote</code> commands help manage remote credentials</li> </ul>"},{"location":"mcp-http-setup/#production-deployment","title":"\ud83c\udf10 Production Deployment","text":""},{"location":"mcp-http-setup/#docker-compose","title":"Docker Compose","text":"<pre><code>version: '3.8'\n\nservices:\n  kagura-api:\n    image: kagura-ai:4.0.0\n    ports:\n      - \"8000:8000\"\n    environment:\n      - KAGURA_API_KEY=${KAGURA_API_KEY}\n    command: uvicorn kagura.api.server:app --host 0.0.0.0 --port 8000\n    restart: always\n\n  nginx:\n    image: nginx:alpine\n    ports:\n      - \"443:443\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf\n      - ./ssl:/etc/ssl\n    depends_on:\n      - kagura-api\n</code></pre>"},{"location":"mcp-http-setup/#nginx-configuration","title":"Nginx Configuration","text":"<pre><code>server {\n    listen 443 ssl;\n    server_name your-domain.com;\n\n    ssl_certificate /etc/ssl/cert.pem;\n    ssl_certificate_key /etc/ssl/key.pem;\n\n    location /mcp {\n        proxy_pass http://kagura-api:8000/mcp;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n\n        # SSE support\n        proxy_buffering off;\n        proxy_set_header X-Accel-Buffering no;\n    }\n}\n</code></pre>"},{"location":"mcp-http-setup/#troubleshooting","title":"\ud83d\udd0d Troubleshooting","text":""},{"location":"mcp-http-setup/#connection-refused","title":"Connection Refused","text":"<p>Problem: Cannot connect to <code>/mcp</code> endpoint</p> <p>Solutions: 1. Verify API server is running: <code>curl http://localhost:8000/</code> 2. Check firewall rules 3. Verify port 8000 is not in use</p>"},{"location":"mcp-http-setup/#406-not-acceptable","title":"406 Not Acceptable","text":"<p>Problem: Receiving HTTP 406 errors</p> <p>Cause: Missing <code>Accept</code> header for MCP protocol</p> <p>Solution: Include proper MCP headers in requests</p>"},{"location":"mcp-http-setup/#background-task-not-starting","title":"Background Task Not Starting","text":"<p>Problem: MCP server background task fails to start</p> <p>Cause: Event loop not available</p> <p>Solution: Ensure the first request to <code>/mcp</code> is made after the API server has fully started</p>"},{"location":"mcp-http-setup/#api-reference","title":"\ud83d\udcda API Reference","text":""},{"location":"mcp-http-setup/#available-mcp-tools","title":"Available MCP Tools","text":"<p>When connected via <code>/mcp</code>, the following tools are available:</p>"},{"location":"mcp-http-setup/#memory-tools","title":"Memory Tools","text":"<ul> <li><code>kagura_tool_memory_store</code> - Store information</li> <li><code>kagura_tool_memory_recall</code> - Semantic search</li> <li><code>kagura_tool_memory_search</code> - Full-text search</li> <li><code>kagura_tool_memory_list</code> - List all memories</li> <li><code>kagura_tool_memory_delete</code> - Delete memory</li> </ul>"},{"location":"mcp-http-setup/#graph-tools-if-enabled","title":"Graph Tools (if enabled)","text":"<ul> <li><code>kagura_tool_graph_link</code> - Link memories</li> <li><code>kagura_tool_graph_query</code> - Query knowledge graph</li> </ul> <p>For full tool documentation, call <code>tools/list</code> via the MCP protocol.</p>"},{"location":"mcp-http-setup/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>MCP Protocol Specification</li> <li>Kagura API Reference</li> <li>ChatGPT Connectors Documentation</li> <li>Self-Hosting Guide (coming soon)</li> </ul>"},{"location":"mcp-http-setup/#support","title":"\ud83d\udcac Support","text":"<ul> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> </ul> <p>Last Updated: 2025-10-27 Version: 4.0.0</p>"},{"location":"mcp-setup/","title":"MCP Setup Guide - Claude Desktop Integration","text":"<p>Connect Kagura to Claude Desktop in 2 minutes</p> <p>This guide shows how to integrate Kagura's universal memory with Claude Desktop using the Model Context Protocol (MCP).</p>"},{"location":"mcp-setup/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<ul> <li>Kagura AI v4.0+ installed</li> <li>Claude Desktop (supports MCP)</li> </ul>"},{"location":"mcp-setup/#automatic-setup-recommended","title":"\u26a1 Automatic Setup (Recommended)","text":"<p>Kagura can automatically configure Claude Desktop for you:</p> <pre><code># Install Kagura MCP server to Claude Desktop\nkagura mcp install\n</code></pre> <p>Output: <pre><code>\u2705 Successfully installed!\n\nConfiguration:\n  Server name: kagura-memory\n  Command: kagura mcp serve\n  Config file: ~/.config/claude/claude_desktop_config.json\n\nNext steps:\n  1. Restart Claude Desktop\n  2. Start a new conversation\n  3. Try: 'Remember that I prefer Python'\n</code></pre></p> <p>That's it! Kagura is now connected to Claude Desktop.</p>"},{"location":"mcp-setup/#manual-setup-alternative","title":"\ud83d\udd27 Manual Setup (Alternative)","text":"<p>If automatic setup doesn't work, you can manually edit the config file.</p>"},{"location":"mcp-setup/#step-1-locate-claude-desktop-config","title":"Step 1: Locate Claude Desktop Config","text":"<p>macOS/Linux: <pre><code>~/.config/claude/claude_desktop_config.json\n</code></pre></p> <p>Windows: <pre><code>%APPDATA%\\Claude\\claude_desktop_config.json\n</code></pre></p>"},{"location":"mcp-setup/#step-2-edit-configuration","title":"Step 2: Edit Configuration","text":"<p>Add Kagura to the <code>mcpServers</code> section:</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura-memory\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {}\n    }\n  }\n}\n</code></pre> <p>Full example: <pre><code>{\n  \"mcpServers\": {\n    \"kagura-memory\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {}\n    },\n    \"other-server\": {\n      \"command\": \"other-command\",\n      \"args\": [\"serve\"]\n    }\n  }\n}\n</code></pre></p>"},{"location":"mcp-setup/#step-3-restart-claude-desktop","title":"Step 3: Restart Claude Desktop","text":"<p>Close and reopen Claude Desktop to apply changes.</p>"},{"location":"mcp-setup/#verify-integration","title":"\u2705 Verify Integration","text":""},{"location":"mcp-setup/#method-1-ask-claude","title":"Method 1: Ask Claude","text":"<p>Start a new conversation in Claude Desktop and try:</p> <p>You: \"Remember that I prefer Python over JavaScript for backend projects\"</p> <p>Claude will use the <code>memory_store</code> tool to save this.</p> <p>You: \"What programming languages do I prefer?\"</p> <p>Claude will use <code>memory_recall</code> or <code>memory_search</code> to retrieve the information.</p>"},{"location":"mcp-setup/#method-2-check-diagnostics","title":"Method 2: Check Diagnostics","text":"<pre><code>kagura mcp doctor\n</code></pre> <p>Look for: <pre><code>Claude Desktop \u2502 \u2705 configured \u2502 Kagura MCP server configured\n</code></pre></p>"},{"location":"mcp-setup/#available-memory-tools","title":"\ud83e\udde0 Available Memory Tools","text":"<p>Once integrated, Claude has access to these memory tools:</p>"},{"location":"mcp-setup/#core-tools","title":"Core Tools","text":"Tool Purpose Example memory_store Save information \"Remember X\" memory_recall Get by key \"What did I say about Y?\" memory_search Semantic search \"Find memories about Z\" memory_list List all memories \"What do you remember about me?\" memory_feedback Mark useful/outdated Automatic memory_delete Forget information \"Forget about X\""},{"location":"mcp-setup/#memory-scopes","title":"Memory Scopes","text":"<ul> <li>working: Temporary, session-only (default)</li> <li>persistent: Saved to disk, survives restart</li> </ul>"},{"location":"mcp-setup/#example-interactions","title":"Example Interactions","text":"<p>Store persistent memory:</p> <p>\"Remember that my favorite Python library is FastAPI. This is important and should be persistent.\"</p> <p>Search memories:</p> <p>\"What do you know about my coding preferences?\"</p> <p>Feedback (automatic):</p> <p>Claude automatically marks memories as \"useful\" when they help answer your questions.</p> <p>Delete:</p> <p>\"Forget about my old JavaScript preference\"</p>"},{"location":"mcp-setup/#troubleshooting","title":"\ud83d\udd0d Troubleshooting","text":""},{"location":"mcp-setup/#claude-desktop-doesnt-see-kagura-tools","title":"Claude Desktop doesn't see Kagura tools","text":"<p>Check 1: Verify installation <pre><code>kagura mcp doctor\n</code></pre></p> <p>Check 2: Restart Claude Desktop - Quit Claude Desktop completely - Reopen it - Start a new conversation</p> <p>Check 3: Check logs <pre><code># Claude Desktop logs (macOS)\ntail -f ~/Library/Logs/Claude/mcp*.log\n</code></pre></p>"},{"location":"mcp-setup/#kagura-command-not-found","title":"\"kagura command not found\"","text":"<p>Solution: Use full path in config</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura-memory\": {\n      \"command\": \"/full/path/to/kagura\",\n      \"args\": [\"mcp\", \"serve\"]\n    }\n  }\n}\n</code></pre> <p>Find full path: <pre><code>which kagura\n# Output: /home/user/.local/bin/kagura\n</code></pre></p>"},{"location":"mcp-setup/#memory-not-persisting-across-conversations","title":"Memory not persisting across conversations","text":"<p>Cause: Using <code>scope=\"working\"</code> (default)</p> <p>Solution: Explicitly use <code>scope=\"persistent\"</code></p> <p>Or tell Claude:</p> <p>\"Remember this permanently: I prefer Python\"</p>"},{"location":"mcp-setup/#uninstall","title":"\ud83d\udeab Uninstall","text":"<p>To remove Kagura from Claude Desktop:</p> <pre><code>kagura mcp uninstall\n</code></pre> <p>This removes the configuration but does not delete your stored memories.</p>"},{"location":"mcp-setup/#related","title":"\ud83d\udd17 Related","text":"<ul> <li>Getting Started - Installation guide</li> <li>API Reference - REST API docs</li> <li>Architecture - System design</li> </ul> <p>Version: 4.0.0a Last updated: 2025-10-26</p>"},{"location":"memory-export/","title":"Memory Export/Import Guide","text":"<p>Kagura AI v4.0.0 - Universal AI Memory Platform</p> <p>This guide explains how to export and import your Kagura memory data for backup, migration, or GDPR compliance.</p>"},{"location":"memory-export/#overview","title":"\ud83d\udccb Overview","text":"<p>Kagura provides export/import functionality in JSONL (JSON Lines) format:</p> <ul> <li>Human-readable - Plain text JSON, one record per line</li> <li>Portable - Works across different machines and versions</li> <li>Comprehensive - Exports memories, graph data, and metadata</li> <li>GDPR-compliant - Complete data export for user requests</li> </ul>"},{"location":"memory-export/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"memory-export/#export-all-data","title":"Export All Data","text":"<pre><code># Export everything to ./backup directory\nkagura memory export --output ./backup\n\n# Output:\n# \u2713 Export completed successfully!\n#\n# Exported:\n#   \u2022 Memories: 150\n#   \u2022 Graph nodes: 87\n#   \u2022 Graph edges: 42\n#\n# Files created:\n#   \u2022 memories.jsonl\n#   \u2022 graph.jsonl\n#   \u2022 metadata.json\n</code></pre>"},{"location":"memory-export/#import-from-backup","title":"Import from Backup","text":"<pre><code># Import from backup directory\nkagura memory import --input ./backup\n\n# Output:\n# \u2713 Import completed successfully!\n#\n# Imported:\n#   \u2022 Memories: 150\n#   \u2022 Graph nodes: 87\n#   \u2022 Graph edges: 42\n</code></pre>"},{"location":"memory-export/#export-options","title":"\ud83d\udd27 Export Options","text":""},{"location":"memory-export/#selective-export","title":"Selective Export","text":"<pre><code># Export only persistent memory (skip working memory)\nkagura memory export --output ./backup --no-working\n\n# Export only working memory (skip persistent)\nkagura memory export --output ./backup --no-persistent\n\n# Export without graph data\nkagura memory export --output ./backup --no-graph\n</code></pre>"},{"location":"memory-export/#user-specific-export","title":"User-Specific Export","text":"<pre><code># Export for specific user\nkagura memory export --output ./alice-backup --user-id user_alice\n\n# Export for specific agent\nkagura memory export --output ./backup --agent-name my_agent\n</code></pre>"},{"location":"memory-export/#import-options","title":"\ud83d\udce5 Import Options","text":""},{"location":"memory-export/#clear-existing-data","title":"Clear Existing Data","text":"<pre><code># Clear existing data before import (\u26a0\ufe0f DESTRUCTIVE)\nkagura memory import --input ./backup --clear\n\n# WARNING: This will delete all existing memory data!\n</code></pre>"},{"location":"memory-export/#import-for-specific-user","title":"Import for Specific User","text":"<pre><code># Import into specific user's memory\nkagura memory import --input ./backup --user-id user_alice --agent-name global\n</code></pre>"},{"location":"memory-export/#export-format","title":"\ud83d\udcc1 Export Format","text":""},{"location":"memory-export/#directory-structure","title":"Directory Structure","text":"<pre><code>backup/\n\u251c\u2500\u2500 memories.jsonl       # All memory records\n\u251c\u2500\u2500 graph.jsonl          # Graph nodes and edges (if enabled)\n\u2514\u2500\u2500 metadata.json        # Export metadata\n</code></pre>"},{"location":"memory-export/#jsonl-format","title":"JSONL Format","text":""},{"location":"memory-export/#memory-records-memoriesjsonl","title":"Memory Records (<code>memories.jsonl</code>)","text":"<pre><code>{\"type\":\"memory\",\"scope\":\"working\",\"key\":\"user_preference\",\"value\":\"Python backend\",\"user_id\":\"user_jfk\",\"agent_name\":\"global\",\"exported_at\":\"2025-10-27T10:30:00Z\"}\n{\"type\":\"memory\",\"scope\":\"persistent\",\"key\":\"api_key\",\"value\":\"***\",\"user_id\":\"user_jfk\",\"agent_name\":\"global\",\"created_at\":\"2025-10-26T12:00:00Z\",\"updated_at\":\"2025-10-27T10:00:00Z\",\"metadata\":{\"tags\":[\"config\"],\"importance\":0.9},\"exported_at\":\"2025-10-27T10:30:00Z\"}\n</code></pre> <p>Fields: - <code>type</code>: Always \"memory\" - <code>scope</code>: \"working\" or \"persistent\" - <code>key</code>: Memory key - <code>value</code>: Stored value (any JSON type) - <code>user_id</code>: User identifier - <code>agent_name</code>: Agent name - <code>created_at</code>, <code>updated_at</code>: Timestamps (persistent only) - <code>metadata</code>: Optional metadata dict - <code>exported_at</code>: Export timestamp</p>"},{"location":"memory-export/#graph-records-graphjsonl","title":"Graph Records (<code>graph.jsonl</code>)","text":"<pre><code>{\"type\":\"node\",\"id\":\"mem_001\",\"node_type\":\"memory\",\"data\":{\"key\":\"user_preference\"},\"exported_at\":\"2025-10-27T10:30:00Z\"}\n{\"type\":\"edge\",\"src\":\"mem_001\",\"dst\":\"mem_002\",\"rel_type\":\"related_to\",\"weight\":0.8,\"data\":{},\"exported_at\":\"2025-10-27T10:30:00Z\"}\n</code></pre> <p>Node Fields: - <code>type</code>: \"node\" - <code>id</code>: Node identifier - <code>node_type</code>: Node type (e.g., \"memory\", \"user\", \"topic\") - <code>data</code>: Node attributes</p> <p>Edge Fields: - <code>type</code>: \"edge\" - <code>src</code>: Source node ID - <code>dst</code>: Destination node ID - <code>rel_type</code>: Relationship type - <code>weight</code>: Edge weight (0.0-1.0)</p>"},{"location":"memory-export/#metadata-metadatajson","title":"Metadata (<code>metadata.json</code>)","text":"<pre><code>{\n  \"exported_at\": \"2025-10-27T10:30:00Z\",\n  \"user_id\": \"user_jfk\",\n  \"agent_name\": \"global\",\n  \"stats\": {\n    \"memories\": 150,\n    \"graph_nodes\": 87,\n    \"graph_edges\": 42\n  },\n  \"format_version\": \"1.0\"\n}\n</code></pre>"},{"location":"memory-export/#use-cases","title":"\ud83d\udd04 Use Cases","text":""},{"location":"memory-export/#1-backup-before-major-changes","title":"1. Backup Before Major Changes","text":"<pre><code># Before upgrading Kagura\nkagura memory export --output ./backup-before-upgrade\n\n# Upgrade Kagura\npip install --upgrade kagura-ai\n\n# If something goes wrong, restore\nkagura memory import --input ./backup-before-upgrade --clear\n</code></pre>"},{"location":"memory-export/#2-migration-to-new-machine","title":"2. Migration to New Machine","text":"<pre><code># On old machine\nkagura memory export --output ./kagura-backup\n\n# Copy ./kagura-backup to new machine\n\n# On new machine\npip install kagura-ai\nkagura memory import --input ./kagura-backup\n</code></pre>"},{"location":"memory-export/#3-gdpr-data-export","title":"3. GDPR Data Export","text":"<pre><code># Export all user data for GDPR request\nkagura memory export --output ./gdpr-export --user-id user_alice\n\n# Provide ./gdpr-export to user\n</code></pre>"},{"location":"memory-export/#4-selective-backup","title":"4. Selective Backup","text":"<pre><code># Daily backup (working memory only)\nkagura memory export --output ./daily-backup-$(date +%Y%m%d) --no-persistent\n\n# Weekly full backup\nkagura memory export --output ./weekly-backup-$(date +%Y%m%d)\n</code></pre>"},{"location":"memory-export/#important-notes","title":"\u26a0\ufe0f Important Notes","text":""},{"location":"memory-export/#data-loss-prevention","title":"Data Loss Prevention","text":"<ul> <li>Always backup before using <code>--clear</code> flag</li> <li>Test import on a copy first</li> <li>Verify roundtrip with critical data</li> </ul>"},{"location":"memory-export/#large-exports","title":"Large Exports","text":"<p>For large memory databases (&gt;10,000 records): - Export may take several minutes - JSONL files can be large (100MB+) - Consider selective exports by user or scope</p>"},{"location":"memory-export/#version-compatibility","title":"Version Compatibility","text":"<ul> <li>Format version 1.0 (current)</li> <li>Future versions will maintain backward compatibility</li> <li>Metadata includes <code>format_version</code> for validation</li> </ul>"},{"location":"memory-export/#testing-exportimport","title":"\ud83e\uddea Testing Export/Import","text":""},{"location":"memory-export/#verify-export","title":"Verify Export","text":"<pre><code># Export\nkagura memory export --output ./test-export\n\n# Check files exist\nls -lh ./test-export/\n\n# Expected:\n# memories.jsonl\n# graph.jsonl\n# metadata.json\n</code></pre>"},{"location":"memory-export/#verify-roundtrip","title":"Verify Roundtrip","text":"<pre><code># Store test data\necho 'manager.working.set(\"test\", \"value\")' | python -c \"...\"\n\n# Export\nkagura memory export --output ./roundtrip-test\n\n# Clear (\u26a0\ufe0f for testing only)\nrm ~/.local/share/kagura/memory.db\n\n# Import\nkagura memory import --input ./roundtrip-test\n\n# Verify data restored\n# (check with kagura mcp tools)\n</code></pre>"},{"location":"memory-export/#api-reference","title":"\ud83d\udcda API Reference","text":""},{"location":"memory-export/#python-api","title":"Python API","text":"<pre><code>from kagura.core.memory import MemoryManager\nfrom kagura.core.memory.export import MemoryExporter, MemoryImporter\n\n# Create manager\nmanager = MemoryManager(user_id=\"user_jfk\", agent_name=\"global\")\n\n# Export\nexporter = MemoryExporter(manager)\nstats = await exporter.export_all(\n    output_dir=\"./backup\",\n    include_working=True,\n    include_persistent=True,\n    include_graph=True,\n)\nprint(f\"Exported {stats['memories']} memories\")\n\n# Import\nimporter = MemoryImporter(manager)\nstats = await importer.import_all(\n    input_dir=\"./backup\",\n    clear_existing=False,  # Merge with existing data\n)\nprint(f\"Imported {stats['memories']} memories\")\n</code></pre>"},{"location":"memory-export/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>API Reference</li> <li>Memory Management</li> <li>Graph Memory</li> </ul> <p>Last Updated: 2025-10-27 Version: 4.0.0</p>"},{"location":"memory-improvements/","title":"Memory Accuracy Improvements (v4.0.0a0)","text":"<p>This document describes the memory accuracy improvements implemented in Kagura AI v4.0.0a0, consisting of three phases.</p>"},{"location":"memory-improvements/#overview","title":"Overview","text":"<p>The memory system has been significantly enhanced with: - Phase 1: E5 multilingual embeddings, cross-encoder reranking, multi-dimensional recall scoring - Phase 2: Hybrid search (vector + lexical) with RRF fusion - Phase 3: Temporal graph for time-aware knowledge management</p> <p>Expected precision improvement: +40-60% overall</p>"},{"location":"memory-improvements/#phase-1-foundation-embeddings-reranking","title":"Phase 1: Foundation (Embeddings &amp; Reranking)","text":""},{"location":"memory-improvements/#11-e5-multilingual-embeddings","title":"1.1 E5 Multilingual Embeddings","text":"<p>Problem: Previous model (<code>all-MiniLM-L6-v2</code>) only supports English.</p> <p>Solution: Switch to <code>intfloat/multilingual-e5-large</code> - Languages: 100+ languages including Japanese, Chinese, Korean - Dimensions: 1024 (vs 384 previously) - Prefix handling: Automatic <code>query:</code>/<code>passage:</code> prefixes</p> <p>Migration Required: <pre><code>kagura memory reindex --model intfloat/multilingual-e5-large\n</code></pre></p> <p>Configuration: <pre><code>from kagura.config.memory_config import EmbeddingConfig\n\nconfig = EmbeddingConfig(\n    model=\"intfloat/multilingual-e5-large\",\n    dimension=1024,\n    use_prefix=True  # Required for E5 models\n)\n</code></pre></p>"},{"location":"memory-improvements/#12-cross-encoder-reranking","title":"1.2 Cross-Encoder Reranking","text":"<p>Two-stage retrieval for improved precision: 1. Fast bi-encoder retrieval (100 candidates) 2. Accurate cross-encoder reranking (top 20)</p> <p>Usage: <pre><code>from kagura.core.memory import MemoryManager\n\nmanager = MemoryManager(user_id=\"user_jfk\", agent_name=\"global\")\n\n# With reranking (recommended)\nresults = manager.recall_semantic_with_rerank(\n    query=\"Python\u306e\u975e\u540c\u671f\u51e6\u7406\u306b\u3064\u3044\u3066\",\n    top_k=20,\n    candidates_k=100,\n    enable_rerank=True\n)\n</code></pre></p> <p>Expected improvement: +10-15% in top-result precision</p>"},{"location":"memory-improvements/#13-multi-dimensional-recall-scoring","title":"1.3 Multi-Dimensional Recall Scoring","text":"<p>Inspired by DNC/NTM (Differentiable Neural Computer), combines: - Semantic similarity (30%) - Content-based addressing - Recency (20%) - Temporal decay - Access frequency (15%) - Usage-based weighting - Graph distance (15%) - Relational proximity - Importance (20%) - User-assigned priority</p> <p>Formula: <pre><code>score = w_semantic * sim + w_recency * exp(-days/30) +\n        w_frequency * log(count) + w_graph * 1/(1+dist) +\n        w_importance * importance\n</code></pre></p> <p>Configuration: <pre><code>from kagura.config.memory_config import RecallScorerConfig\n\nconfig = RecallScorerConfig(\n    weights={\n        \"semantic_similarity\": 0.30,\n        \"recency\": 0.20,\n        \"access_frequency\": 0.15,\n        \"graph_distance\": 0.15,\n        \"importance\": 0.20\n    },\n    recency_decay_days=30,\n    frequency_saturation=100\n)\n</code></pre></p>"},{"location":"memory-improvements/#phase-2-hybrid-search-vector-lexical","title":"Phase 2: Hybrid Search (Vector + Lexical)","text":""},{"location":"memory-improvements/#21-bm25-lexical-search","title":"2.1 BM25 Lexical Search","text":"<p>Traditional keyword-based search using BM25Okapi algorithm.</p> <p>Strengths: - Exact keyword matches - Proper nouns (SnapDish, Kagura AI) - Technical terms (asyncio, pytest) - Japanese kanji variants</p> <p>Usage: <pre><code>from kagura.core.memory.lexical_search import BM25Searcher\n\nsearcher = BM25Searcher()\nsearcher.index_documents([\n    {\"id\": \"doc1\", \"content\": \"Python is a programming language\"},\n    {\"id\": \"doc2\", \"content\": \"FastAPI is a Python framework\"},\n])\n\nresults = searcher.search(\"Python\", k=10)\n</code></pre></p>"},{"location":"memory-improvements/#22-rrf-reciprocal-rank-fusion","title":"2.2 RRF (Reciprocal Rank Fusion)","text":"<p>Combines vector + lexical results using SIGIR'09 algorithm.</p> <p>Formula: <pre><code>RRF(d) = \u03a3_s 1 / (k + rank_s(d))\n</code></pre> where k=60 is the standard constant.</p> <p>Usage: <pre><code>from kagura.core.memory.hybrid_search import rrf_fusion\n\nvector_results = [{\"id\": \"doc1\", \"rank\": 1}, ...]\nlexical_results = [{\"id\": \"doc2\", \"rank\": 1}, ...]\n\nfused = rrf_fusion(vector_results, lexical_results, k=60)\n</code></pre></p>"},{"location":"memory-improvements/#23-hybrid-recall","title":"2.3 Hybrid Recall","text":"<p>Three-stage retrieval pipeline: 1. Vector search (semantic) 2. Lexical search (keyword) 3. RRF fusion \u2192 Cross-encoder reranking</p> <p>Usage: <pre><code># Maximum precision (recommended for production)\nresults = manager.recall_hybrid(\n    query=\"Python\u306e\u975e\u540c\u671f\u51e6\u7406\",\n    top_k=20,\n    candidates_k=100,\n    enable_rerank=True\n)\n</code></pre></p> <p>Expected improvement: - Japanese queries: +10-15% - Exact keyword matches: +20-30%</p>"},{"location":"memory-improvements/#phase-3-temporal-graphmemory","title":"Phase 3: Temporal GraphMemory","text":""},{"location":"memory-improvements/#31-time-aware-knowledge-graph","title":"3.1 Time-Aware Knowledge Graph","text":"<p>Handles temporal relationships and contradictions.</p> <p>New edge attributes: - <code>valid_from</code>: Start of validity - <code>valid_until</code>: End of validity (None = still valid) - <code>source</code>: Evidence URL - <code>confidence</code>: Confidence score (0.0-1.0)</p> <p>Usage: <pre><code>from datetime import datetime\nfrom kagura.core.graph import GraphMemory\n\ngraph = GraphMemory()\n\n# Add nodes\ngraph.add_node(\"person_kiyota\", \"user\")\ngraph.add_node(\"company_snapdish\", \"topic\")\n\n# Add temporal relationship\ngraph.add_edge(\n    \"person_kiyota\",\n    \"company_snapdish\",\n    \"works_on\",\n    valid_from=datetime(2016, 1, 1),\n    valid_until=None,  # Still valid\n    source=\"https://snapdish.co/about\",\n    confidence=1.0\n)\n</code></pre></p>"},{"location":"memory-improvements/#32-contradiction-handling","title":"3.2 Contradiction Handling","text":"<p>Invalidate superseded facts: <pre><code># Old fact: \"Kiyota works at OldCorp\"\ngraph.add_edge(\"person_kiyota\", \"company_old\", \"works_on\")\n\n# New fact contradicts old - invalidate old edge\ngraph.invalidate_edge(\"person_kiyota\", \"company_old\")\n\n# Add new relationship\ngraph.add_edge(\"person_kiyota\", \"company_snapdish\", \"works_on\")\n</code></pre></p>"},{"location":"memory-improvements/#33-historical-reasoning","title":"3.3 Historical Reasoning","text":"<p>Query past state: <pre><code># What was true in 2015?\nresult = graph.query_graph_temporal(\n    seed_ids=[\"person_kiyota\"],\n    hops=2,\n    timestamp=datetime(2015, 1, 1)\n)\n\n# Current state\nresult_now = graph.query_graph_temporal([\"person_kiyota\"], hops=2)\n</code></pre></p> <p>Use cases: - Time-series fact tracking - Version history - Event timelines - Contradiction resolution</p>"},{"location":"memory-improvements/#configuration","title":"Configuration","text":""},{"location":"memory-improvements/#complete-configuration-example","title":"Complete Configuration Example","text":"<pre><code>from kagura.config.memory_config import MemorySystemConfig\nfrom kagura.core.memory import MemoryManager\n\n# Full configuration\nconfig = MemorySystemConfig(\n    embedding=EmbeddingConfig(\n        model=\"intfloat/multilingual-e5-large\",\n        dimension=1024,\n        use_prefix=True\n    ),\n    rerank=RerankConfig(\n        enabled=True,\n        model=\"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n        candidates_k=100,\n        top_k=20\n    ),\n    hybrid_search=HybridSearchConfig(\n        enabled=True,\n        rrf_k=60,\n        candidates_k=100\n    ),\n    recall_scorer=RecallScorerConfig(\n        weights={\n            \"semantic_similarity\": 0.30,\n            \"recency\": 0.20,\n            \"access_frequency\": 0.15,\n            \"graph_distance\": 0.15,\n            \"importance\": 0.20\n        }\n    )\n)\n\n# Use configured memory\nmanager = MemoryManager(\n    user_id=\"user_jfk\",\n    agent_name=\"global\",\n    memory_config=config\n)\n</code></pre>"},{"location":"memory-improvements/#performance-comparison","title":"Performance Comparison","text":"Method Precision Speed Best For <code>recall_semantic()</code> Baseline Fast General queries <code>recall_semantic_with_rerank()</code> +10-15% Medium Accuracy-critical <code>recall_hybrid()</code> +20-30% Slower Production use"},{"location":"memory-improvements/#breaking-changes","title":"Breaking Changes","text":""},{"location":"memory-improvements/#required-migration","title":"Required Migration","text":"<p>Re-index all memories: <pre><code>kagura memory reindex --model intfloat/multilingual-e5-large\n</code></pre></p> <p>Database schema changes (auto-migrated): - Added <code>access_count</code> column - Added <code>last_accessed_at</code> column</p>"},{"location":"memory-improvements/#testing","title":"Testing","text":"<p>Run memory tests: <pre><code># All memory tests\npytest tests/core/memory/ -v\n\n# Specific phases\npytest tests/core/memory/test_embeddings.py          # Phase 1\npytest tests/core/memory/test_hybrid_search.py       # Phase 2\npytest tests/core/graph/test_memory.py::TestTemporal # Phase 3\n</code></pre></p>"},{"location":"memory-improvements/#references","title":"References","text":""},{"location":"memory-improvements/#research-papers","title":"Research Papers","text":"<p>Phase 1 (Neural Memory): - Graves et al. (2016) - Differentiable Neural Computer - Graves et al. (2014) - Neural Turing Machine</p> <p>Phase 2 (Hybrid Search): - Cormack et al. (SIGIR 2009) - Reciprocal Rank Fusion - Robertson &amp; Zaragoza (2009) - BM25 scoring</p> <p>Phase 3 (Temporal Knowledge): - Microsoft GraphRAG (2024) - Zep Temporal KG (2024)</p>"},{"location":"memory-improvements/#models","title":"Models","text":"<ul> <li>E5 Embeddings: https://huggingface.co/intfloat/multilingual-e5-large</li> <li>Cross-Encoder: https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2</li> <li>BM25: https://github.com/dorianbrown/rank_bm25</li> </ul>"},{"location":"memory-improvements/#troubleshooting","title":"Troubleshooting","text":""},{"location":"memory-improvements/#issue-reindexing-takes-too-long","title":"Issue: Reindexing takes too long","text":"<p>Solution: Use smaller batch size <pre><code>kagura memory reindex --batch-size 50\n</code></pre></p>"},{"location":"memory-improvements/#issue-out-of-memory-during-reindexing","title":"Issue: Out of memory during reindexing","text":"<p>Solution: Use E5-base (smaller model) <pre><code>kagura memory reindex --model intfloat/multilingual-e5-base --dimension 768\n</code></pre></p>"},{"location":"memory-improvements/#issue-bm25-not-working","title":"Issue: BM25 not working","text":"<p>Solution: Install dependency <pre><code>pip install rank-bm25\n</code></pre></p>"},{"location":"memory-improvements/#next-steps","title":"Next Steps","text":""},{"location":"memory-improvements/#future-enhancements-post-v400a0","title":"Future Enhancements (Post-v4.0.0a0)","text":"<ul> <li>LLM Query Expansion: Automatic query variant generation</li> <li>PGroonga Integration: Better Japanese full-text search</li> <li>MVD (Multi-Vector Doc): Multimodal memory support</li> <li>Evaluation Benchmarks: MIRACL-ja, LoCoMo, RULER</li> </ul> <p>Related Issues: - #418 - Memory accuracy improvements (this document) - #417 - RAG accuracy improvements - #348 - Neural memory research</p> <p>Last Updated: 2025-10-27</p>"},{"location":"migration-v3-to-v4/","title":"Migration Guide: v3.0 \u2192 v4.0","text":"<p>This guide helps you migrate from Kagura AI v3.0 to v4.0.</p> <p>Target audience: Existing v3.0 users upgrading to v4.0</p>"},{"location":"migration-v3-to-v4/#overview","title":"\ud83c\udfaf Overview","text":"<p>v4.0 is a major release focusing on Universal AI Memory Platform: - REST API (FastAPI) - 34 MCP Tools (vs 15 in v3.0) - GraphMemory (knowledge graphs) - Remote MCP Server (HTTP/SSE) - Production-ready infrastructure</p> <p>Upgrade effort: ~30 minutes Compatibility: Most v3.0 code works with minimal changes</p>"},{"location":"migration-v3-to-v4/#breaking-changes","title":"\ud83d\udccb Breaking Changes","text":""},{"location":"migration-v3-to-v4/#1-memory-api-user_id-now-required","title":"1. Memory API: <code>user_id</code> Now Required","text":"<p>v3.0: <pre><code>from kagura import MemoryManager\n\nmemory = MemoryManager()\nawait memory.store(\"key\", \"value\")\n</code></pre></p> <p>v4.0: <pre><code>from kagura.core.memory import MemoryManager\n\nmemory = MemoryManager(user_id=\"alice\")  # \u2b05\ufe0f Required\nawait memory.store(\"key\", \"value\")\n</code></pre></p> <p>Why: Multi-user support for remote MCP server and cloud deployment.</p> <p>Migration: - Add <code>user_id</code> parameter to all <code>MemoryManager()</code> calls - Use consistent user_id across your application - For single-user: Use any identifier (e.g., <code>\"default\"</code>, <code>\"me\"</code>)</p>"},{"location":"migration-v3-to-v4/#2-embedding-model-change","title":"2. Embedding Model Change","text":"<p>v3.0: <code>all-MiniLM-L6-v2</code> (English-only, 384 dimensions) v4.0: <code>multilingual-e5-large</code> (100+ languages, 1024 dimensions)</p> <p>Impact: - \u2705 Better accuracy (+40-60% precision) - \u2705 Multilingual support (Japanese, Chinese, etc.) - \u26a0\ufe0f Requires reindexing existing memories</p> <p>Migration: <pre><code># Export old memories (v3.0)\nkagura memory export --output=./backup-v3\n\n# Upgrade to v4.0\npip install --upgrade kagura-ai[full]\n\n# Import memories (will reindex automatically)\nkagura memory import --input=./backup-v3\n</code></pre></p> <p>Note: First search after upgrade may be slower (embedding generation).</p>"},{"location":"migration-v3-to-v4/#3-mcp-tool-name-changes","title":"3. MCP Tool Name Changes","text":"v3.0 Tool v4.0 Tool Change <code>memory_save</code> <code>memory_store</code> Renamed <code>memory_fetch</code> <code>memory_recall</code> Renamed <code>memory_query</code> <code>memory_search</code> Renamed <p>Migration: Update your MCP configurations if using specific tool names.</p>"},{"location":"migration-v3-to-v4/#4-configuration-file-location-xdg-compliance","title":"4. Configuration File Location (XDG Compliance)","text":"<p>v3.0: <pre><code>~/.kagura/memory.db\n~/.kagura/config.json\n~/.kagura/chromadb/\n</code></pre></p> <p>v4.0 (Linux/macOS): <pre><code>~/.cache/kagura/           # Temporary/cache\n~/.local/share/kagura/     # Persistent data\n~/.config/kagura/          # Configuration\n</code></pre></p> <p>v4.0 (Windows): <pre><code>%LOCALAPPDATA%\\kagura\\cache\\\n%LOCALAPPDATA%\\kagura\\data\\\n%APPDATA%\\kagura\\\n</code></pre></p> <p>Migration: <pre><code># Auto-migration on first v4.0 run\nkagura config doctor\n\n# Manual migration (if needed)\nmv ~/.kagura/memory.db ~/.local/share/kagura/\nmv ~/.kagura/config.json ~/.config/kagura/\nmv ~/.kagura/chromadb ~/.cache/kagura/\n</code></pre></p> <p>Why: XDG Base Directory specification for better OS integration.</p>"},{"location":"migration-v3-to-v4/#new-features","title":"\u2728 New Features","text":""},{"location":"migration-v3-to-v4/#1-graphmemory-knowledge-graphs","title":"1. GraphMemory (Knowledge Graphs)","text":"<p>Not available in v3.0. Now you can:</p> <pre><code>from kagura.core.memory import MemoryManager\n\nmemory = MemoryManager(user_id=\"alice\", enable_graph=True)\n\n# Create relationship\nawait memory.link(\n    src=\"python_tips\",\n    dst=\"fastapi_tutorial\",\n    rel_type=\"related_to\"\n)\n\n# Multi-hop traversal\nrelated = await memory.query_graph(\n    seed_ids=[\"python_tips\"],\n    hops=2\n)\n</code></pre> <p>Use cases: - Track learning paths - Find related memories - Discover connections</p>"},{"location":"migration-v3-to-v4/#2-remote-mcp-server","title":"2. Remote MCP Server","text":"<p>New in v4.0: Connect ChatGPT, custom agents via HTTP/SSE.</p> <pre><code># Start remote MCP server\nkagura api serve --host 0.0.0.0 --port 8000\n\n# Create API key\nkagura api create-key --name \"chatgpt\"\n\n# Configure ChatGPT\nURL: https://your-domain.com/mcp\nAuth: Bearer &lt;api-key&gt;\n</code></pre> <p>See: MCP over HTTP Setup</p>"},{"location":"migration-v3-to-v4/#3-memory-exportimport","title":"3. Memory Export/Import","text":"<pre><code># Export (JSONL format)\nkagura memory export --output=./backup --user-id=alice\n\n# Import to another instance\nkagura memory import --input=./backup --user-id=bob\n</code></pre> <p>Format: Human-readable JSONL + metadata.</p>"},{"location":"migration-v3-to-v4/#4-production-docker-setup","title":"4. Production Docker Setup","text":"<p>v3.0: Development only v4.0: Production-ready with Caddy reverse proxy</p> <pre><code># Production deployment\ndocker compose -f docker-compose.prod.yml up -d\n</code></pre> <p>Includes: - PostgreSQL + pgvector - Redis caching - Caddy (HTTPS) - API key authentication</p>"},{"location":"migration-v3-to-v4/#step-by-step-migration","title":"\ud83d\udd27 Step-by-Step Migration","text":""},{"location":"migration-v3-to-v4/#step-1-backup-v30-data","title":"Step 1: Backup v3.0 Data","text":"<pre><code># Export memories (v3.0)\nkagura memory export --output=./backup-v3-$(date +%Y%m%d)\n\n# Backup config\ncp ~/.kagura/config.json ./backup-v3-config.json\n</code></pre>"},{"location":"migration-v3-to-v4/#step-2-upgrade-package","title":"Step 2: Upgrade Package","text":"<pre><code># Upgrade via pip\npip install --upgrade kagura-ai[full]\n\n# Verify version\nkagura --version  # Should show v4.0.0\n</code></pre>"},{"location":"migration-v3-to-v4/#step-3-update-code","title":"Step 3: Update Code","text":"<p>Update imports: <pre><code># v3.0\nfrom kagura import MemoryManager\n\n# v4.0\nfrom kagura.core.memory import MemoryManager  # \u2b05\ufe0f Changed\n</code></pre></p> <p>Add user_id: <pre><code># v3.0\nmemory = MemoryManager()\n\n# v4.0\nmemory = MemoryManager(user_id=\"your-user-id\")  # \u2b05\ufe0f Required\n</code></pre></p>"},{"location":"migration-v3-to-v4/#step-4-run-configuration-doctor","title":"Step 4: Run Configuration Doctor","text":"<pre><code># Auto-detect and fix issues\nkagura config doctor\n\n# Check MCP setup\nkagura mcp doctor\n</code></pre>"},{"location":"migration-v3-to-v4/#step-5-reindex-memories-if-needed","title":"Step 5: Reindex Memories (if needed)","text":"<pre><code># Import backup (auto-reindex with new embeddings)\nkagura memory import --input=./backup-v3-$(date +%Y%m%d)\n</code></pre>"},{"location":"migration-v3-to-v4/#step-6-test","title":"Step 6: Test","text":"<pre><code>from kagura.core.memory import MemoryManager\n\nasync def test_migration():\n    memory = MemoryManager(user_id=\"test\")\n\n    # Test store\n    await memory.store(\"test_key\", \"test_value\")\n\n    # Test recall\n    results = await memory.recall(\"test_value\", top_k=1)\n    assert len(results) &gt; 0\n\n    print(\"\u2705 Migration successful!\")\n\n# Run test\nimport asyncio\nasyncio.run(test_migration())\n</code></pre>"},{"location":"migration-v3-to-v4/#recommended-updates","title":"\ud83c\udd95 Recommended Updates","text":""},{"location":"migration-v3-to-v4/#1-enable-graphmemory","title":"1. Enable GraphMemory","text":"<pre><code>memory = MemoryManager(\n    user_id=\"alice\",\n    enable_graph=True  # \u2b05\ufe0f Enable knowledge graph\n)\n</code></pre>"},{"location":"migration-v3-to-v4/#2-use-new-hybrid-search","title":"2. Use New Hybrid Search","text":"<pre><code># v4.0: Hybrid search (BM25 + vector)\nresults = await memory.recall_hybrid(\n    query=\"Python tips\",\n    top_k=5,\n    semantic_weight=0.5,  # Balance semantic vs lexical\n    lexical_weight=0.5\n)\n</code></pre>"},{"location":"migration-v3-to-v4/#3-configure-remote-mcp-optional","title":"3. Configure Remote MCP (Optional)","text":"<pre><code># For multi-platform access\nkagura api create-key --name \"production\"\nkagura api serve --host 0.0.0.0\n</code></pre>"},{"location":"migration-v3-to-v4/#troubleshooting","title":"\ud83d\udc1b Troubleshooting","text":""},{"location":"migration-v3-to-v4/#issue-user_id-is-required","title":"Issue: \"user_id is required\"","text":"<p>Error: <pre><code>TypeError: __init__() missing 1 required positional argument: 'user_id'\n</code></pre></p> <p>Solution: <pre><code># Add user_id parameter\nmemory = MemoryManager(user_id=\"your-user-id\")\n</code></pre></p>"},{"location":"migration-v3-to-v4/#issue-cannot-find-memories-from-v30","title":"Issue: \"Cannot find memories from v3.0\"","text":"<p>Cause: Embedding model change requires reindexing.</p> <p>Solution: <pre><code># Export from v3.0 backup\nkagura memory import --input=./backup-v3\n</code></pre></p>"},{"location":"migration-v3-to-v4/#issue-modulenotfounderror-no-module-named-kaguracore","title":"Issue: \"ModuleNotFoundError: No module named 'kagura.core'\"","text":"<p>Cause: v3.0 imports are outdated.</p> <p>Solution: <pre><code># Update imports\nfrom kagura.core.memory import MemoryManager  # v4.0\n</code></pre></p>"},{"location":"migration-v3-to-v4/#issue-config-file-not-found","title":"Issue: \"Config file not found\"","text":"<p>Cause: XDG directory migration.</p> <p>Solution: <pre><code># Auto-migrate\nkagura config doctor\n\n# Or manually move files\nmkdir -p ~/.config/kagura ~/.local/share/kagura ~/.cache/kagura\nmv ~/.kagura/config.json ~/.config/kagura/\nmv ~/.kagura/memory.db ~/.local/share/kagura/\n</code></pre></p>"},{"location":"migration-v3-to-v4/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>v4.0 Release Notes</li> <li>v4.0 Implementation Roadmap</li> <li>MCP Setup Guide</li> <li>Self-Hosting Guide</li> <li>API Reference</li> </ul>"},{"location":"migration-v3-to-v4/#need-help","title":"\ud83d\udcac Need Help?","text":"<ul> <li>\ud83d\udcd6 Documentation: https://docs.kagura.ai</li> <li>\ud83d\udcac Discussions: https://github.com/JFK/kagura-ai/discussions</li> <li>\ud83d\udc1b Bug Reports: https://github.com/JFK/kagura-ai/issues</li> <li>\ud83d\udce7 Email: support@kagura.ai</li> </ul>"},{"location":"migration-v3-to-v4/#migration-checklist","title":"\u2705 Migration Checklist","text":"<ul> <li>[ ] Backup v3.0 data (<code>kagura memory export</code>)</li> <li>[ ] Upgrade package (<code>pip install --upgrade kagura-ai[full]</code>)</li> <li>[ ] Update imports (<code>from kagura.core.memory import MemoryManager</code>)</li> <li>[ ] Add <code>user_id</code> parameter to <code>MemoryManager()</code></li> <li>[ ] Run <code>kagura config doctor</code></li> <li>[ ] Import backup (<code>kagura memory import</code>)</li> <li>[ ] Test basic operations (store/recall)</li> <li>[ ] Update MCP configuration (if applicable)</li> <li>[ ] Review new features (GraphMemory, Remote MCP)</li> <li>[ ] Update documentation/README in your project</li> </ul> <p>Welcome to Kagura AI v4.0! \ud83c\udf89</p>"},{"location":"quickstart/","title":"Quick Start - Kagura AI","text":"<p>Get started with Kagura AI in 5 minutes.</p>"},{"location":"quickstart/#installation","title":"Installation","text":"<pre><code>pip install kagura-ai[full]\n</code></pre>"},{"location":"quickstart/#setup-api-key","title":"Setup API Key","text":"<pre><code>export OPENAI_API_KEY=sk-...\n</code></pre>"},{"location":"quickstart/#your-first-agent-30-seconds","title":"Your First Agent (30 seconds)","text":"<pre><code>from kagura import agent\n\n@agent\nasync def translator(text: str, lang: str = \"ja\") -&gt; str:\n    '''Translate to {{ lang }}: {{ text }}'''\n\n# Use it\nresult = await translator(\"Hello World\", lang=\"ja\")\nprint(result)  # \"\u3053\u3093\u306b\u3061\u306f\u4e16\u754c\"\n</code></pre>"},{"location":"quickstart/#type-safe-output","title":"Type-Safe Output","text":"<pre><code>from kagura import agent\nfrom pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    '''Extract person info from: {{ text }}'''\n\nperson = await extract_person(\"Alice is 30 and works as an engineer\")\nprint(person.name)  # \"Alice\" - fully typed!\n</code></pre>"},{"location":"quickstart/#with-built-in-tools","title":"With Built-in Tools","text":"<pre><code>@agent(tools=[\"web_search\"])\nasync def researcher(topic: str) -&gt; str:\n    '''Research {{ topic }} using web_search(query) tool.'''\n\nresult = await researcher(\"Latest Python frameworks\")\n# Uses Brave Search automatically\n</code></pre>"},{"location":"quickstart/#try-interactive-chat","title":"Try Interactive Chat","text":"<pre><code>kagura chat\n</code></pre> <p>Then try: <pre><code>[You] &gt; Read report.pdf and summarize\n[AI] &gt; (analyzes PDF, provides summary)\n\n[You] &gt; Search for similar reports\n[AI] &gt; (searches web, finds content)\n</code></pre></p> <p>All features work automatically.</p>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>SDK Guide - Learn @agent, @tool, memory</li> <li>Examples - 30+ code examples</li> <li>Chat Guide - Interactive chat features</li> </ul>"},{"location":"rest-api-usage/","title":"REST API Usage Guide","text":"<p>Kagura AI v4.0 - REST API\u6d3b\u7528\u30ac\u30a4\u30c9</p> <p>REST API\u306f\u3001MCP\u4ee5\u5916\u306e\u65b9\u6cd5\u3067Kagura\u30e1\u30e2\u30ea\u30fc\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b\u305f\u3081\u306e\u91cd\u8981\u306a\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3067\u3059\u3002</p>"},{"location":"rest-api-usage/#rest-api","title":"\ud83c\udfaf REST API\u306e\u6d3b\u7528\u30b7\u30fc\u30f3","text":""},{"location":"rest-api-usage/#1-agenttool","title":"1. \u30ab\u30b9\u30bf\u30e0Agent/Tool\u304b\u3089\u306e\u5229\u7528","text":"<p>Kagura\u306e<code>@agent</code>\u3084<code>@tool</code>\u304b\u3089\u3001REST API\u7d4c\u7531\u3067\u30e1\u30e2\u30ea\u30fc\u64cd\u4f5c\uff1a</p> <pre><code>import httpx\nfrom kagura import tool\n\n@tool\nasync def store_to_kagura(key: str, value: str) -&gt; str:\n    \"\"\"Store data to Kagura Memory via REST API\"\"\"\n    async with httpx.AsyncClient() as client:\n        response = await client.post(\n            \"http://localhost:8000/api/v1/memory\",\n            json={\n                \"key\": key,\n                \"value\": value,\n                \"scope\": \"persistent\",\n                \"tags\": [\"custom_tool\"]\n            },\n            headers={\"X-User-ID\": \"my_agent\"}\n        )\n        return f\"Stored: {response.json()}\"\n</code></pre> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - \u30ab\u30b9\u30bf\u30e0\u30c4\u30fc\u30eb\u304b\u3089\u30e1\u30e2\u30ea\u30fc\u4fdd\u5b58 - \u5916\u90e8\u30b7\u30b9\u30c6\u30e0\u3068\u306e\u7d71\u5408 - \u8907\u96d1\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc</p>"},{"location":"rest-api-usage/#2","title":"2. \u4ed6\u306e\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u8a00\u8a9e\u304b\u3089\u306e\u5229\u7528","text":"<p>Node.js: <pre><code>// Node.js \u304b\u3089Kagura\u30e1\u30e2\u30ea\u30fc\u306b\u30a2\u30af\u30bb\u30b9\nconst axios = require('axios');\n\nasync function storeMemory(key, value) {\n  const response = await axios.post('http://localhost:8000/api/v1/memory', {\n    key: key,\n    value: value,\n    scope: 'persistent'\n  }, {\n    headers: {\n      'X-User-ID': 'nodejs_client',\n      'Authorization': 'Bearer kagura_your_api_key'\n    }\n  });\n  return response.data;\n}\n</code></pre></p> <p>Go: <pre><code>// Go \u304b\u3089Kagura\u30e1\u30e2\u30ea\u30fc\u306b\u30a2\u30af\u30bb\u30b9\npackage main\n\nimport (\n    \"bytes\"\n    \"encoding/json\"\n    \"net/http\"\n)\n\nfunc storeMemory(key, value string) error {\n    payload := map[string]interface{}{\n        \"key\": key,\n        \"value\": value,\n        \"scope\": \"persistent\",\n    }\n\n    body, _ := json.Marshal(payload)\n    req, _ := http.NewRequest(\"POST\",\n        \"http://localhost:8000/api/v1/memory\",\n        bytes.NewBuffer(body))\n    req.Header.Set(\"Content-Type\", \"application/json\")\n    req.Header.Set(\"X-User-ID\", \"go_client\")\n\n    client := &amp;http.Client{}\n    resp, err := client.Do(req)\n    return err\n}\n</code></pre></p> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - \u30de\u30eb\u30c1\u8a00\u8a9e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8 - \u65e2\u5b58\u306eNode.js/Go/Rust\u30a2\u30d7\u30ea\u3068\u306e\u7d71\u5408 - \u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3</p>"},{"location":"rest-api-usage/#3-web-ui","title":"3. Web UI\u30d5\u30ed\u30f3\u30c8\u30a8\u30f3\u30c9\u304b\u3089\u306e\u5229\u7528","text":"<p>React Example: <pre><code>// React \u30d5\u30ed\u30f3\u30c8\u30a8\u30f3\u30c9\u304b\u3089Kagura API\nimport axios from 'axios';\n\nconst KaguraClient = axios.create({\n  baseURL: 'http://localhost:8000/api/v1',\n  headers: {\n    'X-User-ID': 'web_user_123',\n    'Authorization': `Bearer ${localStorage.getItem('kagura_api_key')}`\n  }\n});\n\n// Memory\u4e00\u89a7\u53d6\u5f97\nasync function fetchMemories() {\n  const response = await KaguraClient.get('/memory');\n  return response.data;\n}\n\n// Semantic\u691c\u7d22\nasync function searchMemories(query: string) {\n  const response = await KaguraClient.post('/recall', {\n    query: query,\n    k: 10\n  });\n  return response.data.results;\n}\n</code></pre></p> <p>Vue Example: <pre><code>&lt;template&gt;\n  &lt;div&gt;\n    &lt;input v-model=\"query\" @keyup.enter=\"search\" /&gt;\n    &lt;div v-for=\"result in results\" :key=\"result.key\"&gt;\n      {{ result.value }}\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/template&gt;\n\n&lt;script setup&gt;\nimport { ref } from 'vue';\nimport axios from 'axios';\n\nconst query = ref('');\nconst results = ref([]);\n\nasync function search() {\n  const response = await axios.post(\n    'http://localhost:8000/api/v1/recall',\n    { query: query.value, k: 5 }\n  );\n  results.value = response.data.results;\n}\n&lt;/script&gt;\n</code></pre></p> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - \u30e1\u30e2\u30ea\u30fc\u7ba1\u7406Web UI - \u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9 - \u691c\u7d22\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9 - \u30b0\u30e9\u30d5\u30d3\u30b8\u30e5\u30a2\u30e9\u30a4\u30bc\u30fc\u30b7\u30e7\u30f3</p>"},{"location":"rest-api-usage/#4-webhook","title":"4. Webhook/\u81ea\u52d5\u5316\u30b9\u30af\u30ea\u30d7\u30c8\u304b\u3089\u306e\u5229\u7528","text":"<p>GitHub Webhook: <pre><code># GitHub webhook\u3067commit\u3092\u30e1\u30e2\u30ea\u30fc\u306b\u4fdd\u5b58\nfrom fastapi import FastAPI, Request\nimport httpx\n\napp = FastAPI()\n\n@app.post(\"/webhook/github\")\nasync def github_webhook(request: Request):\n    payload = await request.json()\n\n    if payload.get(\"commits\"):\n        for commit in payload[\"commits\"]:\n            # Kagura API\u306b\u4fdd\u5b58\n            async with httpx.AsyncClient() as client:\n                await client.post(\n                    \"http://localhost:8000/api/v1/memory\",\n                    json={\n                        \"key\": f\"commit_{commit['id']}\",\n                        \"value\": commit['message'],\n                        \"scope\": \"persistent\",\n                        \"tags\": [\"github\", \"commit\"]\n                    },\n                    headers={\"X-User-ID\": \"github_bot\"}\n                )\n\n    return {\"status\": \"ok\"}\n</code></pre></p> <p>\u5b9a\u671f\u30d0\u30c3\u30c1\u51e6\u7406: <pre><code># cron\u3067\u5b9a\u671f\u5b9f\u884c\u3057\u3066\u30e1\u30e2\u30ea\u30fc\u7d71\u8a08\u3092\u4fdd\u5b58\nimport httpx\nfrom datetime import datetime\n\nasync def daily_memory_snapshot():\n    async with httpx.AsyncClient() as client:\n        # \u30e1\u30c8\u30ea\u30af\u30b9\u53d6\u5f97\n        metrics = await client.get(\"http://localhost:8000/api/v1/metrics\")\n\n        # \u30b9\u30ca\u30c3\u30d7\u30b7\u30e7\u30c3\u30c8\u4fdd\u5b58\n        await client.post(\n            \"http://localhost:8000/api/v1/memory\",\n            json={\n                \"key\": f\"snapshot_{datetime.now().isoformat()}\",\n                \"value\": metrics.json(),\n                \"scope\": \"persistent\",\n                \"tags\": [\"metrics\", \"snapshot\"]\n            }\n        )\n</code></pre></p> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - CI/CD\u7d71\u5408\uff08\u30c6\u30b9\u30c8\u7d50\u679c\u4fdd\u5b58\u7b49\uff09 - \u76e3\u8996\u30b7\u30b9\u30c6\u30e0\u7d71\u5408 - \u30c7\u30fc\u30bf\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3 - \u30b9\u30b1\u30b8\u30e5\u30fc\u30e9\u30fc\u9023\u643a</p>"},{"location":"rest-api-usage/#5","title":"5. \u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\u9593\u901a\u4fe1","text":"<p>\u30b5\u30fc\u30d3\u30b9A \u2192 Kagura \u2192 \u30b5\u30fc\u30d3\u30b9B:</p> <pre><code># Service A: \u30c7\u30fc\u30bf\u3092Kagura\u306b\u4fdd\u5b58\nasync def process_and_store(data):\n    async with httpx.AsyncClient() as client:\n        await client.post(\n            \"http://kagura-api:8000/api/v1/memory\",\n            json={\n                \"key\": f\"user_{user_id}_preference\",\n                \"value\": data,\n                \"scope\": \"persistent\"\n            }\n        )\n\n# Service B: Kagura\u304b\u3089\u30c7\u30fc\u30bf\u53d6\u5f97\nasync def fetch_user_preference(user_id):\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\n            f\"http://kagura-api:8000/api/v1/memory/user_{user_id}_preference\"\n        )\n        return response.json()\n</code></pre> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - \u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\u9593\u306e\u72b6\u614b\u5171\u6709 - \u30bb\u30c3\u30b7\u30e7\u30f3\u7ba1\u7406 - \u30e6\u30fc\u30b6\u30fc\u30d7\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9\u5171\u6709</p>"},{"location":"rest-api-usage/#rest-api-vs-mcp","title":"\ud83d\udcca REST API vs MCP \u306e\u4f7f\u3044\u5206\u3051","text":"\u30b7\u30fc\u30f3 \u63a8\u5968 \u7406\u7531 Claude Desktop MCP (stdio) \u30cd\u30a4\u30c6\u30a3\u30d6\u7d71\u5408\u3001\u5168\u30c4\u30fc\u30eb\u5229\u7528\u53ef ChatGPT Connector MCP (HTTP/SSE) \u6a19\u6e96\u30d7\u30ed\u30c8\u30b3\u30eb\u3001\u7c21\u5358\u8a2d\u5b9a Python Agent REST API httpx\u7c21\u5358\u3001\u975e\u540c\u671f\u5bfe\u5fdc Web UI REST API \u30d5\u30ed\u30f3\u30c8\u30a8\u30f3\u30c9\u304b\u3089\u76f4\u63a5\u30a2\u30af\u30bb\u30b9 \u4ed6\u8a00\u8a9e REST API \u8a00\u8a9e\u975e\u4f9d\u5b58\u3001HTTP\u6a19\u6e96 Webhook REST API HTTP POST\u7c21\u5358 \u30d0\u30c3\u30c1\u51e6\u7406 REST API curl/httpx\u3067\u7c21\u5358"},{"location":"rest-api-usage/#python-sdkrest-api","title":"\ud83d\udee0\ufe0f Python SDK\u4f8b\uff08REST API\u6d3b\u7528\uff09","text":"<pre><code># Kagura REST API Client wrapper\nimport httpx\nfrom typing import Optional, List, Dict, Any\n\nclass KaguraClient:\n    \"\"\"Kagura Memory API Client\"\"\"\n\n    def __init__(\n        self,\n        base_url: str = \"http://localhost:8000\",\n        api_key: Optional[str] = None,\n        user_id: str = \"default_user\"\n    ):\n        self.base_url = base_url\n        self.headers = {\"X-User-ID\": user_id}\n        if api_key:\n            self.headers[\"Authorization\"] = f\"Bearer {api_key}\"\n\n    async def store(\n        self,\n        key: str,\n        value: str,\n        scope: str = \"persistent\",\n        tags: Optional[List[str]] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Store memory\"\"\"\n        async with httpx.AsyncClient() as client:\n            response = await client.post(\n                f\"{self.base_url}/api/v1/memory\",\n                json={\n                    \"key\": key,\n                    \"value\": value,\n                    \"scope\": scope,\n                    \"tags\": tags or []\n                },\n                headers=self.headers\n            )\n            response.raise_for_status()\n            return response.json()\n\n    async def recall(\n        self,\n        query: str,\n        k: int = 5\n    ) -&gt; List[Dict[str, Any]]:\n        \"\"\"Semantic search\"\"\"\n        async with httpx.AsyncClient() as client:\n            response = await client.post(\n                f\"{self.base_url}/api/v1/recall\",\n                json={\"query\": query, \"k\": k},\n                headers=self.headers\n            )\n            response.raise_for_status()\n            return response.json().get(\"results\", [])\n\n    async def get(self, key: str) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Get memory by key\"\"\"\n        async with httpx.AsyncClient() as client:\n            response = await client.get(\n                f\"{self.base_url}/api/v1/memory/{key}\",\n                headers=self.headers\n            )\n            if response.status_code == 404:\n                return None\n            response.raise_for_status()\n            return response.json()\n\n# Usage\nclient = KaguraClient(user_id=\"my_app\")\nawait client.store(\"pref\", \"Python\")\nresults = await client.recall(\"what's my preference?\")\n</code></pre> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - FastAPI/Flask \u30a2\u30d7\u30ea\u304b\u3089\u306e\u5229\u7528 - \u30c7\u30fc\u30bf\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3 - \u30ab\u30b9\u30bf\u30e0Agent</p>"},{"location":"rest-api-usage/#rest-api_1","title":"\ud83c\udf10 REST API \u306e\u5f37\u307f","text":""},{"location":"rest-api-usage/#vs-mcp","title":"vs MCP","text":"<p>REST API\u306e\u5229\u70b9: - \u2705 \u8a00\u8a9e\u975e\u4f9d\u5b58 - \u3069\u3093\u306a\u8a00\u8a9e\u304b\u3089\u3067\u3082\u30a2\u30af\u30bb\u30b9\u53ef - \u2705 \u6a19\u6e96\u7684 - HTTP/JSON\u3001\u5168\u958b\u767a\u8005\u304c\u7406\u89e3 - \u2705 \u30b7\u30f3\u30d7\u30eb - curl 1\u884c\u3067\u52d5\u4f5c\u78ba\u8a8d - \u2705 OpenAPI - \u81ea\u52d5\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u751f\u6210 - \u2705 Web\u7d71\u5408 - \u30d5\u30ed\u30f3\u30c8\u30a8\u30f3\u30c9\u304b\u3089\u76f4\u63a5\u30a2\u30af\u30bb\u30b9</p> <p>MCP\u306e\u5229\u70b9: - \u2705 \u6a19\u6e96\u5316 - AI\u30c4\u30fc\u30eb\u9023\u643a\u306e\u6a19\u6e96\u30d7\u30ed\u30c8\u30b3\u30eb - \u2705 \u30cd\u30a4\u30c6\u30a3\u30d6\u7d71\u5408 - Claude Desktop\u7b49\u3067\u81ea\u52d5\u8a8d\u8b58 - \u2705 \u30ea\u30c3\u30c1\u30c4\u30fc\u30eb - \u8907\u96d1\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u30fb\u30b9\u30ad\u30fc\u30de</p> <p>\u7d50\u8ad6: \u4e21\u65b9\u3092\u4f75\u7528\u3059\u308b\u306e\u304c\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9</p>"},{"location":"rest-api-usage/#rest-apiexamples","title":"\ud83d\udcdd \u63a8\u5968: REST API\u6d3b\u7528\u4f8b\u3092Examples\u306b\u8ffd\u52a0","text":"<p>\u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3092 <code>examples/</code> \u306b\u8ffd\u52a0\u3059\u308b\u3053\u3068\u3092\u63a8\u5968\uff1a</p> <ol> <li><code>examples/09_rest_api/</code></li> <li><code>python_client.py</code> - Python REST client\u4f8b</li> <li><code>fastapi_integration.py</code> - FastAPI\u30a2\u30d7\u30ea\u7d71\u5408</li> <li><code>webhook_example.py</code> - Webhook\u7d71\u5408</li> <li> <p><code>batch_processing.py</code> - \u30d0\u30c3\u30c1\u51e6\u7406\u4f8b</p> </li> <li> <p><code>examples/10_frontend/</code></p> </li> <li><code>react_example/</code> - React Web UI</li> <li> <p><code>vue_example/</code> - Vue.js\u4f8b</p> </li> <li> <p><code>examples/11_multi_language/</code></p> </li> <li><code>nodejs_client.js</code> - Node.js client</li> <li><code>go_client.go</code> - Go client</li> <li><code>rust_client.rs</code> - Rust client</li> </ol>"},{"location":"rest-api-usage/#_1","title":"\ud83d\udd17 \u95a2\u9023\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li>API Reference - \u5168\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8</li> <li>Getting Started</li> <li>MCP Setup - MCP vs REST\u6bd4\u8f03</li> </ul> <p>\u7d50\u8ad6: REST API\u306f\u524a\u9664\u305b\u305a\u3001\u7a4d\u6975\u7684\u306b\u6d3b\u7528\u3059\u3079\u304d\u91cd\u8981\u306a\u6a5f\u80fd\u3067\u3059\u3002</p> <p>Last Updated: 2025-10-27 Version: 4.0.0</p>"},{"location":"self-hosting/","title":"Self-Hosting Guide","text":"<p>Kagura AI v4.0.0 - Universal AI Memory Platform</p> <p>This guide explains how to self-host Kagura AI for production use with Docker.</p>"},{"location":"self-hosting/#overview","title":"\ud83d\udccb Overview","text":"<p>Self-hosting Kagura AI gives you: - Full control over your data - Multi-user support with authentication - Remote access from any MCP client - Production-ready setup with SSL/TLS</p> <p>Stack: - Kagura API - FastAPI server with MCP endpoint - PostgreSQL - Persistent storage with pgvector - Redis - Caching and job queue - Caddy - Reverse proxy with automatic HTTPS</p>"},{"location":"self-hosting/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"self-hosting/#prerequisites","title":"Prerequisites","text":"<ul> <li>Server: Ubuntu 22.04 LTS (or similar)</li> <li>Docker: 20.10+ and Docker Compose v2</li> <li>Domain: A domain name pointing to your server</li> <li>Ports: 80, 443 open</li> </ul>"},{"location":"self-hosting/#1-install-docker","title":"1. Install Docker","text":"<pre><code># Install Docker\ncurl -fsSL https://get.docker.com | sh\n\n# Install Docker Compose\nsudo apt-get update\nsudo apt-get install docker-compose-plugin\n\n# Verify\ndocker --version\ndocker compose version\n</code></pre>"},{"location":"self-hosting/#2-clone-repository","title":"2. Clone Repository","text":"<pre><code>git clone https://github.com/YourUsername/kagura-ai.git\ncd kagura-ai\n</code></pre>"},{"location":"self-hosting/#3-configure-environment","title":"3. Configure Environment","text":"<pre><code># Copy example env file\ncp .env.example .env\n\n# Edit .env\nnano .env\n</code></pre> <p>Required settings in <code>.env</code>:</p> <pre><code># Domain name (required for HTTPS)\nDOMAIN=your-domain.com\n\n# PostgreSQL password (required)\nPOSTGRES_PASSWORD=your_secure_password_here\n\n# Optional: API Key requirement\nAPI_KEY_REQUIRED=false  # Set to true to require API keys\n\n# Optional: CORS origins\nCORS_ORIGINS=https://chat.openai.com,https://claude.ai\n</code></pre>"},{"location":"self-hosting/#4-start-services","title":"4. Start Services","text":"<pre><code># Build and start\ndocker compose -f docker-compose.prod.yml up -d\n\n# Check logs\ndocker compose -f docker-compose.prod.yml logs -f\n\n# Check health\ncurl https://your-domain.com/api/v1/health\n</code></pre>"},{"location":"self-hosting/#configuration","title":"\ud83d\udd27 Configuration","text":""},{"location":"self-hosting/#environment-variables","title":"Environment Variables","text":"Variable Required Default Description <code>DOMAIN</code> \u2705 Yes - Your domain name <code>POSTGRES_PASSWORD</code> \u2705 Yes - Database password <code>POSTGRES_DB</code> No <code>kagura</code> Database name <code>POSTGRES_USER</code> No <code>kagura</code> Database user <code>LOG_LEVEL</code> No <code>warning</code> Log level (debug/info/warning/error) <code>CORS_ORIGINS</code> No * Allowed CORS origins (comma-separated) <code>API_KEY_REQUIRED</code> No <code>false</code> Require API key for all requests"},{"location":"self-hosting/#ssltls-configuration","title":"SSL/TLS Configuration","text":"<p>Caddy automatically obtains SSL certificates from Let's Encrypt.</p> <p>Requirements: 1. Domain must resolve to your server 2. Ports 80 and 443 must be accessible 3. Valid email for Let's Encrypt (Caddy will prompt)</p> <p>Manual SSL (if needed):</p> <p>Edit <code>Caddyfile</code>: <pre><code>your-domain.com {\n    tls your-email@example.com\n    # ... rest of config\n}\n</code></pre></p>"},{"location":"self-hosting/#security","title":"\ud83d\udd10 Security","text":""},{"location":"self-hosting/#1-api-key-authentication","title":"1. API Key Authentication","text":"<pre><code># Generate API key\ndocker compose -f docker-compose.prod.yml exec api kagura api create-key --name \"production\"\n\n# Output:\n# kagura_abc123xyz789...\n\n# Save securely and use in requests\ncurl -H \"Authorization: Bearer kagura_abc123...\" \\\n     https://your-domain.com/mcp\n</code></pre>"},{"location":"self-hosting/#2-firewall-configuration","title":"2. Firewall Configuration","text":"<pre><code># Allow HTTP/HTTPS only\nsudo ufw allow 80/tcp\nsudo ufw allow 443/tcp\nsudo ufw enable\n\n# Block direct database access\nsudo ufw deny 5432/tcp\n</code></pre>"},{"location":"self-hosting/#3-regular-updates","title":"3. Regular Updates","text":"<pre><code># Update Kagura\ncd kagura-ai\ngit pull\ndocker compose -f docker-compose.prod.yml build\ndocker compose -f docker-compose.prod.yml up -d\n\n# Update system packages\nsudo apt-get update &amp;&amp; sudo apt-get upgrade -y\n</code></pre>"},{"location":"self-hosting/#backup-restore","title":"\ud83d\udcbe Backup &amp; Restore","text":""},{"location":"self-hosting/#automated-backup","title":"Automated Backup","text":"<p>Create backup script <code>backup.sh</code>:</p> <pre><code>#!/bin/bash\nBACKUP_DIR=\"/backups/kagura-$(date +%Y%m%d)\"\nmkdir -p \"$BACKUP_DIR\"\n\n# Export memory data\ndocker compose -f docker-compose.prod.yml exec -T api \\\n  kagura memory export --output /app/data/export\n\n# Copy export from container\ndocker cp kagura-api-prod:/app/data/export \"$BACKUP_DIR/\"\n\n# Backup PostgreSQL\ndocker compose -f docker-compose.prod.yml exec -T postgres \\\n  pg_dump -U kagura kagura &gt; \"$BACKUP_DIR/postgres.sql\"\n\n# Compress\ntar -czf \"$BACKUP_DIR.tar.gz\" \"$BACKUP_DIR\"\nrm -rf \"$BACKUP_DIR\"\n\necho \"Backup saved to $BACKUP_DIR.tar.gz\"\n</code></pre> <p>Schedule with cron:</p> <pre><code># Run daily at 2 AM\n0 2 * * * /path/to/backup.sh\n</code></pre>"},{"location":"self-hosting/#restore-from-backup","title":"Restore from Backup","text":"<pre><code># Extract backup\ntar -xzf kagura-20251027.tar.gz\n\n# Import memory data\ndocker compose -f docker-compose.prod.yml exec api \\\n  kagura memory import --input /app/data/export\n\n# Restore PostgreSQL (if needed)\ndocker compose -f docker-compose.prod.yml exec -T postgres \\\n  psql -U kagura kagura &lt; postgres.sql\n</code></pre>"},{"location":"self-hosting/#monitoring","title":"\ud83d\udcca Monitoring","text":""},{"location":"self-hosting/#health-checks","title":"Health Checks","text":"<pre><code># API health\ncurl https://your-domain.com/api/v1/health\n\n# Expected:\n# {\"status\":\"healthy\",\"services\":{\"database\":\"healthy\",\"redis\":\"healthy\"}}\n\n# Service status\ndocker compose -f docker-compose.prod.yml ps\n</code></pre>"},{"location":"self-hosting/#logs","title":"Logs","text":"<pre><code># All services\ndocker compose -f docker-compose.prod.yml logs -f\n\n# API only\ndocker compose -f docker-compose.prod.yml logs -f api\n\n# Caddy access logs\ndocker compose -f docker-compose.prod.yml exec caddy \\\n  tail -f /var/log/caddy/access.log\n</code></pre>"},{"location":"self-hosting/#metrics","title":"Metrics","text":"<pre><code># Memory usage\ncurl https://your-domain.com/api/v1/metrics\n\n# Expected:\n# {\n#   \"memories_count\": 1500,\n#   \"graph_nodes\": 800,\n#   \"graph_edges\": 450,\n#   \"storage_size_mb\": 25.3\n# }\n</code></pre>"},{"location":"self-hosting/#maintenance","title":"\ud83d\udd27 Maintenance","text":""},{"location":"self-hosting/#update-kagura","title":"Update Kagura","text":"<pre><code>cd kagura-ai\ngit pull\ndocker compose -f docker-compose.prod.yml build api\ndocker compose -f docker-compose.prod.yml up -d api\n</code></pre>"},{"location":"self-hosting/#restart-services","title":"Restart Services","text":"<pre><code># Restart all\ndocker compose -f docker-compose.prod.yml restart\n\n# Restart API only\ndocker compose -f docker-compose.prod.yml restart api\n</code></pre>"},{"location":"self-hosting/#database-maintenance","title":"Database Maintenance","text":"<pre><code># Vacuum database (cleanup)\ndocker compose -f docker-compose.prod.yml exec postgres \\\n  psql -U kagura -c \"VACUUM ANALYZE;\"\n\n# Check database size\ndocker compose -f docker-compose.prod.yml exec postgres \\\n  psql -U kagura -c \"SELECT pg_size_pretty(pg_database_size('kagura'));\"\n</code></pre>"},{"location":"self-hosting/#connecting-clients","title":"\ud83c\udf10 Connecting Clients","text":""},{"location":"self-hosting/#chatgpt-connector","title":"ChatGPT Connector","text":"<ol> <li>Enable Developer Mode in ChatGPT</li> <li>Add connector:</li> <li>Name: Kagura Memory</li> <li>URL: <code>https://your-domain.com/mcp</code></li> <li>Authentication: Bearer token (if API key required)</li> </ol>"},{"location":"self-hosting/#claude-desktop-remote","title":"Claude Desktop (Remote)","text":"<p>Coming soon - stdio \u2192 HTTP proxy connector</p>"},{"location":"self-hosting/#custom-mcp-clients","title":"Custom MCP Clients","text":"<pre><code>import httpx\n\n# MCP over HTTP/SSE\nresponse = httpx.post(\n    \"https://your-domain.com/mcp\",\n    json={\n        \"jsonrpc\": \"2.0\",\n        \"id\": 1,\n        \"method\": \"tools/list\",\n        \"params\": {}\n    },\n    headers={\"Authorization\": \"Bearer kagura_your_api_key\"}\n)\n</code></pre>"},{"location":"self-hosting/#troubleshooting","title":"\ud83d\udc1b Troubleshooting","text":""},{"location":"self-hosting/#issue-caddy-cannot-obtain-ssl-certificate","title":"Issue: Caddy cannot obtain SSL certificate","text":"<p>Symptoms: HTTP works but HTTPS fails</p> <p>Solutions: 1. Verify domain DNS points to server: <code>nslookup your-domain.com</code> 2. Check ports 80/443 are accessible: <code>telnet your-domain.com 80</code> 3. Check Caddy logs: <code>docker logs kagura-caddy-prod</code> 4. Verify email is valid for Let's Encrypt</p>"},{"location":"self-hosting/#issue-api-returns-503-service-unavailable","title":"Issue: API returns 503 Service Unavailable","text":"<p>Symptoms: <code>/api/v1/health</code> returns 503</p> <p>Solutions: 1. Check database is healthy: <code>docker compose -f docker-compose.prod.yml ps postgres</code> 2. Check logs: <code>docker logs kagura-api-prod</code> 3. Verify DATABASE_URL is correct in <code>.env</code></p>"},{"location":"self-hosting/#issue-high-memory-usage","title":"Issue: High memory usage","text":"<p>Symptoms: Container using &gt;2GB RAM</p> <p>Solutions: 1. Enable Redis caching 2. Limit RAG vector database size 3. Run memory consolidation: <code>kagura memory export</code> then clear old data</p>"},{"location":"self-hosting/#issue-cannot-connect-from-chatgpt","title":"Issue: Cannot connect from ChatGPT","text":"<p>Symptoms: 401 Unauthorized or CORS errors</p> <p>Solutions: 1. Verify API key is valid: <code>kagura api list-keys</code> 2. Check CORS_ORIGINS includes <code>https://chat.openai.com</code> 3. Verify domain is accessible: <code>curl https://your-domain.com/mcp</code></p>"},{"location":"self-hosting/#performance-tuning","title":"\ud83d\udcc8 Performance Tuning","text":""},{"location":"self-hosting/#database-optimization","title":"Database Optimization","text":"<pre><code># Increase connection pool\n# Add to docker-compose.prod.yml api environment:\nDATABASE_POOL_SIZE=20\nDATABASE_MAX_OVERFLOW=10\n</code></pre>"},{"location":"self-hosting/#redis-caching","title":"Redis Caching","text":"<pre><code># Configure Redis for caching\n# Add to docker-compose.prod.yml redis command:\ncommand: redis-server --maxmemory 512mb --maxmemory-policy allkeys-lru\n</code></pre>"},{"location":"self-hosting/#api-workers","title":"API Workers","text":"<pre><code># Use gunicorn for multiple workers\n# Update api command in docker-compose.prod.yml:\ncommand: gunicorn kagura.api.server:app -w 4 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8000\n</code></pre>"},{"location":"self-hosting/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>MCP over HTTP/SSE Setup</li> <li>API Authentication (coming soon)</li> <li>Memory Export/Import</li> <li>API Reference</li> </ul>"},{"location":"self-hosting/#support","title":"\ud83d\udcac Support","text":"<ul> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> </ul> <p>Last Updated: 2025-10-27 Version: 4.0.0</p>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>Common issues and solutions for Kagura AI</p> <p>This guide helps you diagnose and fix common problems with Kagura AI integration.</p>"},{"location":"troubleshooting/#quick-diagnostics","title":"\ud83d\udd0d Quick Diagnostics","text":""},{"location":"troubleshooting/#step-1-run-doctor-command","title":"Step 1: Run Doctor Command","text":"<pre><code>kagura mcp doctor\n</code></pre> <p>Expected output: <pre><code>Kagura MCP Diagnostics\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\n\u2705 Python version: 3.11.5\n\u2705 Kagura installed: 4.0.0\n\u2705 MCP server: Configured\n\u2705 Database: Connected (342 memories)\n\u2705 Vector store: Healthy (ChromaDB)\n\nConfiguration:\n  Data dir: ~/.local/share/kagura\n  Cache dir: ~/.cache/kagura\n  Config dir: ~/.config/kagura\n</code></pre></p>"},{"location":"troubleshooting/#step-2-check-server-status","title":"Step 2: Check Server Status","text":"<p>Local MCP (Claude Desktop/Code): <pre><code># Claude Code\nclaude mcp list\n\n# Check Kagura logs\nkagura mcp log --tail\n</code></pre></p> <p>Remote MCP (ChatGPT): <pre><code># Check API health\ncurl http://localhost:8080/api/v1/health\n\n# Check MCP endpoint\ncurl http://localhost:8080/mcp\n\n# Check logs\ndocker compose logs -f api\n</code></pre></p>"},{"location":"troubleshooting/#common-issues","title":"\ud83d\udea8 Common Issues","text":""},{"location":"troubleshooting/#issue-1-mcp-server-not-connecting","title":"Issue 1: MCP Server Not Connecting","text":"<p>Symptoms: - Claude can't see Kagura tools - \"Server not responding\" error - Tools list is empty</p> <p>Diagnosis:</p> <pre><code># Claude Code\nclaude mcp list\n# Should show: kagura: \u2713 Connected\n\n# If not connected, check logs\nkagura mcp log\n</code></pre> <p>Solutions:</p>"},{"location":"troubleshooting/#solution-a-restart-mcp-server-local","title":"Solution A: Restart MCP Server (Local)","text":"<pre><code># Claude Desktop\n# 1. Quit Claude Desktop completely\n# 2. Restart Claude Desktop\n# 3. Start new conversation\n\n# Claude Code\n# 1. Remove and re-add server\nclaude mcp remove kagura\nclaude mcp add --transport stdio kagura -- kagura mcp serve\n\n# 2. Verify\nclaude mcp list\n</code></pre>"},{"location":"troubleshooting/#solution-b-check-command-path","title":"Solution B: Check Command Path","text":"<p>Problem: <code>kagura: command not found</code></p> <pre><code># Find kagura path\nwhich kagura\n# Output: /home/user/.local/bin/kagura\n\n# Use full path in config\nclaude mcp add --transport stdio kagura -- /home/user/.local/bin/kagura mcp serve\n</code></pre>"},{"location":"troubleshooting/#solution-c-check-permissions","title":"Solution C: Check Permissions","text":"<pre><code># Make sure kagura is executable\nchmod +x $(which kagura)\n\n# Check Python environment\npython --version  # Should be 3.11+\npip show kagura-ai  # Should show version 4.0.0+\n</code></pre>"},{"location":"troubleshooting/#issue-2-memory-not-persisting","title":"Issue 2: Memory Not Persisting","text":"<p>Symptoms: - Memories disappear after conversation ends - \"No memories found\" in next session - Lost progress</p> <p>Diagnosis:</p> <pre><code># Check memory statistics\nkagura mcp tools  # In Claude, run: \"Show memory stats\"\n\n# Check database\nls -lh ~/.local/share/kagura/memory.db\n</code></pre> <p>Solutions:</p>"},{"location":"troubleshooting/#solution-a-use-persistent-scope","title":"Solution A: Use Persistent Scope","text":"<p>Problem: Using default <code>scope=\"working\"</code> (temporary)</p> <p>Fix: Explicitly request persistent storage</p> <pre><code>\u274c \"Remember that I prefer Python\"\n\u2705 \"Remember PERMANENTLY: I prefer Python\"\n\u2705 \"Save this with scope='persistent': I prefer Python\"\n</code></pre> <p>In prompts: <pre><code>memory_store(\n    key=\"python_preference\",\n    value=\"FastAPI over Django\",\n    scope=\"persistent\"  # \u2190 Important!\n)\n</code></pre></p>"},{"location":"troubleshooting/#solution-b-check-user_id","title":"Solution B: Check user_id","text":"<p>Problem: Different <code>user_id</code> in each session</p> <pre><code># Session 1\n\"Remember for user_id='john': I prefer Python\"\n\n# Session 2 (different user_id!)\n\"What do I prefer?\"  # Uses default user_id \u2192 no results\n</code></pre> <p>Fix: Use consistent <code>user_id</code>:</p> <pre><code># Always specify the same user_id\n\"For user_id='john': What programming languages do I prefer?\"\n</code></pre>"},{"location":"troubleshooting/#issue-3-file-operations-not-working-remote-mcp","title":"Issue 3: File Operations Not Working (Remote MCP)","text":"<p>Symptoms: - \"file_read not found\" - \"Cannot access files\" - Upload doesn't work</p> <p>Diagnosis:</p> <p>This is expected behavior for Remote MCP (ChatGPT, Claude Chat).</p> <p>Why: Remote MCP runs over HTTP/SSE and doesn't have direct file system access for security reasons.</p> <p>Solutions:</p>"},{"location":"troubleshooting/#solution-a-use-local-mcp-for-file-operations","title":"Solution A: Use Local MCP for File Operations","text":"<p>Switch to Claude Desktop or Claude Code:</p> <pre><code># Claude Desktop\nkagura mcp install\n\n# Claude Code\nclaude mcp add --transport stdio kagura -- kagura mcp serve\n</code></pre> <p>Now you can use: - <code>file_read</code> - <code>file_write</code> - <code>dir_list</code> - <code>media_open_*</code></p>"},{"location":"troubleshooting/#solution-b-copypaste-content-remote-mcp","title":"Solution B: Copy/Paste Content (Remote MCP)","text":"<p>If you must use Remote MCP:</p> <pre><code># Instead of \"Read config.py\"\n# \u2192 Copy/paste the file content into chat\n\nUser: \"Here's my config.py content:\n      [paste content]\n\n      Analyze this configuration\"\n</code></pre>"},{"location":"troubleshooting/#solution-c-wait-for-v41-file-upload","title":"Solution C: Wait for v4.1 File Upload","text":"<p>Future: Multimodal Upload API is planned for v4.1</p> <p>See: Issue #462</p>"},{"location":"troubleshooting/#issue-4-search-returns-no-results","title":"Issue 4: Search Returns No Results","text":"<p>Symptoms: - <code>memory_search</code> returns empty - \"No memories found\" - Can't find stored information</p> <p>Diagnosis:</p> <pre><code># In Claude/ChatGPT:\n\"List all my memories\"\n[Uses memory_list]\n\n\"Show memory statistics\"\n[Uses memory_stats]\n</code></pre> <p>Solutions:</p>"},{"location":"troubleshooting/#solution-a-check-memory-exists","title":"Solution A: Check Memory Exists","text":"<pre><code>\"List all memories\"\n\n# If empty \u2192 No memories stored yet\n# If has memories \u2192 Continue to next solutions\n</code></pre>"},{"location":"troubleshooting/#solution-b-use-correct-search-type","title":"Solution B: Use Correct Search Type","text":"<p>Semantic search (meaning-based): <pre><code>\u2705 \"Find memories about backend development\"\n\u2705 \"Search for information on API design\"\n</code></pre></p> <p>Exact key recall: <pre><code>\u2705 \"Recall memory with key='python_preference'\"\n</code></pre></p> <p>Wrong approach: <pre><code>\u274c \"Search for exact text 'I prefer FastAPI over Django'\"\n</code></pre></p>"},{"location":"troubleshooting/#solution-c-check-filters","title":"Solution C: Check Filters","text":"<p>Problem: Too restrictive filters</p> <pre><code># Too specific (no results)\nmemory_search(\n    query=\"FastAPI\",\n    tags=[\"python\", \"web\", \"api\", \"backend\", \"2024\"]  # Too many tags\n)\n\n# Better (more results)\nmemory_search(\n    query=\"FastAPI\",\n    tags=[\"python\"]  # Fewer tags\n)\n\n# Best (most results)\nmemory_search(\n    query=\"FastAPI\"  # No filters\n)\n</code></pre>"},{"location":"troubleshooting/#solution-d-verify-user_id-and-agent_name","title":"Solution D: Verify user_id and agent_name","text":"<pre><code># Check what you're searching\n\"Search memories for user_id='john' with agent_name='global'\"\n\n# If no results, try different combinations\n\"Search all memories regardless of user_id\"\n</code></pre>"},{"location":"troubleshooting/#issue-5-high-api-costs","title":"Issue 5: High API Costs","text":"<p>Symptoms: - Unexpected OpenAI/Anthropic bills - Embedding API costs too high - Token usage warnings</p> <p>Diagnosis:</p> <pre><code># Check cost summary\n\"Show telemetry cost summary\"\n[Uses telemetry_cost]\n\n# Check tool usage\nkagura mcp stats\n</code></pre> <p>Solutions:</p>"},{"location":"troubleshooting/#solution-a-use-local-embeddings","title":"Solution A: Use Local Embeddings","text":"<p>Problem: Using OpenAI API for embeddings</p> <p>Fix: Switch to local sentence-transformers</p> <pre><code># Install AI extras (includes sentence-transformers)\npip install kagura-ai[ai]\n\n# Configure to use local embeddings\n# In .env or environment:\nKAGURA_EMBEDDING_MODEL=local  # Uses E5 model (free, local)\n</code></pre> <p>Cost comparison: - OpenAI embeddings: $0.0001 per 1K tokens - Local E5 embeddings: $0 (runs on your machine)</p>"},{"location":"troubleshooting/#solution-b-use-low-token-search","title":"Solution B: Use Low-Token Search","text":"<p>Instead of <code>memory_search</code> (returns full content), use <code>memory_search_ids</code>:</p> <pre><code># High token usage\nmemory_search(query=\"FastAPI\", k=10)\n# Returns 10 full memories \u2192 ~5000 tokens\n\n# Low token usage\nmemory_search_ids(query=\"FastAPI\", k=10)\n# Returns 10 IDs + previews \u2192 ~500 tokens\n</code></pre>"},{"location":"troubleshooting/#solution-c-reduce-search-frequency","title":"Solution C: Reduce Search Frequency","text":"<p>Cache search results:</p> <pre><code># Instead of searching multiple times\n\"Find memories about Python\"  # Search 1\n\"Find memories about Python\"  # Search 2 (duplicate!)\n\n# Better: Search once, then reference\n\"Find memories about Python\"  # Search once\n\"Based on those memories, what should I use for backend?\"  # No search\n</code></pre>"},{"location":"troubleshooting/#solution-d-monitor-costs","title":"Solution D: Monitor Costs","text":"<pre><code># Regular cost checks\n\"Show me telemetry cost for the last week\"\n\n# Set budget alerts (future feature)\n</code></pre>"},{"location":"troubleshooting/#issue-6-slow-performance","title":"Issue 6: Slow Performance","text":"<p>Symptoms: - Search takes &gt; 5 seconds - Memory operations timeout - API responses slow</p> <p>Diagnosis:</p> <pre><code># Check database size\ndu -sh ~/.local/share/kagura/\n\n# Check memory count\nkagura mcp tools  # Then: \"Show memory stats\"\n\n# Check system resources\ntop  # Look for high CPU/memory usage\n</code></pre> <p>Solutions:</p>"},{"location":"troubleshooting/#solution-a-clean-up-old-memories","title":"Solution A: Clean Up Old Memories","text":"<pre><code># Export first (backup)\nkagura memory export --output=./backup\n\n# Delete old/unused memories\n# In Claude/ChatGPT:\n\"Delete memories older than 6 months with usefulness score &lt; 0.3\"\n</code></pre>"},{"location":"troubleshooting/#solution-b-optimize-chromadb","title":"Solution B: Optimize ChromaDB","text":"<pre><code># Compact database\ncd ~/.cache/kagura/chromadb\n# ChromaDB auto-compacts, but you can restart to force it\n\n# Or rebuild from scratch\nkagura memory export --output=./backup\nrm -rf ~/.cache/kagura/chromadb\nkagura memory import --input=./backup\n</code></pre>"},{"location":"troubleshooting/#solution-c-use-bm25-for-exact-matches","title":"Solution C: Use BM25 for Exact Matches","text":"<p>Semantic search (slow for large datasets): <pre><code>memory_search(query=\"FastAPI\", mode=\"vector\")  # Slow for 10K+ memories\n</code></pre></p> <p>BM25 lexical search (fast): <pre><code>memory_search(query=\"FastAPI\", mode=\"bm25\")  # Fast even for 100K+ memories\n</code></pre></p> <p>Hybrid (best accuracy + speed): <pre><code>memory_search(query=\"FastAPI\", mode=\"hybrid\")  # Balanced\n</code></pre></p>"},{"location":"troubleshooting/#issue-7-authentication-errors-remote-mcp","title":"Issue 7: Authentication Errors (Remote MCP)","text":"<p>Symptoms: - \"401 Unauthorized\" - \"Invalid API key\" - \"Authentication required\"</p> <p>Diagnosis:</p> <pre><code># Check API key exists\nkagura api list-keys\n\n# Test authentication\ncurl -H \"Authorization: Bearer YOUR_KEY\" \\\n     http://localhost:8080/api/v1/health\n</code></pre> <p>Solutions:</p>"},{"location":"troubleshooting/#solution-a-create-api-key","title":"Solution A: Create API Key","text":"<pre><code># Generate new API key\nkagura api create-key --name \"chatgpt-integration\"\n\n# Output:\n# Created API key: kg_xxxxxxxxxxxxxxxxxxxxxxxx\n# Save this key securely!\n</code></pre>"},{"location":"troubleshooting/#solution-b-configure-mcp-with-api-key","title":"Solution B: Configure MCP with API Key","text":"<p>ChatGPT MCP configuration: <pre><code>{\n  \"url\": \"https://your-domain.com/mcp\",\n  \"headers\": {\n    \"Authorization\": \"Bearer kg_xxxxxxxxxxxxxxxxxxxxxxxx\"\n  }\n}\n</code></pre></p>"},{"location":"troubleshooting/#solution-c-check-key-permissions","title":"Solution C: Check Key Permissions","text":"<pre><code># View key details\nkagura api get-key kg_xxxxxxxx\n\n# Rotate if compromised\nkagura api rotate-key kg_xxxxxxxx\n\n# Revoke if needed\nkagura api revoke-key kg_xxxxxxxx\n</code></pre>"},{"location":"troubleshooting/#issue-8-docker-issues","title":"Issue 8: Docker Issues","text":"<p>Symptoms: - \"Cannot connect to Docker daemon\" - Containers not starting - Port conflicts</p> <p>Diagnosis:</p> <pre><code># Check Docker status\ndocker ps\n\n# Check logs\ndocker compose logs -f\n\n# Check ports\nlsof -i :8080  # API port\nlsof -i :5432  # PostgreSQL port\nlsof -i :6379  # Redis port\n</code></pre> <p>Solutions:</p>"},{"location":"troubleshooting/#solution-a-start-docker","title":"Solution A: Start Docker","text":"<pre><code># Linux\nsudo systemctl start docker\n\n# macOS\n# Open Docker Desktop\n\n# Verify\ndocker ps\n</code></pre>"},{"location":"troubleshooting/#solution-b-fix-port-conflicts","title":"Solution B: Fix Port Conflicts","text":"<p>Problem: Port 8080 already in use</p> <pre><code># Find what's using the port\nlsof -i :8080\n\n# Kill the process\nkill -9 &lt;PID&gt;\n\n# Or change Kagura port in docker-compose.yml\nports:\n  - \"8090:8080\"  # Use 8090 instead\n</code></pre>"},{"location":"troubleshooting/#solution-c-reset-docker-environment","title":"Solution C: Reset Docker Environment","text":"<pre><code># Stop all containers\ndocker compose down\n\n# Remove volumes (\u26a0\ufe0f deletes data!)\ndocker compose down -v\n\n# Rebuild\ndocker compose up -d --build\n\n# Check health\ncurl http://localhost:8080/api/v1/health\n</code></pre>"},{"location":"troubleshooting/#advanced-troubleshooting","title":"\ud83d\udd27 Advanced Troubleshooting","text":""},{"location":"troubleshooting/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code># Set log level\nexport KAGURA_LOG_LEVEL=DEBUG\n\n# Start MCP server with debug logs\nkagura mcp serve\n\n# Or for API\nuvicorn kagura.api.server:app --log-level debug\n</code></pre>"},{"location":"troubleshooting/#check-database-integrity","title":"Check Database Integrity","text":"<pre><code># SQLite integrity check\nsqlite3 ~/.local/share/kagura/memory.db \"PRAGMA integrity_check;\"\n\n# Expected output: ok\n</code></pre>"},{"location":"troubleshooting/#rebuild-vector-index","title":"Rebuild Vector Index","text":"<pre><code># Export memories\nkagura memory export --output=./backup\n\n# Clear vector store\nrm -rf ~/.cache/kagura/chromadb\n\n# Re-import (will rebuild vectors)\nkagura memory import --input=./backup\n</code></pre>"},{"location":"troubleshooting/#test-mcp-tools-manually","title":"Test MCP Tools Manually","text":"<pre><code># Test individual tools via API\ncurl -X POST http://localhost:8080/api/v1/memory/store \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"key\": \"test\",\n    \"value\": \"test value\",\n    \"scope\": \"working\"\n  }'\n\n# Check if it was stored\ncurl http://localhost:8080/api/v1/memory/list\n</code></pre>"},{"location":"troubleshooting/#getting-help","title":"\ud83d\udcda Getting Help","text":""},{"location":"troubleshooting/#1-check-documentation","title":"1. Check Documentation","text":"<ul> <li>Chat Integration Tips</li> <li>MCP Setup Guides</li> <li>API Reference</li> <li>Architecture</li> </ul>"},{"location":"troubleshooting/#2-search-existing-issues","title":"2. Search Existing Issues","text":"<p>GitHub Issues</p>"},{"location":"troubleshooting/#3-ask-the-community","title":"3. Ask the Community","text":"<p>GitHub Discussions</p>"},{"location":"troubleshooting/#4-report-a-bug","title":"4. Report a Bug","text":"<pre><code># Create a new issue with diagnostic info\nkagura mcp doctor &gt; diagnostics.txt\n\n# Attach diagnostics.txt when creating issue\ngh issue create --title \"Bug: [describe issue]\" \\\n                --body \"See attached diagnostics.txt\"\n</code></pre>"},{"location":"troubleshooting/#diagnostic-checklist","title":"\ud83d\udcca Diagnostic Checklist","text":"<p>Before reporting an issue, collect this information:</p> <pre><code># 1. Version info\nkagura --version\npython --version\npip show kagura-ai\n\n# 2. System info\nuname -a  # Linux/macOS\ncat /etc/os-release  # Linux distribution\n\n# 3. Diagnostic report\nkagura mcp doctor\n\n# 4. Recent logs\nkagura mcp log --lines 100\n\n# 5. Error message\n# Copy the full error message + stack trace\n\n# 6. Steps to reproduce\n# Write down exact steps that cause the issue\n</code></pre> <p>Version: 4.0.0 Last updated: 2025-11-02</p>"},{"location":"configuration/environment-variables/","title":"Environment Variables","text":"<p>Kagura AI uses environment variables for configuration, including API keys, default settings, and feature toggles. This guide documents all available environment variables and how to use them.</p>"},{"location":"configuration/environment-variables/#quick-start","title":"Quick Start","text":"<ol> <li> <p>Copy the example file:    <pre><code>cp .env.example .env\n</code></pre></p> </li> <li> <p>Add your API keys:    <pre><code># At least one LLM provider is required\nOPENAI_API_KEY=sk-...\n</code></pre></p> </li> <li> <p>Load environment variables (optional):    <pre><code># Kagura automatically loads .env files\n# Or use python-dotenv:\npython -m dotenv run kagura chat\n</code></pre></p> </li> </ol>"},{"location":"configuration/environment-variables/#required-variables","title":"Required Variables","text":"<p>At least one LLM provider API key is required for Kagura to work:</p> Variable Provider Get API Key Models <code>OPENAI_API_KEY</code> OpenAI platform.openai.com gpt-4o, gpt-5-mini, gpt-4-turbo, gpt-3.5-turbo <code>ANTHROPIC_API_KEY</code> Anthropic console.anthropic.com claude-3-5-sonnet, claude-3-opus, claude-3-haiku <code>GOOGLE_API_KEY</code> Google AI aistudio.google.com gemini-1.5-pro, gemini-1.5-flash, gemini-pro"},{"location":"configuration/environment-variables/#example","title":"Example","text":"<pre><code># Option 1: OpenAI (most common)\nOPENAI_API_KEY=sk-proj-...\n\n# Option 2: Anthropic\nANTHROPIC_API_KEY=sk-ant-...\n\n# Option 3: Google AI (for multimodal features)\nGOOGLE_API_KEY=AIza...\n\n# Or use multiple providers\nOPENAI_API_KEY=sk-proj-...\nANTHROPIC_API_KEY=sk-ant-...\n</code></pre>"},{"location":"configuration/environment-variables/#optional-variables","title":"Optional Variables","text":""},{"location":"configuration/environment-variables/#web-search","title":"Web Search","text":"Variable Service Get API Key Purpose <code>BRAVE_SEARCH_API_KEY</code> Brave Search brave.com/search/api Web search capabilities <p>Example: <pre><code>BRAVE_SEARCH_API_KEY=BSA...\n</code></pre></p> <p>Note: This API key is required for web search functionality.</p>"},{"location":"configuration/environment-variables/#default-settings","title":"Default Settings","text":"Variable Default Description <code>DEFAULT_MODEL</code> <code>gpt-5-mini</code> Default LLM model to use <code>DEFAULT_TEMPERATURE</code> <code>0.7</code> Default temperature (0.0-2.0) <p>Example: <pre><code># Use GPT-4o by default\nDEFAULT_MODEL=gpt-4o\n\n# Make responses more creative\nDEFAULT_TEMPERATURE=1.0\n</code></pre></p>"},{"location":"configuration/environment-variables/#programmatic-access","title":"Programmatic Access","text":"<p>Kagura provides a centralized API for accessing environment variables:</p> <pre><code>from kagura.config.env import (\n    get_openai_api_key,\n    get_anthropic_api_key,\n    get_google_api_key,\n    get_brave_search_api_key,\n    get_default_model,\n    get_default_temperature,\n)\n\n# Get API keys (returns None if not set)\nopenai_key = get_openai_api_key()\nbrave_key = get_brave_search_api_key()\n\n# Get defaults (returns default value if not set)\nmodel = get_default_model()  # \"gpt-5-mini\"\ntemperature = get_default_temperature()  # 0.7\n</code></pre>"},{"location":"configuration/environment-variables/#utility-functions","title":"Utility Functions","text":"<pre><code>from kagura.config.env import list_env_vars, check_required_env_vars\n\n# List all environment variables (API keys are masked)\nenv_vars = list_env_vars()\nprint(env_vars)\n# {\n#   'OPENAI_API_KEY': '***',\n#   'ANTHROPIC_API_KEY': None,\n#   'GOOGLE_API_KEY': '***',\n#   'BRAVE_SEARCH_API_KEY': '***',\n#   'DEFAULT_MODEL': 'gpt-5-mini',\n#   'DEFAULT_TEMPERATURE': '0.7'\n# }\n\n# Check for missing required variables\nmissing = check_required_env_vars()\nif missing:\n    print(f\"Missing: {', '.join(missing)}\")\n</code></pre>"},{"location":"configuration/environment-variables/#backward-compatibility","title":"Backward Compatibility","text":"<p>Kagura AI v3.0 uses <code>BRAVE_SEARCH_API_KEY</code> for web search (previously <code>BRAVE_API_KEY</code> in older versions).</p>"},{"location":"configuration/environment-variables/#additional-providers","title":"Additional Providers","text":"<p>Kagura uses LiteLLM which supports 100+ LLM providers. You can add keys for any supported provider:</p>"},{"location":"configuration/environment-variables/#azure-openai","title":"Azure OpenAI","text":"<pre><code>AZURE_API_KEY=...\nAZURE_API_BASE=https://your-resource.openai.azure.com/\nAZURE_API_VERSION=2024-02-15-preview\n</code></pre>"},{"location":"configuration/environment-variables/#aws-bedrock","title":"AWS Bedrock","text":"<pre><code>AWS_ACCESS_KEY_ID=...\nAWS_SECRET_ACCESS_KEY=...\nAWS_REGION_NAME=us-east-1\n</code></pre>"},{"location":"configuration/environment-variables/#other-providers","title":"Other Providers","text":"<ul> <li>Cohere: <code>COHERE_API_KEY</code></li> <li>Hugging Face: <code>HUGGINGFACE_API_KEY</code></li> <li>Together AI: <code>TOGETHERAI_API_KEY</code></li> <li>Replicate: <code>REPLICATE_API_KEY</code></li> </ul> <p>See LiteLLM Providers for full list.</p>"},{"location":"configuration/environment-variables/#security-best-practices","title":"Security Best Practices","text":""},{"location":"configuration/environment-variables/#1-never-commit-api-keys","title":"1. Never Commit API Keys","text":"<pre><code># \u2705 Good: Use .env (already in .gitignore)\necho \"OPENAI_API_KEY=sk-...\" &gt; .env\n\n# \u274c Bad: Never commit keys to Git\ngit add .env  # Don't do this!\n</code></pre>"},{"location":"configuration/environment-variables/#2-use-environment-specific-files","title":"2. Use Environment-Specific Files","text":"<pre><code>.env              # Local development (gitignored)\n.env.production   # Production (never committed)\n.env.example      # Template (safe to commit)\n</code></pre>"},{"location":"configuration/environment-variables/#3-rotate-keys-regularly","title":"3. Rotate Keys Regularly","text":"<ul> <li>Rotate API keys every 90 days</li> <li>Use separate keys for development/production</li> <li>Revoke keys immediately if compromised</li> </ul>"},{"location":"configuration/environment-variables/#4-limit-key-permissions","title":"4. Limit Key Permissions","text":"<ul> <li>Use read-only keys when possible</li> <li>Set spending limits on API keys</li> <li>Use service-specific keys (not admin keys)</li> </ul>"},{"location":"configuration/environment-variables/#troubleshooting","title":"Troubleshooting","text":""},{"location":"configuration/environment-variables/#no-api-key-found","title":"\"No API key found\"","text":"<p>Error: <pre><code>ValueError: Google API key not found.\nSet GOOGLE_API_KEY environment variable or pass api_key parameter.\n</code></pre></p> <p>Solution: <pre><code># Check if variable is set\necho $GOOGLE_API_KEY\n\n# Set the variable\nexport GOOGLE_API_KEY=AIza...\n\n# Or add to .env\necho \"GOOGLE_API_KEY=AIza...\" &gt;&gt; .env\n</code></pre></p>"},{"location":"configuration/environment-variables/#invalid-temperature","title":"\"Invalid temperature\"","text":"<p>Error: <pre><code>UserWarning: Invalid DEFAULT_TEMPERATURE value: abc. Using default: 0.7\n</code></pre></p> <p>Solution: <pre><code># Temperature must be a number between 0.0 and 2.0\nDEFAULT_TEMPERATURE=0.7  # \u2705 Valid\nDEFAULT_TEMPERATURE=abc  # \u274c Invalid\n</code></pre></p>"},{"location":"configuration/environment-variables/#environment-not-loading","title":"Environment not loading","text":"<p>Problem: Changes to <code>.env</code> not taking effect</p> <p>Solutions: <pre><code># 1. Restart your shell/terminal\n\n# 2. Explicitly load .env\npython -m dotenv run kagura chat\n\n# 3. Check .env file location\npwd  # Should be in project root\n\n# 4. Verify .env syntax\ncat .env  # Check for typos, missing =, etc.\n</code></pre></p>"},{"location":"configuration/environment-variables/#related-documentation","title":"Related Documentation","text":"<ul> <li>Quick Start Guide</li> <li>Agent Configuration</li> <li>LiteLLM Providers</li> <li>API Reference</li> </ul>"},{"location":"configuration/environment-variables/#reference-all-variables","title":"Reference: All Variables","text":""},{"location":"configuration/environment-variables/#llm-providers-required","title":"LLM Providers (Required)","text":"<ul> <li><code>OPENAI_API_KEY</code> - OpenAI API key</li> <li><code>ANTHROPIC_API_KEY</code> - Anthropic API key</li> <li><code>GOOGLE_API_KEY</code> - Google AI API key</li> </ul>"},{"location":"configuration/environment-variables/#features-optional","title":"Features (Optional)","text":"<ul> <li><code>BRAVE_SEARCH_API_KEY</code> - Brave Search API key</li> </ul>"},{"location":"configuration/environment-variables/#defaults-optional","title":"Defaults (Optional)","text":"<ul> <li><code>DEFAULT_MODEL</code> - Default LLM model (default: <code>gpt-5-mini</code>)</li> <li><code>DEFAULT_TEMPERATURE</code> - Default temperature (default: <code>0.7</code>)</li> </ul> <p>Last updated: 2025-10-19 Version: v3.0</p>"},{"location":"examples/chatgpt-workflow/","title":"ChatGPT + Kagura AI \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u4f8b","text":"<p>Kagura AI\u3068ChatGPT\u3092\u4f7f\u7528\u3057\u305f\u5b9f\u8df5\u7684\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc</p> <p>\u3053\u306e\u30ac\u30a4\u30c9\u306f\u3001Remote MCP\u3092\u4ecb\u3057\u3066Kagura AI\u3092ChatGPT\u3068\u7d71\u5408\u3059\u308b\u305f\u3081\u306e\u5b9f\u4e16\u754c\u306e\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u4f8b\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"examples/chatgpt-workflow/#_1","title":"\ud83d\udccb \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":""},{"location":"examples/chatgpt-workflow/#_2","title":"\u524d\u63d0\u6761\u4ef6","text":"<ol> <li>Kagura Remote MCP\u30b5\u30fc\u30d0\u30fc \u304c\u5b9f\u884c\u4e2d</li> <li>ChatGPT \u304cMCP\u63a5\u7d9a\u3067\u8a2d\u5b9a\u6e08\u307f</li> <li>API Keys (\u30aa\u30d7\u30b7\u30e7\u30f3): Brave Search\u3001Gemini</li> </ol> <p>\u53c2\u7167: MCP over HTTP/SSE \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u30ac\u30a4\u30c9</p>"},{"location":"examples/chatgpt-workflow/#1","title":"\ud83c\udfaf \u30ef\u30fc\u30af\u30d5\u30ed\u30fc1: \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u7ba1\u7406","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: \u8907\u6570\u306e\u4f1a\u8a71\u3067\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30bf\u30b9\u30af\u3001\u4f1a\u8b70\u30e1\u30e2\u3001\u6c7a\u5b9a\u4e8b\u9805\u3092\u8ffd\u8de1</p>"},{"location":"examples/chatgpt-workflow/#1_1","title":"\u30bb\u30c3\u30b7\u30e7\u30f3\u4f8b1: \u671d\u306e\u8a08\u753b","text":"<pre><code>\u30e6\u30fc\u30b6\u30fc: \"kagura-ai v4.0 \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u7528\u306e\u65b0\u3057\u3044\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u8ffd\u8de1\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u958b\u59cb\u3057\u3066\"\n\nChatGPT: [coding_start_session\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"tags=['documentation', 'v4.0']\u3067\u3053\u308c\u3089\u306e\u512a\u5148\u4e8b\u9805\u3092\u899a\u3048\u3066:\n       1. \u30c1\u30e3\u30c3\u30c8\u7d71\u5408\u306e\u30d2\u30f3\u30c8\n       2. \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u4f8b\n       3. \u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u30ac\u30a4\u30c9\"\n\nChatGPT: [scope=\"persistent\"\u3067memory_store\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u7de0\u5207\u30922025\u5e7411\u670815\u65e5\u306b\u8a2d\u5b9a\u3002\u3053\u308c\u306f\u91cd\u8981\u3067\u3059\u3002\"\n\nChatGPT: [memory_store\u3092\u4f7f\u7528]\n</code></pre>"},{"location":"examples/chatgpt-workflow/#2","title":"\u30bb\u30c3\u30b7\u30e7\u30f3\u4f8b2: \u5348\u5f8c\u306e\u4f5c\u696d","text":"<pre><code>\u30e6\u30fc\u30b6\u30fc: \"\u79c1\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u512a\u5148\u4e8b\u9805\u306f\u4f55\u3067\u3059\u304b?\"\n\nChatGPT: [tags=['documentation', 'v4.0']\u3067memory_search\u3092\u4f7f\u7528]\n         \"\u3042\u306a\u305f\u306e\u512a\u5148\u4e8b\u9805\u306f:\n          1. \u30c1\u30e3\u30c3\u30c8\u7d71\u5408\u306e\u30d2\u30f3\u30c8\n          2. \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u4f8b\n          3. \u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u30ac\u30a4\u30c9\"\n\n\u30e6\u30fc\u30b6\u30fc: \"\u30c1\u30e3\u30c3\u30c8\u7d71\u5408\u306e\u30d2\u30f3\u30c8\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u5b8c\u6210\u3055\u305b\u307e\u3057\u305f\u3002\u3053\u308c\u3092\u8a18\u9332\u3057\u3066\u3002\"\n\nChatGPT: [coding_track_file_change\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"\u6280\u8853\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u4f5c\u6210\u306e\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\u3092Web\u3067\u691c\u7d22\"\n\nChatGPT: [brave_web_search\u3092\u4f7f\u7528]\n</code></pre>"},{"location":"examples/chatgpt-workflow/#3","title":"\u30bb\u30c3\u30b7\u30e7\u30f3\u4f8b3: \u5915\u65b9\u306e\u30ec\u30d3\u30e5\u30fc","text":"<pre><code>\u30e6\u30fc\u30b6\u30fc: \"\u79c1\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u7de0\u5207\u306f?\"\n\nChatGPT: [memory_recall\u3092\u4f7f\u7528]\n         \"\u3042\u306a\u305f\u306e\u7de0\u5207\u306f2025\u5e7411\u670815\u65e5\u3067\u3059\"\n\n\u30e6\u30fc\u30b6\u30fc: \"\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u7d42\u4e86\u3057\u3066\u8981\u7d04\u3092\u751f\u6210\"\n\nChatGPT: [coding_end_session\u3092\u4f7f\u7528]\n         \"\u8981\u7d04: \u30c1\u30e3\u30c3\u30c8\u7d71\u5408\u306e\u30d2\u30f3\u30c8\u3092\u5b8c\u6210 (370\u884c)\u3002\n          \u30b3\u30b9\u30c8: \u57cb\u3081\u8fbc\u307f\u306b$0.15\u3002\u6b8b\u308a: \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u4f8b\u3001\n          \u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u30ac\u30a4\u30c9\u3002\"\n</code></pre>"},{"location":"examples/chatgpt-workflow/#_3","title":"\u30e1\u30ea\u30c3\u30c8","text":"<ul> <li>\u2705 \u6c38\u7d9a\u7684\u30e1\u30e2\u30ea\u30fc: \u30bf\u30b9\u30af\u306f\u4f1a\u8a71\u3092\u8d85\u3048\u3066\u5b58\u7d9a</li> <li>\u2705 \u30af\u30ed\u30b9\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0: \u4efb\u610f\u306eChatGPT\u30bb\u30c3\u30b7\u30e7\u30f3\u304b\u3089\u30a2\u30af\u30bb\u30b9</li> <li>\u2705 AI\u8981\u7d04: \u30b3\u30b9\u30c8\u8ffd\u8de1\u4ed8\u304d\u306e\u81ea\u52d5\u30bb\u30c3\u30b7\u30e7\u30f3\u8981\u7d04</li> <li>\u2705 \u691c\u7d22\u53ef\u80fd: \u30bf\u30b0\u3001\u30ad\u30fc\u30ef\u30fc\u30c9\u3001\u307e\u305f\u306f\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u691c\u7d22\u3067\u30bf\u30b9\u30af\u3092\u691c\u7d22</li> </ul>"},{"location":"examples/chatgpt-workflow/#2_1","title":"\ud83d\udcda \u30ef\u30fc\u30af\u30d5\u30ed\u30fc2: \u5b66\u7fd2\u3068\u7814\u7a76\u30ce\u30fc\u30c8","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: YouTube\u52d5\u753b\u3001Web\u8a18\u4e8b\u3001\u8ad6\u6587\u304b\u3089\u500b\u4eba\u7684\u306a\u30ca\u30ec\u30c3\u30b8\u30d9\u30fc\u30b9\u3092\u69cb\u7bc9</p>"},{"location":"examples/chatgpt-workflow/#fastapi","title":"\u4f8b: FastAPI\u3092\u5b66\u3076","text":"<pre><code>\u30e6\u30fc\u30b6\u30fc: \"FastAPI\u3092\u5b66\u3093\u3067\u3044\u307e\u3059\u3002\u3053\u308c\u3092\u8ffd\u8de1\u958b\u59cb\u3057\u3066\u3002\"\n\nChatGPT: [coding_start_session\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"YouTube\u3067'FastAPI tutorial for beginners'\u3092\u691c\u7d22\"\n\nChatGPT: [brave_video_search\u3092\u4f7f\u7528]\n         \"\u898b\u3064\u304b\u308a\u307e\u3057\u305f: 'FastAPI Tutorial - Build a REST API in 15 Minutes'\n          URL: https://www.youtube.com/watch?v=xxxxx\"\n\n\u30e6\u30fc\u30b6\u30fc: \"\u3053\u306e\u52d5\u753b\u3092\u8981\u7d04\u3057\u3066: https://www.youtube.com/watch?v=xxxxx\"\n\nChatGPT: [youtube_summarize\u3092\u4f7f\u7528]\n         \"\u8981\u7d04: FastAPI\u306e\u57fa\u672c\u3092\u30ab\u30d0\u30fc\u3001\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u3001\n          Pydantic\u30e2\u30c7\u30eb\u3001\u81ea\u52d5\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3001\u975e\u540c\u671f\u30b5\u30dd\u30fc\u30c8...\"\n\n\u30e6\u30fc\u30b6\u30fc: \"tags=['fastapi', 'tutorial', 'learning']\u3067\u3053\u306e\u8981\u7d04\u3092\u899a\u3048\u3066\u3002\n       \u3053\u308c\u306f\u5c06\u6765\u306e\u53c2\u7167\u306e\u305f\u3081\u306b\u91cd\u8981\u3067\u3059\u3002\"\n\nChatGPT: [scope=\"persistent\"\u3067memory_store\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"API \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6700\u9069\u5316\u306b\u95a2\u3059\u308b\u8ad6\u6587\u3092arXiv\u3067\u691c\u7d22\"\n\nChatGPT: [arxiv_search\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"tags=['fastapi', 'performance', 'research']\u3067\u30c8\u30c3\u30d73\u306e\u8ad6\u6587\u3092\u899a\u3048\u3066\"\n\nChatGPT: [memory_store\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"FastAPI\u3068Django\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3092Web\u3067\u691c\u7d22\"\n\nChatGPT: [brave_web_search\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"tags=['fastapi', 'django', 'comparison']\u3067\u3053\u306e\u6bd4\u8f03\u3092\u4fdd\u5b58:\n       FastAPI: \u975e\u540c\u671f\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u30673\u500d\u9ad8\u901f\u3001\u3088\u308a\u826f\u3044\u578b\u5b89\u5168\u6027\n       Django: \u3088\u308a\u591a\u304f\u306e\u30d0\u30c3\u30c6\u30ea\u30fc\u540c\u68b1\u3001\u5927\u304d\u306a\u30a8\u30b3\u30b7\u30b9\u30c6\u30e0\"\n\nChatGPT: [memory_store\u3092\u4f7f\u7528]\n</code></pre>"},{"location":"examples/chatgpt-workflow/#_4","title":"\u5f8c\u306e\u30bb\u30c3\u30b7\u30e7\u30f3: \u30ca\u30ec\u30c3\u30b8\u3092\u601d\u3044\u51fa\u3059","text":"<pre><code>\u30e6\u30fc\u30b6\u30fc: \"FastAPI\u306b\u3064\u3044\u3066\u4f55\u3092\u5b66\u3073\u307e\u3057\u305f\u304b?\"\n\nChatGPT: [query=\"FastAPI learning\"\u3067memory_search\u3092\u4f7f\u7528]\n         \"\u3042\u306a\u305f\u304c\u5b66\u3093\u3060\u3053\u3068:\n          1. FastAPI\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u8981\u7d04 (\u975e\u540c\u671f\u3001Pydantic\u3001\u81ea\u52d5\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8)\n          2. \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9: \u975e\u540c\u671f\u3067Django\u3088\u308a3\u500d\u9ad8\u901f\n          3. \u7814\u7a76\u8ad6\u6587: [3\u3064\u306e\u8ad6\u6587\u3092\u30ea\u30b9\u30c8]\"\n\n\u30e6\u30fc\u30b6\u30fc: \"'fastapi'\u3067\u30bf\u30b0\u4ed8\u3051\u3055\u308c\u305f\u3059\u3079\u3066\u306e\u30e1\u30e2\u30ea\u30fc\u3092\u8868\u793a\"\n\nChatGPT: [tags=['fastapi']\u3067memory_search\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"FastAPI\u3068Django\u306e\u4e3b\u306a\u9055\u3044\u306f\u4f55\u3067\u3059\u304b?\"\n\nChatGPT: [memory_recall\u3092\u4f7f\u7528]\n         \"FastAPI: \u975e\u540c\u671f\u30673\u500d\u9ad8\u901f\u3001\u3088\u308a\u826f\u3044\u578b\u5b89\u5168\u6027\n          Django: \u3088\u308a\u591a\u304f\u306e\u30d0\u30c3\u30c6\u30ea\u30fc\u540c\u68b1\u3001\u5927\u304d\u306a\u30a8\u30b3\u30b7\u30b9\u30c6\u30e0\"\n</code></pre>"},{"location":"examples/chatgpt-workflow/#_5","title":"\u30e1\u30ea\u30c3\u30c8","text":"<ul> <li>\u2705 \u30ca\u30ec\u30c3\u30b8\u4fdd\u6301: \u5b66\u3093\u3060\u3053\u3068\u3092\u6c7a\u3057\u3066\u5fd8\u308c\u306a\u3044</li> <li>\u2705 \u6574\u7406: \u7c21\u5358\u306a\u53d6\u5f97\u306e\u305f\u3081\u306e\u30bf\u30b0</li> <li>\u2705 \u30de\u30eb\u30c1\u30bd\u30fc\u30b9: YouTube\u3001Web\u3001arXiv\u3001\u3059\u3079\u3066\u4e00\u7b87\u6240\u306b</li> <li>\u2705 \u691c\u7d22\u53ef\u80fd: \u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u691c\u7d22\u304c\u95a2\u9023\u30c8\u30d4\u30c3\u30af\u3092\u898b\u3064\u3051\u308b</li> </ul>"},{"location":"examples/chatgpt-workflow/#3_1","title":"\ud83d\udcbb \u30ef\u30fc\u30af\u30d5\u30ed\u30fc3: \u30b3\u30fc\u30c9\u958b\u767a\u3068\u30a8\u30e9\u30fc\u8ffd\u8de1","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: \u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30bb\u30c3\u30b7\u30e7\u30f3\u3001\u30a8\u30e9\u30fc\u3001\u5c06\u6765\u306e\u53c2\u7167\u306e\u305f\u3081\u306e\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3\u3092\u8ffd\u8de1</p>"},{"location":"examples/chatgpt-workflow/#python","title":"\u4f8b: Python\u30a8\u30e9\u30fc\u306e\u30c7\u30d0\u30c3\u30b0","text":"<pre><code>\u30e6\u30fc\u30b6\u30fc: \"'\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u63a5\u7d9a\u554f\u984c\u306e\u4fee\u6b63'\u306e\u305f\u3081\u306e\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u958b\u59cb\"\n\nChatGPT: [coding_start_session\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"\u3053\u306e\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3057\u3066\u3044\u307e\u3059:\n       psycopg2.OperationalError: could not connect to server:\n       Connection refused\"\n\nChatGPT: \"\u904e\u53bb\u306e\u985e\u4f3c\u30a8\u30e9\u30fc\u3092\u691c\u7d22\u3055\u305b\u3066\u304f\u3060\u3055\u3044\"\n         [coding_search_errors\u3092\u4f7f\u7528]\n\n         \"2\u9031\u9593\u524d\u306b\u985e\u4f3c\u306e\u30a8\u30e9\u30fc\u306b\u906d\u9047\u3057\u307e\u3057\u305f\u3002\u89e3\u6c7a\u7b56\u306f:\n          PostgreSQL\u304c\u5b9f\u884c\u4e2d\u304b\u78ba\u8a8d: sudo systemctl start postgresql\"\n\n\u30e6\u30fc\u30b6\u30fc: \"\u305d\u308c\u3067\u76f4\u308a\u307e\u3057\u305f! \u3053\u306e\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3\u3092\u8a18\u9332\u3057\u3066\u3002\"\n\nChatGPT: [\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3\u4ed8\u304d\u3067coding_record_error\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"\u63a5\u7d9a\u30b3\u30fc\u30c9\u306b\u30ea\u30c8\u30e9\u30a4\u30ed\u30b8\u30c3\u30af\u3082\u8ffd\u52a0\u3057\u307e\u3057\u305f\"\n\nChatGPT: \"\u7d20\u6674\u3089\u3057\u3044\u8a2d\u8a08\u6c7a\u5b9a\u3067\u3059\u3002\u8a18\u9332\u3055\u305b\u3066\u304f\u3060\u3055\u3044\u3002\"\n         [coding_record_decision\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"PostgreSQL\u63a5\u7d9a\u30d7\u30fc\u30ea\u30f3\u30b0\u306e\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\u3092Web\u3067\u691c\u7d22\"\n\nChatGPT: [brave_web_search\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"tags=['postgresql', 'connection-pooling', 'best-practice']\u3067\u3053\u308c\u3092\u899a\u3048\u3066:\n       \u672c\u756a\u74b0\u5883\u3067\u306f\u63a5\u7d9a\u30d7\u30fc\u30ea\u30f3\u30b0\u306bpgBouncer\u3092\u4f7f\u7528\u3002\n       \u6700\u5927\u30d7\u30fc\u30eb\u30b5\u30a4\u30ba = (2 \u00d7 CPU\u30b3\u30a2) + \u30c7\u30a3\u30b9\u30af\u6570\"\n\nChatGPT: [memory_store\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u7d42\u4e86\u3057\u3066\u8981\u7d04\u3092\u751f\u6210\"\n\nChatGPT: [coding_end_session\u3092\u4f7f\u7528]\n         \"\u8981\u7d04: PostgreSQL\u63a5\u7d9a\u30a8\u30e9\u30fc\u3092\u4fee\u6b63\u3002\u30ea\u30c8\u30e9\u30a4\u30ed\u30b8\u30c3\u30af\u3092\u8ffd\u52a0\u3002\n          \u63a5\u7d9a\u30d7\u30fc\u30ea\u30f3\u30b0\u306e\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\u3092\u7814\u7a76\u3002\n          \u5909\u66f4\u3055\u308c\u305f\u30d5\u30a1\u30a4\u30eb: 1 (database.py)\n          \u30b3\u30b9\u30c8: $0.08\"\n</code></pre>"},{"location":"examples/chatgpt-workflow/#_6","title":"\u5f8c\u3067: \u985e\u4f3c\u30a8\u30e9\u30fc\u306b\u906d\u9047","text":"<pre><code>\u30e6\u30fc\u30b6\u30fc: \"\u307e\u305f'Connection refused'\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3057\u3066\u3044\u307e\u3059\"\n\nChatGPT: [coding_search_errors\u3092\u4f7f\u7528]\n         \"\u4ee5\u524d\u306b\u898b\u305f\u3053\u3068\u304c\u3042\u308a\u307e\u3059! \u89e3\u6c7a\u7b56:\n          1. PostgreSQL\u304c\u5b9f\u884c\u4e2d\u304b\u78ba\u8a8d\n          2. database.py\u306b\u30ea\u30c8\u30e9\u30a4\u30ed\u30b8\u30c3\u30af\u3092\u8ffd\u52a0\u3057\u307e\u3057\u305f\n          3. \u30d7\u30fc\u30ea\u30f3\u30b0\u306bpgBouncer\u306e\u4f7f\u7528\u3092\u691c\u8a0e\"\n\n\u30e6\u30fc\u30b6\u30fc: \"\u63a5\u7d9a\u30d7\u30fc\u30ea\u30f3\u30b0\u306e\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\u306f\u4f55\u3067\u3057\u305f\u304b?\"\n\nChatGPT: [memory_search\u3092\u4f7f\u7528]\n         \"\u3042\u306a\u305f\u304c\u5b66\u3093\u3060\u3053\u3068: \u672c\u756a\u74b0\u5883\u3067pgBouncer\u3092\u4f7f\u7528\u3002\n          \u6700\u5927\u30d7\u30fc\u30eb\u30b5\u30a4\u30ba = (2 \u00d7 CPU\u30b3\u30a2) + \u30c7\u30a3\u30b9\u30af\u6570\"\n</code></pre>"},{"location":"examples/chatgpt-workflow/#_7","title":"\u30e1\u30ea\u30c3\u30c8","text":"<ul> <li>\u2705 \u30a8\u30e9\u30fc\u5c65\u6b74: \u540c\u3058\u554f\u984c\u3092\u4e8c\u5ea6\u3068\u30c7\u30d0\u30c3\u30b0\u3057\u306a\u3044</li> <li>\u2705 \u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3\u8ffd\u8de1: \u4f55\u304c\u6a5f\u80fd\u3057\u305f\u304b\u3092\u899a\u3048\u3066\u3044\u308b</li> <li>\u2705 \u8a2d\u8a08\u6c7a\u5b9a: \u306a\u305c\u305d\u306e\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3\u3092\u9078\u3093\u3060\u304b\u3092\u6587\u66f8\u5316</li> <li>\u2705 \u30d1\u30bf\u30fc\u30f3\u5b66\u7fd2: AI\u304c\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30d1\u30bf\u30fc\u30f3\u3092\u5206\u6790</li> </ul>"},{"location":"examples/chatgpt-workflow/#4","title":"\ud83c\udfa8 \u30ef\u30fc\u30af\u30d5\u30ed\u30fc4: \u30b3\u30f3\u30c6\u30f3\u30c4\u4f5c\u6210\u3068\u57f7\u7b46","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: \u6c38\u7d9a\u7684\u30e1\u30e2\u30ea\u30fc\u3067\u7814\u7a76\u3001\u4e0b\u66f8\u304d\u3001\u30b3\u30f3\u30c6\u30f3\u30c4\u3092\u6d17\u7df4</p>"},{"location":"examples/chatgpt-workflow/#_8","title":"\u4f8b: \u30d6\u30ed\u30b0\u6295\u7a3f\u3092\u66f8\u304f","text":"<pre><code>\u30e6\u30fc\u30b6\u30fc: \"'\u306a\u305cFastAPI\u306fML API\u306b\u6700\u9069\u304b'\u306b\u3064\u3044\u3066\u30d6\u30ed\u30b0\u6295\u7a3f\u3092\u66f8\u3044\u3066\u3044\u307e\u3059\u3002\n       \u3053\u308c\u3092\u8ffd\u8de1\u958b\u59cb\u3057\u3066\u3002\"\n\nChatGPT: [coding_start_session\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"\u6700\u65b0\u306eFastAPI\u63a1\u7528\u7d71\u8a08\u3092Web\u3067\u691c\u7d22\"\n\nChatGPT: [brave_web_search\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"tags=['fastapi', 'adoption', 'blog']\u3067\u3053\u308c\u3089\u306e\u7d71\u8a08\u3092\u899a\u3048\u3066:\n       - GitHub \u30b9\u30bf\u30fc 50K+\n       - Netflix\u3001Uber\u3001Microsoft\u3067\u4f7f\u7528\n       - \u975e\u540c\u671f\u3067Flask\u3088\u308a3\u500d\u9ad8\u901f\"\n\nChatGPT: [memory_store\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"ML\u30b5\u30fc\u30d3\u30f3\u30b0\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306b\u95a2\u3059\u308b\u7814\u7a76\u8ad6\u6587\u3092\u691c\u7d22\"\n\nChatGPT: [arxiv_search\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"\u672c\u756a\u74b0\u5883\u3067\u306eFastAPI\u306b\u95a2\u3059\u308bYouTube\u30c8\u30fc\u30af\u3092\u691c\u7d22\"\n\nChatGPT: [brave_video_search\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"\u3053\u306e\u30c8\u30fc\u30af\u3092\u8981\u7d04: [URL]\"\n\nChatGPT: [youtube_summarize\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"tags=['blog', 'outline']\u3067\u3053\u306e\u30a2\u30a6\u30c8\u30e9\u30a4\u30f3\u3092\u4fdd\u5b58:\n       1. \u5c0e\u5165 (FastAPI\u63a1\u7528)\n       2. \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u30d9\u30f3\u30c1\u30de\u30fc\u30af\n       3. ML\u56fa\u6709\u306e\u6a5f\u80fd (Pydantic\u3001\u975e\u540c\u671f)\n       4. \u672c\u756a\u74b0\u5883\u306e\u30b1\u30fc\u30b9\u30b9\u30bf\u30c7\u30a3\n       5. \u7d50\u8ad6\"\n\nChatGPT: [memory_store\u3092\u4f7f\u7528]\n</code></pre>"},{"location":"examples/chatgpt-workflow/#_9","title":"\u6b21\u306e\u30bb\u30c3\u30b7\u30e7\u30f3: \u4e0b\u66f8\u304d\u3092\u66f8\u304f","text":"<pre><code>\u30e6\u30fc\u30b6\u30fc: \"\u30d6\u30ed\u30b0\u6295\u7a3f\u306e\u30a2\u30a6\u30c8\u30e9\u30a4\u30f3\u3092\u8868\u793a\"\n\nChatGPT: [memory_recall\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"\u53ce\u96c6\u3057\u305f\u7d71\u8a08\u306f\u4f55\u3067\u3059\u304b?\"\n\nChatGPT: [tags=['fastapi', 'adoption']\u3067memory_search\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"\u5c0e\u5165\u3092\u7d42\u3048\u307e\u3057\u305f\u3002\u3053\u306e\u5909\u66f4\u3092\u8ffd\u8de1\u3057\u3066\u3002\"\n\nChatGPT: [coding_track_file_change\u3092\u4f7f\u7528]\n</code></pre>"},{"location":"examples/chatgpt-workflow/#_10","title":"\u6700\u5f8c\u306e\u30bb\u30c3\u30b7\u30e7\u30f3: \u516c\u958b","text":"<pre><code>\u30e6\u30fc\u30b6\u30fc: \"\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u7d42\u4e86\u3057\u3066\u57f7\u7b46\u30ed\u30b0\u306e\u8981\u7d04\u3092\u751f\u6210\"\n\nChatGPT: [coding_end_session\u3092\u4f7f\u7528]\n         \"\u30d6\u30ed\u30b0\u6295\u7a3f\u5b8c\u6210: '\u306a\u305cFastAPI\u306fML API\u306b\u6700\u9069\u304b'\n          \u7814\u7a76: 5\u3064\u306eWeb\u30bd\u30fc\u30b9\u30013\u3064\u306e\u8ad6\u6587\u30012\u3064\u306eYouTube\u30c8\u30fc\u30af\n          \u30bb\u30af\u30b7\u30e7\u30f3: 5 (\u3059\u3079\u3066\u5b8c\u4e86)\n          \u30b3\u30b9\u30c8: $0.22\"\n\n\u30e6\u30fc\u30b6\u30fc: \"2025\u5e7411\u670810\u65e5\u306b\u516c\u958b\u3059\u308b\u3053\u3068\u3092\u899a\u3048\u3066\"\n\nChatGPT: [tags=['blog', 'deadline']\u3067memory_store\u3092\u4f7f\u7528]\n</code></pre>"},{"location":"examples/chatgpt-workflow/#_11","title":"\u30e1\u30ea\u30c3\u30c8","text":"<ul> <li>\u2705 \u7814\u7a76\u6574\u7406: \u3059\u3079\u3066\u306e\u30bd\u30fc\u30b9\u304c\u4e00\u7b87\u6240\u306b</li> <li>\u2705 \u30d0\u30fc\u30b8\u30e7\u30f3\u8ffd\u8de1: \u30a2\u30a6\u30c8\u30e9\u30a4\u30f3\u3068\u4e0b\u66f8\u304d\u306e\u5909\u66f4\u3092\u8ffd\u8de1</li> <li>\u2705 \u30af\u30ed\u30b9\u30bb\u30c3\u30b7\u30e7\u30f3: \u3044\u3064\u3067\u3082\u4f5c\u696d\u3092\u518d\u958b</li> <li>\u2705 AI\u8981\u7d04: \u81ea\u52d5\u9032\u6357\u8981\u7d04</li> </ul>"},{"location":"examples/chatgpt-workflow/#5","title":"\ud83d\udcca \u30ef\u30fc\u30af\u30d5\u30ed\u30fc5: \u30c7\u30fc\u30bf\u5206\u6790\u3068\u30a4\u30f3\u30b5\u30a4\u30c8","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: \u81ea\u5206\u306e\u30a4\u30f3\u30bf\u30e9\u30af\u30b7\u30e7\u30f3\u30d1\u30bf\u30fc\u30f3\u3068\u8208\u5473\u3092\u5206\u6790</p>"},{"location":"examples/chatgpt-workflow/#_12","title":"\u4f8b: \u81ea\u5df1\u7701\u5bdf","text":"<pre><code>\u30e6\u30fc\u30b6\u30fc: \"\u904e\u53bb1\u304b\u6708\u306e\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30d1\u30bf\u30fc\u30f3\u3092\u5206\u6790\"\n\nChatGPT: [coding_analyze_patterns\u3092\u4f7f\u7528]\n         \"\u3042\u306a\u305f\u306e\u30d1\u30bf\u30fc\u30f3:\n          - \u4e3b\u8981\u8a00\u8a9e: Python (85%)\n          - \u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af: FastAPI (60%)\u3001Django (25%)\u3001Flask (15%)\n          - \u6700\u3082\u4e00\u822c\u7684\u306a\u30a8\u30e9\u30fc: \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u63a5\u7d9a (12\u56de)\n          - \u30d4\u30fc\u30af\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u6642\u9593: \u5348\u524d9-11\u6642\u3001\u5348\u5f8c2-4\u6642\n          - \u5e73\u5747\u30bb\u30c3\u30b7\u30e7\u30f3: 2.3\u6642\u9593\"\n\n\u30e6\u30fc\u30b6\u30fc: \"\u79c1\u304c\u6700\u3082\u30a4\u30f3\u30bf\u30e9\u30af\u30b7\u30e7\u30f3\u3059\u308b\u30c8\u30d4\u30c3\u30af\u306f\u4f55\u3067\u3059\u304b?\"\n\nChatGPT: [memory_get_user_pattern\u3092\u4f7f\u7528]\n         \"\u3042\u306a\u305f\u306e\u30c8\u30c3\u30d7\u8208\u5473:\n          1. \u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u958b\u767a (FastAPI\u3001Django)\n          2. \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u6700\u9069\u5316 (PostgreSQL)\n          3. API\u8a2d\u8a08\n          4. \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u4f5c\u6210\n          5. Python\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\"\n\n\u30e6\u30fc\u30b6\u30fc: \"\u30e1\u30e2\u30ea\u30fc\u7d71\u8a08\u3092\u8868\u793a\"\n\nChatGPT: [memory_stats\u3092\u4f7f\u7528]\n         \"\u30e1\u30e2\u30ea\u30fc\u30d8\u30eb\u30b9\u30ec\u30dd\u30fc\u30c8:\n          - \u7dcf\u30e1\u30e2\u30ea\u30fc: 342\n          - \u6c38\u7d9a\u7684: 198 (57.8%)\n          - \u30ef\u30fc\u30ad\u30f3\u30b0: 144 (42.2%)\n          - \u30c8\u30c3\u30d7\u30bf\u30b0: python (87)\u3001fastapi (56)\u3001tutorial (42)\n          - \u30b9\u30c8\u30ec\u30fc\u30b8: 2.4 MB\n          - \u6700\u5f8c\u306e\u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7: 3\u65e5\u524d\"\n\n\u30e6\u30fc\u30b6\u30fc: \"\u6700\u3082\u6709\u7528\u306a\u30e1\u30e2\u30ea\u30fc\u306f\u4f55\u3067\u3059\u304b?\"\n\nChatGPT: [\u30d5\u30a3\u30eb\u30bf\u30fc\u4ed8\u304d\u3067memory_list\u3092\u4f7f\u7528]\n         \"\u30c8\u30c3\u30d7\u8a55\u4fa1\u30e1\u30e2\u30ea\u30fc (\u6709\u7528\u6027\u30b9\u30b3\u30a2\u306b\u3088\u308b):\n          1. PostgreSQL\u63a5\u7d9a\u30d7\u30fc\u30ea\u30f3\u30b0\u306e\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9 (0.95)\n          2. FastAPI vs Django\u6bd4\u8f03 (0.92)\n          3. Python\u578b\u30d2\u30f3\u30c8\u30ac\u30a4\u30c9 (0.88)\"\n</code></pre>"},{"location":"examples/chatgpt-workflow/#_13","title":"\u30e1\u30ea\u30c3\u30c8","text":"<ul> <li>\u2705 \u81ea\u5df1\u8a8d\u8b58: \u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u7fd2\u6163\u3092\u7406\u89e3</li> <li>\u2705 \u8208\u5473\u8ffd\u8de1: \u6c17\u306b\u304b\u3051\u3066\u3044\u308b\u30c8\u30d4\u30c3\u30af\u3092\u78ba\u8a8d</li> <li>\u2705 \u30e1\u30e2\u30ea\u30fc\u30d8\u30eb\u30b9: \u30e1\u30e2\u30ea\u30fc\u4f7f\u7528\u3092\u76e3\u8996\u30fb\u6700\u9069\u5316</li> <li>\u2705 \u54c1\u8cea\u30e1\u30c8\u30ea\u30af\u30b9: \u6700\u3082\u4fa1\u5024\u306e\u3042\u308b\u30e1\u30e2\u30ea\u30fc\u3092\u7279\u5b9a</li> </ul>"},{"location":"examples/chatgpt-workflow/#6","title":"\ud83d\udd04 \u30ef\u30fc\u30af\u30d5\u30ed\u30fc6: \u30af\u30ed\u30b9\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u7d99\u7d9a\u6027","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: ChatGPT\u3067\u4f5c\u696d\u3092\u958b\u59cb\u3057\u3001Claude Desktop/Code\u3067\u7d9a\u884c</p>"},{"location":"examples/chatgpt-workflow/#chatgpt-web","title":"\u671d: ChatGPT (Web)","text":"<pre><code>\u30e6\u30fc\u30b6\u30fc: \"user_id='john_doe'\u7528\u306b\u899a\u3048\u3066: \u4eca\u65e5\u306e\u30bf\u30b9\u30af\u306f\n       FastAPI\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306bOAuth2\u8a8d\u8a3c\u3092\u5b9f\u88c5\u3059\u308b\u3053\u3068\"\n\nChatGPT: [user_id=\"john_doe\"\u3067memory_store\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"OAuth2\u306e\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\u3092\u691c\u7d22\"\n\nChatGPT: [brave_web_search\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"tags=['oauth2', 'plan']\u3067\u3053\u306e\u5b9f\u88c5\u8a08\u753b\u3092\u4fdd\u5b58:\n       1. python-jose\u3001passlib\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n       2. \u30e6\u30fc\u30b6\u30fc\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\n       3. \u30c8\u30fc\u30af\u30f3\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u3092\u5b9f\u88c5\n       4. \u4fdd\u8b77\u3055\u308c\u305f\u30eb\u30fc\u30c8\u3092\u8ffd\u52a0\n       5. \u30c6\u30b9\u30c8\u3092\u66f8\u304f\"\n\nChatGPT: [memory_store\u3092\u4f7f\u7528]\n</code></pre>"},{"location":"examples/chatgpt-workflow/#claude-desktop","title":"\u5348\u5f8c: Claude Desktop (\u30ed\u30fc\u30ab\u30eb)","text":"<pre><code>\u30e6\u30fc\u30b6\u30fc: \"user_id='john_doe'\u7528\u306b\u4eca\u65e5\u8a2d\u5b9a\u3057\u305f\u30bf\u30b9\u30af\u306f\u4f55\u3067\u3059\u304b?\"\n\nClaude: [user_id=\"john_doe\"\u3067memory_recall\u3092\u4f7f\u7528]\n        \"\u4eca\u65e5\u306e\u30bf\u30b9\u30af: FastAPI\u3067OAuth2\u8a8d\u8a3c\u3092\u5b9f\u88c5\"\n\n\u30e6\u30fc\u30b6\u30fc: \"\u5b9f\u88c5\u8a08\u753b\u3092\u8868\u793a\"\n\nClaude: [tags=['oauth2', 'plan']\u3067memory_search\u3092\u4f7f\u7528]\n\n\u30e6\u30fc\u30b6\u30fc: \"\u73fe\u5728\u306eauth.py\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u3093\u3067\"\n\nClaude: [file_read\u3092\u4f7f\u7528 - Local MCP\u306e\u307f]\n\n\u30e6\u30fc\u30b6\u30fc: \"\u30b9\u30c6\u30c3\u30d71-3\u3092\u5b9f\u88c5\u3057\u307e\u3057\u305f\u3002user_id='john_doe'\u7528\u306b\u3053\u308c\u3089\u306e\u5909\u66f4\u3092\u8ffd\u8de1\"\n\nClaude: [coding_track_file_change\u3092\u4f7f\u7528]\n</code></pre>"},{"location":"examples/chatgpt-workflow/#chatgpt","title":"\u5915\u65b9: ChatGPT (\u30e2\u30d0\u30a4\u30eb)","text":"<pre><code>\u30e6\u30fc\u30b6\u30fc: \"user_id='john_doe'\u304cOAuth2\u3067\u4f55\u306e\u9032\u6357\u3092\u3057\u307e\u3057\u305f\u304b?\"\n\nChatGPT: [memory_search + coding session history\u3092\u4f7f\u7528]\n         \"\u30b9\u30c6\u30c3\u30d71-3\u3092\u5b8c\u4e86:\n          1. \u2705 \u4f9d\u5b58\u95a2\u4fc2\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n          2. \u2705 \u30e6\u30fc\u30b6\u30fc\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\n          3. \u2705 \u30c8\u30fc\u30af\u30f3\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u3092\u5b9f\u88c5\n          \u6b8b\u308a: \u4fdd\u8b77\u3055\u308c\u305f\u30eb\u30fc\u30c8\u3001\u30c6\u30b9\u30c8\"\n</code></pre>"},{"location":"examples/chatgpt-workflow/#_14","title":"\u30e1\u30ea\u30c3\u30c8","text":"<ul> <li>\u2705 \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u72ec\u7acb\u6027: \u30c7\u30d0\u30a4\u30b9\u9593\u3067\u30b7\u30fc\u30e0\u30ec\u30b9\u306b\u4f5c\u696d</li> <li>\u2705 \u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u4fdd\u6301: \u73fe\u5728\u5730\u3092\u6c7a\u3057\u3066\u5931\u308f\u306a\u3044</li> <li>\u2705 \u7d71\u4e00\u30e1\u30e2\u30ea\u30fc: \u552f\u4e00\u306e\u771f\u5b9f\u306e\u30bd\u30fc\u30b9</li> <li>\u2705 \u67d4\u8edf\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc: \u5404\u30bf\u30b9\u30af\u306b\u6700\u9069\u306a\u30c4\u30fc\u30eb\u3092\u4f7f\u7528</li> </ul>"},{"location":"examples/chatgpt-workflow/#_15","title":"\ud83d\udca1 \u30d7\u30ed\u306e\u30d2\u30f3\u30c8","text":""},{"location":"examples/chatgpt-workflow/#1-user_id","title":"1. \u4e00\u8cab\u3057\u305fuser_id\u3092\u4f7f\u7528","text":"<p>\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u9593\u3067\u5e38\u306b\u540c\u3058 <code>user_id</code> \u3092\u6307\u5b9a:</p> <pre><code>\"user_id='john_doe'\u7528\u306b\u899a\u3048\u3066: [\u60c5\u5831]\"\n</code></pre>"},{"location":"examples/chatgpt-workflow/#2_2","title":"2. \u3059\u3079\u3066\u306b\u30bf\u30b0\u3092\u4ed8\u3051\u308b","text":"<p>\u30bf\u30b0\u306f\u53d6\u5f97\u3092\u7c21\u5358\u306b\u3057\u307e\u3059:</p> <pre><code>\"tags=['python', 'best-practice', 'typing']\u3067\u3053\u308c\u3092\u4fdd\u5b58: ...\"\n</code></pre>"},{"location":"examples/chatgpt-workflow/#3_2","title":"3. \u6c38\u7d9a\u6027\u306b\u3064\u3044\u3066\u660e\u793a\u7684\u306b","text":"<p>\u30c7\u30d5\u30a9\u30eb\u30c8\u306b\u4f9d\u5b58\u3057\u306a\u3044:</p> <pre><code>\"\u3053\u308c\u3092\u6c38\u4e45\u306b\u899a\u3048\u3066: ...\"\n\"\u3053\u306e\u30bb\u30c3\u30b7\u30e7\u30f3\u7528\u306b\u4e00\u6642\u7684\u306b\u3053\u308c\u3092\u4fdd\u5b58: ...\"\n</code></pre>"},{"location":"examples/chatgpt-workflow/#4_1","title":"4. \u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u691c\u7d22\u3092\u4f7f\u7528","text":"<p>\u6b63\u78ba\u306a\u30ad\u30fc\u30ef\u30fc\u30c9\u3092\u691c\u7d22\u3057\u306a\u3044:</p> <pre><code>\u2705 \"\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u6700\u9069\u5316\u306b\u95a2\u3059\u308b\u30e1\u30e2\u30ea\u30fc\u3092\u691c\u7d22\"\n\u274c \"\u30ad\u30fc'postgresql_connection_pooling_2024'\u3067\u30e1\u30e2\u30ea\u30fc\u3092\u691c\u7d22\"\n</code></pre>"},{"location":"examples/chatgpt-workflow/#5_1","title":"5. \u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\u3092\u63d0\u4f9b","text":"<p>Kagura\u304c\u4f55\u304c\u6709\u7528\u304b\u3092\u5b66\u3076\u306e\u3092\u52a9\u3051\u308b:</p> <pre><code>\"\u3053\u306e\u30e1\u30e2\u30ea\u30fc\u3092\u975e\u5e38\u306b\u6709\u7528\u3068\u3057\u3066\u30de\u30fc\u30af\"\n\"\u3053\u306e\u60c5\u5831\u306f\u53e4\u304f\u306a\u3063\u3066\u3044\u307e\u3059\"\n</code></pre>"},{"location":"examples/chatgpt-workflow/#_16","title":"\ud83d\udd17 \u95a2\u9023\u30ea\u30bd\u30fc\u30b9","text":"<ul> <li>\u30c1\u30e3\u30c3\u30c8\u7d71\u5408\u306e\u30d2\u30f3\u30c8 - \u30e1\u30a4\u30f3\u30ac\u30a4\u30c9</li> <li>Claude\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u4f8b - Claude\u56fa\u6709\u306e\u30ef\u30fc\u30af\u30d5\u30ed\u30fc</li> <li>MCP\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7 (ChatGPT) - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u30ac\u30a4\u30c9</li> </ul> <p>Version: 4.0.0 Last updated: 2025-11-02</p>"},{"location":"examples/claude-workflow/","title":"Claude + Kagura AI Workflow Examples","text":"<p>Practical workflows for using Kagura AI with Claude Desktop and Claude Code</p> <p>This guide provides real-world workflow examples for integrating Kagura AI with Claude platforms (Desktop and Code) via Local MCP.</p>"},{"location":"examples/claude-workflow/#setup","title":"\ud83d\udccb Setup","text":""},{"location":"examples/claude-workflow/#prerequisites","title":"Prerequisites","text":"<p>Claude Desktop: 1. Kagura installed: <code>pip install kagura-ai[full]</code> 2. MCP configured: <code>kagura mcp install</code> 3. Claude Desktop restarted</p> <p>Claude Code: 1. Kagura installed: <code>pip install kagura-ai[full]</code> 2. MCP added: <code>claude mcp add --transport stdio kagura -- kagura mcp serve</code> 3. Verify: <code>claude mcp list</code></p> <p>See: - Claude Desktop Setup - Claude Code Setup</p>"},{"location":"examples/claude-workflow/#workflow-1-full-stack-development-local-mcp","title":"\ud83d\udcbb Workflow 1: Full-Stack Development (Local MCP)","text":"<p>Use Case: Develop a FastAPI application with full file access and Git integration</p> <p>Unique to Local MCP: File read/write, shell execution, media preview</p>"},{"location":"examples/claude-workflow/#example-building-an-api","title":"Example: Building an API","text":"<pre><code>User: \"Start coding session for 'Build user authentication API'\"\n\nClaude: [Uses coding_start_session]\n\nUser: \"Read the current project structure\"\n\nClaude: [Uses dir_list, file_read]\n        \"Your project:\n         - main.py (FastAPI app)\n         - models.py (User model exists)\n         - auth.py (empty, needs implementation)\"\n\nUser: \"Create an OAuth2 implementation in auth.py\"\n\nClaude: [Uses file_write]\n        \"I've created auth.py with:\n         - TokenData and User schemas\n         - get_current_user dependency\n         - create_access_token function\"\n\nUser: \"Run the tests\"\n\nClaude: [Uses shell_exec - generates command]\n        \"Command: pytest tests/test_auth.py -v\"\n\nUser: \"The tests failed with ImportError. Record this error.\"\n\nClaude: [Uses coding_record_error]\n\nUser: \"Search for similar errors I've had before\"\n\nClaude: [Uses coding_search_errors]\n        \"You had a similar ImportError 5 days ago.\n         Solution: Add __init__.py to auth module\"\n\nUser: \"Fix it and re-run tests\"\n\nClaude: [Uses file_write, shell_exec]\n        \"Fixed! All tests passing \u2705\"\n\nUser: \"Track all these changes\"\n\nClaude: [Uses coding_track_file_change]\n\nUser: \"Create a GitHub issue for documenting this auth system\"\n\nClaude: [Uses github_issue_create via github_exec]\n        \"Created issue #475: 'Document OAuth2 authentication'\"\n\nUser: \"End session and generate PR description\"\n\nClaude: [Uses coding_end_session, coding_generate_pr_description]\n        \"Summary: Implemented OAuth2 authentication\n         Files: auth.py (new), __init__.py (modified)\n         Tests: 12 passing\n         Cost: $0.18\n\n         PR Description:\n         ## What\n         Implement OAuth2 JWT authentication for user endpoints\n\n         ## Why\n         Secure API access with industry-standard authentication\n\n         ## Changes\n         - Add auth.py with JWT token handling\n         - Create User schema and dependencies\n         - Add 12 unit tests\n\n         ## Testing\n         - \u2705 All tests passing\n         - \u2705 Manual testing with Postman\n\n         Closes #475\"\n</code></pre>"},{"location":"examples/claude-workflow/#benefits","title":"Benefits","text":"<ul> <li>\u2705 File Access: Read/write project files directly</li> <li>\u2705 Shell Commands: Run tests, linters, Git commands</li> <li>\u2705 Error Tracking: Learn from past mistakes</li> <li>\u2705 GitHub Integration: Create issues, PRs seamlessly</li> <li>\u2705 AI Summaries: Automatic session summaries + PR descriptions</li> </ul>"},{"location":"examples/claude-workflow/#workflow-2-documentation-writing","title":"\ud83d\udcdd Workflow 2: Documentation Writing","text":"<p>Use Case: Write and preview documentation with live file editing</p>"},{"location":"examples/claude-workflow/#example-writing-api-docs","title":"Example: Writing API Docs","text":"<pre><code>User: \"Start session for 'Write API documentation'\"\n\nClaude: [Uses coding_start_session]\n\nUser: \"Read the current API endpoints from main.py\"\n\nClaude: [Uses file_read]\n        \"Found endpoints:\n         - POST /auth/login\n         - POST /auth/register\n         - GET /users/me\n         - PUT /users/me\n         - DELETE /users/me\"\n\nUser: \"Create API documentation in docs/api.md\"\n\nClaude: [Uses file_write]\n        \"I've created comprehensive API docs with:\n         - Authentication section\n         - All 5 endpoints with examples\n         - Error responses\n         - Rate limiting notes\"\n\nUser: \"Read it back to me to verify\"\n\nClaude: [Uses file_read]\n        [Shows full content]\n\nUser: \"Search the web for API documentation best practices\"\n\nClaude: [Uses brave_web_search]\n\nUser: \"Remember these best practices with tags=['documentation', 'api']:\n       - Use OpenAPI/Swagger spec\n       - Provide curl examples\n       - Document error codes\n       - Include rate limits\n       - Add versioning info\"\n\nClaude: [Uses memory_store]\n\nUser: \"Update the docs with these best practices\"\n\nClaude: [Uses file_write]\n\nUser: \"List all markdown files in docs/\"\n\nClaude: [Uses dir_list]\n\nUser: \"Track this documentation change\"\n\nClaude: [Uses coding_track_file_change]\n\nUser: \"End session with summary\"\n\nClaude: [Uses coding_end_session]\n        \"Documentation session complete:\n         - Created docs/api.md (125 lines)\n         - Researched best practices\n         - Applied improvements\n         Cost: $0.12\"\n</code></pre>"},{"location":"examples/claude-workflow/#benefits_1","title":"Benefits","text":"<ul> <li>\u2705 File Editing: Write docs directly in project</li> <li>\u2705 Content Verification: Read back to check accuracy</li> <li>\u2705 Research Integration: Web search + persistent memory</li> <li>\u2705 Change Tracking: Monitor documentation growth</li> </ul>"},{"location":"examples/claude-workflow/#workflow-3-image-analysis-multimodal-rag","title":"\ud83c\udfa8 Workflow 3: Image Analysis &amp; Multimodal RAG","text":"<p>Use Case: Index project screenshots and find them semantically</p> <p>Requires: Gemini API key</p>"},{"location":"examples/claude-workflow/#example-screenshot-management","title":"Example: Screenshot Management","text":"<pre><code>User: \"Index all images in ./screenshots directory\"\n\nClaude: [Uses dir_list, multimodal_index]\n        \"Indexed 47 images:\n         - UI mockups: 12\n         - Error screenshots: 18\n         - Architecture diagrams: 8\n         - Performance graphs: 9\"\n\nUser: \"Find screenshots of database connection errors\"\n\nClaude: [Uses multimodal_search]\n        \"Found 3 matches:\n         1. error_postgres_connection_refused.png (similarity: 0.92)\n         2. db_timeout_error.png (similarity: 0.87)\n         3. connection_pool_exhausted.png (similarity: 0.81)\"\n\nUser: \"Open the first one\"\n\nClaude: [Uses media_open_image - Local MCP only]\n        \"Opening error_postgres_connection_refused.png...\"\n\nUser: \"This is the error I'm seeing now! What was the solution?\"\n\nClaude: [Uses coding_search_errors]\n        \"You fixed this before:\n         1. Check PostgreSQL is running\n         2. Verify connection string\n         3. Add retry logic\"\n\nUser: \"Remember to create a troubleshooting guide with this screenshot\"\n\nClaude: [Uses memory_store with tags=['todo', 'documentation']]\n</code></pre>"},{"location":"examples/claude-workflow/#benefits_2","title":"Benefits","text":"<ul> <li>\u2705 Visual Memory: Find images by description</li> <li>\u2705 Multi-Language: Works in 100+ languages</li> <li>\u2705 Quick Preview: Open images directly from Claude</li> <li>\u2705 Context Linking: Connect images to solutions</li> </ul>"},{"location":"examples/claude-workflow/#workflow-4-data-analysis-with-csv-files","title":"\ud83d\udd2c Workflow 4: Data Analysis with CSV Files","text":"<p>Use Case: Analyze CSV data with direct file access</p>"},{"location":"examples/claude-workflow/#example-performance-analysis","title":"Example: Performance Analysis","text":"<pre><code>User: \"Read the performance_metrics.csv file\"\n\nClaude: [Uses file_read]\n        \"CSV contains:\n         - Timestamp, endpoint, response_time_ms, status_code\n         - 10,000 rows of API performance data\"\n\nUser: \"Start analyzing this data. Track this session.\"\n\nClaude: [Uses coding_start_session]\n\nUser: \"What's the average response time?\"\n\nClaude: [Analyzes data from file_read]\n        \"Average response time: 245ms\n         Median: 198ms\n         95th percentile: 850ms\n         Slowest endpoint: /api/search (avg 1200ms)\"\n\nUser: \"Search the web for API response time best practices\"\n\nClaude: [Uses brave_web_search]\n\nUser: \"Remember this benchmark with tags=['performance', 'api']:\n       - Excellent: &lt; 100ms\n       - Good: 100-300ms\n       - Acceptable: 300-1000ms\n       - Slow: &gt; 1000ms\"\n\nClaude: [Uses memory_store]\n\nUser: \"Based on this, which endpoints need optimization?\"\n\nClaude: \"According to the benchmark you saved:\n         - /api/search: 1200ms (SLOW - needs optimization)\n         - /api/reports: 780ms (Acceptable, but room for improvement)\n         - All others: Good to Excellent\"\n\nUser: \"Create a GitHub issue to optimize /api/search\"\n\nClaude: [Uses github_issue_create]\n        \"Created Issue #476: 'Optimize /api/search endpoint (1200ms avg)'\"\n\nUser: \"Write analysis summary to performance_analysis.md\"\n\nClaude: [Uses file_write]\n\nUser: \"End session\"\n\nClaude: [Uses coding_end_session]\n        \"Analysis complete:\n         - Analyzed 10,000 API requests\n         - Identified 1 critical optimization target\n         - Created GitHub issue #476\n         - Generated analysis report\n         Cost: $0.09\"\n</code></pre>"},{"location":"examples/claude-workflow/#benefits_3","title":"Benefits","text":"<ul> <li>\u2705 Direct File Access: Read CSV without copy/paste</li> <li>\u2705 Large Data: Handle 10K+ rows efficiently</li> <li>\u2705 Persistent Benchmarks: Save standards for future reference</li> <li>\u2705 Action Items: Create issues directly from analysis</li> </ul>"},{"location":"examples/claude-workflow/#workflow-5-learning-from-video-content","title":"\ud83c\udfa5 Workflow 5: Learning from Video Content","text":"<p>Use Case: Extract and organize knowledge from YouTube tutorials</p>"},{"location":"examples/claude-workflow/#example-learning-docker","title":"Example: Learning Docker","text":"<pre><code>User: \"Search for Docker tutorial videos\"\n\nClaude: [Uses brave_video_search]\n        \"Found:\n         1. 'Docker Tutorial for Beginners' (1.2M views)\n         2. 'Docker Compose in 12 Minutes' (500K views)\n         3. 'Docker Production Best Practices' (300K views)\"\n\nUser: \"Get the transcript for video #1\"\n\nClaude: [Uses get_youtube_transcript]\n        [Returns full transcript]\n\nUser: \"Summarize this tutorial\"\n\nClaude: [Uses youtube_summarize]\n        \"Summary:\n         - Docker basics: containers vs VMs\n         - Key concepts: images, containers, Dockerfile\n         - Commands: docker build, run, ps, stop\n         - Volumes for data persistence\n         - Networks for container communication\"\n\nUser: \"Save this summary with tags=['docker', 'tutorial', 'learning']\"\n\nClaude: [Uses memory_store]\n\nUser: \"Fact-check the claim that 'containers are 10x more efficient than VMs'\"\n\nClaude: [Uses youtube_fact_check]\n        \"Claim verified:\n         - Multiple sources confirm 5-10x resource efficiency\n         - Containers share OS kernel (lighter overhead)\n         - Startup time: containers (seconds) vs VMs (minutes)\n         Sources: Docker docs, research papers, benchmarks\"\n\nUser: \"Remember this with tags=['docker', 'performance', 'verified']\"\n\nClaude: [Uses memory_store]\n\nUser: \"Create a Dockerfile for our FastAPI project based on what I learned\"\n\nClaude: [Uses file_write with knowledge from memory]\n        \"Created Dockerfile:\n         FROM python:3.11-slim\n         WORKDIR /app\n         COPY requirements.txt .\n         RUN pip install -r requirements.txt\n         COPY . .\n         CMD ['uvicorn', 'main:app', '--host', '0.0.0.0']\"\n\nUser: \"Search for Docker security best practices\"\n\nClaude: [Uses brave_web_search]\n\nUser: \"Update the Dockerfile with security improvements\"\n\nClaude: [Uses file_write]\n        \"Updated with best practices:\n         - Non-root user\n         - Multi-stage build\n         - Minimal base image\n         - .dockerignore file\"\n</code></pre>"},{"location":"examples/claude-workflow/#benefits_4","title":"Benefits","text":"<ul> <li>\u2705 Video Learning: Extract knowledge without watching</li> <li>\u2705 Fact Verification: Check claims against web sources</li> <li>\u2705 Applied Learning: Immediately create files based on lessons</li> <li>\u2705 Knowledge Retention: Persistent memory for future reference</li> </ul>"},{"location":"examples/claude-workflow/#workflow-6-refactoring-with-dependency-analysis","title":"\ud83d\udd04 Workflow 6: Refactoring with Dependency Analysis","text":"<p>Use Case: Safely refactor code by understanding dependencies</p>"},{"location":"examples/claude-workflow/#example-refactoring-a-module","title":"Example: Refactoring a Module","text":"<pre><code>User: \"I want to refactor the database.py module. Analyze its dependencies first.\"\n\nClaude: [Uses coding_analyze_file_dependencies]\n        \"database.py dependencies:\n         Imports:\n         - psycopg2 (external)\n         - config (internal: ./config.py)\n         - models (internal: ./models.py)\n\n         Used by (7 files):\n         - main.py (imports: get_db)\n         - auth.py (imports: get_db, User)\n         - api/users.py (imports: get_db)\n         - api/posts.py (imports: get_db)\n         - tests/test_db.py (imports: all functions)\n         - tests/test_api.py (imports: get_db)\n         - migrations/init_db.py (imports: engine)\"\n\nUser: \"What's the safe order to refactor if I also need to update auth.py and models.py?\"\n\nClaude: [Uses coding_suggest_refactor_order]\n        \"Safe refactoring order:\n         1. models.py (no dependencies on others)\n         2. database.py (depends on models)\n         3. auth.py (depends on database, models)\n\n         Reasoning:\n         - models.py is at the bottom of dependency chain\n         - database.py imports models\n         - auth.py imports both\n         - Refactoring bottom-up avoids breaking imports\"\n\nUser: \"Analyze the impact if I change the get_db function signature\"\n\nClaude: [Uses coding_analyze_refactor_impact]\n        \"Impact analysis:\n         \u26a0\ufe0f HIGH IMPACT - get_db is used in 6 files\n\n         Files affected:\n         - main.py: 1 usage\n         - auth.py: 3 usages\n         - api/users.py: 5 usages\n         - api/posts.py: 4 usages\n         - tests/test_api.py: 12 usages\n\n         Recommendation:\n         1. Update function signature\n         2. Update all 25 usages\n         3. Run full test suite\n         4. Consider deprecation warning for gradual migration\"\n\nUser: \"Record this design decision: We'll use async database connections\"\n\nClaude: [Uses coding_record_decision]\n        \"Design decision recorded:\n         - Decision: Migrate to async database connections\n         - Rationale: Better performance for I/O-bound operations\n         - Impact: 6 files affected, 25 usages to update\n         - Risk: High (core dependency)\n         - Mitigation: Full test coverage before deployment\"\n\nUser: \"Start the refactoring. Update models.py first.\"\n\nClaude: [Uses file_read, file_write]\n        \"Updated models.py with async SQLAlchemy support\"\n\nUser: \"Track this change\"\n\nClaude: [Uses coding_track_file_change]\n</code></pre>"},{"location":"examples/claude-workflow/#benefits_5","title":"Benefits","text":"<ul> <li>\u2705 Dependency Awareness: Know what breaks before you break it</li> <li>\u2705 Safe Ordering: Refactor in the right sequence</li> <li>\u2705 Impact Analysis: Understand scope of changes</li> <li>\u2705 Decision Documentation: Record why you made changes</li> </ul>"},{"location":"examples/claude-workflow/#workflow-7-cross-platform-memory-sync","title":"\ud83e\udde0 Workflow 7: Cross-Platform Memory Sync","text":"<p>Use Case: Start in Claude Desktop (local files), continue in Claude Code (CLI)</p>"},{"location":"examples/claude-workflow/#morning-claude-desktop","title":"Morning: Claude Desktop","text":"<pre><code>User: \"Start coding session for 'Implement rate limiting'\"\n\nClaude Desktop: [Uses coding_start_session]\n\nUser: \"Read the current API implementation\"\n\nClaude Desktop: [Uses file_read on main.py]\n\nUser: \"Search the web for rate limiting algorithms\"\n\nClaude Desktop: [Uses brave_web_search]\n\nUser: \"Remember for user_id='john': Use token bucket algorithm with Redis backend.\n       Tags: ['rate-limiting', 'design']\"\n\nClaude Desktop: [Uses memory_store]\n\nUser: \"I need to leave for a meeting. Save my progress.\"\n\nClaude Desktop: [Uses coding_track_file_change]\n</code></pre>"},{"location":"examples/claude-workflow/#afternoon-claude-code-cli","title":"Afternoon: Claude Code (CLI)","text":"<pre><code>$ claude\n\nUser: \"What was I working on for user_id='john'?\"\n\nClaude Code: [Uses memory_search with user_id=\"john\"]\n             \"You were implementing rate limiting using token bucket\n              algorithm with Redis backend\"\n\nUser: \"Show me the design I chose\"\n\nClaude Code: [Uses memory_recall with tags=['rate-limiting', 'design']]\n\nUser: \"Continue the implementation. Install dependencies first.\"\n\nClaude Code: [Uses shell_exec]\n             \"Running: pip install redis fastapi-limiter\"\n\nUser: \"Create rate_limiter.py\"\n\nClaude Code: [Uses file_write]\n\nUser: \"Run tests\"\n\nClaude Code: [Uses shell_exec]\n             \"pytest tests/test_rate_limit.py -v\n              \u2705 5 passing\"\n\nUser: \"End session\"\n\nClaude Code: [Uses coding_end_session]\n             \"Session complete:\n              - Implemented token bucket rate limiting\n              - Added Redis backend\n              - 5 tests passing\n              Cost: $0.14\"\n</code></pre>"},{"location":"examples/claude-workflow/#benefits_6","title":"Benefits","text":"<ul> <li>\u2705 Seamless Transition: Desktop GUI \u2192 CLI without losing context</li> <li>\u2705 Unified Memory: Same user_id, same memories</li> <li>\u2705 Flexible Environment: Use best tool for each task</li> <li>\u2705 Continuous Sessions: Pick up exactly where you left off</li> </ul>"},{"location":"examples/claude-workflow/#pro-tips-for-local-mcp","title":"\ud83d\udca1 Pro Tips for Local MCP","text":""},{"location":"examples/claude-workflow/#1-leverage-file-access","title":"1. Leverage File Access","text":"<p>Use <code>file_read</code> instead of copy/paste:</p> <pre><code>\u2705 \"Read config.py and show me the database settings\"\n\u274c [copy/paste entire file]\n</code></pre>"},{"location":"examples/claude-workflow/#2-safe-shell-execution","title":"2. Safe Shell Execution","text":"<p>Use <code>github_exec</code> for Git operations:</p> <pre><code>\"Execute: gh issue list --state open\"\n\"Run: git status\"\n</code></pre>"},{"location":"examples/claude-workflow/#3-preview-media-files","title":"3. Preview Media Files","text":"<p>Open images/videos directly:</p> <pre><code>\"Show me screenshot.png\"\n[Uses media_open_image]\n</code></pre>"},{"location":"examples/claude-workflow/#4-analyze-dependencies-before-refactoring","title":"4. Analyze Dependencies Before Refactoring","text":"<p>Always check dependencies first:</p> <pre><code>\"Analyze dependencies for auth.py before I refactor it\"\n[Uses coding_analyze_file_dependencies]\n</code></pre>"},{"location":"examples/claude-workflow/#5-track-everything","title":"5. Track Everything","text":"<p>Don't forget to track file changes:</p> <pre><code>After every file modification:\n\"Track this change to database.py\"\n[Uses coding_track_file_change]\n</code></pre>"},{"location":"examples/claude-workflow/#related-resources","title":"\ud83d\udd17 Related Resources","text":"<ul> <li>Chat Integration Tips - Main guide</li> <li>ChatGPT Workflow Examples - ChatGPT-specific workflows</li> <li>Claude Desktop Setup - Setup guide</li> <li>Claude Code Setup - CLI setup</li> </ul> <p>Version: 4.0.0 Last updated: 2025-11-02</p>"},{"location":"guides/claude-code-mcp-setup/","title":"Claude Code MCP Setup","text":"<p>Use all Kagura features from Claude Code with a single configuration.</p>"},{"location":"guides/claude-code-mcp-setup/#quick-setup","title":"Quick Setup","text":""},{"location":"guides/claude-code-mcp-setup/#1-find-your-mcp-configuration-file","title":"1. Find your MCP configuration file","text":"<p>Location (varies by installation): - <code>~/.config/claude-code/mcp.json</code> (Linux/macOS) - <code>~/Library/Application Support/Claude/mcp.json</code> (macOS alternative) - Check Claude Code documentation for exact path</p>"},{"location":"guides/claude-code-mcp-setup/#2-add-kagura-to-mcp-config","title":"2. Add Kagura to MCP config","text":"<p>Edit your MCP config file:</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura-ai\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"]\n    }\n  }\n}\n</code></pre>"},{"location":"guides/claude-code-mcp-setup/#3-restart-claude-code","title":"3. Restart Claude Code","text":"<p>Restart Claude Code to load the new MCP server.</p>"},{"location":"guides/claude-code-mcp-setup/#4-verify","title":"4. Verify","text":"<p>In Claude Code, you should now have access to all Kagura tools:</p> <pre><code>User: List available Kagura tools\nClaude: [Lists all 15+ built-in tools]\n</code></pre>"},{"location":"guides/claude-code-mcp-setup/#available-tools","title":"Available Tools","text":""},{"location":"guides/claude-code-mcp-setup/#memory-operations","title":"Memory Operations","text":"<ul> <li><code>kagura_tool_memory_store</code> - Store information</li> <li><code>kagura_tool_memory_recall</code> - Recall stored information</li> <li><code>kagura_tool_memory_search</code> - Semantic search in memory</li> <li><code>kagura_tool_memory_list</code> - List all stored memories (debugging)</li> </ul>"},{"location":"guides/claude-code-mcp-setup/#web-operations","title":"Web Operations","text":"<ul> <li><code>kagura_tool_web_search</code> - Search the web</li> <li><code>kagura_tool_web_scrape</code> - Scrape web pages</li> </ul>"},{"location":"guides/claude-code-mcp-setup/#filedirectory-operations","title":"File/Directory Operations","text":"<ul> <li><code>kagura_tool_file_read</code> - Read file contents</li> <li><code>kagura_tool_file_write</code> - Write to files</li> <li><code>kagura_tool_dir_list</code> - List directory contents</li> <li><code>kagura_tool_shell_exec</code> - Execute shell commands safely</li> </ul>"},{"location":"guides/claude-code-mcp-setup/#observability","title":"Observability","text":"<ul> <li><code>kagura_tool_telemetry_stats</code> - Get execution statistics</li> <li><code>kagura_tool_telemetry_cost</code> - Analyze costs</li> </ul>"},{"location":"guides/claude-code-mcp-setup/#meta-agent","title":"Meta Agent","text":"<ul> <li><code>kagura_tool_meta_create_agent</code> - Generate new agents</li> </ul>"},{"location":"guides/claude-code-mcp-setup/#multimodal-requires-web-extra","title":"Multimodal (requires <code>web</code> extra)","text":"<ul> <li><code>kagura_tool_multimodal_index</code> - Index multimedia files</li> <li><code>kagura_tool_multimodal_search</code> - Search indexed content</li> </ul>"},{"location":"guides/claude-code-mcp-setup/#usage-examples","title":"Usage Examples","text":""},{"location":"guides/claude-code-mcp-setup/#example-1-memory","title":"Example 1: Memory","text":"<pre><code>User: Remember that my favorite programming language is Python\nClaude: [Uses kagura_tool_memory_store]\n       \u2713 Stored information\n\nUser: What's my favorite language?\nClaude: [Uses kagura_tool_memory_recall]\n       Your favorite programming language is Python\n</code></pre>"},{"location":"guides/claude-code-mcp-setup/#example-2-web-search-file","title":"Example 2: Web Search + File","text":"<pre><code>User: Search for latest Python news and save to news.txt\nClaude: [Uses kagura_tool_web_search]\n       [Uses kagura_tool_file_write]\n       \u2713 Saved to news.txt\n</code></pre>"},{"location":"guides/claude-code-mcp-setup/#example-3-code-generation","title":"Example 3: Code Generation","text":"<pre><code>User: Create a translator agent\nClaude: [Uses kagura_tool_meta_create_agent]\n       Generated agent code...\n</code></pre>"},{"location":"guides/claude-code-mcp-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/claude-code-mcp-setup/#tools-not-appearing","title":"Tools not appearing","text":"<ol> <li>Check MCP config syntax is valid JSON</li> <li>Verify <code>kagura</code> command is in PATH</li> <li>Restart Claude Code completely</li> <li>Check Claude Code logs for errors</li> </ol>"},{"location":"guides/claude-code-mcp-setup/#requires-x-extra-errors","title":"\"requires X extra\" errors","text":"<p>Install required extras:</p> <pre><code># All features\npip install kagura-ai[full]\n\n# Specific features\npip install kagura-ai[ai]     # Memory, Routing\npip install kagura-ai[web]    # Web, Multimodal\n</code></pre>"},{"location":"guides/claude-code-mcp-setup/#permission-errors","title":"Permission errors","text":"<p>Ensure <code>kagura</code> command is executable:</p> <pre><code>which kagura\nchmod +x $(which kagura)\n</code></pre>"},{"location":"guides/claude-code-mcp-setup/#advanced","title":"Advanced","text":""},{"location":"guides/claude-code-mcp-setup/#custom-tools","title":"Custom Tools","text":"<p>You can also expose your own @tool definitions:</p> <pre><code># my_tools.py\nfrom kagura import tool\n\n@tool\ndef custom_calculator(x: float, y: float) -&gt; float:\n    '''Add two numbers'''\n    return x + y\n</code></pre> <p>Just import before starting MCP:</p> <pre><code>python -c \"import my_tools; import kagura.mcp.builtin\" &amp;&amp; kagura mcp serve\n</code></pre> <p>Or create a wrapper script.</p>"},{"location":"guides/cli-performance/","title":"CLI Performance","text":"<p>Kagura CLI uses lazy loading to ensure fast startup times.</p>"},{"location":"guides/cli-performance/#startup-performance","title":"Startup Performance","text":"<p>Before optimization: <code>kagura --help</code> took 8.8 seconds</p> <p>After optimization: <code>kagura --help</code> takes 0.1 seconds (98.9% faster!)</p>"},{"location":"guides/cli-performance/#how-it-works","title":"How It Works","text":""},{"location":"guides/cli-performance/#lazy-loading","title":"Lazy Loading","text":"<p>Subcommands are imported only when invoked:</p> <pre><code># Before (slow)\nfrom .mcp import mcp          # Always imported - 393ms!\nfrom .monitor import monitor  # Always imported\n\n# After (fast)\n@click.group(cls=LazyGroup, lazy_subcommands={\n    \"mcp\": (\"kagura.cli.mcp\", \"mcp\", \"MCP commands\"),     # Import on demand\n    \"monitor\": (\"kagura.cli.monitor\", \"monitor\", \"Monitor telemetry\"),\n})\n</code></pre> <p>Benefits: - <code>kagura --help</code>: No heavy modules loaded - <code>kagura chat</code>: Only chat module loaded - <code>kagura mcp start</code>: Only MCP module loaded</p>"},{"location":"guides/cli-performance/#module-level-lazy-imports","title":"Module-level Lazy Imports","text":"<p>The main <code>kagura</code> package also uses lazy imports via <code>__getattr__</code>:</p> <pre><code># kagura/__init__.py\n\ndef __getattr__(name: str):\n    \"\"\"Lazy import attributes on demand\"\"\"\n    if name == \"agent\":\n        from .core.decorators import agent\n        return agent\n    # ...\n</code></pre> <p>Benefits: - CLI startup doesn't load decorators, memory, etc. - User code loads only what it needs</p>"},{"location":"guides/cli-performance/#performance-metrics","title":"Performance Metrics","text":"Command Before After Improvement <code>kagura --help</code> 8.8s 0.1s 98.9% faster <code>kagura version</code> 8.8s 0.1s 98.9% faster <code>kagura chat</code> 8.8s 0.5s 94.3% faster <code>kagura mcp start</code> 8.8s 1.0s 88.6% faster"},{"location":"guides/cli-performance/#adding-new-commands","title":"Adding New Commands","text":"<p>When adding a new CLI command, use lazy loading to maintain performance:</p> <pre><code># src/kagura/cli/main.py\n\n@click.group(cls=LazyGroup, lazy_subcommands={\n    # Add your command here\n    \"mycommand\": (\"kagura.cli.mycommand\", \"mycommand\", \"My command description\"),\n})\ndef cli():\n    pass\n</code></pre> <p>Guidelines: 1. Always add new commands to <code>lazy_subcommands</code> 2. Provide a short description (third tuple element) 3. Avoid top-level imports in <code>main.py</code></p>"},{"location":"guides/cli-performance/#benchmarking","title":"Benchmarking","text":""},{"location":"guides/cli-performance/#measure-startup-time","title":"Measure Startup Time","text":"<pre><code># Overall time\ntime kagura --help\n\n# Import time only\npython -c \"\nimport time\nstart = time.time()\nfrom kagura.cli.main import cli\nprint(f'Import: {(time.time()-start)*1000:.0f}ms')\n\"\n</code></pre>"},{"location":"guides/cli-performance/#profile-imports","title":"Profile Imports","text":"<pre><code># Detailed import profiling\npython -X importtime -c \"from kagura.cli.main import cli\" 2&gt;&amp;1 | tail -50\n</code></pre>"},{"location":"guides/cli-performance/#expected-results","title":"Expected Results","text":"<ul> <li>CLI import: &lt; 50ms</li> <li><code>kagura --help</code>: &lt; 200ms</li> <li>No heavy modules (mcp, observability) loaded on <code>--help</code></li> </ul>"},{"location":"guides/cli-performance/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/cli-performance/#q-my-command-is-slow-to-start","title":"Q: My command is slow to start","text":"<p>A: Check if you're importing heavy modules at the top level:</p> <pre><code># Bad - imports immediately\nfrom heavy_module import something\n\n@click.command()\ndef mycommand():\n    pass\n\n# Good - imports on execution\n@click.command()\ndef mycommand():\n    from heavy_module import something  # Import here\n    pass\n</code></pre>"},{"location":"guides/cli-performance/#q-how-do-i-know-if-a-module-is-heavy","title":"Q: How do I know if a module is heavy?","text":"<p>A: Use <code>python -X importtime</code>:</p> <pre><code>python -X importtime -c \"import my_module\" 2&gt;&amp;1 | tail -20\n</code></pre> <p>Look for cumulative times &gt; 100ms.</p>"},{"location":"guides/cli-performance/#q-can-i-disable-lazy-loading","title":"Q: Can I disable lazy loading?","text":"<p>A: Not recommended, but you can import modules explicitly in <code>main.py</code>:</p> <pre><code># Not recommended - slow startup\nfrom .mcp import mcp\nfrom .monitor import monitor\n# ...\n\ncli.add_command(mcp)\ncli.add_command(monitor)\n</code></pre>"},{"location":"guides/cli-performance/#best-practices","title":"Best Practices","text":"<ol> <li>Always use lazy loading for CLI commands</li> <li>Import heavy modules inside functions, not at module level</li> <li>Test startup time in CI (see <code>tests/cli/test_lazy_loading.py</code>)</li> <li>Profile regularly to catch regressions</li> </ol>"},{"location":"guides/cli-performance/#future-improvements","title":"Future Improvements","text":"<ul> <li>Pre-compiled bytecode (<code>.pyc</code>) optimization</li> <li>Startup profiling in CI</li> <li>Dynamic help text loading</li> </ul>"},{"location":"guides/context-compression/","title":"Context Compression Guide","text":"<p>RFC-024 Phase 1: Token Management</p> <p>Since: v2.5.0</p>"},{"location":"guides/context-compression/#overview","title":"Overview","text":"<p>Context compression enables efficient long-form conversations by managing token usage and preventing context window overflow.</p> <p>Phase 1 (current) provides: - \u2705 Accurate token counting for all major LLM models - \u2705 Real-time context usage monitoring - \u2705 Compression recommendations</p> <p>Future phases will add: - \ud83d\udccb Phase 2: Message trimming (Week 2) - \ud83d\udccb Phase 3: LLM-based summarization (Week 3-4) - \ud83d\udccb Phase 4: Automatic compression (Week 5)</p>"},{"location":"guides/context-compression/#installation","title":"Installation","text":"<pre><code># Install with AI features (includes context compression)\npip install kagura-ai[ai]\n\n# Or install all features\npip install kagura-ai[all]\n</code></pre> <p>Dependencies: - <code>tiktoken&gt;=0.7.0</code> - OpenAI's token counting library</p>"},{"location":"guides/context-compression/#quick-start","title":"Quick Start","text":""},{"location":"guides/context-compression/#basic-token-counting","title":"Basic Token Counting","text":"<pre><code>from kagura.core.compression import TokenCounter\n\n# Create counter\ncounter = TokenCounter(model=\"gpt-4o-mini\")\n\n# Count tokens in text\ntext = \"Hello, world!\"\ntokens = counter.count_tokens(text)\nprint(f\"Tokens: {tokens}\")  # Tokens: 4\n\n# Count tokens in messages\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Hello!\"},\n    {\"role\": \"assistant\", \"content\": \"Hi there!\"}\n]\n\ntotal_tokens = counter.count_tokens_messages(messages)\nprint(f\"Total tokens: {total_tokens}\")  # Includes message overhead\n</code></pre>"},{"location":"guides/context-compression/#context-usage-monitoring","title":"Context Usage Monitoring","text":"<pre><code>from kagura.core.compression import TokenCounter, ContextMonitor\n\n# Create counter and monitor\ncounter = TokenCounter(model=\"gpt-4o-mini\")\nmonitor = ContextMonitor(counter, max_tokens=10000)\n\n# Check usage\nmessages = [...]  # Your conversation history\nusage = monitor.check_usage(messages, system_prompt=\"Be helpful.\")\n\n# Display usage\nprint(f\"Usage: {usage.usage_ratio:.1%}\")  # e.g., 45.3%\nprint(f\"Tokens: {usage.total_tokens:,} / {usage.max_tokens:,}\")\n\nif usage.should_compress:\n    print(\"\u26a0\ufe0f Context is getting full!\")\n    print(\"Consider compressing (Phase 2+)\")\n</code></pre>"},{"location":"guides/context-compression/#advanced-usage","title":"Advanced Usage","text":""},{"location":"guides/context-compression/#auto-detect-model-limits","title":"Auto-Detect Model Limits","text":"<pre><code># Automatically detect max tokens from model\ncounter = TokenCounter(model=\"claude-3-5-sonnet\")\nmonitor = ContextMonitor(counter, max_tokens=None)\n\nprint(f\"Max tokens: {monitor.max_tokens:,}\")\n# For Claude 3.5 Sonnet: 196,000 (200k - 4k reserved)\n</code></pre>"},{"location":"guides/context-compression/#custom-compression-threshold","title":"Custom Compression Threshold","text":"<pre><code># Trigger compression at 70% instead of default 80%\nshould_compress = counter.should_compress(\n    current_tokens=usage.total_tokens,\n    max_tokens=usage.max_tokens,\n    threshold=0.7  # 70%\n)\n\nif should_compress:\n    print(\"Time to compress!\")\n</code></pre>"},{"location":"guides/context-compression/#estimate-context-size","title":"Estimate Context Size","text":"<pre><code># Estimate how much context a conversation will use\nestimate = counter.estimate_context_size(\n    messages=messages,\n    system_prompt=\"You are helpful.\",\n    max_tokens=1000  # Reserve for completion\n)\n\nprint(f\"Prompt: {estimate['prompt_tokens']:,} tokens\")\nprint(f\"Completion: {estimate['completion_tokens']:,} tokens\")\nprint(f\"Total: {estimate['total_tokens']:,} tokens\")\n</code></pre>"},{"location":"guides/context-compression/#model-support","title":"Model Support","text":""},{"location":"guides/context-compression/#supported-models","title":"Supported Models","text":"<p>All major LLM providers are supported:</p> <pre><code># OpenAI\ncounter_openai = TokenCounter(model=\"gpt-4o-mini\")\n\n# Anthropic Claude\ncounter_claude = TokenCounter(model=\"claude-3-5-sonnet\")\n\n# Google Gemini\ncounter_gemini = TokenCounter(model=\"gemini-1.5-pro\")\n</code></pre>"},{"location":"guides/context-compression/#model-limits","title":"Model Limits","text":"<p>Get token limits for any model:</p> <pre><code>limits = counter.get_model_limits(\"gpt-4o-mini\")\nprint(f\"Context window: {limits['context_window']:,}\")  # 128,000\nprint(f\"Max completion: {limits['max_completion']:,}\")  # 16,384\n</code></pre> <p>Available Limits:</p> Model Context Window Max Completion gpt-4o-mini 128,000 16,384 gpt-4o 128,000 16,384 claude-3-5-sonnet 200,000 8,192 gemini-1.5-pro 2,000,000 8,192 <p>For unknown models, defaults to 8,000 / 2,000.</p>"},{"location":"guides/context-compression/#best-practices","title":"Best Practices","text":""},{"location":"guides/context-compression/#1-monitor-usage-regularly","title":"1. Monitor Usage Regularly","text":"<pre><code># Check usage after each turn\nusage = monitor.check_usage(messages)\n\nif usage.usage_ratio &gt; 0.7:\n    print(f\"\u26a0\ufe0f Warning: {usage.usage_ratio:.0%} full\")\n\nif usage.should_compress:\n    print(\"\ud83d\udea8 Compression recommended\")\n    # In Phase 2+: await compress(messages)\n</code></pre>"},{"location":"guides/context-compression/#2-reserve-space-for-completion","title":"2. Reserve Space for Completion","text":"<p>When creating a monitor, ensure you reserve enough tokens for model responses:</p> <pre><code># Good: Auto-detect reserves 4000 tokens\nmonitor = ContextMonitor(counter, max_tokens=None)\n\n# Custom: Reserve explicit amount\nmodel_limit = 128_000\nreserved_for_completion = 8_000\nmonitor = ContextMonitor(counter, max_tokens=model_limit - reserved_for_completion)\n</code></pre>"},{"location":"guides/context-compression/#3-choose-appropriate-model","title":"3. Choose Appropriate Model","text":"<p>For long conversations, prefer models with larger context windows:</p> <pre><code># Small context (16k) - frequent compression needed\ncounter_small = TokenCounter(model=\"gpt-3.5-turbo\")\n\n# Large context (128k) - less compression needed\ncounter_large = TokenCounter(model=\"gpt-4o-mini\")\n\n# Huge context (2M) - minimal compression needed\ncounter_huge = TokenCounter(model=\"gemini-1.5-pro\")\n</code></pre>"},{"location":"guides/context-compression/#examples","title":"Examples","text":""},{"location":"guides/context-compression/#example-1-track-conversation-growth","title":"Example 1: Track Conversation Growth","text":"<pre><code>from kagura.core.compression import TokenCounter, ContextMonitor\n\ncounter = TokenCounter(model=\"gpt-4o-mini\")\nmonitor = ContextMonitor(counter, max_tokens=50000)\n\nmessages = [{\"role\": \"system\", \"content\": \"You are helpful.\"}]\n\nfor turn in range(100):\n    # Add user message\n    messages.append({\"role\": \"user\", \"content\": f\"Question {turn}\"})\n\n    # Check usage before responding\n    usage = monitor.check_usage(messages)\n    print(f\"Turn {turn}: {usage.usage_ratio:.1%} full\")\n\n    if usage.should_compress:\n        print(f\"\u26a0\ufe0f Compression needed at turn {turn}\")\n        break\n\n    # Add assistant response\n    messages.append({\"role\": \"assistant\", \"content\": f\"Answer {turn}\"})\n</code></pre>"},{"location":"guides/context-compression/#example-2-multi-model-comparison","title":"Example 2: Multi-Model Comparison","text":"<pre><code>models = [\"gpt-4o-mini\", \"claude-3-5-sonnet\", \"gemini-1.5-pro\"]\n\ntext = \"The quick brown fox jumps over the lazy dog.\"\n\nfor model in models:\n    counter = TokenCounter(model=model)\n    tokens = counter.count_tokens(text)\n    limits = counter.get_model_limits(model)\n\n    print(f\"{model}:\")\n    print(f\"  Tokens: {tokens}\")\n    print(f\"  Context window: {limits['context_window']:,}\")\n</code></pre> <p>Output: <pre><code>gpt-4o-mini:\n  Tokens: 10\n  Context window: 128,000\n\nclaude-3-5-sonnet:\n  Tokens: 10\n  Context window: 200,000\n\ngemini-1.5-pro:\n  Tokens: 10\n  Context window: 2,000,000\n</code></pre></p>"},{"location":"guides/context-compression/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/context-compression/#q-token-count-seems-inaccurate","title":"Q: Token count seems inaccurate","text":"<p>A: Different models use different tokenizers. TokenCounter uses <code>tiktoken</code> which is optimized for OpenAI models. For Claude and Gemini, it uses <code>cl100k_base</code> as an approximation (\u00b110% accuracy).</p>"},{"location":"guides/context-compression/#q-what-if-i-exceed-context-window","title":"Q: What if I exceed context window?","text":"<p>A: Phase 1 only monitors usage. Phases 2-4 will provide automatic compression: - Phase 2: Message trimming - Phase 3: LLM-based summarization - Phase 4: Automatic compression</p>"},{"location":"guides/context-compression/#q-how-accurate-is-token-counting","title":"Q: How accurate is token counting?","text":"<p>A: Very accurate for OpenAI models (\u00b11%). For other models: \u00b15-10%.</p>"},{"location":"guides/context-compression/#q-can-i-use-this-with-streaming","title":"Q: Can I use this with streaming?","text":"<p>A: Yes! Count tokens before and after streaming to track usage.</p>"},{"location":"guides/context-compression/#next-steps","title":"Next Steps","text":"<p>Phase 1 (current) provides monitoring only.</p> <p>Coming soon: - Phase 2 (Week 2): Message trimming with 4 strategies - Phase 3 (Week 3-4): Context summarization - Phase 4 (Week 5): Automatic compression integrated with <code>@agent</code> decorator</p> <p>Stay tuned for updates!</p>"},{"location":"guides/context-compression/#see-also","title":"See Also","text":"<ul> <li>Compression API Reference - Detailed API documentation</li> <li>RFC-024 - Full specification</li> <li>Memory Management - Memory system (integrates in Phase 4)</li> </ul> <p>Phase 1 implementation provides the foundation for efficient long-form conversations!</p>"},{"location":"guides/meta-agent/","title":"Meta Agent: AI-Powered Agent Code Generator","text":""},{"location":"guides/meta-agent/#overview","title":"Overview","text":"<p>The Meta Agent is an AI-powered code generator that creates Kagura agents from natural language descriptions. Simply describe what you want your agent to do, and Meta Agent will generate complete, production-ready Python code.</p>"},{"location":"guides/meta-agent/#quick-start","title":"Quick Start","text":""},{"location":"guides/meta-agent/#interactive-mode","title":"Interactive Mode","text":"<pre><code>kagura build agent\n</code></pre> <p>You'll be prompted to describe your agent:</p> <pre><code>\ud83e\udd16 Kagura Agent Builder\nDescribe your agent in natural language and I'll generate the code.\n\nWhat should your agent do? Translate English to Japanese\n\n\ud83d\udd0d Parsing agent specification...\n\n\ud83d\udccb Agent Specification\nName: translator\nDescription: Translate English to Japanese\nInput: str\nOutput: str\nTools: None\nMemory: No\n\n\u2699\ufe0f  Generating agent code...\n\ud83d\udd12 Validating code security...\n\u2705 Code validated\n\n\u2705 Agent created: agents/translator.py\n</code></pre>"},{"location":"guides/meta-agent/#non-interactive-mode","title":"Non-Interactive Mode","text":"<pre><code>kagura build agent \\\n  --description \"Translate English to Japanese\" \\\n  --output translator.py \\\n  --no-interactive\n</code></pre>"},{"location":"guides/meta-agent/#generated-code-example","title":"Generated Code Example","text":"<p>For the description \"Translate English to Japanese\", Meta Agent generates:</p> <pre><code>\"\"\"Translate English to Japanese\n\nAuto-generated by Kagura Meta Agent\nCreated: 2025-10-13 12:00:00\nKagura Version: 2.5.0\n\"\"\"\n\nfrom kagura import agent\n\n\n@agent(\n    model=\"gpt-4o-mini\",\n    temperature=0.7,\n)\nasync def translator(input_data: str) -&gt; str:\n    \"\"\"Translate English to Japanese\n\n    Args:\n        input_data: str - Input data\n\n    Returns:\n        str - Generated result\n    \"\"\"\n    # System prompt for this agent\n    system_prompt = \"\"\"You are a professional translator. Translate text from English to Japanese.\"\"\"\n\n    # Template variable for LLM (will be rendered at runtime)\n    return f\"{system_prompt}\\n\\nInput: {input_data}\"\n</code></pre>"},{"location":"guides/meta-agent/#advanced-features","title":"Advanced Features","text":""},{"location":"guides/meta-agent/#agent-with-tools","title":"Agent with Tools","text":"<p>If your description mentions code execution, web search, or other tools, Meta Agent will automatically include them:</p> <pre><code>kagura build agent -d \"Execute Python code to solve math problems\" --no-interactive\n</code></pre> <p>Generated code will include:</p> <pre><code>from kagura import agent\nfrom kagura.core.executor import CodeExecutor\n\n@agent(\n    model=\"gpt-4o-mini\",\n    temperature=0.7,\n    tools=[CodeExecutor()],\n)\nasync def math_solver(input_data: str) -&gt; str:\n    \"\"\"Solve math problems using Python\"\"\"\n    # ...\n</code></pre>"},{"location":"guides/meta-agent/#agent-with-memory","title":"Agent with Memory","text":"<p>For conversational agents:</p> <pre><code>kagura build agent -d \"Chatbot that remembers conversation history\" --no-interactive\n</code></pre> <p>Generated code will include:</p> <pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n@agent(\n    model=\"gpt-4o-mini\",\n    temperature=0.7,\n    enable_memory=True,\n    max_messages=100,\n)\nasync def chatbot(input_data: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Conversational chatbot with memory\"\"\"\n    memory.add_message(\"user\", str(input_data))\n    # ...\n</code></pre>"},{"location":"guides/meta-agent/#cli-options","title":"CLI Options","text":""},{"location":"guides/meta-agent/#kagura-build-agent","title":"<code>kagura build agent</code>","text":"<p>Options:</p> <ul> <li><code>-d, --description TEXT</code>: Natural language agent description</li> <li><code>-o, --output PATH</code>: Output file path (default: <code>agents/&lt;name&gt;.py</code>)</li> <li><code>--model TEXT</code>: LLM model for code generation (default: <code>gpt-4o-mini</code>)</li> <li><code>--interactive / --no-interactive</code>: Interactive mode (default: <code>True</code>)</li> <li><code>--no-validate</code>: Skip code validation</li> </ul>"},{"location":"guides/meta-agent/#examples","title":"Examples","text":"<pre><code># Interactive mode (default)\nkagura build agent\n\n# Direct generation\nkagura build agent -d \"Summarize text in 3 bullet points\" -o summarizer.py\n\n# Use GPT-4\nkagura build agent -d \"Complex reasoning task\" --model gpt-4o\n\n# Skip validation (not recommended)\nkagura build agent -d \"Test agent\" --no-validate\n</code></pre>"},{"location":"guides/meta-agent/#how-it-works","title":"How It Works","text":"<p>Meta Agent uses a multi-stage pipeline:</p> <ol> <li>Natural Language Parsing: Uses LLM to extract structured specification from your description</li> <li>Code Generation: Uses Jinja2 templates to generate clean Python code</li> <li>Security Validation: AST analysis ensures generated code is safe</li> <li>File Creation: Saves the generated agent to a file</li> </ol>"},{"location":"guides/meta-agent/#architecture","title":"Architecture","text":"<pre><code>Natural Language \u2192 NLSpecParser \u2192 AgentSpec \u2192 CodeGenerator \u2192 Python Code\n                                                    \u2193\n                                              CodeValidator (Security)\n</code></pre>"},{"location":"guides/meta-agent/#security","title":"Security","text":"<p>All generated code is validated for security:</p> <ul> <li>\u2705 Syntax checking</li> <li>\u2705 Forbidden import detection (subprocess, eval, etc.)</li> <li>\u2705 Dangerous function call detection</li> <li>\u2705 Required @agent decorator verification</li> </ul> <p>Dangerous code will be rejected before saving.</p>"},{"location":"guides/meta-agent/#best-practices","title":"Best Practices","text":""},{"location":"guides/meta-agent/#writing-good-descriptions","title":"Writing Good Descriptions","text":"<p>Good descriptions are specific:</p> <p>\u2705 \"Translate English to Japanese\" \u2705 \"Summarize articles in 3 bullet points\" \u2705 \"Execute Python code to solve math problems\"</p> <p>Avoid vague descriptions:</p> <p>\u274c \"Do something with text\" \u274c \"Help me\" \u274c \"Agent\"</p>"},{"location":"guides/meta-agent/#tool-detection","title":"Tool Detection","text":"<p>Meta Agent automatically detects when tools are needed:</p> <ul> <li>Code Execution: \"execute code\", \"run python\", \"calculate\"</li> <li>Web Search: \"search web\", \"google\", \"find online\"</li> <li>Memory: \"remember\", \"conversation history\", \"recall\"</li> <li>File Operations: \"read file\", \"write file\"</li> </ul> <p>Be explicit if you need specific tools.</p>"},{"location":"guides/meta-agent/#programmatic-usage","title":"Programmatic Usage","text":"<p>You can also use Meta Agent from Python:</p> <pre><code>from kagura.meta import MetaAgent\n\n# Initialize\nmeta = MetaAgent(model=\"gpt-4o-mini\")\n\n# Generate from description\ncode = await meta.generate(\"Translate English to Japanese\")\nprint(code)\n\n# Generate from spec\nfrom kagura.meta.spec import AgentSpec\n\nspec = AgentSpec(\n    name=\"translator\",\n    description=\"Translate text\",\n    input_type=\"str\",\n    output_type=\"str\",\n    system_prompt=\"You are a professional translator.\"\n)\n\ncode = await meta.generate_from_spec(spec)\n</code></pre>"},{"location":"guides/meta-agent/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/meta-agent/#validation-failed-missing-agent-decorator","title":"\"Validation failed: Missing @agent decorator\"","text":"<p>The generated code doesn't include the <code>@agent</code> decorator. This is a bug - please report it.</p>"},{"location":"guides/meta-agent/#validation-failed-disallowed-import-subprocess","title":"\"Validation failed: Disallowed import: subprocess\"","text":"<p>The LLM generated code with dangerous imports. Try a more specific description or use <code>--no-validate</code> (not recommended).</p>"},{"location":"guides/meta-agent/#generated-code-doesnt-work","title":"Generated code doesn't work","text":"<p>The generated code is a starting point. You may need to:</p> <ol> <li>Adjust the system prompt</li> <li>Add more specific logic</li> <li>Test and iterate</li> </ol>"},{"location":"guides/meta-agent/#examples_1","title":"Examples","text":"<p>See <code>examples/meta_agent/</code> for complete examples:</p> <ul> <li><code>translator.py</code>: Simple translation agent</li> <li><code>code_solver.py</code>: Agent with code execution</li> <li><code>chatbot.py</code>: Agent with memory</li> </ul>"},{"location":"guides/meta-agent/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Agent Builder for more complex configurations</li> <li>Explore Testing Framework for testing generated agents</li> <li>Read the Meta Agent API Reference</li> </ul>"},{"location":"guides/oauth2-authentication/","title":"OAuth2 Authentication Guide","text":"<p>Learn how to use OAuth2 authentication with Kagura AI to access Google models (like Gemini) without managing API keys.</p> <p>\ud83d\udccc Important Note</p> <p>For most users, using API Keys is recommended as it's simpler and faster to set up: - Gemini: Get API key from Google AI Studio \u2192 Set <code>GOOGLE_API_KEY</code> - Claude: Get API key from Anthropic Console \u2192 Set <code>ANTHROPIC_API_KEY</code> - OpenAI: Get API key from OpenAI Platform \u2192 Set <code>OPENAI_API_KEY</code></p> <p>OAuth2 is an advanced feature for specific use cases like: - Multi-user applications where each user authenticates with their own Google account - Production environments requiring strict access controls - Applications that need per-user quota management</p> <p>Currently, only Google/Gemini supports OAuth2. Claude and OpenAI use API keys only.</p>"},{"location":"guides/oauth2-authentication/#overview","title":"Overview","text":"<p>Kagura AI supports OAuth2 authentication for Google services only, allowing you to:</p> <ul> <li>No API Key Management: Use Google models without storing API keys</li> <li>Secure Authentication: OAuth2 tokens are encrypted locally (Fernet/AES-128)</li> <li>Automatic Token Refresh: Tokens are automatically refreshed when expired</li> <li>Simple CLI Commands: Easy login/logout/status management</li> </ul>"},{"location":"guides/oauth2-authentication/#prerequisites","title":"Prerequisites","text":"<ol> <li>Google Cloud Project with Generative Language API enabled</li> <li>OAuth 2.0 Client ID (Desktop application type)</li> <li>Kagura AI with OAuth support installed:</li> </ol> <pre><code>pip install kagura-ai[auth]\n</code></pre>"},{"location":"guides/oauth2-authentication/#setup-guide","title":"Setup Guide","text":""},{"location":"guides/oauth2-authentication/#step-1-create-oauth-20-client-id","title":"Step 1: Create OAuth 2.0 Client ID","text":"<ol> <li>Go to Google Cloud Console - Credentials</li> <li>Click \"Create Credentials\" \u2192 \"OAuth client ID\"</li> <li>Select \"Desktop app\" as the application type</li> <li>Name it (e.g., \"Kagura AI Desktop\")</li> <li>Click \"Create\"</li> <li>Download the JSON file</li> </ol>"},{"location":"guides/oauth2-authentication/#step-2-save-client-secrets","title":"Step 2: Save Client Secrets","text":"<p>Save the downloaded JSON file as <code>~/.config/kagura/client_secrets.json</code>:</p> <pre><code>mkdir -p ~/.kagura\nmv ~/Downloads/client_secret_*.json ~/.config/kagura/client_secrets.json\nchmod 600 ~/.config/kagura/client_secrets.json\n</code></pre> <p>Important: Keep this file secure! It contains your OAuth client credentials.</p>"},{"location":"guides/oauth2-authentication/#step-3-login","title":"Step 3: Login","text":"<p>Run the <code>kagura auth login</code> command:</p> <pre><code>kagura auth login --provider google\n</code></pre> <p>This will: 1. Open your browser for Google OAuth2 authentication 2. Ask you to authorize Kagura AI to access Google Generative Language API 3. Save encrypted credentials to <code>~/.config/kagura/credentials.json.enc</code></p> <p>Output: <pre><code>\u2713 Authentication successful!\n\u2713 Credentials saved to: /home/user/.kagura/credentials.json.enc\n</code></pre></p>"},{"location":"guides/oauth2-authentication/#step-4-verify-authentication","title":"Step 4: Verify Authentication","text":"<p>Check your authentication status:</p> <pre><code>kagura auth status --provider google\n</code></pre> <p>Output: <pre><code>\u2713 Authenticated with google\nToken expires: 2025-10-13 15:30:00 UTC\n</code></pre></p>"},{"location":"guides/oauth2-authentication/#using-oauth2-in-your-code","title":"Using OAuth2 in Your Code","text":""},{"location":"guides/oauth2-authentication/#basic-usage-with-llmconfig","title":"Basic Usage with LLMConfig","text":"<pre><code>from kagura.core.llm import LLMConfig, call_llm\n\n# Configure OAuth2 authentication\nconfig = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\"\n)\n\n# Call LLM (OAuth2 token retrieved automatically)\nresponse = await call_llm(\"What is the capital of France?\", config)\nprint(response)  # \"The capital of France is Paris.\"\n</code></pre>"},{"location":"guides/oauth2-authentication/#using-with-agent-decorator","title":"Using with @agent Decorator","text":"<pre><code>from kagura import agent\nfrom kagura.core.llm import LLMConfig\n\n# Create OAuth2 config\ngemini_config = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\",\n    temperature=0.7\n)\n\n@agent(\n    name=\"translator\",\n    template=\"Translate '{{ text }}' to {{ language }}\",\n    llm_config=gemini_config\n)\ndef translate(text: str, language: str) -&gt; str:\n    pass\n\n# Use the agent\nresult = translate(\"Hello\", \"Japanese\")\nprint(result)  # \"\u3053\u3093\u306b\u3061\u306f\"\n</code></pre>"},{"location":"guides/oauth2-authentication/#switching-between-api-key-and-oauth2","title":"Switching Between API Key and OAuth2","text":"<p>You can use both authentication methods in the same project:</p> <pre><code>from kagura.core.llm import LLMConfig\n\n# OpenAI with API key (uses OPENAI_API_KEY env var)\nopenai_config = LLMConfig(\n    model=\"gpt-4o-mini\",\n    auth_type=\"api_key\"  # default\n)\n\n# Gemini with OAuth2\ngemini_config = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\"\n)\n</code></pre>"},{"location":"guides/oauth2-authentication/#cli-commands","title":"CLI Commands","text":""},{"location":"guides/oauth2-authentication/#login","title":"Login","text":"<p>Authenticate with Google OAuth2:</p> <pre><code>kagura auth login --provider google\n</code></pre> <p>Options: - <code>--provider</code>: OAuth2 provider (default: <code>google</code>)</p>"},{"location":"guides/oauth2-authentication/#logout","title":"Logout","text":"<p>Remove stored credentials:</p> <pre><code>kagura auth logout --provider google\n</code></pre> <p>Output: <pre><code>\u2713 Logged out from google\n</code></pre></p>"},{"location":"guides/oauth2-authentication/#status","title":"Status","text":"<p>Check authentication status:</p> <pre><code>kagura auth status --provider google\n</code></pre> <p>Possible outputs:</p> <p>Authenticated: <pre><code>\u2713 Authenticated with google\nToken expires: 2025-10-13 15:30:00 UTC\n</code></pre></p> <p>Not Authenticated: <pre><code>\u2717 Not authenticated with google\nRun: kagura auth login --provider google\n</code></pre></p>"},{"location":"guides/oauth2-authentication/#security","title":"Security","text":""},{"location":"guides/oauth2-authentication/#credential-storage","title":"Credential Storage","text":"<p>OAuth2 credentials are stored securely:</p> <ul> <li>Location: <code>~/.config/kagura/credentials.json.enc</code></li> <li>Encryption: Fernet (AES-128 in CBC mode)</li> <li>Key Storage: <code>~/.config/kagura/.key</code> (with 0600 permissions)</li> <li>File Permissions: Both files have 0600 (owner read/write only)</li> </ul>"},{"location":"guides/oauth2-authentication/#token-refresh","title":"Token Refresh","text":"<p>Access tokens are automatically refreshed:</p> <ol> <li>Automatic: Tokens are checked before each API call</li> <li>Transparent: Refresh happens automatically when expired</li> <li>Secure: Refresh tokens are encrypted and stored locally</li> </ol>"},{"location":"guides/oauth2-authentication/#best-practices","title":"Best Practices","text":"<ol> <li>Never commit <code>~/.config/kagura/</code> directory to version control</li> <li>Keep <code>client_secrets.json</code> secure - it's like a password</li> <li>Don't share your <code>credentials.json.enc</code> file</li> <li>Logout when you're done on shared machines</li> <li>Regenerate OAuth client ID if credentials are compromised</li> </ol>"},{"location":"guides/oauth2-authentication/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/oauth2-authentication/#client-secrets-file-not-found","title":"\"Client secrets file not found\"","text":"<p>Error: <pre><code>FileNotFoundError: Client secrets file not found: /home/user/.kagura/client_secrets.json\n</code></pre></p> <p>Solution: 1. Download OAuth 2.0 Client ID JSON from Google Cloud Console 2. Save it as <code>~/.config/kagura/client_secrets.json</code></p>"},{"location":"guides/oauth2-authentication/#not-authenticated-with-google","title":"\"Not authenticated with google\"","text":"<p>Error: <pre><code>NotAuthenticatedError: Not authenticated with google. Please run: kagura auth login --provider google\n</code></pre></p> <p>Solution: Run <code>kagura auth login --provider google</code> to authenticate.</p>"},{"location":"guides/oauth2-authentication/#token-refresh-failed","title":"\"Token refresh failed\"","text":"<p>Error: <pre><code>TokenRefreshError: Failed to refresh token for google\n</code></pre></p> <p>Solution: 1. Logout: <code>kagura auth logout --provider google</code> 2. Login again: <code>kagura auth login --provider google</code></p>"},{"location":"guides/oauth2-authentication/#invalid-credentials","title":"\"Invalid credentials\"","text":"<p>Error: <pre><code>InvalidCredentialsError: Failed to decrypt credentials\n</code></pre></p> <p>Possible causes: - Corrupted credentials file - Encryption key was regenerated</p> <p>Solution: 1. Remove credentials: <code>rm ~/.config/kagura/credentials.json.enc</code> 2. Login again: <code>kagura auth login --provider google</code></p>"},{"location":"guides/oauth2-authentication/#environment-variables","title":"Environment Variables","text":"<p>OAuth2 authentication does NOT use environment variables. All authentication is handled through the OAuth2 flow and stored encrypted credentials.</p> <p>If you prefer to use API keys instead:</p> <pre><code># For Gemini (using API key)\nexport GOOGLE_API_KEY=\"your-api-key\"\n\n# Then use api_key auth type (default)\nconfig = LLMConfig(model=\"gemini/gemini-1.5-flash\")\n</code></pre>"},{"location":"guides/oauth2-authentication/#comparison-oauth2-vs-api-key","title":"Comparison: OAuth2 vs API Key","text":"Feature OAuth2 API Key Supported LLMs Google/Gemini only All LLMs (OpenAI, Claude, Gemini) Setup Complexity Complex (Google Cloud Console setup required) Simple (just get API key) Security OAuth2 tokens (short-lived, auto-refresh) Long-lived API keys Use Case Multi-user apps, production with strict access control Personal development, prototyping, CI/CD Recommended For Advanced users with specific needs Most users (recommended) Expiration Auto-refresh Manual rotation Revocation Can revoke from Google Console Delete/regenerate key"},{"location":"guides/oauth2-authentication/#when-to-use-api-key-recommended","title":"When to Use API Key (Recommended)","text":"<p>\u2705 Use API Key if: - You're doing personal development or prototyping - You want quick and simple setup - You're using Claude or OpenAI (OAuth2 not supported) - You're running in CI/CD pipelines - You're building single-user applications</p> <p>How to get API Keys: - Gemini: Google AI Studio (fastest way!) - Claude: Anthropic Console - OpenAI: OpenAI Platform</p>"},{"location":"guides/oauth2-authentication/#when-to-use-oauth2-advanced","title":"When to Use OAuth2 (Advanced)","text":"<p>\u26a0\ufe0f Use OAuth2 only if: - You're building a multi-user application - Each user needs their own Google account authentication - You need strict per-user quota management - You have specific security requirements - You're comfortable with Google Cloud Console setup</p> <p>Note: OAuth2 is only available for Google/Gemini.</p>"},{"location":"guides/oauth2-authentication/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"guides/oauth2-authentication/#custom-client-secrets-path","title":"Custom Client Secrets Path","text":"<p>If you want to store <code>client_secrets.json</code> in a custom location:</p> <pre><code>from kagura.auth import OAuth2Manager, AuthConfig\nfrom pathlib import Path\n\n# Custom config\nconfig = AuthConfig(\n    provider=\"google\",\n    client_secrets_path=Path(\"/custom/path/client_secrets.json\")\n)\n\n# Use custom config\nauth = OAuth2Manager(config=config)\nauth.login()\n</code></pre>"},{"location":"guides/oauth2-authentication/#custom-scopes","title":"Custom Scopes","text":"<p>The default scopes are: - <code>https://www.googleapis.com/auth/generative-language</code> - <code>openid</code></p> <p>To use custom scopes:</p> <pre><code>from kagura.auth import OAuth2Manager, AuthConfig\n\nconfig = AuthConfig(\n    provider=\"google\",\n    scopes=[\n        \"https://www.googleapis.com/auth/generative-language\",\n        \"openid\",\n        \"https://www.googleapis.com/auth/userinfo.email\"\n    ]\n)\n\nauth = OAuth2Manager(config=config)\n</code></pre>"},{"location":"guides/oauth2-authentication/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Agent Routing</li> <li>Explore Memory Management</li> <li>Try MCP Integration</li> </ul>"},{"location":"guides/oauth2-authentication/#related-documentation","title":"Related Documentation","text":"<ul> <li>API Reference: OAuth2Manager</li> <li>Installation Guide</li> <li>Quickstart Tutorial</li> </ul>"},{"location":"guides/performance-caching/","title":"Performance: LLM Response Caching","text":"<p>Reduce response times by 70% and API costs by 60% through intelligent LLM response caching.</p>"},{"location":"guides/performance-caching/#overview","title":"Overview","text":"<p>Kagura AI automatically caches LLM responses to:</p> <ul> <li>Reduce response times: 70%+ faster for cached queries</li> <li>Lower API costs: 60%+ cost reduction through cache reuse</li> <li>Improve scalability: Handle more concurrent users</li> <li>Better UX: Instant responses for repeated queries</li> </ul>"},{"location":"guides/performance-caching/#how-it-works","title":"How It Works","text":"<pre><code>from kagura import agent, LLMConfig\n\n# Caching is enabled by default\nconfig = LLMConfig(model=\"gpt-4o-mini\", enable_cache=True)\n\n@agent(config=config)\nasync def translator(text: str, target_lang: str) -&gt; str:\n    \"\"\"Translate {{ text }} to {{ target_lang }}\"\"\"\n    pass\n\n# First call: Cache miss (~2s)\nresult1 = await translator(\"Hello\", \"Japanese\")\n\n# Second call: Cache hit (~0ms) \u26a1\nresult2 = await translator(\"Hello\", \"Japanese\")  # Instant!\n</code></pre>"},{"location":"guides/performance-caching/#quick-start","title":"Quick Start","text":""},{"location":"guides/performance-caching/#default-behavior","title":"Default Behavior","text":"<p>Caching is enabled by default with sensible defaults:</p> <pre><code>from kagura import LLMConfig\n\n# These are equivalent:\nconfig1 = LLMConfig(model=\"gpt-4o-mini\")\nconfig2 = LLMConfig(\n    model=\"gpt-4o-mini\",\n    enable_cache=True,      # Enabled by default\n    cache_ttl=3600,         # 1 hour TTL\n    cache_backend=\"memory\"  # In-memory cache\n)\n</code></pre>"},{"location":"guides/performance-caching/#disabling-cache","title":"Disabling Cache","text":"<p>For non-deterministic or time-sensitive queries:</p> <pre><code>config = LLMConfig(\n    model=\"gpt-4o-mini\",\n    enable_cache=False  # Disable caching\n)\n\n@agent(config=config)\nasync def breaking_news() -&gt; str:\n    \"\"\"Get latest breaking news\"\"\"\n    pass\n</code></pre>"},{"location":"guides/performance-caching/#configuration","title":"Configuration","text":""},{"location":"guides/performance-caching/#cache-ttl-time-to-live","title":"Cache TTL (Time-To-Live)","text":"<p>Control how long responses are cached:</p> <pre><code># Short TTL for frequently changing data\nconfig_short = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_ttl=300  # 5 minutes\n)\n\n# Long TTL for stable data\nconfig_long = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_ttl=86400  # 24 hours\n)\n\n# No expiration (cache indefinitely)\nconfig_infinite = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_ttl=0  # Never expires (use with caution!)\n)\n</code></pre>"},{"location":"guides/performance-caching/#cache-backend","title":"Cache Backend","text":"<p>Choose between in-memory and Redis backends:</p> <pre><code># In-memory cache (default, fast, single-process)\nconfig_memory = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_backend=\"memory\"\n)\n\n# Redis cache (shared across processes, persistent)\n# Note: Redis backend will be available in Phase 1 Day 3\nconfig_redis = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_backend=\"redis\"  # Coming soon!\n)\n</code></pre>"},{"location":"guides/performance-caching/#cache-management","title":"Cache Management","text":""},{"location":"guides/performance-caching/#inspecting-cache","title":"Inspecting Cache","text":"<p>Get cache statistics:</p> <pre><code>from kagura.core.llm import get_llm_cache\n\ncache = get_llm_cache()\nstats = cache.stats()\n\nprint(f\"Cache size: {stats['size']}/{stats['max_size']}\")\nprint(f\"Hit rate: {stats['hit_rate']:.1%}\")\nprint(f\"Hits: {stats['hits']}, Misses: {stats['misses']}\")\n</code></pre> <p>Example output: <pre><code>Cache size: 243/1000\nHit rate: 87.3%\nHits: 1247, Misses: 182\n</code></pre></p>"},{"location":"guides/performance-caching/#cache-invalidation","title":"Cache Invalidation","text":"<p>Clear cache when data changes:</p> <pre><code>cache = get_llm_cache()\n\n# Clear all cache entries\nawait cache.invalidate()\n\n# Clear specific pattern\nawait cache.invalidate(\"translate\")  # Clears all translation caches\n</code></pre>"},{"location":"guides/performance-caching/#custom-cache-instance","title":"Custom Cache Instance","text":"<p>Use a custom cache configuration:</p> <pre><code>from kagura.core.cache import LLMCache\nfrom kagura.core.llm import set_llm_cache\n\n# Create custom cache\ncustom_cache = LLMCache(\n    max_size=5000,      # Store up to 5000 entries\n    default_ttl=7200    # 2 hour default TTL\n)\n\nset_llm_cache(custom_cache)\n</code></pre>"},{"location":"guides/performance-caching/#best-practices","title":"Best Practices","text":""},{"location":"guides/performance-caching/#1-enable-caching-for-stable-queries","title":"1. Enable Caching for Stable Queries","text":"<p>\u2705 Good use cases: - Translation services - Text summarization - Code generation (same prompt) - General knowledge queries</p> <pre><code>@agent(config=LLMConfig(enable_cache=True))\nasync def translator(text: str) -&gt; str:\n    \"\"\"Translate {{ text }} to English\"\"\"\n    pass\n</code></pre> <p>\u274c Bad use cases: - Real-time data (news, weather, stock prices) - User-specific personalized responses - Queries with timestamps</p> <pre><code>@agent(config=LLMConfig(enable_cache=False))\nasync def weather_now() -&gt; str:\n    \"\"\"Get current weather\"\"\"\n    pass\n</code></pre>"},{"location":"guides/performance-caching/#2-adjust-ttl-based-on-data-stability","title":"2. Adjust TTL Based on Data Stability","text":"<pre><code># Fast-changing data: Short TTL\nnews_config = LLMConfig(cache_ttl=300)  # 5 min\n\n# Stable data: Long TTL\ndocs_config = LLMConfig(cache_ttl=86400)  # 24 hours\n\n# Never changes: Very long TTL\nconst_config = LLMConfig(cache_ttl=604800)  # 1 week\n</code></pre>"},{"location":"guides/performance-caching/#3-tool-functions-disable-caching","title":"3. Tool Functions Disable Caching","text":"<p>Caching is automatically disabled when using tool functions:</p> <pre><code>@agent(config=LLMConfig(enable_cache=True))\nasync def research(query: str) -&gt; str:\n    \"\"\"Research {{ query }}\"\"\"\n    pass\n\n# Caching enabled (no tools)\nresult1 = await research(\"AI trends\")\n\n# Caching disabled (tools provided)\nresult2 = await research(\n    \"AI trends\",\n    tools=[web_search, calculator]  # Tools disable cache\n)\n</code></pre> <p>Reason: Tool functions may have side effects or return different results each time.</p>"},{"location":"guides/performance-caching/#4-monitor-cache-performance","title":"4. Monitor Cache Performance","text":"<p>Track hit rate to optimize:</p> <pre><code>import asyncio\nfrom kagura.core.llm import get_llm_cache\n\nasync def monitor_cache():\n    while True:\n        cache = get_llm_cache()\n        stats = cache.stats()\n\n        hit_rate = stats['hit_rate']\n        if hit_rate &lt; 0.5:\n            print(f\"\u26a0\ufe0f Low hit rate: {hit_rate:.1%}\")\n            print(\"Consider: Longer TTL or fewer unique queries\")\n\n        await asyncio.sleep(60)  # Check every minute\n</code></pre> <p>Target hit rate: 70-90% for most applications</p>"},{"location":"guides/performance-caching/#performance-benchmarks","title":"Performance Benchmarks","text":""},{"location":"guides/performance-caching/#response-time-reduction","title":"Response Time Reduction","text":"Scenario Without Cache With Cache (Hit) Improvement Simple query 1.5s ~0ms 99.9% faster \u26a1 Complex query 3.2s ~0ms 99.9% faster \u26a1 Translation 1.8s ~0ms 99.9% faster \u26a1"},{"location":"guides/performance-caching/#cost-reduction","title":"Cost Reduction","text":"<p>Assuming 1000 requests/day with 85% cache hit rate:</p> Model Without Cache With Cache Savings gpt-4o-mini $2.00/day $0.30/day 85% cheaper \ud83d\udcb0 gpt-4o $30.00/day $4.50/day 85% cheaper \ud83d\udcb0 claude-3-5-sonnet $15.00/day $2.25/day 85% cheaper \ud83d\udcb0"},{"location":"guides/performance-caching/#advanced-topics","title":"Advanced Topics","text":""},{"location":"guides/performance-caching/#cache-key-generation","title":"Cache Key Generation","text":"<p>Cache keys include: - Prompt text - Model name - All LLM parameters (temperature, max_tokens, etc.)</p> <pre><code># Same cache key (identical parameters)\nconfig = LLMConfig(model=\"gpt-4o-mini\", temperature=0.7)\nresult1 = await call_llm(\"Hello\", config)\nresult2 = await call_llm(\"Hello\", config)  # Cache hit \u2705\n\n# Different cache key (different temperature)\nconfig2 = LLMConfig(model=\"gpt-4o-mini\", temperature=0.9)\nresult3 = await call_llm(\"Hello\", config2)  # Cache miss \u274c\n</code></pre>"},{"location":"guides/performance-caching/#cache-eviction","title":"Cache Eviction","text":"<p>When cache reaches <code>max_size</code>, the oldest entries are evicted (LRU):</p> <pre><code>cache = LLMCache(max_size=1000)\n\n# After 1000 unique queries:\n# - Query 1001: Evicts oldest entry\n# - Query 1002: Evicts next oldest entry\n</code></pre> <p>Tip: Increase <code>max_size</code> if you have many unique queries.</p>"},{"location":"guides/performance-caching/#memory-usage","title":"Memory Usage","text":"<p>Approximate memory usage per cached entry:</p> <ul> <li>Simple response (100 chars): ~500 bytes</li> <li>Complex response (2000 chars): ~8 KB</li> <li>1000 entries: ~5-8 MB</li> </ul> <pre><code># Low memory: Small cache\nlow_mem_cache = LLMCache(max_size=100)\n\n# High memory: Large cache\nhigh_mem_cache = LLMCache(max_size=10000)\n</code></pre>"},{"location":"guides/performance-caching/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/performance-caching/#cache-not-working","title":"Cache Not Working","text":"<p>Symptom: All queries are cache misses</p> <p>Possible causes: 1. Caching disabled: <code>enable_cache=False</code> 2. Tool functions provided (auto-disables cache) 3. Different parameters on each call</p> <p>Solution: <pre><code># Check cache is enabled\nconfig = LLMConfig(enable_cache=True)\n\n# Verify no tools\nresult = await call_llm(prompt, config, tool_functions=None)\n\n# Check stats\ncache = get_llm_cache()\nprint(cache.stats())\n</code></pre></p>"},{"location":"guides/performance-caching/#low-hit-rate","title":"Low Hit Rate","text":"<p>Symptom: Hit rate &lt; 50%</p> <p>Possible causes: 1. Too many unique queries 2. TTL too short (entries expiring) 3. Dynamic prompts (timestamps, user IDs in prompt)</p> <p>Solution: <pre><code># Increase TTL\nconfig = LLMConfig(cache_ttl=7200)  # 2 hours\n\n# Remove dynamic parts from prompt\n# \u274c Bad: Includes timestamp\nprompt = f\"Translate 'hello' at {datetime.now()}\"\n\n# \u2705 Good: Static prompt\nprompt = \"Translate 'hello' to French\"\n</code></pre></p>"},{"location":"guides/performance-caching/#memory-issues","title":"Memory Issues","text":"<p>Symptom: High memory usage</p> <p>Solution: <pre><code># Reduce cache size\ncache = LLMCache(max_size=500)  # Smaller cache\nset_llm_cache(cache)\n\n# Or invalidate periodically\nawait cache.invalidate()  # Clear all entries\n</code></pre></p>"},{"location":"guides/performance-caching/#next-steps","title":"Next Steps","text":"<ul> <li>API Reference: cache.py</li> <li>API Reference: llm.py</li> <li>Performance Optimization Guide (coming soon)</li> </ul> <p>Need help? Open an issue</p>"},{"location":"guides/web-integration/","title":"Web Integration Guide","text":"<p>This guide explains how to use Kagura AI's web search and scraping capabilities to access real-time information from the internet.</p>"},{"location":"guides/web-integration/#overview","title":"Overview","text":"<p>Web integration allows you to: - Search the web for current information - Scrape content from websites - Combine local knowledge (RAG) with web data - Get up-to-date answers beyond LLM training cutoff</p>"},{"location":"guides/web-integration/#prerequisites","title":"Prerequisites","text":""},{"location":"guides/web-integration/#installation","title":"Installation","text":"<p>Install Kagura AI with web support:</p> <pre><code>pip install kagura-ai[web]\n</code></pre> <p>This installs: - <code>httpx</code> - Async HTTP client - <code>beautifulsoup4</code> - HTML parsing - <code>lxml</code> - Fast XML/HTML parser - <code>brave-search-python-client</code> - Brave Search API</p>"},{"location":"guides/web-integration/#api-key-setup-required","title":"API Key Setup (Required)","text":"<p>For Brave Search:</p> <pre><code>export BRAVE_SEARCH_API_KEY=\"your-brave-api-key\"\n</code></pre> <p>Get a free API key from Brave Search API (2000 queries/month free).</p> <p>Note: Web search requires a valid BRAVE_SEARCH_API_KEY.</p>"},{"location":"guides/web-integration/#quick-start","title":"Quick Start","text":""},{"location":"guides/web-integration/#basic-usage","title":"Basic Usage","text":"<p>Start chat with web search enabled:</p> <pre><code>kagura chat --enable-web\n</code></pre> <p>The AI will automatically search the web when needed:</p> <pre><code>$ kagura chat --enable-web\n\n[You] &gt; What are the latest AI news today?\n\n\ud83c\udf10 Searching the web for: latest AI news\n\u2713 Web search completed\n\ud83d\udcac Generating response...\n\n[AI]\nHere are today's top AI news:\n\n1. **OpenAI releases GPT-5 Preview** - OpenAI announced a preview of\n   GPT-5 with improved reasoning capabilities...\n\n2. **Google's Gemini 2.0 launched** - Google released Gemini 2.0 with\n   native multimodal support...\n\n3. **AI regulation update** - EU Parliament approved new AI safety\n   regulations affecting...\n\n[Sources: TechCrunch, The Verge, MIT Technology Review]\n</code></pre>"},{"location":"guides/web-integration/#web-search","title":"Web Search","text":""},{"location":"guides/web-integration/#automatic-search-detection","title":"Automatic Search Detection","text":"<p>The AI decides when to search the web:</p> <pre><code>from kagura import agent\n\n@agent(\n    model=\"gpt-4o-mini\",\n    enable_web=True  # Enable automatic web search\n)\nasync def research_assistant(question: str) -&gt; str:\n    \"\"\"Answer the user's question.\n\n    Question: {{ question }}\n\n    If you need current information, use web search.\n    \"\"\"\n    pass\n\n# The agent will automatically search when needed\nresponse = await research_assistant(\"What's the weather in Tokyo?\")\n</code></pre>"},{"location":"guides/web-integration/#manual-web-search","title":"Manual Web Search","text":"<p>Use the <code>web_search</code> function directly:</p> <pre><code>from kagura.web import web_search\n\n# Search the web\nresults_text = await web_search(\"Python async best practices 2025\")\nprint(results_text)\n</code></pre> <p>Output format:</p> <pre><code>Search results for: Python async best practices 2025\n\n1. Best Practices for Async Python in 2025\n   https://realpython.com/async-python-2025\n   Comprehensive guide to async/await patterns, asyncio best practices...\n\n2. Asyncio Performance Tips - 2025 Edition\n   https://python.org/asyncio-tips\n   Learn how to optimize asyncio applications for production...\n</code></pre>"},{"location":"guides/web-integration/#brave-search-engine","title":"Brave Search Engine","text":"<p>Kagura uses Brave Search for web queries:</p> <pre><code>from kagura.web.search import BraveSearch\n\nsearch = BraveSearch(api_key=\"your-key\")\nresults = await search.search(\"query\", max_results=10)\n\nfor result in results:\n    print(f\"{result.title}: {result.url}\")\n</code></pre>"},{"location":"guides/web-integration/#search-api","title":"Search API","text":"<pre><code>from kagura.web.search import SearchResult\n\n# Search returns list of SearchResult objects\nresults: list[SearchResult] = await search.search(\"query\")\n\nfor result in results:\n    print(f\"Title: {result.title}\")\n    print(f\"URL: {result.url}\")\n    print(f\"Snippet: {result.snippet}\")\n    print(f\"Source: {result.source}\")  # \"brave\"\n    print()\n</code></pre>"},{"location":"guides/web-integration/#web-scraping","title":"Web Scraping","text":""},{"location":"guides/web-integration/#basic-scraping","title":"Basic Scraping","text":"<p>Fetch and parse webpage content:</p> <pre><code>from kagura.web.scraper import WebScraper\n\nscraper = WebScraper()\n\n# Fetch HTML\nhtml = await scraper.fetch(\"https://example.com\")\n\n# Extract text content\ntext = await scraper.fetch_text(\"https://example.com\")\nprint(text)  # Clean, readable text\n\n# Scrape with CSS selectors\ntitles = await scraper.scrape(\n    \"https://news.ycombinator.com\",\n    selector=\"span.titleline &gt; a\"\n)\nfor title in titles:\n    print(title)\n</code></pre>"},{"location":"guides/web-integration/#robotstxt-compliance","title":"robots.txt Compliance","text":"<p>Kagura respects robots.txt by default:</p> <pre><code>scraper = WebScraper(\n    respect_robots_txt=True,  # Default: True\n    user_agent=\"KaguraAI/2.5.0\",\n    rate_limit_delay=1.0  # Delay between requests (seconds)\n)\n</code></pre> <p>If a site disallows scraping:</p> <pre><code>try:\n    html = await scraper.fetch(\"https://example.com/private\")\nexcept ValueError as e:\n    print(f\"Blocked by robots.txt: {e}\")\n</code></pre>"},{"location":"guides/web-integration/#rate-limiting","title":"Rate Limiting","text":"<p>Automatic rate limiting prevents overwhelming servers:</p> <pre><code>from kagura.web.scraper import WebScraper\n\nscraper = WebScraper(rate_limit_delay=2.0)  # 2 seconds between requests\n\n# These will be rate-limited automatically\nawait scraper.fetch(\"https://example.com/page1\")\nawait scraper.fetch(\"https://example.com/page2\")  # Waits 2 seconds\nawait scraper.fetch(\"https://example.com/page3\")  # Waits 2 seconds\n</code></pre>"},{"location":"guides/web-integration/#advanced-scraping","title":"Advanced Scraping","text":"<pre><code>from kagura.web.scraper import WebScraper\n\nscraper = WebScraper(\n    user_agent=\"MyBot/1.0 (+https://mysite.com/bot)\",\n    respect_robots_txt=True,\n    rate_limit_delay=1.5\n)\n\n# Custom timeout\nhtml = await scraper.fetch(\"https://slow-site.com\", timeout=60.0)\n\n# Parse specific elements\narticles = await scraper.scrape(\n    \"https://blog.com\",\n    selector=\"article.post\"\n)\n</code></pre>"},{"location":"guides/web-integration/#agent-integration","title":"Agent Integration","text":""},{"location":"guides/web-integration/#web-enabled-agent","title":"Web-Enabled Agent","text":"<p>Create an agent that can search the web:</p> <pre><code>from kagura import agent\nfrom kagura.web import web_search\n\nasync def search_tool(query: str) -&gt; str:\n    \"\"\"Search the web for information.\"\"\"\n    return await web_search(query)\n\n@agent(\n    model=\"gpt-4o-mini\",\n    tools=[search_tool]\n)\nasync def research_agent(topic: str) -&gt; str:\n    \"\"\"Research {{ topic }} using web search.\n\n    Use search_tool(query) to search the web.\n    \"\"\"\n    pass\n\n# The agent will use the tool when needed\nreport = await research_agent(\"AI safety regulations 2025\")\n</code></pre>"},{"location":"guides/web-integration/#custom-web-tools","title":"Custom Web Tools","text":"<p>Create specialized web tools:</p> <pre><code>from kagura import agent\nfrom kagura.web.scraper import WebScraper\n\nasync def fetch_news(topic: str) -&gt; str:\n    \"\"\"Fetch latest news about a topic.\"\"\"\n    scraper = WebScraper()\n\n    # Scrape news site\n    headlines = await scraper.scrape(\n        f\"https://news-site.com/search?q={topic}\",\n        selector=\"h2.headline\"\n    )\n\n    return \"\\n\".join(headlines[:5])\n\n@agent(tools=[fetch_news])\nasync def news_assistant(query: str) -&gt; str:\n    \"\"\"Answer questions about current news.\n\n    Query: {{ query }}\n    \"\"\"\n    pass\n</code></pre>"},{"location":"guides/web-integration/#configuration","title":"Configuration","text":""},{"location":"guides/web-integration/#environment-variables","title":"Environment Variables","text":"<pre><code># Brave Search (optional)\nexport BRAVE_SEARCH_API_KEY=\"your-key\"\n\n# User agent (optional)\nexport USER_AGENT=\"MyBot/1.0\"\n\n# Rate limiting (optional)\nexport WEB_RATE_LIMIT=1.5\n</code></pre>"},{"location":"guides/web-integration/#programmatic-configuration","title":"Programmatic Configuration","text":"<pre><code>from kagura.web.search import BraveSearch\nfrom kagura.web.scraper import WebScraper\nimport os\n\n# Configure search (requires API key)\nsearch = BraveSearch(api_key=os.getenv(\"BRAVE_SEARCH_API_KEY\"))\n\n# Configure scraper\nscraper = WebScraper(\n    user_agent=os.getenv(\"USER_AGENT\", \"KaguraAI/2.5.0\"),\n    respect_robots_txt=True,\n    rate_limit_delay=float(os.getenv(\"WEB_RATE_LIMIT\", \"1.0\"))\n)\n</code></pre>"},{"location":"guides/web-integration/#best-practices","title":"Best Practices","text":""},{"location":"guides/web-integration/#1-respect-robotstxt","title":"1. Respect robots.txt","text":"<p>Always check robots.txt before scraping:</p> <pre><code>scraper = WebScraper(respect_robots_txt=True)  # Default\n</code></pre>"},{"location":"guides/web-integration/#2-use-appropriate-user-agent","title":"2. Use Appropriate User Agent","text":"<p>Identify your bot:</p> <pre><code>scraper = WebScraper(\n    user_agent=\"MyBot/1.0 (+https://mysite.com/bot-info)\"\n)\n</code></pre>"},{"location":"guides/web-integration/#3-rate-limiting","title":"3. Rate Limiting","text":"<p>Be a good citizen:</p> <pre><code>scraper = WebScraper(rate_limit_delay=1.0)  # Minimum 1 second\n</code></pre>"},{"location":"guides/web-integration/#4-handle-errors","title":"4. Handle Errors","text":"<pre><code>from httpx import HTTPError\n\ntry:\n    content = await scraper.fetch_text(url)\nexcept HTTPError as e:\n    print(f\"HTTP error: {e}\")\nexcept ValueError as e:\n    print(f\"Blocked by robots.txt: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"guides/web-integration/#5-cache-results","title":"5. Cache Results","text":"<p>Avoid repeated requests:</p> <pre><code>from functools import lru_cache\n\n@lru_cache(maxsize=100)\nasync def cached_search(query: str) -&gt; str:\n    return await web_search(query)\n</code></pre>"},{"location":"guides/web-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/web-integration/#importerror-httpx-not-installed","title":"\"ImportError: httpx not installed\"","text":"<p>Install web dependencies:</p> <pre><code>pip install kagura-ai[web]\n</code></pre>"},{"location":"guides/web-integration/#rate-limit-exceeded","title":"\"Rate limit exceeded\"","text":"<p>Increase delay between requests:</p> <pre><code>scraper = WebScraper(rate_limit_delay=2.0)\n</code></pre> <p>Or wait before retrying:</p> <pre><code>import asyncio\n\ntry:\n    results = await search.search(query)\nexcept Exception as e:\n    print(f\"Rate limited, waiting...\")\n    await asyncio.sleep(60)\n    results = await search.search(query)\n</code></pre>"},{"location":"guides/web-integration/#robotstxt-disallows-fetching","title":"\"robots.txt disallows fetching\"","text":"<p>Either:</p> <ol> <li>Respect the site's wishes (recommended)</li> <li>Disable robots.txt check (not recommended):</li> </ol> <pre><code>scraper = WebScraper(respect_robots_txt=False)\n</code></pre>"},{"location":"guides/web-integration/#connection-timeout","title":"Connection Timeout","text":"<p>Increase timeout:</p> <pre><code>html = await scraper.fetch(url, timeout=60.0)  # 60 seconds\n</code></pre>"},{"location":"guides/web-integration/#examples","title":"Examples","text":""},{"location":"guides/web-integration/#example-1-news-aggregator","title":"Example 1: News Aggregator","text":"<pre><code>from kagura import agent\nfrom kagura.web import web_search\n\n@agent(model=\"gpt-4o-mini\")\nasync def news_bot(topic: str) -&gt; str:\n    \"\"\"Fetch and summarize news about {{ topic }}.\n\n    Use web_search() to find latest news.\n    \"\"\"\n    pass\n\n# Usage\nsummary = await news_bot(\"AI breakthroughs\")\n</code></pre>"},{"location":"guides/web-integration/#example-2-documentation-fetcher","title":"Example 2: Documentation Fetcher","text":"<pre><code>from kagura.web.scraper import WebScraper\n\nasync def fetch_api_docs(library: str) -&gt; str:\n    \"\"\"Fetch API documentation for a library.\"\"\"\n    scraper = WebScraper()\n\n    # Fetch official docs\n    docs_url = f\"https://{library}.readthedocs.io/\"\n    text = await scraper.fetch_text(docs_url)\n\n    return text[:5000]  # First 5000 chars\n\n# Usage\ndocs = await fetch_api_docs(\"httpx\")\n</code></pre>"},{"location":"guides/web-integration/#example-3-competitor-analysis","title":"Example 3: Competitor Analysis","text":"<pre><code>from kagura import agent\nfrom kagura.web import web_search\nfrom kagura.web.scraper import WebScraper\n\nasync def analyze_competitor(competitor_url: str) -&gt; dict:\n    \"\"\"Analyze competitor website.\"\"\"\n    scraper = WebScraper()\n\n    # Fetch homepage\n    text = await scraper.fetch_text(competitor_url)\n\n    # Extract features\n    features = await scraper.scrape(\n        competitor_url,\n        selector=\"div.feature h3\"\n    )\n\n    return {\n        \"content\": text[:2000],\n        \"features\": features\n    }\n\n@agent\nasync def market_analyst(company_name: str) -&gt; str:\n    \"\"\"Analyze {{ company_name }} and competitors.\"\"\"\n    pass\n</code></pre>"},{"location":"guides/web-integration/#performance-tips","title":"Performance Tips","text":""},{"location":"guides/web-integration/#1-parallel-requests","title":"1. Parallel Requests","text":"<p>Use asyncio.gather for parallel fetching:</p> <pre><code>import asyncio\n\nurls = [\"https://site1.com\", \"https://site2.com\", \"https://site3.com\"]\n\n# Fetch in parallel\nresults = await asyncio.gather(\n    *[scraper.fetch_text(url) for url in urls]\n)\n</code></pre>"},{"location":"guides/web-integration/#2-connection-pooling","title":"2. Connection Pooling","text":"<p>httpx automatically pools connections:</p> <pre><code># Reuse scraper instance\nscraper = WebScraper()\n\nfor url in urls:\n    await scraper.fetch(url)  # Reuses connections\n</code></pre>"},{"location":"guides/web-integration/#3-timeout-management","title":"3. Timeout Management","text":"<p>Set appropriate timeouts:</p> <pre><code># Fast timeout for quick checks\nawait scraper.fetch(url, timeout=5.0)\n\n# Longer timeout for heavy pages\nawait scraper.fetch(url, timeout=30.0)\n</code></pre>"},{"location":"guides/web-integration/#next-steps","title":"Next Steps","text":"<ul> <li>Multimodal RAG Guide - Add local file indexing</li> <li>Full-Featured Mode - Combine all features</li> <li>API Reference - Detailed API documentation</li> </ul>"},{"location":"guides/web-integration/#resources","title":"Resources","text":"<ul> <li>Brave Search API</li> <li>httpx Documentation</li> <li>BeautifulSoup Documentation</li> <li>robots.txt Specification</li> </ul>"},{"location":"tutorials/01-basic-agent/","title":"Tutorial 1: Creating Your First Agent","text":"<p>Learn how to create a basic AI agent using the <code>@agent</code> decorator.</p>"},{"location":"tutorials/01-basic-agent/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed (<code>pip install kagura-ai</code>)</li> <li>OpenAI API key (or other LLM provider)</li> </ul>"},{"location":"tutorials/01-basic-agent/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand the <code>@agent</code> decorator - Create a simple conversational agent - Run and test your agent - Understand how prompts work</p>"},{"location":"tutorials/01-basic-agent/#step-1-set-up-your-environment","title":"Step 1: Set Up Your Environment","text":"<p>First, set your API key:</p> <pre><code>export OPENAI_API_KEY=\"your-key-here\"\n</code></pre> <p>Create a new file called <code>hello_agent.py</code>:</p> <pre><code>touch hello_agent.py\n</code></pre>"},{"location":"tutorials/01-basic-agent/#step-2-import-kagura","title":"Step 2: Import Kagura","text":"<p>Open <code>hello_agent.py</code> and add the import:</p> <pre><code>import asyncio\nfrom kagura import agent\n</code></pre> <p>Explanation: - <code>asyncio</code>: Python's built-in library for async operations - <code>agent</code>: The core decorator from Kagura AI</p>"},{"location":"tutorials/01-basic-agent/#step-3-define-your-first-agent","title":"Step 3: Define Your First Agent","text":"<p>Add this agent definition:</p> <pre><code>@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n</code></pre> <p>Let's break this down:</p> <ol> <li><code>@agent</code> - The decorator that converts the function into an AI agent</li> <li><code>async def hello</code> - An async function (required for all agents)</li> <li><code>(name: str)</code> - Function parameter with type hint</li> <li><code>-&gt; str</code> - Return type annotation (tells parser to expect a string)</li> <li><code>'''Say hello to {{ name }}'''</code> - The prompt template using Jinja2 syntax</li> <li><code>pass</code> - Function body (ignored, as decorator replaces it)</li> </ol>"},{"location":"tutorials/01-basic-agent/#step-4-create-a-main-function","title":"Step 4: Create a Main Function","text":"<p>Add code to run the agent:</p> <pre><code>async def main():\n    # Call the agent\n    result = await hello(\"World\")\n    print(result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"tutorials/01-basic-agent/#step-5-run-your-agent","title":"Step 5: Run Your Agent","text":"<p>Execute the script:</p> <pre><code>python hello_agent.py\n</code></pre> <p>Expected output: <pre><code>Hello, World! How can I assist you today?\n</code></pre></p> <p>\ud83c\udf89 Congratulations! You've created your first AI agent.</p>"},{"location":"tutorials/01-basic-agent/#complete-code","title":"Complete Code","text":"<p>Here's the full <code>hello_agent.py</code>:</p> <pre><code>import asyncio\nfrom kagura import agent\n\n\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\n\nasync def main():\n    result = await hello(\"World\")\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"tutorials/01-basic-agent/#understanding-what-happened","title":"Understanding What Happened","text":"<p>Let's trace the execution:</p> <ol> <li>You call: <code>await hello(\"World\")</code></li> <li>Decorator extracts: Parameter <code>name = \"World\"</code></li> <li>Template renders: <code>\"Say hello to World\"</code></li> <li>LLM is called: With the rendered prompt</li> <li>Response is parsed: As a string (because <code>-&gt; str</code>)</li> <li>Result returned: <code>\"Hello, World! How can I assist you today?\"</code></li> </ol>"},{"location":"tutorials/01-basic-agent/#experiment-different-names","title":"Experiment: Different Names","text":"<p>Try calling with different names:</p> <pre><code>async def main():\n    print(await hello(\"Alice\"))\n    print(await hello(\"Bob\"))\n    print(await hello(\"\u795e\u697d\"))  # Japanese name\n</code></pre> <p>Output: <pre><code>Hello, Alice! How can I help you?\nHello, Bob! Nice to meet you!\n\u3053\u3093\u306b\u3061\u306f\u3001\u795e\u697d\u3055\u3093\uff01\u304a\u624b\u4f1d\u3044\u3067\u304d\u308b\u3053\u3068\u306f\u3042\u308a\u307e\u3059\u304b\uff1f\n</code></pre></p> <p>Notice how the LLM adapts its response based on the input!</p>"},{"location":"tutorials/01-basic-agent/#experiment-multiple-parameters","title":"Experiment: Multiple Parameters","text":"<p>Let's create an agent with multiple parameters:</p> <pre><code>@agent\nasync def greet(name: str, time_of_day: str = \"morning\") -&gt; str:\n    '''Good {{ time_of_day }}, {{ name }}! How are you doing?'''\n    pass\n\n\nasync def main():\n    print(await greet(\"Alice\"))\n    print(await greet(\"Bob\", \"evening\"))\n</code></pre> <p>Output: <pre><code>Good morning, Alice! How are you doing?\nI hope you're doing well!\n\nGood evening, Bob! How are you doing?\nI hope you had a great day!\n</code></pre></p>"},{"location":"tutorials/01-basic-agent/#experiment-different-prompts","title":"Experiment: Different Prompts","text":"<p>The prompt greatly affects the response. Try these variations:</p>"},{"location":"tutorials/01-basic-agent/#formal-greeting","title":"Formal Greeting","text":"<pre><code>@agent\nasync def formal_greet(name: str) -&gt; str:\n    '''Provide a formal business greeting to {{ name }}, a potential client.'''\n    pass\n</code></pre>"},{"location":"tutorials/01-basic-agent/#casual-greeting","title":"Casual Greeting","text":"<pre><code>@agent\nasync def casual_greet(name: str) -&gt; str:\n    '''Give a super casual, friendly greeting to {{ name }}, your best friend.'''\n    pass\n</code></pre>"},{"location":"tutorials/01-basic-agent/#poetic-greeting","title":"Poetic Greeting","text":"<pre><code>@agent\nasync def poetic_greet(name: str) -&gt; str:\n    '''Write a short, poetic greeting to {{ name }} (2-3 lines).'''\n    pass\n</code></pre>"},{"location":"tutorials/01-basic-agent/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"tutorials/01-basic-agent/#1-the-agent-decorator","title":"1. The @agent Decorator","text":"<p>Converts a function into an AI agent: - Extracts function signature - Uses docstring as prompt template - Calls LLM automatically - Parses response based on return type</p>"},{"location":"tutorials/01-basic-agent/#2-asyncawait","title":"2. Async/Await","text":"<p>All agents are async functions: <pre><code>result = await hello(\"World\")  # \u2713 Correct\nresult = hello(\"World\")        # \u2717 Wrong - missing await\n</code></pre></p>"},{"location":"tutorials/01-basic-agent/#3-type-hints","title":"3. Type Hints","text":"<p>Type hints tell the parser how to handle the response: <pre><code>async def hello(name: str) -&gt; str:  # Returns string\n    pass\n</code></pre></p>"},{"location":"tutorials/01-basic-agent/#4-prompt-templates","title":"4. Prompt Templates","text":"<p>Docstrings use Jinja2 syntax for dynamic prompts: <pre><code>'''Say hello to {{ name }}'''  # {{ }} injects variables\n</code></pre></p>"},{"location":"tutorials/01-basic-agent/#common-mistakes","title":"Common Mistakes","text":""},{"location":"tutorials/01-basic-agent/#1-forgetting-asyncawait","title":"1. Forgetting <code>async</code>/<code>await</code>","text":"<pre><code># Wrong\n@agent\ndef hello(name: str) -&gt; str:  # Missing 'async'\n    pass\n\nresult = hello(\"World\")  # Missing 'await'\n\n# Correct\n@agent\nasync def hello(name: str) -&gt; str:\n    pass\n\nresult = await hello(\"World\")\n</code></pre>"},{"location":"tutorials/01-basic-agent/#2-missing-return-type","title":"2. Missing Return Type","text":"<pre><code># Less good\n@agent\nasync def hello(name: str):  # No return type\n    pass\n\n# Better\n@agent\nasync def hello(name: str) -&gt; str:  # Explicit return type\n    pass\n</code></pre>"},{"location":"tutorials/01-basic-agent/#3-empty-docstring","title":"3. Empty Docstring","text":"<pre><code># Won't work well\n@agent\nasync def hello(name: str) -&gt; str:\n    pass  # No docstring = no prompt!\n\n# Correct\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n</code></pre>"},{"location":"tutorials/01-basic-agent/#next-steps","title":"Next Steps","text":"<p>Now that you understand basic agents, you can:</p> <ol> <li>Learn about templates - Tutorial 2: Template Engine</li> <li>Explore type parsing - Tutorial 3: Type-Based Parsing</li> <li>Try Interactive Chat - Run <code>kagura chat</code> to experiment</li> </ol>"},{"location":"tutorials/01-basic-agent/#practice-exercises","title":"Practice Exercises","text":""},{"location":"tutorials/01-basic-agent/#exercise-1-sentiment-analysis","title":"Exercise 1: Sentiment Analysis","text":"<p>Create an agent that analyzes sentiment:</p> <pre><code>@agent\nasync def analyze_sentiment(text: str) -&gt; str:\n    '''Analyze the sentiment (positive/negative/neutral) of: {{ text }}'''\n    pass\n</code></pre> <p>Test it: <pre><code>print(await analyze_sentiment(\"I love this product!\"))\nprint(await analyze_sentiment(\"This is terrible.\"))\nprint(await analyze_sentiment(\"It's okay.\"))\n</code></pre></p>"},{"location":"tutorials/01-basic-agent/#exercise-2-language-translation","title":"Exercise 2: Language Translation","text":"<p>Create a translation agent:</p> <pre><code>@agent\nasync def translate(text: str, target_language: str) -&gt; str:\n    '''Translate to {{ target_language }}: {{ text }}'''\n    pass\n</code></pre> <p>Test it: <pre><code>print(await translate(\"Hello, world!\", \"Japanese\"))\nprint(await translate(\"Hello, world!\", \"French\"))\n</code></pre></p>"},{"location":"tutorials/01-basic-agent/#exercise-3-question-answering","title":"Exercise 3: Question Answering","text":"<p>Create a Q&amp;A agent:</p> <pre><code>@agent\nasync def answer_question(question: str) -&gt; str:\n    '''Answer this question concisely: {{ question }}'''\n    pass\n</code></pre> <p>Test it: <pre><code>print(await answer_question(\"What is Python?\"))\nprint(await answer_question(\"How do I install Kagura AI?\"))\n</code></pre></p>"},{"location":"tutorials/01-basic-agent/#summary","title":"Summary","text":"<p>You learned: - \u2713 How to use the <code>@agent</code> decorator - \u2713 How to create async agent functions - \u2713 How to use type hints for return types - \u2713 How to write prompt templates with Jinja2 - \u2713 How to call and test agents</p> <p>Continue to Tutorial 2: Template Engine to learn more advanced prompting techniques!</p>"},{"location":"tutorials/02-templates/","title":"Tutorial 02: Template Engine","text":"<p>Learn how to use Jinja2 templates in your AI agents to create dynamic prompts.</p>"},{"location":"tutorials/02-templates/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How to use Jinja2 template syntax in agent docstrings</li> <li>Template variables and expressions</li> <li>Advanced template features (loops, conditionals)</li> <li>Best practices for prompt engineering</li> </ul>"},{"location":"tutorials/02-templates/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Tutorial 01: Your First Agent</li> <li>Basic understanding of Python f-strings</li> </ul>"},{"location":"tutorials/02-templates/#template-basics","title":"Template Basics","text":"<p>Kagura uses Jinja2 template syntax in agent docstrings. Templates are rendered before being sent to the LLM.</p>"},{"location":"tutorials/02-templates/#simple-variables","title":"Simple Variables","text":"<pre><code>from kagura import agent\n\n@agent\nasync def greet(name: str) -&gt; str:\n    \"\"\"Say hello to {{ name }}\"\"\"\n    pass\n\n# Template renders to: \"Say hello to Alice\"\nresult = await greet(\"Alice\")\n</code></pre> <p>Key Points: - Use <code>{{ variable }}</code> to insert values - Variable names must match function parameters - Values are automatically escaped</p>"},{"location":"tutorials/02-templates/#multiple-variables","title":"Multiple Variables","text":"<pre><code>@agent\nasync def introduce(name: str, age: int, occupation: str) -&gt; str:\n    \"\"\"\n    Introduce yourself as {{ name }}, a {{ age }}-year-old {{ occupation }}.\n    Be friendly and professional.\n    \"\"\"\n    pass\n\nresult = await introduce(\"Bob\", 30, \"engineer\")\n# Template renders to: \"Introduce yourself as Bob, a 30-year-old engineer...\"\n</code></pre>"},{"location":"tutorials/02-templates/#template-expressions","title":"Template Expressions","text":"<p>Jinja2 supports Python-like expressions:</p> <pre><code>@agent\nasync def analyze(score: int) -&gt; str:\n    \"\"\"\n    The score is {{ score }}.\n    {% if score &gt;= 80 %}\n    This is excellent performance!\n    {% elif score &gt;= 60 %}\n    This is good performance.\n    {% else %}\n    This needs improvement.\n    {% endif %}\n    \"\"\"\n    pass\n</code></pre> <p>Expressions You Can Use: - Arithmetic: <code>{{ price * 1.1 }}</code> - Comparison: <code>{% if age &gt; 18 %}</code> - String methods: <code>{{ name.upper() }}</code> - List access: <code>{{ items[0] }}</code></p>"},{"location":"tutorials/02-templates/#loops","title":"Loops","text":"<p>Process lists and dictionaries in templates:</p> <pre><code>from typing import List\n\n@agent\nasync def summarize_items(items: List[str]) -&gt; str:\n    \"\"\"\n    Summarize the following items:\n    {% for item in items %}\n    - {{ item }}\n    {% endfor %}\n\n    Provide a brief overview.\n    \"\"\"\n    pass\n\nresult = await summarize_items([\"apples\", \"oranges\", \"bananas\"])\n</code></pre> <p>Loop Features: - <code>{% for item in list %}</code>: Iterate over lists - <code>{{ loop.index }}</code>: Current iteration (1-based) - <code>{{ loop.first }}</code>: True on first iteration - <code>{{ loop.last }}</code>: True on last iteration</p>"},{"location":"tutorials/02-templates/#filters","title":"Filters","text":"<p>Transform values with filters:</p> <pre><code>@agent\nasync def format_text(text: str) -&gt; str:\n    \"\"\"\n    Original: {{ text }}\n    Uppercase: {{ text | upper }}\n    Capitalized: {{ text | capitalize }}\n    First 50 chars: {{ text[:50] }}\n    \"\"\"\n    pass\n</code></pre> <p>Common Filters: - <code>upper</code>, <code>lower</code>, <code>capitalize</code>: Text transformation - <code>length</code>: Get length of string/list - <code>default(value)</code>: Default value if undefined - <code>join(separator)</code>: Join list items</p>"},{"location":"tutorials/02-templates/#complex-data-structures","title":"Complex Data Structures","text":"<p>Work with dictionaries and objects:</p> <pre><code>from pydantic import BaseModel\nfrom typing import Dict\n\nclass User(BaseModel):\n    name: str\n    email: str\n    age: int\n\n@agent\nasync def analyze_user(user: User) -&gt; str:\n    \"\"\"\n    Analyze user profile:\n    - Name: {{ user.name }}\n    - Email: {{ user.email }}\n    - Age: {{ user.age }}\n\n    Provide insights about this user.\n    \"\"\"\n    pass\n\nuser = User(name=\"Alice\", email=\"alice@example.com\", age=25)\nresult = await analyze_user(user)\n</code></pre> <p>Accessing Data: - Dictionary: <code>{{ data['key'] }}</code> or <code>{{ data.key }}</code> - Object attributes: <code>{{ obj.attribute }}</code> - Nested: <code>{{ user.address.city }}</code></p>"},{"location":"tutorials/02-templates/#multiline-templates","title":"Multiline Templates","text":"<p>For complex prompts, use multiline docstrings:</p> <pre><code>@agent\nasync def write_email(\n    recipient: str,\n    subject: str,\n    points: List[str],\n    tone: str = \"professional\"\n) -&gt; str:\n    \"\"\"\n    Write an email with the following specifications:\n\n    To: {{ recipient }}\n    Subject: {{ subject }}\n    Tone: {{ tone }}\n\n    Key points to cover:\n    {% for point in points %}\n    {{ loop.index }}. {{ point }}\n    {% endfor %}\n\n    Make it {{ tone }} and concise.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/02-templates/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/02-templates/#1-clear-instructions","title":"1. Clear Instructions","text":"<pre><code># \u2705 Good: Clear instructions\n@agent\nasync def translate(text: str, target_lang: str) -&gt; str:\n    \"\"\"\n    Translate the following text to {{ target_lang }}:\n    {{ text }}\n\n    Return only the translated text, no explanations.\n    \"\"\"\n    pass\n\n# \u274c Bad: Vague instructions\n@agent\nasync def translate(text: str, target_lang: str) -&gt; str:\n    \"\"\"{{ text }} {{ target_lang }}\"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/02-templates/#2-structure-your-prompts","title":"2. Structure Your Prompts","text":"<pre><code>@agent\nasync def analyze(data: str) -&gt; str:\n    \"\"\"\n    ## Task\n    Analyze the following data.\n\n    ## Data\n    {{ data }}\n\n    ## Requirements\n    - Identify key trends\n    - Provide insights\n    - Be concise\n    \"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/02-templates/#3-use-conditionals-wisely","title":"3. Use Conditionals Wisely","text":"<pre><code>@agent\nasync def respond(message: str, context: str = None) -&gt; str:\n    \"\"\"\n    {% if context %}\n    Context: {{ context }}\n    {% endif %}\n\n    User message: {{ message }}\n\n    Respond appropriately{{ \" based on the context\" if context else \"\" }}.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/02-templates/#4-validate-input","title":"4. Validate Input","text":"<pre><code>@agent\nasync def process(items: List[str]) -&gt; str:\n    \"\"\"\n    {% if items %}\n    Process these items:\n    {% for item in items %}\n    - {{ item }}\n    {% endfor %}\n    {% else %}\n    No items to process.\n    {% endif %}\n    \"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/02-templates/#common-patterns","title":"Common Patterns","text":""},{"location":"tutorials/02-templates/#chain-of-thought","title":"Chain of Thought","text":"<pre><code>@agent\nasync def solve_math(problem: str) -&gt; str:\n    \"\"\"\n    Solve this math problem: {{ problem }}\n\n    Think step by step:\n    1. First, identify the operation\n    2. Then, calculate the result\n    3. Finally, verify your answer\n    \"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/02-templates/#few-shot-learning","title":"Few-Shot Learning","text":"<pre><code>@agent\nasync def classify(text: str) -&gt; str:\n    \"\"\"\n    Classify the sentiment of the text.\n\n    Examples:\n    Text: \"I love this!\" \u2192 Sentiment: positive\n    Text: \"This is terrible\" \u2192 Sentiment: negative\n    Text: \"It's okay\" \u2192 Sentiment: neutral\n\n    Text: {{ text }} \u2192 Sentiment: ?\n    \"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/02-templates/#role-based-prompts","title":"Role-Based Prompts","text":"<pre><code>@agent\nasync def code_review(code: str, language: str) -&gt; str:\n    \"\"\"\n    You are an expert {{ language }} developer.\n    Review this code and provide suggestions:\n\n    ```{{ language }}\n    {{ code }}\n    ```\n\n    Focus on:\n    - Code quality\n    - Best practices\n    - Potential bugs\n    \"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/02-templates/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/02-templates/#template-syntax-errors","title":"Template Syntax Errors","text":"<pre><code># \u274c Wrong: Missing closing tag\n\"\"\"\n{% for item in items %}\n{{ item }}\n\"\"\"\n\n# \u2705 Correct: Proper closing\n\"\"\"\n{% for item in items %}\n{{ item }}\n{% endfor %}\n\"\"\"\n</code></pre>"},{"location":"tutorials/02-templates/#variable-not-found","title":"Variable Not Found","text":"<pre><code># \u274c Wrong: Variable doesn't match parameter\n@agent\nasync def greet(name: str) -&gt; str:\n    \"\"\"Hello {{ username }}\"\"\"  # username doesn't exist\n    pass\n\n# \u2705 Correct: Variable matches parameter\n@agent\nasync def greet(name: str) -&gt; str:\n    \"\"\"Hello {{ name }}\"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/02-templates/#escaping-special-characters","title":"Escaping Special Characters","text":"<pre><code># If you need literal {{ or }}\n@agent\nasync def explain() -&gt; str:\n    \"\"\"\n    In Jinja2, use {% raw %}{{ variable }}{% endraw %} for templates.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/02-templates/#practice-exercises","title":"Practice Exercises","text":""},{"location":"tutorials/02-templates/#exercise-1-user-profile-generator","title":"Exercise 1: User Profile Generator","text":"<p>Create an agent that generates user profiles:</p> <pre><code>from typing import List\n\n@agent\nasync def create_profile(\n    name: str,\n    skills: List[str],\n    experience_years: int\n) -&gt; str:\n    \"\"\"\n    # TODO: Write template that:\n    # - Introduces the person\n    # - Lists their skills\n    # - Mentions experience level\n    \"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/02-templates/#exercise-2-conditional-email-writer","title":"Exercise 2: Conditional Email Writer","text":"<p>Create an agent with conditional formatting:</p> <pre><code>@agent\nasync def write_email(\n    recipient: str,\n    is_urgent: bool,\n    has_attachments: bool\n) -&gt; str:\n    \"\"\"\n    # TODO: Write template that:\n    # - Adds [URGENT] to subject if urgent\n    # - Mentions attachments if present\n    \"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/02-templates/#exercise-3-data-analyzer","title":"Exercise 3: Data Analyzer","text":"<p>Create an agent that analyzes data with loops:</p> <pre><code>from typing import Dict\n\n@agent\nasync def analyze_metrics(metrics: Dict[str, float]) -&gt; str:\n    \"\"\"\n    # TODO: Write template that:\n    # - Iterates over metrics\n    # - Highlights values &gt; 80\n    # - Provides summary\n    \"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/02-templates/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial 03: Type-Based Parsing - Learn how to parse structured responses</li> <li>API Reference: Templates - Complete template documentation</li> </ul>"},{"location":"tutorials/02-templates/#additional-resources","title":"Additional Resources","text":"<ul> <li>Jinja2 Documentation</li> <li>Prompt Engineering Guide</li> </ul>"},{"location":"tutorials/03-type-parsing/","title":"Tutorial 03: Type-Based Parsing","text":"<p>Learn how to use Python type hints to automatically parse LLM responses into structured data.</p>"},{"location":"tutorials/03-type-parsing/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How type-based parsing works in Kagura</li> <li>Using Pydantic models for complex structures</li> <li>Handling lists, dicts, and nested objects</li> <li>Error handling and validation</li> </ul>"},{"location":"tutorials/03-type-parsing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Tutorial 01: Basic Agent</li> <li>Basic understanding of Python type hints</li> <li>Familiarity with Pydantic (helpful but not required)</li> </ul>"},{"location":"tutorials/03-type-parsing/#why-type-based-parsing","title":"Why Type-Based Parsing?","text":"<p>LLMs return unstructured text, but your application needs structured data. Kagura automatically converts LLM responses to Python types based on your return type annotation.</p> <pre><code># Without parsing: raw string\nasync def get_age(name: str) -&gt; str:\n    \"\"\"What is {{ name }}'s age?\"\"\"\n    pass\n\nresult = await get_age(\"Alice\")\n# result = \"Alice is 25 years old.\"  \u2190 Hard to use in code\n\n# With parsing: structured data\nasync def get_age(name: str) -&gt; int:\n    \"\"\"What is {{ name }}'s age? Return only the number.\"\"\"\n    pass\n\nresult = await get_age(\"Alice\")\n# result = 25  \u2190 Easy to use!\n</code></pre>"},{"location":"tutorials/03-type-parsing/#basic-types","title":"Basic Types","text":""},{"location":"tutorials/03-type-parsing/#strings","title":"Strings","text":"<pre><code>from kagura import agent\n\n@agent\nasync def summarize(text: str) -&gt; str:\n    \"\"\"Summarize this in one sentence: {{ text }}\"\"\"\n    pass\n\nresult = await summarize(\"Long article...\")\n# result: str = \"Article summary.\"\n</code></pre>"},{"location":"tutorials/03-type-parsing/#numbers","title":"Numbers","text":"<pre><code>@agent\nasync def count_words(text: str) -&gt; int:\n    \"\"\"Count the words in: {{ text }}. Return only the number.\"\"\"\n    pass\n\nresult = await count_words(\"Hello world\")\n# result: int = 2\n\n@agent\nasync def calculate_average(numbers: list[int]) -&gt; float:\n    \"\"\"Calculate the average of {{ numbers }}. Return only the number.\"\"\"\n    pass\n\nresult = await calculate_average([1, 2, 3, 4, 5])\n# result: float = 3.0\n</code></pre>"},{"location":"tutorials/03-type-parsing/#booleans","title":"Booleans","text":"<pre><code>@agent\nasync def is_positive(text: str) -&gt; bool:\n    \"\"\"Is this text positive in sentiment? {{ text }}\n    Return only 'true' or 'false'.\"\"\"\n    pass\n\nresult = await is_positive(\"I love this!\")\n# result: bool = True\n</code></pre>"},{"location":"tutorials/03-type-parsing/#collections","title":"Collections","text":""},{"location":"tutorials/03-type-parsing/#lists","title":"Lists","text":"<pre><code>from typing import List\n\n@agent\nasync def extract_keywords(text: str) -&gt; List[str]:\n    \"\"\"Extract keywords from: {{ text }}\n    Return as JSON array.\"\"\"\n    pass\n\nresult = await extract_keywords(\"Python is great for AI\")\n# result: List[str] = [\"Python\", \"AI\", \"programming\"]\n</code></pre> <p>Supported List Types: - <code>List[str]</code>: List of strings - <code>List[int]</code>: List of integers - <code>List[float]</code>: List of floats - <code>List[YourModel]</code>: List of Pydantic models</p>"},{"location":"tutorials/03-type-parsing/#dictionaries","title":"Dictionaries","text":"<pre><code>from typing import Dict\n\n@agent\nasync def extract_metadata(text: str) -&gt; Dict[str, str]:\n    \"\"\"Extract metadata from: {{ text }}\n    Return as JSON object.\"\"\"\n    pass\n\nresult = await extract_metadata(\"Title: Hello\\nAuthor: Alice\")\n# result: Dict[str, str] = {\"title\": \"Hello\", \"author\": \"Alice\"}\n</code></pre>"},{"location":"tutorials/03-type-parsing/#pydantic-models","title":"Pydantic Models","text":"<p>For complex structures, use Pydantic models:</p> <pre><code>from pydantic import BaseModel, Field\nfrom typing import List\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    email: str\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    \"\"\"Extract person information from: {{ text }}\n    Return as JSON object with fields: name, age, email.\"\"\"\n    pass\n\nresult = await extract_person(\"Alice (25) - alice@example.com\")\n# result: Person = Person(name=\"Alice\", age=25, email=\"alice@example.com\")\n</code></pre>"},{"location":"tutorials/03-type-parsing/#model-validation","title":"Model Validation","text":"<p>Pydantic automatically validates the data:</p> <pre><code>from pydantic import BaseModel, EmailStr, validator\n\nclass User(BaseModel):\n    name: str\n    email: EmailStr  # Validates email format\n    age: int\n\n    @validator('age')\n    def age_must_be_positive(cls, v):\n        if v &lt; 0:\n            raise ValueError('age must be positive')\n        return v\n\n@agent\nasync def extract_user(text: str) -&gt; User:\n    \"\"\"Extract user info from: {{ text }}\n    Return as JSON: {name, email, age}\"\"\"\n    pass\n\n# Valid input\nresult = await extract_user(\"Bob, bob@example.com, 30\")\n# result: User(name=\"Bob\", email=\"bob@example.com\", age=30)\n\n# Invalid input (bad email)\n# Will raise ValidationError\n</code></pre>"},{"location":"tutorials/03-type-parsing/#field-descriptions","title":"Field Descriptions","text":"<p>Help the LLM understand fields:</p> <pre><code>class Article(BaseModel):\n    title: str = Field(description=\"The article title\")\n    summary: str = Field(description=\"Brief summary, max 100 words\")\n    tags: List[str] = Field(description=\"Relevant tags, 3-5 items\")\n    published: bool = Field(description=\"Whether article is published\")\n\n@agent\nasync def analyze_article(content: str) -&gt; Article:\n    \"\"\"Analyze this article: {{ content }}\n    Return as JSON with: title, summary, tags, published.\"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/03-type-parsing/#nested-structures","title":"Nested Structures","text":""},{"location":"tutorials/03-type-parsing/#nested-models","title":"Nested Models","text":"<pre><code>class Address(BaseModel):\n    street: str\n    city: str\n    country: str\n\nclass Company(BaseModel):\n    name: str\n    address: Address\n    employees: int\n\n@agent\nasync def extract_company(text: str) -&gt; Company:\n    \"\"\"Extract company information from: {{ text }}\n    Return as JSON with nested address object.\"\"\"\n    pass\n\nresult = await extract_company(\"Acme Corp, 123 Main St, NYC, USA, 500 employees\")\n# result: Company(\n#     name=\"Acme Corp\",\n#     address=Address(street=\"123 Main St\", city=\"NYC\", country=\"USA\"),\n#     employees=500\n# )\n</code></pre>"},{"location":"tutorials/03-type-parsing/#lists-of-models","title":"Lists of Models","text":"<pre><code>class Task(BaseModel):\n    title: str\n    priority: str\n    estimated_hours: int\n\n@agent\nasync def extract_tasks(text: str) -&gt; List[Task]:\n    \"\"\"Extract tasks from: {{ text }}\n    Return as JSON array of objects.\"\"\"\n    pass\n\nresult = await extract_tasks(\"\"\"\n    1. Fix bug - High priority - 3 hours\n    2. Write docs - Low priority - 5 hours\n\"\"\")\n# result: List[Task] = [\n#     Task(title=\"Fix bug\", priority=\"High\", estimated_hours=3),\n#     Task(title=\"Write docs\", priority=\"Low\", estimated_hours=5)\n# ]\n</code></pre>"},{"location":"tutorials/03-type-parsing/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"tutorials/03-type-parsing/#optional-fields","title":"Optional Fields","text":"<pre><code>from typing import Optional\n\nclass Product(BaseModel):\n    name: str\n    price: float\n    discount: Optional[float] = None\n    description: Optional[str] = None\n\n@agent\nasync def extract_product(text: str) -&gt; Product:\n    \"\"\"Extract product info from: {{ text }}\n    Return as JSON. discount and description are optional.\"\"\"\n    pass\n\nresult = await extract_product(\"Laptop $999\")\n# result: Product(name=\"Laptop\", price=999.0, discount=None, description=None)\n</code></pre>"},{"location":"tutorials/03-type-parsing/#union-types","title":"Union Types","text":"<pre><code>from typing import Union\n\n@agent\nasync def parse_value(text: str) -&gt; Union[int, str]:\n    \"\"\"Parse the value from: {{ text }}\n    Return as number if numeric, otherwise as string.\"\"\"\n    pass\n\nresult1 = await parse_value(\"42\")        # returns int: 42\nresult2 = await parse_value(\"hello\")     # returns str: \"hello\"\n</code></pre>"},{"location":"tutorials/03-type-parsing/#enums","title":"Enums","text":"<pre><code>from enum import Enum\n\nclass Priority(str, Enum):\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n\nclass Issue(BaseModel):\n    title: str\n    priority: Priority\n\n@agent\nasync def extract_issue(text: str) -&gt; Issue:\n    \"\"\"Extract issue from: {{ text }}\n    Priority must be: low, medium, or high.\"\"\"\n    pass\n\nresult = await extract_issue(\"Fix login bug - high priority\")\n# result: Issue(title=\"Fix login bug\", priority=Priority.HIGH)\n</code></pre>"},{"location":"tutorials/03-type-parsing/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/03-type-parsing/#1-clear-return-format-instructions","title":"1. Clear Return Format Instructions","text":"<pre><code># \u2705 Good: Explicit format\n@agent\nasync def extract_data(text: str) -&gt; Person:\n    \"\"\"Extract person from: {{ text }}\n    Return as JSON: {\"name\": str, \"age\": int, \"email\": str}\"\"\"\n    pass\n\n# \u274c Bad: Unclear format\n@agent\nasync def extract_data(text: str) -&gt; Person:\n    \"\"\"Get person from: {{ text }}\"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/03-type-parsing/#2-use-field-descriptions","title":"2. Use Field Descriptions","text":"<pre><code># \u2705 Good: Descriptive fields\nclass Report(BaseModel):\n    summary: str = Field(description=\"Executive summary, 2-3 sentences\")\n    findings: List[str] = Field(description=\"Key findings, bullet points\")\n    score: int = Field(description=\"Overall score 0-100\")\n\n# \u274c Bad: No descriptions\nclass Report(BaseModel):\n    summary: str\n    findings: List[str]\n    score: int\n</code></pre>"},{"location":"tutorials/03-type-parsing/#3-validate-constraints","title":"3. Validate Constraints","text":"<pre><code>from pydantic import validator, Field\n\nclass Temperature(BaseModel):\n    celsius: float = Field(ge=-273.15, description=\"Temperature in Celsius\")\n\n    @validator('celsius')\n    def validate_temp(cls, v):\n        if v &lt; -273.15:\n            raise ValueError('Temperature below absolute zero')\n        return v\n</code></pre>"},{"location":"tutorials/03-type-parsing/#4-handle-errors-gracefully","title":"4. Handle Errors Gracefully","text":"<pre><code>from pydantic import ValidationError\n\n@agent\nasync def extract_safe(text: str) -&gt; Optional[Person]:\n    \"\"\"Extract person from: {{ text }}\n    Return as JSON or null if not found.\"\"\"\n    pass\n\ntry:\n    result = await extract_safe(\"No person here\")\nexcept ValidationError as e:\n    print(f\"Validation failed: {e}\")\n</code></pre>"},{"location":"tutorials/03-type-parsing/#error-handling","title":"Error Handling","text":""},{"location":"tutorials/03-type-parsing/#validation-errors","title":"Validation Errors","text":"<pre><code>from pydantic import ValidationError\n\n@agent\nasync def parse_age(text: str) -&gt; int:\n    \"\"\"Extract age from: {{ text }}. Return only the number.\"\"\"\n    pass\n\ntry:\n    result = await parse_age(\"Alice is twenty-five\")\n    # LLM returns \"twenty-five\" instead of 25\nexcept ValidationError as e:\n    print(f\"Failed to parse: {e}\")\n    # Handle error: retry, use default, etc.\n</code></pre>"},{"location":"tutorials/03-type-parsing/#missing-fields","title":"Missing Fields","text":"<pre><code>class Contact(BaseModel):\n    name: str\n    email: str\n    phone: str  # Required\n\n@agent\nasync def extract_contact(text: str) -&gt; Contact:\n    \"\"\"Extract contact from: {{ text }}\n    Return JSON with: name, email, phone.\"\"\"\n    pass\n\n# If LLM omits phone, ValidationError is raised\ntry:\n    result = await extract_contact(\"John, john@example.com\")\nexcept ValidationError as e:\n    print(\"Missing required field:\", e)\n</code></pre>"},{"location":"tutorials/03-type-parsing/#type-mismatches","title":"Type Mismatches","text":"<pre><code>@agent\nasync def get_count(text: str) -&gt; int:\n    \"\"\"Count items in: {{ text }}. Return only the number.\"\"\"\n    pass\n\n# If LLM returns \"five\" instead of 5\ntry:\n    result = await get_count(\"five items\")\nexcept ValidationError:\n    # Retry with more explicit instructions\n    @agent\n    async def get_count_strict(text: str) -&gt; int:\n        \"\"\"Count items in: {{ text }}.\n        Return ONLY a numeric digit, no words.\"\"\"\n        pass\n</code></pre>"},{"location":"tutorials/03-type-parsing/#common-patterns","title":"Common Patterns","text":""},{"location":"tutorials/03-type-parsing/#progressive-extraction","title":"Progressive Extraction","text":"<pre><code># Step 1: Extract basic info\n@agent\nasync def extract_basic(text: str) -&gt; Dict[str, str]:\n    \"\"\"Extract key-value pairs from: {{ text }}\"\"\"\n    pass\n\n# Step 2: Parse into model\nbasic = await extract_basic(text)\nperson = Person(**basic)\n</code></pre>"},{"location":"tutorials/03-type-parsing/#fallback-values","title":"Fallback Values","text":"<pre><code>class Config(BaseModel):\n    timeout: int = 30  # Default value\n    retries: int = 3\n    debug: bool = False\n\n@agent\nasync def parse_config(text: str) -&gt; Config:\n    \"\"\"Parse config from: {{ text }}\n    Use defaults for missing values.\"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/03-type-parsing/#multi-step-validation","title":"Multi-Step Validation","text":"<pre><code>class ValidatedData(BaseModel):\n    data: str\n\n    @validator('data')\n    def clean_data(cls, v):\n        # Clean and validate\n        return v.strip().lower()\n\n@agent\nasync def extract_and_validate(text: str) -&gt; ValidatedData:\n    \"\"\"Extract data from: {{ text }}\"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/03-type-parsing/#practice-exercises","title":"Practice Exercises","text":""},{"location":"tutorials/03-type-parsing/#exercise-1-contact-extractor","title":"Exercise 1: Contact Extractor","text":"<p>Create a model for contact information:</p> <pre><code>class Contact(BaseModel):\n    # TODO: Add fields for name, email, phone, company\n    pass\n\n@agent\nasync def extract_contact(text: str) -&gt; Contact:\n    \"\"\"# TODO: Write prompt to extract contact info\"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/03-type-parsing/#exercise-2-product-list-parser","title":"Exercise 2: Product List Parser","text":"<p>Parse a list of products:</p> <pre><code>class Product(BaseModel):\n    # TODO: Add fields for name, price, stock\n    pass\n\n@agent\nasync def parse_products(text: str) -&gt; List[Product]:\n    \"\"\"# TODO: Write prompt to parse product list\"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/03-type-parsing/#exercise-3-nested-organization","title":"Exercise 3: Nested Organization","text":"<p>Create a nested structure:</p> <pre><code>class Employee(BaseModel):\n    # TODO: name, role, salary\n    pass\n\nclass Department(BaseModel):\n    # TODO: name, employees list, budget\n    pass\n\n@agent\nasync def parse_org(text: str) -&gt; Department:\n    \"\"\"# TODO: Write prompt to parse organization\"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/03-type-parsing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/03-type-parsing/#llm-returns-wrong-format","title":"LLM Returns Wrong Format","text":"<pre><code># Problem: LLM returns \"The age is 25\" instead of just \"25\"\n\n# Solution: Be more explicit\n@agent\nasync def get_age(name: str) -&gt; int:\n    \"\"\"What is {{ name }}'s age?\n    IMPORTANT: Return ONLY the numeric age, nothing else.\n    Example: 25\"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/03-type-parsing/#validation-fails-repeatedly","title":"Validation Fails Repeatedly","text":"<pre><code># Problem: LLM returns data that fails validation\n\n# Solution: Relax constraints or provide examples\nclass Person(BaseModel):\n    age: int = Field(ge=0, le=150, description=\"Age between 0-150\")\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    \"\"\"Extract person from: {{ text }}\n    Return JSON: {\"name\": \"string\", \"age\": number between 0-150}\n    Example: {\"name\": \"Alice\", \"age\": 25}\"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/03-type-parsing/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial 04: Code Execution - Execute Python code with AI</li> <li>API Reference: Type Parsing - Complete parsing documentation</li> <li>Pydantic Documentation - Learn more about Pydantic</li> </ul>"},{"location":"tutorials/03-type-parsing/#additional-resources","title":"Additional Resources","text":"<ul> <li>Type Hints Cheat Sheet</li> <li>Pydantic Field Types</li> </ul>"},{"location":"tutorials/04-code-execution/","title":"Tutorial 04: Code Execution","text":"<p>Learn how to safely execute Python code generated by AI agents.</p>"},{"location":"tutorials/04-code-execution/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How to use the <code>execute_code</code> agent</li> <li>Security constraints and sandboxing</li> <li>Working with execution results</li> <li>Building code-generating workflows</li> <li>Best practices for code execution</li> </ul>"},{"location":"tutorials/04-code-execution/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Tutorial 01: Basic Agent</li> <li>Understanding of Python basics</li> <li>Familiarity with security concepts (helpful)</li> </ul>"},{"location":"tutorials/04-code-execution/#why-code-execution","title":"Why Code Execution?","text":"<p>Sometimes the best way to solve a problem is to write and execute code. Kagura provides a safe way to let AI agents generate and run Python code:</p> <pre><code>from kagura.agents import execute_code\n\nresult = await execute_code(\"Calculate the factorial of 10\")\n\nif result[\"success\"]:\n    print(result[\"result\"])  # 3628800\n    print(result[\"code\"])    # Shows the generated code\n</code></pre>"},{"location":"tutorials/04-code-execution/#basic-usage","title":"Basic Usage","text":""},{"location":"tutorials/04-code-execution/#simple-calculations","title":"Simple Calculations","text":"<pre><code>from kagura.agents import execute_code\n\n# Mathematical operations\nresult = await execute_code(\"What is 2^10?\")\nprint(result[\"result\"])  # 1024\n\n# Data processing\nresult = await execute_code(\"Sum the numbers from 1 to 100\")\nprint(result[\"result\"])  # 5050\n\n# String operations\nresult = await execute_code(\"Reverse the string 'hello'\")\nprint(result[\"result\"])  # \"olleh\"\n</code></pre>"},{"location":"tutorials/04-code-execution/#understanding-the-result","title":"Understanding the Result","text":"<p>The <code>execute_code</code> function returns a dictionary:</p> <pre><code>result = {\n    \"success\": True,         # Whether execution succeeded\n    \"result\": 3628800,       # The value of the `result` variable\n    \"code\": \"...\",          # The generated Python code\n    \"error\": None           # Error message if failed\n}\n</code></pre> <p>Important: The executed code must set a variable named <code>result</code>:</p> <pre><code># \u2705 Good: Sets result variable\nresult = await execute_code(\"Calculate 5 * 5\")\n# Generated code: result = 5 * 5\n\n# \u274c Bad: Doesn't set result\nresult = await execute_code(\"Print hello world\")\n# No result variable \u2192 result[\"result\"] is None\n</code></pre>"},{"location":"tutorials/04-code-execution/#data-processing","title":"Data Processing","text":""},{"location":"tutorials/04-code-execution/#working-with-lists","title":"Working with Lists","text":"<pre><code># Filter data\nresult = await execute_code(\"\"\"\nFind all even numbers in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\"\"\")\nprint(result[\"result\"])  # [2, 4, 6, 8, 10]\n\n# Transform data\nresult = await execute_code(\"\"\"\nSquare each number in [1, 2, 3, 4, 5]\n\"\"\")\nprint(result[\"result\"])  # [1, 4, 9, 16, 25]\n\n# Aggregate data\nresult = await execute_code(\"\"\"\nCalculate the average of [10, 20, 30, 40, 50]\n\"\"\")\nprint(result[\"result\"])  # 30.0\n</code></pre>"},{"location":"tutorials/04-code-execution/#working-with-dictionaries","title":"Working with Dictionaries","text":"<pre><code># Extract data\nresult = await execute_code(\"\"\"\nFrom this data: {'name': 'Alice', 'age': 25, 'city': 'NYC'}\nExtract the age\n\"\"\")\nprint(result[\"result\"])  # 25\n\n# Transform data\nresult = await execute_code(\"\"\"\nConvert this data to uppercase keys:\n{'name': 'Alice', 'role': 'engineer'}\n\"\"\")\nprint(result[\"result\"])  # {'NAME': 'Alice', 'ROLE': 'engineer'}\n</code></pre>"},{"location":"tutorials/04-code-execution/#json-processing","title":"JSON Processing","text":"<pre><code>import json\n\n# Parse and analyze JSON\njson_data = json.dumps({\n    \"users\": [\n        {\"name\": \"Alice\", \"score\": 95},\n        {\"name\": \"Bob\", \"score\": 87},\n        {\"name\": \"Charlie\", \"score\": 92}\n    ]\n})\n\nresult = await execute_code(f\"\"\"\nParse this JSON and find the average score:\n{json_data}\n\"\"\")\nprint(result[\"result\"])  # 91.33...\n</code></pre>"},{"location":"tutorials/04-code-execution/#advanced-features","title":"Advanced Features","text":""},{"location":"tutorials/04-code-execution/#multi-step-calculations","title":"Multi-Step Calculations","text":"<pre><code>result = await execute_code(\"\"\"\n1. Create a list of numbers from 1 to 20\n2. Filter only prime numbers\n3. Calculate their sum\n\"\"\")\n\nprint(result[\"code\"])    # See the generated algorithm\nprint(result[\"result\"])  # Sum of primes\n</code></pre>"},{"location":"tutorials/04-code-execution/#custom-algorithms","title":"Custom Algorithms","text":"<pre><code>result = await execute_code(\"\"\"\nImplement the Fibonacci sequence up to the 10th number\n\"\"\")\n\nprint(result[\"result\"])  # [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n</code></pre>"},{"location":"tutorials/04-code-execution/#data-analysis","title":"Data Analysis","text":"<pre><code>result = await execute_code(\"\"\"\nGiven these test scores: [78, 92, 85, 88, 95, 72, 90]\nCalculate:\n- Mean\n- Median\n- Mode (if exists)\nReturn as a dictionary\n\"\"\")\n\nprint(result[\"result\"])\n# {'mean': 85.71, 'median': 88, 'mode': None}\n</code></pre>"},{"location":"tutorials/04-code-execution/#security","title":"Security","text":"<p>Kagura executes code in a sandboxed environment with strict security constraints.</p>"},{"location":"tutorials/04-code-execution/#allowed-modules","title":"Allowed Modules","text":"<pre><code># \u2705 Allowed: Safe standard library modules\nresult = await execute_code(\"\"\"\nimport math\nresult = math.sqrt(16)\n\"\"\")\n# Success: 4.0\n\nresult = await execute_code(\"\"\"\nimport json\nresult = json.dumps({'key': 'value'})\n\"\"\")\n# Success: '{\"key\": \"value\"}'\n\nresult = await execute_code(\"\"\"\nfrom datetime import datetime\nresult = datetime.now().year\n\"\"\")\n# Success: 2025\n</code></pre> <p>Allowed modules: - <code>math</code>, <code>random</code>, <code>statistics</code> - <code>json</code>, <code>re</code>, <code>string</code> - <code>datetime</code>, <code>collections</code>, <code>itertools</code> - <code>functools</code>, <code>operator</code>, <code>copy</code></p>"},{"location":"tutorials/04-code-execution/#forbidden-operations","title":"Forbidden Operations","text":"<pre><code># \u274c File system access\nresult = await execute_code(\"Read file config.txt\")\n# Error: Forbidden import: os\n\n# \u274c Network access\nresult = await execute_code(\"Fetch data from https://api.example.com\")\n# Error: Forbidden import: requests\n\n# \u274c System commands\nresult = await execute_code(\"Run shell command ls\")\n# Error: Forbidden import: subprocess\n\n# \u274c Code execution\nresult = await execute_code(\"Execute eval('1+1')\")\n# Error: Forbidden operation: eval\n</code></pre> <p>Forbidden modules/operations: - File I/O: <code>os</code>, <code>sys</code>, <code>io</code>, <code>pathlib</code>, <code>open()</code> - Network: <code>socket</code>, <code>urllib</code>, <code>requests</code> - Execution: <code>eval</code>, <code>exec</code>, <code>compile</code>, <code>__import__</code> - System: <code>subprocess</code>, <code>multiprocessing</code></p>"},{"location":"tutorials/04-code-execution/#timeout-protection","title":"Timeout Protection","text":"<pre><code>from kagura.core.executor import CodeExecutor\n\n# Default timeout: 5 seconds\nexecutor = CodeExecutor()\n\n# Custom timeout\nexecutor = CodeExecutor(timeout=10.0)\n\nresult = await executor.execute(\"\"\"\nimport time\ntime.sleep(15)  # Will timeout after 10 seconds\nresult = \"done\"\n\"\"\")\n\nprint(result.success)  # False\nprint(result.error)    # \"Execution timeout\"\n</code></pre>"},{"location":"tutorials/04-code-execution/#custom-codeexecutor","title":"Custom CodeExecutor","text":"<p>For advanced use cases, use <code>CodeExecutor</code> directly:</p> <pre><code>from kagura.core.executor import CodeExecutor\n\n# Create executor with custom settings\nexecutor = CodeExecutor(\n    timeout=10.0,           # 10 second timeout\n    max_output_size=1000    # Limit output size\n)\n\n# Execute code\nresult = await executor.execute(\"\"\"\nresult = sum(range(1, 1001))\n\"\"\")\n\nprint(result.success)    # True\nprint(result.result)     # 500500\nprint(result.code)       # Generated code\nprint(result.error)      # None\n</code></pre>"},{"location":"tutorials/04-code-execution/#execution-result-object","title":"Execution Result Object","text":"<pre><code>from kagura.core.executor import ExecutionResult\n\nresult = await executor.execute(\"result = 42\")\n\n# Result attributes\nprint(result.success)    # bool: True/False\nprint(result.result)     # Any: The result value\nprint(result.code)       # str: Executed code\nprint(result.error)      # Optional[str]: Error message\nprint(result.stdout)     # str: Standard output\n</code></pre>"},{"location":"tutorials/04-code-execution/#building-code-workflows","title":"Building Code Workflows","text":""},{"location":"tutorials/04-code-execution/#plan-code-execute-pattern","title":"Plan-Code-Execute Pattern","text":"<pre><code>from kagura import agent\nfrom kagura.agents import execute_code\n\n@agent\nasync def plan_solution(problem: str) -&gt; str:\n    \"\"\"\n    Analyze this problem and describe the algorithm:\n    {{ problem }}\n\n    Provide step-by-step approach.\n    \"\"\"\n    pass\n\nasync def solve_with_code(problem: str):\n    # Step 1: Plan\n    plan = await plan_solution(problem)\n    print(f\"Plan: {plan}\")\n\n    # Step 2: Execute\n    result = await execute_code(problem)\n\n    # Step 3: Verify\n    if result[\"success\"]:\n        print(f\"Result: {result['result']}\")\n        print(f\"Code:\\n{result['code']}\")\n    else:\n        print(f\"Error: {result['error']}\")\n\n# Use it\nawait solve_with_code(\"Find all prime numbers between 1 and 50\")\n</code></pre>"},{"location":"tutorials/04-code-execution/#iterative-refinement","title":"Iterative Refinement","text":"<pre><code>async def solve_with_retry(problem: str, max_retries: int = 3):\n    for attempt in range(max_retries):\n        result = await execute_code(problem)\n\n        if result[\"success\"]:\n            return result[\"result\"]\n\n        # If failed, try with more specific instructions\n        problem = f\"{problem}\\n\\nPrevious error: {result['error']}\\nPlease fix and try again.\"\n\n    raise Exception(f\"Failed after {max_retries} attempts\")\n</code></pre>"},{"location":"tutorials/04-code-execution/#code-review-agent","title":"Code Review Agent","text":"<pre><code>@agent\nasync def review_code(code: str) -&gt; str:\n    \"\"\"\n    Review this Python code for:\n    - Correctness\n    - Efficiency\n    - Best practices\n\n    Code:\n    ```python\n    {{ code }}\n    ```\n    \"\"\"\n    pass\n\nasync def code_and_review(problem: str):\n    # Generate code\n    result = await execute_code(problem)\n\n    if result[\"success\"]:\n        # Review the code\n        review = await review_code(result[\"code\"])\n        print(f\"Review: {review}\")\n\n        return result[\"result\"]\n</code></pre>"},{"location":"tutorials/04-code-execution/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/04-code-execution/#1-clear-specifications","title":"1. Clear Specifications","text":"<pre><code># \u2705 Good: Clear requirements\nresult = await execute_code(\"\"\"\nCalculate the factorial of 10.\nStore the result in a variable named 'result'.\n\"\"\")\n\n# \u274c Bad: Vague request\nresult = await execute_code(\"Do factorial stuff\")\n</code></pre>"},{"location":"tutorials/04-code-execution/#2-handle-errors","title":"2. Handle Errors","text":"<pre><code># \u2705 Good: Error handling\nresult = await execute_code(problem)\n\nif result[\"success\"]:\n    process_result(result[\"result\"])\nelse:\n    logger.error(f\"Code execution failed: {result['error']}\")\n    fallback_solution()\n\n# \u274c Bad: No error handling\nresult = await execute_code(problem)\nprocess_result(result[\"result\"])  # May fail!\n</code></pre>"},{"location":"tutorials/04-code-execution/#3-validate-results","title":"3. Validate Results","text":"<pre><code># \u2705 Good: Validate output\nresult = await execute_code(\"Calculate sum of [1,2,3]\")\n\nif result[\"success\"]:\n    value = result[\"result\"]\n    if isinstance(value, (int, float)) and value &gt; 0:\n        use_result(value)\n    else:\n        raise ValueError(f\"Unexpected result: {value}\")\n</code></pre>"},{"location":"tutorials/04-code-execution/#4-provide-context","title":"4. Provide Context","text":"<pre><code># \u2705 Good: Context and examples\nresult = await execute_code(f\"\"\"\nGiven this data: {json.dumps(data)}\nExtract all items where status is 'active'\nReturn as a list\n\nExample output: [item1, item2, ...]\n\"\"\")\n</code></pre>"},{"location":"tutorials/04-code-execution/#5-use-appropriate-timeout","title":"5. Use Appropriate Timeout","text":"<pre><code># \u2705 Good: Adjust timeout based on task\nexecutor = CodeExecutor(timeout=1.0)   # Quick tasks\nresult = await executor.execute(\"result = 2 + 2\")\n\nexecutor = CodeExecutor(timeout=30.0)  # Complex tasks\nresult = await executor.execute(\"Analyze large dataset...\")\n</code></pre>"},{"location":"tutorials/04-code-execution/#common-patterns","title":"Common Patterns","text":""},{"location":"tutorials/04-code-execution/#data-transformation-pipeline","title":"Data Transformation Pipeline","text":"<pre><code>async def transform_data(data: list, operations: list[str]):\n    \"\"\"Apply multiple transformations to data\"\"\"\n    current_data = data\n\n    for operation in operations:\n        result = await execute_code(f\"\"\"\nApply this operation to the data: {operation}\nData: {current_data}\n\"\"\")\n        if result[\"success\"]:\n            current_data = result[\"result\"]\n        else:\n            raise Exception(f\"Failed: {result['error']}\")\n\n    return current_data\n\n# Use it\ndata = [1, 2, 3, 4, 5]\noperations = [\n    \"Multiply each by 2\",\n    \"Filter numbers &gt; 5\",\n    \"Sum all numbers\"\n]\nresult = await transform_data(data, operations)\n</code></pre>"},{"location":"tutorials/04-code-execution/#calculator-agent","title":"Calculator Agent","text":"<pre><code>@agent\nasync def calculate(expression: str) -&gt; float:\n    \"\"\"A calculator agent that evaluates expressions\"\"\"\n    result = await execute_code(f\"Calculate: {expression}\")\n\n    if result[\"success\"]:\n        return result[\"result\"]\n    else:\n        raise ValueError(f\"Calculation failed: {result['error']}\")\n\n# Use it\nanswer = await calculate(\"(5 + 3) * 2 - 10\")\nprint(answer)  # 6.0\n</code></pre>"},{"location":"tutorials/04-code-execution/#data-analysis-agent","title":"Data Analysis Agent","text":"<pre><code>async def analyze_dataset(data: list[dict], query: str):\n    \"\"\"Analyze structured data with natural language\"\"\"\n    data_str = json.dumps(data)\n\n    result = await execute_code(f\"\"\"\nDataset: {data_str}\nQuery: {query}\n\nAnalyze the dataset and answer the query.\n\"\"\")\n\n    return result[\"result\"] if result[\"success\"] else None\n\n# Use it\nsales_data = [\n    {\"product\": \"A\", \"revenue\": 1000},\n    {\"product\": \"B\", \"revenue\": 1500},\n    {\"product\": \"C\", \"revenue\": 800}\n]\n\nresult = await analyze_dataset(\n    sales_data,\n    \"What is the total revenue?\"\n)\nprint(result)  # 3300\n</code></pre>"},{"location":"tutorials/04-code-execution/#practice-exercises","title":"Practice Exercises","text":""},{"location":"tutorials/04-code-execution/#exercise-1-prime-number-finder","title":"Exercise 1: Prime Number Finder","text":"<pre><code># TODO: Create a function that finds prime numbers\nasync def find_primes(n: int):\n    \"\"\"Find all prime numbers up to n\"\"\"\n    result = await execute_code(f\"\"\"\n    Find all prime numbers up to {n}\n    Return as a list\n    \"\"\")\n    return result[\"result\"] if result[\"success\"] else []\n</code></pre>"},{"location":"tutorials/04-code-execution/#exercise-2-data-aggregator","title":"Exercise 2: Data Aggregator","text":"<pre><code># TODO: Create a function that aggregates data\nasync def aggregate_sales(sales: list[dict]) -&gt; dict:\n    \"\"\"Calculate total, average, min, max from sales data\"\"\"\n    # Use execute_code to analyze the sales list\n    pass\n</code></pre>"},{"location":"tutorials/04-code-execution/#exercise-3-text-analyzer","title":"Exercise 3: Text Analyzer","text":"<pre><code># TODO: Create a function that analyzes text\nasync def analyze_text(text: str) -&gt; dict:\n    \"\"\"\n    Analyze text and return:\n    - word_count\n    - unique_words\n    - most_common_word\n    - average_word_length\n    \"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/04-code-execution/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/04-code-execution/#result-is-none","title":"Result is None","text":"<pre><code># Problem: result[\"result\"] is None\n\n# Cause: Code doesn't set 'result' variable\nresult = await execute_code(\"print(42)\")  # Only prints\n\n# Solution: Ask for explicit result\nresult = await execute_code(\"Calculate 42 and store in result variable\")\n</code></pre>"},{"location":"tutorials/04-code-execution/#timeout-errors","title":"Timeout Errors","text":"<pre><code># Problem: Execution timeout\n\n# Cause: Complex operation or infinite loop\nresult = await execute_code(\"Calculate factorial of 100000\")\n\n# Solution: Increase timeout or simplify\nexecutor = CodeExecutor(timeout=30.0)\nresult = await executor.execute(\"Calculate factorial of 100\")\n</code></pre>"},{"location":"tutorials/04-code-execution/#security-errors","title":"Security Errors","text":"<pre><code># Problem: Forbidden import error\n\n# Cause: Trying to use restricted module\nresult = await execute_code(\"Read file data.txt\")\n\n# Solution: Use allowed modules or provide data\nresult = await execute_code(f\"Process this data: {data}\")\n</code></pre>"},{"location":"tutorials/04-code-execution/#next-steps","title":"Next Steps","text":"<ul> <li>Interactive Chat: Try <code>kagura chat</code> for hands-on experimentation</li> <li>API Reference: Code Execution - Complete executor documentation</li> <li>Examples: Code Generator - Full example</li> </ul>"},{"location":"tutorials/04-code-execution/#additional-resources","title":"Additional Resources","text":"<ul> <li>Python Security Best Practices</li> <li>AST Module Documentation</li> </ul>"},{"location":"tutorials/06-mcp-integration/","title":"MCP Integration","text":""},{"location":"tutorials/06-mcp-integration/#overview","title":"Overview","text":"<p>Kagura AI supports MCP (Model Context Protocol), enabling your agents to be used as tools in Claude Desktop, Claude Code, Cline, and other MCP-compatible applications.</p> <p>With MCP integration, you can: - Expose Kagura agents as MCP tools - Use agents from Claude Desktop/Code directly - Share agents across MCP-compatible applications - Build agent ecosystems with standard protocols</p>"},{"location":"tutorials/06-mcp-integration/#what-is-mcp","title":"What is MCP?","text":"<p>Model Context Protocol (MCP) is an open protocol developed by Anthropic that standardizes how AI applications connect to external tools and data sources.</p>"},{"location":"tutorials/06-mcp-integration/#installation","title":"Installation","text":"<p>Install Kagura AI with MCP support:</p> <pre><code>pip install kagura-ai[mcp]\n</code></pre> <p>Or with uv:</p> <pre><code>uv add \"kagura-ai[mcp]\"\n</code></pre> <p>This installs additional dependencies: - <code>mcp&gt;=1.0.0</code> - MCP SDK - <code>jsonschema&gt;=4.20.0</code> - Schema validation</p>"},{"location":"tutorials/06-mcp-integration/#quick-start","title":"Quick Start","text":""},{"location":"tutorials/06-mcp-integration/#1-create-an-agent","title":"1. Create an Agent","text":"<p>Create a simple agent in <code>my_agents.py</code>:</p> <pre><code>from kagura import agent\n\n@agent\nasync def analyze_code(code: str, language: str = \"python\") -&gt; str:\n    \"\"\"\n    Analyze code quality and suggest improvements.\n\n    code: Source code to analyze\n    language: Programming language (default: python)\n    \"\"\"\n    pass\n</code></pre> <p>That's it! The agent is automatically registered and ready to use via MCP.</p>"},{"location":"tutorials/06-mcp-integration/#2-start-mcp-server","title":"2. Start MCP Server","text":"<p>Start the Kagura MCP server:</p> <pre><code>kagura mcp serve\n</code></pre> <p>This starts a stdio-based MCP server that listens for requests.</p>"},{"location":"tutorials/06-mcp-integration/#3-configure-claude-desktop","title":"3. Configure Claude Desktop","text":"<p>Add Kagura to your Claude Desktop configuration:</p> <p>macOS: <code>~/Library/Application Support/Claude/claude_desktop_config.json</code> Windows: <code>%APPDATA%\\Claude\\claude_desktop_config.json</code> Linux: <code>~/.config/Claude/claude_desktop_config.json</code></p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n</code></pre> <p>Note: Replace <code>OPENAI_API_KEY</code> with your actual API key, or use <code>ANTHROPIC_API_KEY</code> if using Claude models.</p>"},{"location":"tutorials/06-mcp-integration/#4-restart-claude-desktop","title":"4. Restart Claude Desktop","text":"<ol> <li>Quit Claude Desktop completely</li> <li>Restart Claude Desktop</li> <li>Your Kagura agents are now available as tools!</li> </ol>"},{"location":"tutorials/06-mcp-integration/#5-use-your-agent-in-claude-desktop","title":"5. Use Your Agent in Claude Desktop","text":"<p>In Claude Desktop, simply ask:</p> <pre><code>Can you analyze this Python code for me?\n\ndef calculate(x):\n    return x * 2 + 3\n</code></pre> <p>Claude will automatically use your <code>analyze_code</code> agent via MCP.</p>"},{"location":"tutorials/06-mcp-integration/#configuration-options","title":"Configuration Options","text":""},{"location":"tutorials/06-mcp-integration/#custom-server-name","title":"Custom Server Name","text":"<pre><code>kagura mcp serve --name my-custom-server\n</code></pre>"},{"location":"tutorials/06-mcp-integration/#environment-variables","title":"Environment Variables","text":"<p>Set API keys and other environment variables in the configuration:</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"${OPENAI_API_KEY}\",\n        \"MODEL\": \"gpt-4o-mini\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"tutorials/06-mcp-integration/#multiple-agent-files","title":"Multiple Agent Files","text":"<p>If you have agents in multiple files, import them before starting the server:</p> <pre><code># startup.py\nimport my_agents\nimport more_agents\n\n# Agents are automatically registered on import\n</code></pre> <p>Then configure Claude Desktop to run your startup script:</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"python\",\n      \"args\": [\"-c\", \"import startup; from kagura.cli.main import cli; cli(['mcp', 'serve'])\"]\n    }\n  }\n}\n</code></pre>"},{"location":"tutorials/06-mcp-integration/#managing-agents","title":"Managing Agents","text":""},{"location":"tutorials/06-mcp-integration/#list-registered-agents","title":"List Registered Agents","text":"<p>See all agents available via MCP:</p> <pre><code>kagura mcp list\n</code></pre> <p>Output: <pre><code>Registered agents (1):\n\n  \u2022 analyze_code\n    Analyze code quality and suggest improvements\n</code></pre></p>"},{"location":"tutorials/06-mcp-integration/#agent-naming-convention","title":"Agent Naming Convention","text":"<p>MCP tool names are prefixed with <code>kagura_</code>: - Agent function: <code>analyze_code</code> - MCP tool name: <code>kagura_analyze_code</code></p> <p>This prevents naming conflicts with other MCP tools.</p>"},{"location":"tutorials/06-mcp-integration/#advanced-usage","title":"Advanced Usage","text":""},{"location":"tutorials/06-mcp-integration/#multiple-agents","title":"Multiple Agents","text":"<p>Create multiple specialized agents:</p> <pre><code>from kagura import agent\n\n@agent\nasync def review_code(code: str) -&gt; str:\n    \"\"\"Review code and provide feedback\"\"\"\n    pass\n\n@agent\nasync def generate_tests(code: str, framework: str = \"pytest\") -&gt; str:\n    \"\"\"Generate unit tests for the code\"\"\"\n    pass\n\n@agent\nasync def explain_code(code: str, audience: str = \"beginner\") -&gt; str:\n    \"\"\"Explain code for different audiences\"\"\"\n    pass\n</code></pre> <p>All three agents are automatically available in Claude Desktop.</p>"},{"location":"tutorials/06-mcp-integration/#complex-input-types","title":"Complex Input Types","text":"<p>Use Pydantic models for structured inputs:</p> <pre><code>from kagura import agent\nfrom pydantic import BaseModel\n\nclass CodeReviewRequest(BaseModel):\n    code: str\n    language: str\n    focus_areas: list[str]\n\n@agent\nasync def detailed_review(request: CodeReviewRequest) -&gt; dict:\n    \"\"\"Perform detailed code review\"\"\"\n    return {\n        \"score\": 8.5,\n        \"issues\": [...],\n        \"suggestions\": [...]\n    }\n</code></pre> <p>The Pydantic model is automatically converted to JSON Schema for MCP.</p>"},{"location":"tutorials/06-mcp-integration/#error-handling","title":"Error Handling","text":"<p>Agents should handle errors gracefully:</p> <pre><code>@agent\nasync def safe_analysis(code: str) -&gt; str:\n    \"\"\"Analyze code with error handling\"\"\"\n    try:\n        # Analysis logic\n        return \"Analysis complete\"\n    except Exception as e:\n        return f\"Error during analysis: {str(e)}\"\n</code></pre>"},{"location":"tutorials/06-mcp-integration/#integration-with-other-mcp-clients","title":"Integration with Other MCP Clients","text":"<p>Kagura MCP works with any MCP-compatible client:</p>"},{"location":"tutorials/06-mcp-integration/#claude-code-vs-code-extension","title":"Claude Code (VS Code Extension)","text":"<p>Add to <code>.vscode/settings.json</code>:</p> <pre><code>{\n  \"mcp.servers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"]\n    }\n  }\n}\n</code></pre>"},{"location":"tutorials/06-mcp-integration/#cline-vs-code-extension","title":"Cline (VS Code Extension)","text":"<p>Similar configuration in Cline settings.</p>"},{"location":"tutorials/06-mcp-integration/#custom-mcp-clients","title":"Custom MCP Clients","text":"<p>Use the MCP Python SDK to connect:</p> <pre><code>from mcp import ClientSession\nimport asyncio\n\nasync def test_kagura_mcp():\n    async with ClientSession() as session:\n        # Connect to Kagura MCP server\n        await session.initialize()\n\n        # List tools\n        tools = await session.list_tools()\n        print(f\"Available tools: {[t.name for t in tools]}\")\n\n        # Call agent\n        result = await session.call_tool(\n            \"kagura_analyze_code\",\n            {\"code\": \"def hello(): print('hi')\"}\n        )\n        print(result)\n\nasyncio.run(test_kagura_mcp())\n</code></pre>"},{"location":"tutorials/06-mcp-integration/#debugging","title":"Debugging","text":""},{"location":"tutorials/06-mcp-integration/#enable-verbose-logging","title":"Enable Verbose Logging","text":"<pre><code>kagura -v mcp serve\n</code></pre>"},{"location":"tutorials/06-mcp-integration/#check-agent-registration","title":"Check Agent Registration","text":"<pre><code>kagura mcp list\n</code></pre> <p>If your agent doesn't appear: 1. Ensure the file is imported 2. Check the <code>@agent</code> decorator is applied 3. Verify no import errors</p>"},{"location":"tutorials/06-mcp-integration/#test-without-claude-desktop","title":"Test Without Claude Desktop","text":"<p>Use <code>mcp</code> CLI tool to test directly:</p> <pre><code># Install MCP CLI\nnpm install -g @modelcontextprotocol/cli\n\n# Test Kagura MCP server\nmcp call kagura_analyze_code '{\"code\": \"def test(): pass\"}'\n</code></pre>"},{"location":"tutorials/06-mcp-integration/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/06-mcp-integration/#1-clear-descriptions","title":"1. Clear Descriptions","text":"<p>Write clear docstrings - they become tool descriptions in Claude:</p> <pre><code>@agent\nasync def analyze_code(code: str, language: str = \"python\") -&gt; str:\n    \"\"\"\n    Analyze code quality and suggest improvements.\n\n    This agent examines code structure, identifies potential issues,\n    and provides actionable suggestions for improvement.\n\n    code: Source code to analyze\n    language: Programming language (python, javascript, etc.)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/06-mcp-integration/#2-type-hints","title":"2. Type Hints","text":"<p>Use type hints for automatic schema generation:</p> <pre><code>@agent\nasync def process_data(\n    data: list[dict[str, Any]],\n    max_items: int = 100,\n    include_metadata: bool = False\n) -&gt; dict[str, Any]:\n    \"\"\"Process data with options\"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/06-mcp-integration/#3-default-values","title":"3. Default Values","text":"<p>Provide sensible defaults for optional parameters:</p> <pre><code>@agent\nasync def translate(\n    text: str,\n    target_language: str = \"English\",\n    tone: str = \"neutral\"\n) -&gt; str:\n    \"\"\"Translate text\"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/06-mcp-integration/#4-structured-output","title":"4. Structured Output","text":"<p>Return structured data when appropriate:</p> <pre><code>@agent\nasync def analyze_sentiment(text: str) -&gt; dict:\n    \"\"\"\n    Analyze sentiment of text\n\n    Returns:\n        {\n            \"sentiment\": \"positive\" | \"negative\" | \"neutral\",\n            \"confidence\": float,\n            \"keywords\": list[str]\n        }\n    \"\"\"\n    pass\n</code></pre>"},{"location":"tutorials/06-mcp-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/06-mcp-integration/#agent-not-appearing-in-claude-desktop","title":"Agent Not Appearing in Claude Desktop","text":"<ol> <li>Check configuration file location</li> <li>macOS: <code>~/Library/Application Support/Claude/claude_desktop_config.json</code></li> <li>Windows: <code>%APPDATA%\\Claude\\claude_desktop_config.json</code></li> <li> <p>Linux: <code>~/.config/Claude/claude_desktop_config.json</code></p> </li> <li> <p>Verify JSON syntax <pre><code># Test JSON validity\ncat ~/Library/Application\\ Support/Claude/claude_desktop_config.json | python -m json.tool\n</code></pre></p> </li> <li> <p>Check server logs <pre><code>kagura -v mcp serve 2&gt; mcp_server.log\n</code></pre></p> </li> <li> <p>Restart Claude Desktop completely</p> </li> <li>Quit application</li> <li>Restart</li> <li>Check MCP indicator in status bar</li> </ol>"},{"location":"tutorials/06-mcp-integration/#authentication-errors","title":"Authentication Errors","text":"<p>Make sure API keys are set:</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"sk-...\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"tutorials/06-mcp-integration/#permission-errors","title":"Permission Errors","text":"<p>On Unix systems, ensure <code>kagura</code> is executable:</p> <pre><code>which kagura\nchmod +x $(which kagura)\n</code></pre>"},{"location":"tutorials/06-mcp-integration/#next-steps","title":"Next Steps","text":"<ul> <li> <p>API Reference - MCP API documentation</p> </li> <li> <p>MCP Specification - Learn more about MCP</p> </li> </ul>"},{"location":"tutorials/06-mcp-integration/#example-projects","title":"Example Projects","text":"<p>See <code>examples/mcp_integration/</code> for complete examples: - Code analysis agent - Multi-agent workflow - Custom tool integration</p>"},{"location":"tutorials/08-memory-management/","title":"Memory Management Tutorial","text":"<p>Learn how to build agents with memory capabilities using Kagura AI's memory management system.</p>"},{"location":"tutorials/08-memory-management/#introduction","title":"Introduction","text":"<p>Kagura AI provides a three-tier memory system:</p> <ol> <li>Working Memory: Temporary data during execution</li> <li>Context Memory: Conversation history</li> <li>Persistent Memory: Long-term storage</li> </ol> <p>All three are accessed through the unified <code>MemoryManager</code> interface.</p>"},{"location":"tutorials/08-memory-management/#quick-start","title":"Quick Start","text":""},{"location":"tutorials/08-memory-management/#basic-memory-usage","title":"Basic Memory Usage","text":"<pre><code>from kagura.core.memory import MemoryManager\n\n# Create memory manager\nmemory = MemoryManager(agent_name=\"my_assistant\")\n\n# Store and recall persistent data\nmemory.remember(\"user_name\", \"Alice\")\nname = memory.recall(\"user_name\")  # \"Alice\"\n\n# Track conversation\nmemory.add_message(\"user\", \"Hello!\")\nmemory.add_message(\"assistant\", \"Hi there!\")\n\n# Get conversation context\ncontext = memory.get_llm_context()\n</code></pre>"},{"location":"tutorials/08-memory-management/#agent-with-memory","title":"Agent with Memory","text":"<pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n@agent(enable_memory=True)\nasync def greeter(name: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Greet {{ name }} personally\"\"\"\n\n    # Remember this person\n    memory.remember(f\"greeted_{name}\", True)\n\n    # Check if we've met before\n    met_before = memory.recall(f\"greeted_{name}\")\n\n    if met_before:\n        return f\"Welcome back, {name}!\"\n    else:\n        return f\"Nice to meet you, {name}!\"\n\n# First time\nresult = await greeter(\"Alice\")  # \"Nice to meet you, Alice!\"\n\n# Second time\nresult = await greeter(\"Alice\")  # \"Welcome back, Alice!\"\n</code></pre>"},{"location":"tutorials/08-memory-management/#working-memory","title":"Working Memory","text":"<p>Temporary storage that's cleared after execution.</p>"},{"location":"tutorials/08-memory-management/#use-cases","title":"Use Cases","text":"<ul> <li>Tracking loop iterations</li> <li>Storing intermediate results</li> <li>Temporary configuration</li> </ul>"},{"location":"tutorials/08-memory-management/#example","title":"Example","text":"<pre><code>from kagura.core.memory import MemoryManager\n\nmemory = MemoryManager()\n\n# Store temporary data\nmemory.set_temp(\"retry_count\", 0)\nmemory.set_temp(\"current_task\", \"data_processing\")\n\n# Retrieve\ncount = memory.get_temp(\"retry_count\")  # 0\ntask = memory.get_temp(\"current_task\")  # \"data_processing\"\n\n# Check existence\nif memory.has_temp(\"retry_count\"):\n    count = memory.get_temp(\"retry_count\")\n    memory.set_temp(\"retry_count\", count + 1)\n\n# Delete\nmemory.delete_temp(\"current_task\")\n</code></pre>"},{"location":"tutorials/08-memory-management/#context-memory","title":"Context Memory","text":"<p>Manages conversation history with automatic pruning.</p>"},{"location":"tutorials/08-memory-management/#message-roles","title":"Message Roles","text":"<ul> <li><code>\"user\"</code>: User messages</li> <li><code>\"assistant\"</code>: Agent responses</li> <li><code>\"system\"</code>: System prompts</li> </ul>"},{"location":"tutorials/08-memory-management/#basic-usage","title":"Basic Usage","text":"<pre><code>memory = MemoryManager(max_messages=100)\n\n# Add messages\nmemory.add_message(\"user\", \"What is AI?\")\nmemory.add_message(\"assistant\", \"AI stands for Artificial Intelligence...\")\n\n# Get all messages\nmessages = memory.get_context()\n\n# Get last N messages\nrecent = memory.get_context(last_n=5)\n\n# Get last user message\nlast_user = memory.get_last_message(role=\"user\")\nprint(last_user.content)  # \"What is AI?\"\n</code></pre>"},{"location":"tutorials/08-memory-management/#llm-integration","title":"LLM Integration","text":"<pre><code># Get context for LLM API\nllm_messages = memory.get_llm_context()\n\n# Format: [{\"role\": \"user\", \"content\": \"...\"}, ...]\nfor msg in llm_messages:\n    print(f\"{msg['role']}: {msg['content']}\")\n</code></pre>"},{"location":"tutorials/08-memory-management/#auto-pruning","title":"Auto-Pruning","text":"<p>Context memory automatically prunes old messages when exceeding the limit:</p> <pre><code>memory = MemoryManager(max_messages=3)\n\nmemory.add_message(\"user\", \"Message 1\")\nmemory.add_message(\"assistant\", \"Message 2\")\nmemory.add_message(\"user\", \"Message 3\")\n# 3 messages stored\n\nmemory.add_message(\"assistant\", \"Message 4\")\n# Only last 3 kept: Message 2, 3, 4\n</code></pre>"},{"location":"tutorials/08-memory-management/#metadata","title":"Metadata","text":"<p>Attach metadata to messages:</p> <pre><code>memory.add_message(\n    \"assistant\",\n    \"The answer is 42\",\n    metadata={\n        \"confidence\": 0.95,\n        \"source\": \"knowledge_base\",\n        \"timestamp\": \"2025-01-01T00:00:00Z\"\n    }\n)\n\nmessages = memory.get_context()\nprint(messages[0].metadata[\"confidence\"])  # 0.95\n</code></pre>"},{"location":"tutorials/08-memory-management/#persistent-memory","title":"Persistent Memory","text":"<p>Long-term storage using SQLite.</p>"},{"location":"tutorials/08-memory-management/#basic-operations","title":"Basic Operations","text":"<pre><code>from pathlib import Path\n\nmemory = MemoryManager(\n    agent_name=\"my_agent\",\n    persist_dir=Path(\"./data\")\n)\n\n# Store\nmemory.remember(\"api_key\", \"sk-...\")\nmemory.remember(\"user_prefs\", {\"theme\": \"dark\", \"lang\": \"en\"})\n\n# Recall\napi_key = memory.recall(\"api_key\")\nprefs = memory.recall(\"user_prefs\")\n\n# Delete\nmemory.forget(\"api_key\")\n</code></pre>"},{"location":"tutorials/08-memory-management/#search","title":"Search","text":"<p>Search using SQL LIKE patterns:</p> <pre><code># Store multiple items\nmemory.remember(\"user_name\", \"Alice\")\nmemory.remember(\"user_email\", \"alice@example.com\")\nmemory.remember(\"user_age\", 25)\nmemory.remember(\"product_name\", \"Widget\")\n\n# Search for user-related items\nresults = memory.search_memory(\"user\")\n# Returns: user_name, user_email, user_age\n\nfor item in results:\n    print(f\"{item['key']}: {item['value']}\")\n</code></pre>"},{"location":"tutorials/08-memory-management/#agent-scoping","title":"Agent Scoping","text":"<p>Memories can be scoped to specific agents:</p> <pre><code># Agent 1\nmemory1 = MemoryManager(agent_name=\"agent1\")\nmemory1.remember(\"config\", {\"mode\": \"fast\"})\n\n# Agent 2\nmemory2 = MemoryManager(agent_name=\"agent2\")\nmemory2.remember(\"config\", {\"mode\": \"accurate\"})\n\n# Each agent has separate memories\nconfig1 = memory1.recall(\"config\")  # {\"mode\": \"fast\"}\nconfig2 = memory2.recall(\"config\")  # {\"mode\": \"accurate\"}\n</code></pre>"},{"location":"tutorials/08-memory-management/#maintenance","title":"Maintenance","text":"<pre><code># Prune old memories (older than 30 days)\ndeleted = memory.prune_old(older_than_days=30)\nprint(f\"Deleted {deleted} old memories\")\n\n# Count memories\ncount = memory.persistent.count(agent_name=\"my_agent\")\nprint(f\"{count} memories stored\")\n</code></pre>"},{"location":"tutorials/08-memory-management/#session-management","title":"Session Management","text":"<p>Save and restore complete agent state.</p>"},{"location":"tutorials/08-memory-management/#saving-sessions","title":"Saving Sessions","text":"<pre><code>memory = MemoryManager(agent_name=\"assistant\")\n\n# Have a conversation\nmemory.add_message(\"user\", \"What is machine learning?\")\nmemory.add_message(\"assistant\", \"Machine learning is...\")\n\n# Store temporary data\nmemory.set_temp(\"conversation_step\", 5)\n\n# Save everything\nmemory.save_session(\"ml_discussion\")\n</code></pre>"},{"location":"tutorials/08-memory-management/#loading-sessions","title":"Loading Sessions","text":"<pre><code># Later... create new memory manager\nnew_memory = MemoryManager(agent_name=\"assistant\")\n\n# Restore session\nif new_memory.load_session(\"ml_discussion\"):\n    print(\"Session restored!\")\n\n    # Context is restored\n    messages = new_memory.get_context()\n    print(f\"Restored {len(messages)} messages\")\n\n    # Session ID is restored\n    session_id = new_memory.get_session_id()\nelse:\n    print(\"Session not found\")\n</code></pre>"},{"location":"tutorials/08-memory-management/#agent-integration","title":"Agent Integration","text":""},{"location":"tutorials/08-memory-management/#enable-memory","title":"Enable Memory","text":"<p>Use <code>enable_memory=True</code> in the <code>@agent</code> decorator:</p> <pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n@agent(enable_memory=True)\nasync def chatbot(message: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Chat: {{ message }}\"\"\"\n\n    # Memory is automatically injected\n    memory.add_message(\"user\", message)\n\n    # Use memory for personalization\n    user_name = memory.recall(\"user_name\")\n    if user_name:\n        response = f\"Hello {user_name}! You said: {message}\"\n    else:\n        response = f\"Hello! You said: {message}\"\n\n    memory.add_message(\"assistant\", response)\n    return response\n</code></pre>"},{"location":"tutorials/08-memory-management/#custom-configuration","title":"Custom Configuration","text":"<pre><code>from pathlib import Path\n\n@agent(\n    enable_memory=True,\n    persist_dir=Path(\"./agent_data\"),\n    max_messages=50\n)\nasync def my_agent(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Process: {{ query }}\"\"\"\n    # Custom persist directory and message limit\n    pass\n</code></pre>"},{"location":"tutorials/08-memory-management/#practical-examples","title":"Practical Examples","text":""},{"location":"tutorials/08-memory-management/#personal-assistant","title":"Personal Assistant","text":"<pre><code>@agent(enable_memory=True)\nasync def personal_assistant(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Answer: {{ query }}\"\"\"\n\n    memory.add_message(\"user\", query)\n\n    # Learn user preferences\n    if \"my favorite color is\" in query.lower():\n        color = query.split(\"my favorite color is\")[-1].strip()\n        memory.remember(\"favorite_color\", color)\n\n    if \"my name is\" in query.lower():\n        name = query.split(\"my name is\")[-1].strip()\n        memory.remember(\"user_name\", name)\n\n    # Use learned information\n    name = memory.recall(\"user_name\") or \"there\"\n    fav_color = memory.recall(\"favorite_color\") or \"unknown\"\n\n    response = f\"Hi {name}! Your favorite color is {fav_color}.\"\n    memory.add_message(\"assistant\", response)\n\n    return response\n\n# Usage\nawait personal_assistant(\"Hi, my name is Alice\")\nawait personal_assistant(\"my favorite color is blue\")\nawait personal_assistant(\"what's my name?\")\n# \"Hi Alice! Your favorite color is blue.\"\n</code></pre>"},{"location":"tutorials/08-memory-management/#multi-turn-conversation","title":"Multi-Turn Conversation","text":"<pre><code>@agent(enable_memory=True, max_messages=20)\nasync def conversational_agent(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Continue conversation: {{ query }}\n\n    Previous context:\n    {% for msg in context %}\n    {{ msg.role }}: {{ msg.content }}\n    {% endfor %}\n    \"\"\"\n\n    # Get recent context for prompt\n    context = memory.get_context(last_n=5)\n\n    # Add current message\n    memory.add_message(\"user\", query)\n\n    # Response would come from LLM\n    response = \"...\"  # LLM processes with full context\n\n    memory.add_message(\"assistant\", response)\n    return response\n</code></pre>"},{"location":"tutorials/08-memory-management/#task-tracker","title":"Task Tracker","text":"<pre><code>@agent(enable_memory=True)\nasync def task_tracker(command: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Manage tasks: {{ command }}\"\"\"\n\n    if command.startswith(\"add\"):\n        task = command[4:].strip()\n        tasks = memory.recall(\"tasks\") or []\n        tasks.append(task)\n        memory.remember(\"tasks\", tasks)\n        return f\"Added task: {task}\"\n\n    elif command == \"list\":\n        tasks = memory.recall(\"tasks\") or []\n        if not tasks:\n            return \"No tasks\"\n        return \"Tasks:\\n\" + \"\\n\".join(f\"- {t}\" for t in tasks)\n\n    elif command.startswith(\"done\"):\n        task = command[5:].strip()\n        tasks = memory.recall(\"tasks\") or []\n        if task in tasks:\n            tasks.remove(task)\n            memory.remember(\"tasks\", tasks)\n            return f\"Completed: {task}\"\n        return \"Task not found\"\n\n    return \"Unknown command\"\n\n# Usage\nawait task_tracker(\"add Write documentation\")\nawait task_tracker(\"add Review code\")\nawait task_tracker(\"list\")\n# \"Tasks:\\n- Write documentation\\n- Review code\"\nawait task_tracker(\"done Write documentation\")\n</code></pre>"},{"location":"tutorials/08-memory-management/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/08-memory-management/#1-use-appropriate-memory-types","title":"1. Use Appropriate Memory Types","text":"<ul> <li>Working Memory: Temporary state, loop counters, intermediate results</li> <li>Context Memory: Conversation history, user interactions</li> <li>Persistent Memory: User preferences, learned facts, configuration</li> </ul>"},{"location":"tutorials/08-memory-management/#2-set-reasonable-limits","title":"2. Set Reasonable Limits","text":"<pre><code># For chat applications\nmemory = MemoryManager(max_messages=50)  # Keep last 50 messages\n\n# For long-running agents\nmemory = MemoryManager(max_messages=200)  # More context\n</code></pre>"},{"location":"tutorials/08-memory-management/#3-clean-up-old-data","title":"3. Clean Up Old Data","text":"<pre><code># Periodically prune old memories\nif datetime.now().day == 1:  # First day of month\n    deleted = memory.prune_old(older_than_days=90)\n    print(f\"Pruned {deleted} old memories\")\n</code></pre>"},{"location":"tutorials/08-memory-management/#4-use-agent-scoping","title":"4. Use Agent Scoping","text":"<pre><code># Separate memories for different agents\ntranslator = MemoryManager(agent_name=\"translator\")\nsummarizer = MemoryManager(agent_name=\"summarizer\")\n</code></pre>"},{"location":"tutorials/08-memory-management/#5-add-metadata","title":"5. Add Metadata","text":"<pre><code>memory.remember(\n    \"api_key\",\n    \"sk-...\",\n    metadata={\n        \"created\": \"2025-01-01\",\n        \"expires\": \"2026-01-01\",\n        \"environment\": \"production\"\n    }\n)\n</code></pre>"},{"location":"tutorials/08-memory-management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/08-memory-management/#memory-not-persisting","title":"Memory Not Persisting","text":"<p>Ensure <code>persist_dir</code> exists:</p> <pre><code>from pathlib import Path\n\npersist_dir = Path(\"./data\")\npersist_dir.mkdir(exist_ok=True)\n\nmemory = MemoryManager(persist_dir=persist_dir)\n</code></pre>"},{"location":"tutorials/08-memory-management/#context-too-large","title":"Context Too Large","text":"<p>Reduce <code>max_messages</code>:</p> <pre><code>memory = MemoryManager(max_messages=20)\n</code></pre>"},{"location":"tutorials/08-memory-management/#agent-specific-memories","title":"Agent-Specific Memories","text":"<p>Always use <code>agent_name</code>:</p> <pre><code>memory = MemoryManager(agent_name=\"my_unique_agent\")\n</code></pre>"},{"location":"tutorials/08-memory-management/#next-steps","title":"Next Steps","text":"<ul> <li>Memory Management API Reference</li> <li>Code Execution Tutorial</li> <li>Shell Integration Tutorial</li> </ul>"},{"location":"tutorials/09-agent-routing/","title":"Agent Routing Tutorial","text":"<p>Learn how to use agent routing to automatically select the best agent for user requests.</p>"},{"location":"tutorials/09-agent-routing/#what-is-agent-routing","title":"What is Agent Routing?","text":"<p>Agent routing automatically selects the most appropriate agent based on user input, eliminating the need to manually choose which agent to call.</p> <p>Benefits: - \ud83c\udfaf Automatic agent selection - \ud83d\ude80 Simplified user experience - \ud83d\udd04 Easy to add new agents - \ud83c\udf10 Multilingual support</p>"},{"location":"tutorials/09-agent-routing/#quick-start","title":"Quick Start","text":""},{"location":"tutorials/09-agent-routing/#step-1-install-kagura-ai","title":"Step 1: Install Kagura AI","text":"<pre><code>pip install kagura-ai\n</code></pre>"},{"location":"tutorials/09-agent-routing/#step-2-define-agents","title":"Step 2: Define Agents","text":"<pre><code>from kagura import agent\n\n@agent\nasync def code_reviewer(code: str) -&gt; str:\n    '''Review code quality and suggest improvements.\n    Code: {{ code }}'''\n    pass\n\n@agent\nasync def translator(text: str, target_lang: str = \"en\") -&gt; str:\n    '''Translate text to target language.\n    Text: {{ text }}\n    Target: {{ target_lang }}'''\n    pass\n</code></pre>"},{"location":"tutorials/09-agent-routing/#step-3-create-router","title":"Step 3: Create Router","text":"<pre><code>from kagura.routing import AgentRouter\n\nrouter = AgentRouter()\n\n# Register agents with intent keywords\nrouter.register(\n    code_reviewer,\n    intents=[\"review\", \"check\", \"analyze\"],\n    description=\"Reviews code for quality and bugs\"\n)\n\nrouter.register(\n    translator,\n    intents=[\"translate\", \"\u7ffb\u8a33\", \"translation\"],\n    description=\"Translates text between languages\"\n)\n</code></pre>"},{"location":"tutorials/09-agent-routing/#step-4-use-automatic-routing","title":"Step 4: Use Automatic Routing","text":"<pre><code># The router automatically selects the right agent!\nresult = await router.route(\"Please review this code\")\n# \u2192 code_reviewer is selected\n\nresult = await router.route(\"Translate 'Hello' to Japanese\")\n# \u2192 translator is selected\n</code></pre>"},{"location":"tutorials/09-agent-routing/#basic-usage","title":"Basic Usage","text":""},{"location":"tutorials/09-agent-routing/#registering-agents","title":"Registering Agents","text":"<p>Agents are registered with intent keywords that help the router identify them:</p> <pre><code>from kagura import agent\nfrom kagura.routing import AgentRouter\n\n@agent\nasync def python_expert(question: str) -&gt; str:\n    '''Python programming expert: {{ question }}'''\n    pass\n\nrouter = AgentRouter()\n\nrouter.register(\n    python_expert,\n    intents=[\n        \"python\",      # Programming language\n        \"decorator\",   # Python-specific concepts\n        \"asyncio\",\n        \"pip\"\n    ],\n    description=\"Answers Python programming questions\"\n)\n</code></pre>"},{"location":"tutorials/09-agent-routing/#routing-requests","title":"Routing Requests","text":"<pre><code># These will all route to python_expert\nawait router.route(\"How do I use Python decorators?\")\nawait router.route(\"Explain asyncio in Python\")\nawait router.route(\"What's the best way to use pip?\")\n</code></pre>"},{"location":"tutorials/09-agent-routing/#confidence-threshold","title":"Confidence Threshold","text":"<p>The router calculates a confidence score for each agent. You can control the minimum required confidence:</p> <pre><code>router = AgentRouter(confidence_threshold=0.5)\n</code></pre> <p>How Confidence Works:</p> <pre><code># Agent has intents: [\"review\", \"check\", \"analyze\"]\nuser_input = \"review and check code\"\n\n# Scoring:\n# - \"review\" \u2713 matched\n# - \"check\"  \u2713 matched\n# - \"analyze\" \u2717 not matched\n# Score = 2/3 = 0.67 \u2192 Above threshold (0.5) \u2192 Agent selected\n</code></pre> <p>Lower threshold = more lenient matching Higher threshold = stricter matching</p> <pre><code># Lenient (more matches)\nrouter = AgentRouter(confidence_threshold=0.3)\n\n# Strict (fewer matches, higher accuracy)\nrouter = AgentRouter(confidence_threshold=0.7)\n</code></pre>"},{"location":"tutorials/09-agent-routing/#fallback-agent","title":"Fallback Agent","text":"<p>Always provide a fallback agent for requests that don't match any registered agent:</p> <pre><code>@agent\nasync def general_assistant(query: str) -&gt; str:\n    '''General purpose assistant: {{ query }}'''\n    pass\n\nrouter = AgentRouter(\n    fallback_agent=general_assistant,\n    confidence_threshold=0.4\n)\n\n# If no agent matches or confidence is low, fallback is used\nresult = await router.route(\"What's the weather today?\")\n# \u2192 general_assistant (fallback) handles this\n</code></pre>"},{"location":"tutorials/09-agent-routing/#multilingual-support","title":"Multilingual Support","text":"<p>Add intent keywords in multiple languages:</p> <pre><code>router.register(\n    translator,\n    intents=[\n        # English\n        \"translate\", \"translation\",\n        # Japanese\n        \"\u7ffb\u8a33\", \"\u8a33\u3057\u3066\",\n        # Spanish\n        \"traducir\", \"traducci\u00f3n\",\n        # Korean\n        \"\ubc88\uc5ed\"\n    ],\n    description=\"Multilingual translator\"\n)\n\n# Works with any language\nawait router.route(\"\u3053\u306e\u6587\u7ae0\u3092\u7ffb\u8a33\u3057\u3066\")  # Japanese\nawait router.route(\"Traducir este texto\")  # Spanish\nawait router.route(\"\uc774\uac83\uc744 \ubc88\uc5ed\ud574\uc8fc\uc138\uc694\")  # Korean\n</code></pre>"},{"location":"tutorials/09-agent-routing/#checking-matched-agents","title":"Checking Matched Agents","text":"<p>See which agents match and their confidence scores:</p> <pre><code>matches = router.get_matched_agents(\"review my code\", top_k=3)\n\nfor agent, score in matches:\n    print(f\"{agent.__name__}: {score:.2f}\")\n\n# Output:\n# code_reviewer: 0.67\n# quality_checker: 0.33\n# general_assistant: 0.00\n</code></pre> <p>This is useful for: - Debugging routing issues - Tuning confidence thresholds - Understanding why an agent was selected</p>"},{"location":"tutorials/09-agent-routing/#semantic-routing-advanced","title":"Semantic Routing (Advanced)","text":"<p>Semantic routing uses embedding-based similarity matching for more intelligent routing. Instead of keyword matching, it understands the meaning of user queries.</p>"},{"location":"tutorials/09-agent-routing/#installation","title":"Installation","text":"<pre><code>pip install kagura-ai[ai]\n</code></pre>"},{"location":"tutorials/09-agent-routing/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from kagura import agent\nfrom kagura.routing import AgentRouter\n\n@agent\nasync def code_reviewer(code: str) -&gt; str:\n    '''Review code: {{ code }}'''\n    pass\n\n@agent\nasync def translator(text: str, lang: str = \"en\") -&gt; str:\n    '''Translate: {{ text }} to {{ lang }}'''\n    pass\n\n# Create semantic router\nrouter = AgentRouter(strategy=\"semantic\")\n\n# Register with sample queries (not keywords!)\nrouter.register(\n    code_reviewer,\n    samples=[\n        \"Can you review this code?\",\n        \"Check my implementation\",\n        \"Look at this function\",\n        \"\u3053\u306e\u30b3\u30fc\u30c9\u3092\u30ec\u30d3\u30e5\u30fc\u3057\u3066\"  # Japanese\n    ]\n)\n\nrouter.register(\n    translator,\n    samples=[\n        \"Translate this text\",\n        \"Convert to Japanese\",\n        \"What does this mean in French?\",\n        \"\u7ffb\u8a33\u3057\u3066\"  # Japanese\n    ]\n)\n\n# Semantic matching understands meaning!\nawait router.route(\"Could you look at my Python script?\")\n# \u2192 code_reviewer (understands \"look at\" \u2248 \"review\")\n\nawait router.route(\"\u82f1\u8a9e\u3067\u4f55\u3066\u8a00\u3046\uff1f\")\n# \u2192 translator (understands Japanese intent)\n</code></pre>"},{"location":"tutorials/09-agent-routing/#benefits-of-semantic-routing","title":"Benefits of Semantic Routing","text":"<p>\u2705 Understands synonyms: \"check\", \"review\", \"analyze\" all match \u2705 Cross-language: Matches meaning across languages \u2705 Context-aware: Understands similar phrases \u2705 No keyword tuning: Just provide natural examples</p>"},{"location":"tutorials/09-agent-routing/#intent-vs-semantic-comparison","title":"Intent vs Semantic Comparison","text":"Feature Intent (Keyword) Semantic (Embedding) Speed \u26a1 Very fast (&lt;1ms) \ud83d\udc22 Slower (~50-200ms) Cost \ud83d\udcb0 Free \ud83d\udcb5 API calls required Accuracy \u2713 Good for exact keywords \u2713\u2713 Better for natural language Setup Simple keywords Sample queries needed Offline \u2705 Yes \u274c No (needs API) <p>When to use Intent: - High-volume routing - Offline applications - Clear keyword patterns - Cost-sensitive applications</p> <p>When to use Semantic: - Natural language queries - Multilingual support - Complex intent understanding - User-facing chatbots</p>"},{"location":"tutorials/09-agent-routing/#configuration","title":"Configuration","text":"<pre><code># OpenAI encoder (default)\nrouter = AgentRouter(\n    strategy=\"semantic\",\n    encoder=\"openai\"\n)\n\n# Cohere encoder\nrouter = AgentRouter(\n    strategy=\"semantic\",\n    encoder=\"cohere\"\n)\n\n# With fallback and threshold\nrouter = AgentRouter(\n    strategy=\"semantic\",\n    fallback_agent=general_assistant,\n    confidence_threshold=0.7,\n    encoder=\"openai\"\n)\n</code></pre> <p>Environment Variables:</p> <pre><code># For OpenAI\nexport OPENAI_API_KEY=\"sk-...\"\n\n# For Cohere\nexport COHERE_API_KEY=\"...\"\n</code></pre>"},{"location":"tutorials/09-agent-routing/#practical-examples","title":"Practical Examples","text":""},{"location":"tutorials/09-agent-routing/#example-1-customer-support-bot","title":"Example 1: Customer Support Bot","text":"<pre><code>from kagura import agent\nfrom kagura.routing import AgentRouter\n\n# Define specialized agents\n@agent\nasync def billing_agent(query: str) -&gt; str:\n    '''Handle billing inquiries: {{ query }}'''\n    pass\n\n@agent\nasync def technical_agent(query: str) -&gt; str:\n    '''Handle technical issues: {{ query }}'''\n    pass\n\n@agent\nasync def general_agent(query: str) -&gt; str:\n    '''General customer support: {{ query }}'''\n    pass\n\n# Create router\nrouter = AgentRouter(\n    fallback_agent=general_agent,\n    confidence_threshold=0.4\n)\n\n# Register agents\nrouter.register(\n    billing_agent,\n    intents=[\"billing\", \"payment\", \"invoice\", \"charge\", \"subscription\"],\n    description=\"Handles billing and payment questions\"\n)\n\nrouter.register(\n    technical_agent,\n    intents=[\"technical\", \"bug\", \"error\", \"crash\", \"not working\"],\n    description=\"Handles technical support issues\"\n)\n\n# Use in chat loop\nasync def customer_support_chat():\n    print(\"Customer Support Bot (type 'exit' to quit)\")\n\n    while True:\n        query = input(\"\\nCustomer: \")\n        if query.lower() == \"exit\":\n            break\n\n        response = await router.route(query)\n        print(f\"Support: {response}\")\n\n# Run\nawait customer_support_chat()\n\n# Example conversation:\n# Customer: I was charged twice for my subscription\n# Support: [billing_agent handles this]\n#\n# Customer: The app keeps crashing on startup\n# Support: [technical_agent handles this]\n#\n# Customer: What are your business hours?\n# Support: [general_agent handles this]\n</code></pre>"},{"location":"tutorials/09-agent-routing/#example-2-development-assistant","title":"Example 2: Development Assistant","text":"<pre><code>@agent\nasync def code_generator(description: str) -&gt; str:\n    '''Generate code from description: {{ description }}'''\n    pass\n\n@agent\nasync def code_reviewer(code: str) -&gt; str:\n    '''Review code quality: {{ code }}'''\n    pass\n\n@agent\nasync def bug_finder(code: str) -&gt; str:\n    '''Find bugs in code: {{ code }}'''\n    pass\n\n@agent\nasync def documenter(code: str) -&gt; str:\n    '''Generate documentation: {{ code }}'''\n    pass\n\nrouter = AgentRouter(confidence_threshold=0.3)\n\nrouter.register(code_generator, intents=[\"generate\", \"create\", \"write\"])\nrouter.register(code_reviewer, intents=[\"review\", \"check\", \"assess\"])\nrouter.register(bug_finder, intents=[\"bug\", \"error\", \"issue\", \"debug\"])\nrouter.register(documenter, intents=[\"document\", \"docs\", \"comment\"])\n\n# Automatic task routing\nawait router.route(\"Generate a function to sort a list\")\n# \u2192 code_generator\n\nawait router.route(\"Check this code for issues\")\n# \u2192 code_reviewer\n\nawait router.route(\"Find bugs in this code\")\n# \u2192 bug_finder\n\nawait router.route(\"Add documentation to this function\")\n# \u2192 documenter\n</code></pre>"},{"location":"tutorials/09-agent-routing/#example-3-educational-platform","title":"Example 3: Educational Platform","text":"<pre><code>@agent\nasync def math_tutor(question: str) -&gt; str:\n    '''Math tutor: {{ question }}'''\n    pass\n\n@agent\nasync def physics_tutor(question: str) -&gt; str:\n    '''Physics tutor: {{ question }}'''\n    pass\n\n@agent\nasync def chemistry_tutor(question: str) -&gt; str:\n    '''Chemistry tutor: {{ question }}'''\n    pass\n\n@agent\nasync def general_tutor(question: str) -&gt; str:\n    '''General education tutor: {{ question }}'''\n    pass\n\nrouter = AgentRouter(\n    fallback_agent=general_tutor,\n    confidence_threshold=0.4\n)\n\nrouter.register(\n    math_tutor,\n    intents=[\"math\", \"algebra\", \"calculus\", \"geometry\", \"trigonometry\"],\n    description=\"Mathematics tutor\"\n)\n\nrouter.register(\n    physics_tutor,\n    intents=[\"physics\", \"mechanics\", \"thermodynamics\", \"electricity\"],\n    description=\"Physics tutor\"\n)\n\nrouter.register(\n    chemistry_tutor,\n    intents=[\"chemistry\", \"molecule\", \"reaction\", \"element\"],\n    description=\"Chemistry tutor\"\n)\n\n# Smart subject routing\nawait router.route(\"How do I solve quadratic equations?\")\n# \u2192 math_tutor\n\nawait router.route(\"Explain Newton's laws of motion\")\n# \u2192 physics_tutor\n\nawait router.route(\"What is a covalent bond?\")\n# \u2192 chemistry_tutor\n\nawait router.route(\"How do I study effectively?\")\n# \u2192 general_tutor (fallback)\n</code></pre>"},{"location":"tutorials/09-agent-routing/#managing-agents","title":"Managing Agents","text":""},{"location":"tutorials/09-agent-routing/#list-registered-agents","title":"List Registered Agents","text":"<pre><code>agents = router.list_agents()\nprint(f\"Registered agents: {', '.join(agents)}\")\n# Registered agents: code_reviewer, translator, data_analyzer\n</code></pre>"},{"location":"tutorials/09-agent-routing/#get-agent-information","title":"Get Agent Information","text":"<pre><code>info = router.get_agent_info(\"code_reviewer\")\nprint(f\"Description: {info['description']}\")\nprint(f\"Intents: {info['intents']}\")\n\n# Output:\n# Description: Reviews code for quality and bugs\n# Intents: ['review', 'check', 'analyze']\n</code></pre>"},{"location":"tutorials/09-agent-routing/#error-handling","title":"Error Handling","text":""},{"location":"tutorials/09-agent-routing/#no-agent-found","title":"No Agent Found","text":"<pre><code>from kagura.routing import NoAgentFoundError\n\ntry:\n    result = await router.route(\"Unknown request\")\nexcept NoAgentFoundError as e:\n    print(f\"No agent found for: {e.user_input}\")\n    # Handle the error gracefully\n</code></pre>"},{"location":"tutorials/09-agent-routing/#with-fallback-recommended","title":"With Fallback (Recommended)","text":"<pre><code>@agent\nasync def fallback(query: str) -&gt; str:\n    '''Fallback handler: {{ query }}'''\n    pass\n\nrouter = AgentRouter(fallback_agent=fallback)\n\n# No exception raised - fallback is used automatically\nresult = await router.route(\"Any request\")\n</code></pre>"},{"location":"tutorials/09-agent-routing/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/09-agent-routing/#1-use-specific-intent-keywords","title":"1. Use Specific Intent Keywords","text":"<pre><code># \u2705 Good: Specific, distinctive keywords\nrouter.register(\n    code_reviewer,\n    intents=[\"review\", \"code quality\", \"static analysis\"]\n)\n\n# \u274c Bad: Generic, overlapping keywords\nrouter.register(\n    code_reviewer,\n    intents=[\"help\", \"check\", \"look\"]\n)\n</code></pre>"},{"location":"tutorials/09-agent-routing/#2-provide-agent-descriptions","title":"2. Provide Agent Descriptions","text":"<pre><code># \u2705 Good: Clear description\nrouter.register(\n    translator,\n    intents=[\"translate\"],\n    description=\"Translates text between 50+ languages\"\n)\n\n# \u274c Bad: No description\nrouter.register(translator, intents=[\"translate\"])\n</code></pre>"},{"location":"tutorials/09-agent-routing/#3-test-edge-cases","title":"3. Test Edge Cases","text":"<pre><code># Test ambiguous inputs\ntest_cases = [\n    \"review and translate\",  # Matches multiple agents\n    \"\",  # Empty input\n    \"xyz123\",  # Random input\n    \"\u3053\u3093\u306b\u3061\u306f\",  # Unicode\n]\n\nfor test in test_cases:\n    try:\n        matches = router.get_matched_agents(test)\n        print(f\"{test}: {len(matches)} matches\")\n    except Exception as e:\n        print(f\"{test}: Error - {e}\")\n</code></pre>"},{"location":"tutorials/09-agent-routing/#4-monitor-confidence-scores","title":"4. Monitor Confidence Scores","text":"<pre><code># Log routing decisions\nmatches = router.get_matched_agents(user_input, top_k=1)\nif matches:\n    agent, score = matches[0]\n    print(f\"Selected: {agent.__name__} (confidence: {score:.2f})\")\n\n    if score &lt; 0.5:\n        print(\"Warning: Low confidence routing\")\n</code></pre>"},{"location":"tutorials/09-agent-routing/#5-always-use-fallback","title":"5. Always Use Fallback","text":"<pre><code># \u2705 Good: Always have a fallback\nrouter = AgentRouter(fallback_agent=general_agent)\n\n# \u274c Bad: No fallback (exceptions for unmatched inputs)\nrouter = AgentRouter()\n</code></pre>"},{"location":"tutorials/09-agent-routing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/09-agent-routing/#agent-not-being-selected","title":"Agent Not Being Selected","text":"<p>Problem: Expected agent is not selected</p> <p>Solution: Check intent keywords and scoring</p> <pre><code># Debug: Check matched agents\nmatches = router.get_matched_agents(user_input, top_k=5)\nfor agent, score in matches:\n    print(f\"{agent.__name__}: {score:.2f}\")\n\n# If score is too low, add more intent keywords\nrouter.register(\n    my_agent,\n    intents=[\"original\", \"keywords\", \"plus\", \"more\", \"variants\"]\n)\n</code></pre>"},{"location":"tutorials/09-agent-routing/#fallback-always-used","title":"Fallback Always Used","text":"<p>Problem: Fallback agent is always selected</p> <p>Solution: Lower confidence threshold or add more intent keywords</p> <pre><code># Option 1: Lower threshold\nrouter = AgentRouter(\n    fallback_agent=fallback,\n    confidence_threshold=0.2  # More lenient\n)\n\n# Option 2: Add more intents\nrouter.register(\n    my_agent,\n    intents=[\"many\", \"different\", \"keyword\", \"variations\"]\n)\n</code></pre>"},{"location":"tutorials/09-agent-routing/#multiple-agents-match","title":"Multiple Agents Match","text":"<p>Problem: Multiple agents have similar scores</p> <p>Solution: Make intents more specific</p> <pre><code># Before: Generic intents\nrouter.register(agent1, intents=[\"check\", \"analyze\"])\nrouter.register(agent2, intents=[\"check\", \"review\"])\n\n# After: Specific intents\nrouter.register(agent1, intents=[\"performance check\", \"load analysis\"])\nrouter.register(agent2, intents=[\"code review\", \"quality review\"])\n</code></pre>"},{"location":"tutorials/09-agent-routing/#next-steps","title":"Next Steps","text":"<ul> <li>Phase 2: Semantic routing with embedding-based matching</li> <li>Phase 3: Agent chaining and conditional routing</li> <li>Integration: Use with Chat REPL for conversational AI</li> </ul>"},{"location":"tutorials/09-agent-routing/#see-also","title":"See Also","text":"<ul> <li>Agent Routing API Reference</li> <li>Agent Decorator Guide</li> <li>RFC-016: Agent Routing System</li> </ul>"},{"location":"tutorials/11-tools/","title":"Tools Tutorial","text":"<p>The @tool decorator allows you to convert regular Python functions into tools that can be used by AI agents or exposed via MCP.</p>"},{"location":"tutorials/11-tools/#what-are-tools","title":"What are Tools?","text":"<p>Tools are non-LLM functions that provide deterministic, reliable functionality to your agents:</p> <ul> <li>Calculations: Math, tax, conversions</li> <li>Data Access: Database queries, API calls</li> <li>File Operations: Read, write, process files</li> <li>System Operations: Execute commands, manage resources</li> </ul> <p>Unlike <code>@agent</code> (which calls an LLM), <code>@tool</code> functions execute pure Python code.</p>"},{"location":"tutorials/11-tools/#quick-start","title":"Quick Start","text":""},{"location":"tutorials/11-tools/#basic-tool","title":"Basic Tool","text":"<pre><code>from kagura import tool\n\n@tool\ndef calculate_tax(amount: float, rate: float = 0.1) -&gt; float:\n    \"\"\"Calculate tax amount\"\"\"\n    return amount * rate\n\n# Call directly\ntax = calculate_tax(100.0, 0.15)  # 15.0\n</code></pre>"},{"location":"tutorials/11-tools/#using-tools-with-agents","title":"Using Tools with Agents","text":"<pre><code>from kagura import agent, tool\n\n@tool\ndef get_exchange_rate(from_currency: str, to_currency: str) -&gt; float:\n    \"\"\"Get currency exchange rate (simplified)\"\"\"\n    rates = {\n        (\"USD\", \"EUR\"): 0.85,\n        (\"EUR\", \"USD\"): 1.18,\n        (\"USD\", \"JPY\"): 110.0,\n    }\n    return rates.get((from_currency, to_currency), 1.0)\n\n@agent\nasync def currency_assistant(query: str) -&gt; str:\n    \"\"\"\n    Help with currency conversions.\n\n    Available tools:\n    - get_exchange_rate(from_currency, to_currency): Get exchange rate\n\n    Query: {{ query }}\n    \"\"\"\n    pass\n\n# Use\nresult = await currency_assistant(\"Convert 100 USD to EUR\")\n# AI will suggest using get_exchange_rate(\"USD\", \"EUR\") = 0.85\n# Then calculate: 100 * 0.85 = 85 EUR\n</code></pre>"},{"location":"tutorials/11-tools/#tool-features","title":"Tool Features","text":""},{"location":"tutorials/11-tools/#1-type-validation","title":"1. Type Validation","text":"<p>Tools automatically validate argument types:</p> <pre><code>@tool\ndef divide(a: float, b: float) -&gt; float:\n    \"\"\"Divide two numbers\"\"\"\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n\n# Valid\nresult = divide(10.0, 2.0)  # 5.0\n\n# Invalid - raises TypeError\ndivide(10.0)  # Missing argument\ndivide(10.0, 2.0, 3.0)  # Too many arguments\n</code></pre>"},{"location":"tutorials/11-tools/#2-default-parameters","title":"2. Default Parameters","text":"<pre><code>@tool\ndef greet(name: str, greeting: str = \"Hello\") -&gt; str:\n    \"\"\"Greet someone\"\"\"\n    return f\"{greeting}, {name}!\"\n\ngreet(\"Alice\")  # \"Hello, Alice!\"\ngreet(\"Bob\", \"Hi\")  # \"Hi, Bob!\"\ngreet(name=\"Charlie\", greeting=\"Hey\")  # \"Hey, Charlie!\"\n</code></pre>"},{"location":"tutorials/11-tools/#3-custom-names","title":"3. Custom Names","text":"<pre><code>@tool(name=\"tax_calculator\")\ndef calc_tax(amount: float) -&gt; float:\n    \"\"\"Calculate 10% tax\"\"\"\n    return amount * 0.1\n\n# Registered as \"tax_calculator\" instead of \"calc_tax\"\n</code></pre>"},{"location":"tutorials/11-tools/#4-documentation","title":"4. Documentation","text":"<p>Docstrings are preserved for MCP integration:</p> <pre><code>@tool\ndef search_database(query: str, limit: int = 10) -&gt; list:\n    \"\"\"\n    Search database for records matching query.\n\n    Args:\n        query: Search query string\n        limit: Maximum number of results\n\n    Returns:\n        List of matching records\n    \"\"\"\n    # Implementation here\n    return []\n</code></pre>"},{"location":"tutorials/11-tools/#tool-registry","title":"Tool Registry","text":"<p>All tools are automatically registered in the global <code>tool_registry</code>:</p> <pre><code>from kagura.core.tool_registry import tool_registry\n\n# List all tools\nprint(tool_registry.list_names())\n# ['calculate_tax', 'get_exchange_rate', 'divide', ...]\n\n# Get a specific tool\ntax_tool = tool_registry.get(\"calculate_tax\")\nresult = tax_tool(100.0, 0.15)  # 15.0\n\n# Get all tools\nall_tools = tool_registry.get_all()\nfor name, func in all_tools.items():\n    print(f\"{name}: {func.__doc__}\")\n</code></pre>"},{"location":"tutorials/11-tools/#examples","title":"Examples","text":""},{"location":"tutorials/11-tools/#example-1-calculator-tools","title":"Example 1: Calculator Tools","text":"<pre><code>from kagura import tool\n\n@tool\ndef add(a: float, b: float) -&gt; float:\n    \"\"\"Add two numbers\"\"\"\n    return a + b\n\n@tool\ndef subtract(a: float, b: float) -&gt; float:\n    \"\"\"Subtract b from a\"\"\"\n    return a - b\n\n@tool\ndef multiply(a: float, b: float) -&gt; float:\n    \"\"\"Multiply two numbers\"\"\"\n    return a * b\n\n@tool\ndef divide(a: float, b: float) -&gt; float:\n    \"\"\"Divide a by b\"\"\"\n    if b == 0:\n        raise ValueError(\"Division by zero\")\n    return a / b\n\n# Use directly\nprint(add(5, 3))       # 8.0\nprint(multiply(4, 7))  # 28.0\n</code></pre>"},{"location":"tutorials/11-tools/#example-2-string-processing-tools","title":"Example 2: String Processing Tools","text":"<pre><code>@tool\ndef count_words(text: str) -&gt; int:\n    \"\"\"Count words in text\"\"\"\n    return len(text.split())\n\n@tool\ndef to_uppercase(text: str) -&gt; str:\n    \"\"\"Convert text to uppercase\"\"\"\n    return text.upper()\n\n@tool\ndef extract_emails(text: str) -&gt; list[str]:\n    \"\"\"Extract email addresses from text\"\"\"\n    import re\n    pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n    return re.findall(pattern, text)\n\n# Use\ntext = \"Contact: alice@example.com or bob@test.org\"\nemails = extract_emails(text)\nprint(emails)  # ['alice@example.com', 'bob@test.org']\n</code></pre>"},{"location":"tutorials/11-tools/#example-3-data-processing-tools","title":"Example 3: Data Processing Tools","text":"<pre><code>@tool\ndef filter_dict(data: dict, keys: list[str]) -&gt; dict:\n    \"\"\"Filter dictionary to only include specified keys\"\"\"\n    return {k: v for k, v in data.items() if k in keys}\n\n@tool\ndef merge_dicts(*dicts: dict) -&gt; dict:\n    \"\"\"Merge multiple dictionaries\"\"\"\n    result = {}\n    for d in dicts:\n        result.update(d)\n    return result\n\n@tool\ndef get_nested_value(data: dict, path: str, default=None):\n    \"\"\"Get value from nested dictionary using dot notation\"\"\"\n    keys = path.split('.')\n    value = data\n    for key in keys:\n        if isinstance(value, dict):\n            value = value.get(key, default)\n        else:\n            return default\n    return value\n\n# Use\ndata = {\"user\": {\"name\": \"Alice\", \"age\": 30, \"email\": \"alice@example.com\"}}\nname = get_nested_value(data, \"user.name\")  # \"Alice\"\n</code></pre>"},{"location":"tutorials/11-tools/#example-4-file-tools","title":"Example 4: File Tools","text":"<pre><code>import json\nfrom pathlib import Path\n\n@tool\ndef read_json_file(filepath: str) -&gt; dict:\n    \"\"\"Read and parse JSON file\"\"\"\n    with open(filepath) as f:\n        return json.load(f)\n\n@tool\ndef write_json_file(filepath: str, data: dict) -&gt; None:\n    \"\"\"Write data to JSON file\"\"\"\n    with open(filepath, 'w') as f:\n        json.dump(data, f, indent=2)\n\n@tool\ndef list_files(directory: str, extension: str = \"*\") -&gt; list[str]:\n    \"\"\"List files in directory with optional extension filter\"\"\"\n    path = Path(directory)\n    if extension == \"*\":\n        return [str(f) for f in path.iterdir() if f.is_file()]\n    return [str(f) for f in path.glob(f\"*.{extension}\")]\n\n# Use\nfiles = list_files(\".\", \"py\")  # All .py files in current directory\n</code></pre>"},{"location":"tutorials/11-tools/#integration-with-mcp","title":"Integration with MCP","text":"<p>Tools can be exposed via MCP for use in Claude Desktop:</p> <pre><code>from kagura import tool\n\n@tool\ndef weather_lookup(city: str) -&gt; dict:\n    \"\"\"Get current weather for a city\"\"\"\n    # Implementation\n    return {\n        \"city\": city,\n        \"temperature\": 72,\n        \"condition\": \"sunny\"\n    }\n\n# Automatically available in MCP\n# Run: kagura mcp start\n# Claude Desktop can now call weather_lookup\n</code></pre>"},{"location":"tutorials/11-tools/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/11-tools/#1-clear-documentation","title":"1. Clear Documentation","text":"<pre><code>@tool\ndef calculate_discount(price: float, discount_percent: float) -&gt; float:\n    \"\"\"\n    Calculate discounted price.\n\n    Args:\n        price: Original price\n        discount_percent: Discount percentage (e.g., 15 for 15%)\n\n    Returns:\n        Final price after discount\n\n    Example:\n        &gt;&gt;&gt; calculate_discount(100.0, 15.0)\n        85.0\n    \"\"\"\n    return price * (1 - discount_percent / 100)\n</code></pre>"},{"location":"tutorials/11-tools/#2-input-validation","title":"2. Input Validation","text":"<pre><code>@tool\ndef withdraw_money(account_id: str, amount: float) -&gt; dict:\n    \"\"\"Withdraw money from account\"\"\"\n    if amount &lt;= 0:\n        raise ValueError(\"Amount must be positive\")\n    if amount &gt; 10000:\n        raise ValueError(\"Exceeds daily limit\")\n\n    # Process withdrawal\n    return {\"success\": True, \"new_balance\": 5000 - amount}\n</code></pre>"},{"location":"tutorials/11-tools/#3-error-handling","title":"3. Error Handling","text":"<pre><code>@tool\ndef fetch_user_data(user_id: int) -&gt; dict:\n    \"\"\"Fetch user data from database\"\"\"\n    try:\n        # Database query\n        user = database.get_user(user_id)\n        if not user:\n            raise ValueError(f\"User {user_id} not found\")\n        return user\n    except DatabaseError as e:\n        raise RuntimeError(f\"Database error: {e}\") from e\n</code></pre>"},{"location":"tutorials/11-tools/#4-type-hints","title":"4. Type Hints","text":"<p>Always use type hints for better documentation and validation:</p> <pre><code>@tool\ndef process_order(\n    order_id: str,\n    items: list[dict],\n    shipping_address: dict,\n    priority: bool = False\n) -&gt; dict:\n    \"\"\"Process customer order\"\"\"\n    # Implementation\n    return {\n        \"order_id\": order_id,\n        \"status\": \"processing\",\n        \"estimated_delivery\": \"2025-10-15\"\n    }\n</code></pre>"},{"location":"tutorials/11-tools/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/11-tools/#tool-not-found-in-registry","title":"Tool not found in registry","text":"<pre><code>from kagura.core.tool_registry import tool_registry\n\n# Check if tool is registered\nif \"my_tool\" not in tool_registry.list_names():\n    print(\"Tool not found!\")\n    print(\"Available tools:\", tool_registry.list_names())\n</code></pre>"},{"location":"tutorials/11-tools/#type-validation-errors","title":"Type validation errors","text":"<pre><code>@tool\ndef strict_function(x: int) -&gt; int:\n    return x * 2\n\n# This will raise TypeError\nstrict_function(\"not an int\")  # Error!\nstrict_function(5, 10)  # Too many arguments!\n</code></pre>"},{"location":"tutorials/11-tools/#tool-name-conflicts","title":"Tool name conflicts","text":"<pre><code># This will raise ValueError\n@tool\ndef duplicate():\n    pass\n\n@tool\ndef duplicate():  # Error: already registered!\n    pass\n\n# Solution: Use custom names\n@tool(name=\"duplicate_v2\")\ndef duplicate():\n    pass\n</code></pre>"},{"location":"tutorials/11-tools/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Agent Routing</li> <li>Explore MCP Integration</li> <li>Try Chat REPL</li> </ul>"},{"location":"tutorials/11-tools/#further-reading","title":"Further Reading","text":"<ul> <li>Tools API Reference</li> <li>Tool Registry API</li> <li>MCP Tools Integration</li> </ul>"},{"location":"tutorials/12-workflows/","title":"Workflows Tutorial","text":"<p>The @workflow decorator allows you to create multi-agent orchestrations that coordinate multiple agents and tools to accomplish complex tasks.</p>"},{"location":"tutorials/12-workflows/#what-are-workflows","title":"What are Workflows?","text":"<p>Workflows are multi-agent orchestrations that combine agents and tools in a coordinated sequence:</p> <ul> <li>Coordination: Call multiple agents in sequence or parallel</li> <li>Data Flow: Pass results between agents</li> <li>Complex Tasks: Break down large problems into steps</li> <li>Reusability: Package multi-step processes</li> </ul> <p>Unlike <code>@agent</code> (which calls an LLM) and <code>@tool</code> (which executes pure Python), <code>@workflow</code> executes the function body to orchestrate agent calls.</p>"},{"location":"tutorials/12-workflows/#quick-start","title":"Quick Start","text":""},{"location":"tutorials/12-workflows/#basic-workflow","title":"Basic Workflow","text":"<pre><code>from kagura import workflow, agent\n\n@agent\nasync def search_agent(query: str) -&gt; str:\n    \"\"\"Search for information about {{ query }}\"\"\"\n    ...\n\n@agent\nasync def summarize_agent(text: str) -&gt; str:\n    \"\"\"Summarize: {{ text }}\"\"\"\n    ...\n\n@workflow\nasync def research_workflow(topic: str) -&gt; dict:\n    \"\"\"Research a topic using multiple agents\"\"\"\n    # Step 1: Search for information\n    search_results = await search_agent(topic)\n\n    # Step 2: Summarize findings\n    summary = await summarize_agent(search_results)\n\n    return {\n        \"topic\": topic,\n        \"findings\": search_results,\n        \"summary\": summary\n    }\n\n# Use\nresult = await research_workflow(\"AI safety\")\n</code></pre>"},{"location":"tutorials/12-workflows/#workflow-features","title":"Workflow Features","text":""},{"location":"tutorials/12-workflows/#1-sequential-execution","title":"1. Sequential Execution","text":"<p>Execute agents in a specific order:</p> <pre><code>@workflow\nasync def content_pipeline(topic: str) -&gt; dict:\n    \"\"\"Create content through multiple stages\"\"\"\n    # Research phase\n    research = await research_agent(topic)\n\n    # Writing phase\n    draft = await writing_agent(research)\n\n    # Editing phase\n    final = await editing_agent(draft)\n\n    return {\n        \"topic\": topic,\n        \"draft\": draft,\n        \"final\": final\n    }\n</code></pre>"},{"location":"tutorials/12-workflows/#2-parallel-execution","title":"2. Parallel Execution","text":"<p>Run agents concurrently using <code>asyncio.gather</code>:</p> <pre><code>import asyncio\n\n@workflow\nasync def multi_source_research(topic: str) -&gt; dict:\n    \"\"\"Research from multiple sources in parallel\"\"\"\n    # Execute in parallel\n    results = await asyncio.gather(\n        academic_search_agent(topic),\n        news_search_agent(topic),\n        social_media_agent(topic)\n    )\n\n    academic, news, social = results\n\n    # Combine results\n    combined = await synthesis_agent(\n        f\"Academic: {academic}\\nNews: {news}\\nSocial: {social}\"\n    )\n\n    return {\n        \"academic\": academic,\n        \"news\": news,\n        \"social\": social,\n        \"synthesis\": combined\n    }\n</code></pre>"},{"location":"tutorials/12-workflows/#3-conditional-logic","title":"3. Conditional Logic","text":"<p>Use branching logic based on results:</p> <pre><code>@workflow\nasync def smart_analysis(text: str) -&gt; dict:\n    \"\"\"Analyze text with conditional processing\"\"\"\n    # Classify content type\n    content_type = await classifier_agent(text)\n\n    # Different processing based on type\n    if content_type == \"technical\":\n        analysis = await technical_analyzer(text)\n    elif content_type == \"creative\":\n        analysis = await creative_analyzer(text)\n    else:\n        analysis = await general_analyzer(text)\n\n    return {\n        \"type\": content_type,\n        \"analysis\": analysis\n    }\n</code></pre>"},{"location":"tutorials/12-workflows/#4-error-handling","title":"4. Error Handling","text":"<p>Handle failures gracefully:</p> <pre><code>@workflow\nasync def robust_workflow(query: str) -&gt; dict:\n    \"\"\"Workflow with error handling\"\"\"\n    try:\n        primary_result = await primary_agent(query)\n    except Exception as e:\n        # Fallback to secondary agent\n        primary_result = await fallback_agent(query)\n\n    # Validate result\n    if not primary_result:\n        raise ValueError(\"No results found\")\n\n    return {\n        \"query\": query,\n        \"result\": primary_result\n    }\n</code></pre>"},{"location":"tutorials/12-workflows/#workflow-registry","title":"Workflow Registry","text":"<p>All workflows are automatically registered in the global <code>workflow_registry</code>:</p> <pre><code>from kagura.core.workflow_registry import workflow_registry\n\n# List all workflows\nprint(workflow_registry.list_names())\n# ['research_workflow', 'content_pipeline', ...]\n\n# Get a specific workflow\nworkflow = workflow_registry.get(\"research_workflow\")\nresult = await workflow(\"AI safety\")\n\n# Get all workflows\nall_workflows = workflow_registry.get_all()\nfor name, func in all_workflows.items():\n    print(f\"{name}: {func.__doc__}\")\n</code></pre>"},{"location":"tutorials/12-workflows/#examples","title":"Examples","text":""},{"location":"tutorials/12-workflows/#example-1-document-processing-workflow","title":"Example 1: Document Processing Workflow","text":"<pre><code>@workflow\nasync def process_document(file_path: str) -&gt; dict:\n    \"\"\"Complete document processing pipeline\"\"\"\n    # Extract text\n    text = await extract_text_tool(file_path)\n\n    # Analyze sentiment\n    sentiment = await sentiment_agent(text)\n\n    # Extract key points\n    key_points = await extraction_agent(text)\n\n    # Generate summary\n    summary = await summarization_agent(text)\n\n    # Categorize\n    category = await categorization_agent(text)\n\n    return {\n        \"file\": file_path,\n        \"sentiment\": sentiment,\n        \"key_points\": key_points,\n        \"summary\": summary,\n        \"category\": category\n    }\n</code></pre>"},{"location":"tutorials/12-workflows/#example-2-customer-support-workflow","title":"Example 2: Customer Support Workflow","text":"<pre><code>@workflow\nasync def customer_support_workflow(ticket: dict) -&gt; dict:\n    \"\"\"Handle customer support ticket\"\"\"\n    # Classify urgency\n    urgency = await urgency_classifier(ticket[\"description\"])\n\n    # Route based on urgency\n    if urgency == \"high\":\n        # Immediate escalation\n        response = await senior_support_agent(ticket)\n    else:\n        # Standard processing\n        response = await support_agent(ticket)\n\n    # Generate follow-up\n    follow_up = await follow_up_agent(response)\n\n    return {\n        \"ticket_id\": ticket[\"id\"],\n        \"urgency\": urgency,\n        \"response\": response,\n        \"follow_up\": follow_up\n    }\n</code></pre>"},{"location":"tutorials/12-workflows/#example-3-data-analysis-workflow","title":"Example 3: Data Analysis Workflow","text":"<pre><code>@workflow\nasync def data_analysis_workflow(dataset: str) -&gt; dict:\n    \"\"\"Analyze dataset with multiple techniques\"\"\"\n    # Load and validate data\n    data = await data_loader_tool(dataset)\n\n    # Statistical analysis\n    stats = await statistical_agent(data)\n\n    # Pattern detection\n    patterns = await pattern_detection_agent(data)\n\n    # Visualization\n    viz = await visualization_agent(data, patterns)\n\n    # Report generation\n    report = await report_agent(\n        f\"Stats: {stats}\\nPatterns: {patterns}\"\n    )\n\n    return {\n        \"dataset\": dataset,\n        \"statistics\": stats,\n        \"patterns\": patterns,\n        \"visualization\": viz,\n        \"report\": report\n    }\n</code></pre>"},{"location":"tutorials/12-workflows/#example-4-content-creation-workflow","title":"Example 4: Content Creation Workflow","text":"<pre><code>@workflow\nasync def content_creation_workflow(\n    topic: str,\n    target_audience: str\n) -&gt; dict:\n    \"\"\"Create content tailored to audience\"\"\"\n    # Research topic\n    research = await research_agent(f\"{topic} for {target_audience}\")\n\n    # Generate outline\n    outline = await outline_agent(research)\n\n    # Write content sections in parallel\n    sections = await asyncio.gather(\n        intro_writer_agent(outline[0]),\n        body_writer_agent(outline[1]),\n        conclusion_writer_agent(outline[2])\n    )\n\n    # Combine sections\n    full_content = \"\\n\\n\".join(sections)\n\n    # Edit for audience\n    edited = await editor_agent(\n        f\"Edit for {target_audience}: {full_content}\"\n    )\n\n    # SEO optimization\n    seo_optimized = await seo_agent(edited, topic)\n\n    return {\n        \"topic\": topic,\n        \"audience\": target_audience,\n        \"research\": research,\n        \"outline\": outline,\n        \"content\": seo_optimized\n    }\n</code></pre>"},{"location":"tutorials/12-workflows/#integration-with-agents-and-tools","title":"Integration with Agents and Tools","text":""},{"location":"tutorials/12-workflows/#combining-agents-and-tools","title":"Combining Agents and Tools","text":"<pre><code>from kagura import workflow, agent, tool\n\n@tool\ndef calculate_metrics(data: list) -&gt; dict:\n    \"\"\"Calculate statistical metrics\"\"\"\n    return {\n        \"mean\": sum(data) / len(data),\n        \"max\": max(data),\n        \"min\": min(data)\n    }\n\n@agent\nasync def insights_agent(metrics: dict) -&gt; str:\n    \"\"\"Generate insights from {{ metrics }}\"\"\"\n    ...\n\n@workflow\nasync def analytics_workflow(data: list) -&gt; dict:\n    \"\"\"Analyze data and generate insights\"\"\"\n    # Use tool for calculations\n    metrics = calculate_metrics(data)\n\n    # Use agent for insights\n    insights = await insights_agent(metrics)\n\n    return {\n        \"metrics\": metrics,\n        \"insights\": insights\n    }\n</code></pre>"},{"location":"tutorials/12-workflows/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/12-workflows/#1-clear-workflow-structure","title":"1. Clear Workflow Structure","text":"<pre><code>@workflow\nasync def well_structured_workflow(input_data: str) -&gt; dict:\n    \"\"\"\n    Process data through multiple stages.\n\n    Stages:\n    1. Validation\n    2. Processing\n    3. Analysis\n    4. Reporting\n    \"\"\"\n    # Stage 1: Validation\n    validated = await validation_agent(input_data)\n\n    # Stage 2: Processing\n    processed = await processing_agent(validated)\n\n    # Stage 3: Analysis\n    analyzed = await analysis_agent(processed)\n\n    # Stage 4: Reporting\n    report = await reporting_agent(analyzed)\n\n    return {\n        \"validated\": validated,\n        \"processed\": processed,\n        \"analyzed\": analyzed,\n        \"report\": report\n    }\n</code></pre>"},{"location":"tutorials/12-workflows/#2-error-recovery","title":"2. Error Recovery","text":"<pre><code>@workflow\nasync def resilient_workflow(task: str) -&gt; dict:\n    \"\"\"Workflow with retry logic\"\"\"\n    max_retries = 3\n\n    for attempt in range(max_retries):\n        try:\n            result = await unreliable_agent(task)\n            break\n        except Exception as e:\n            if attempt == max_retries - 1:\n                # Final fallback\n                result = await fallback_agent(task)\n            else:\n                # Retry with backoff\n                await asyncio.sleep(2 ** attempt)\n\n    return {\"task\": task, \"result\": result}\n</code></pre>"},{"location":"tutorials/12-workflows/#3-progress-tracking","title":"3. Progress Tracking","text":"<pre><code>@workflow\nasync def tracked_workflow(items: list) -&gt; dict:\n    \"\"\"Track progress through workflow\"\"\"\n    results = []\n    total = len(items)\n\n    for i, item in enumerate(items, 1):\n        print(f\"Processing {i}/{total}: {item}\")\n        result = await processing_agent(item)\n        results.append(result)\n\n    return {\n        \"total\": total,\n        \"processed\": len(results),\n        \"results\": results\n    }\n</code></pre>"},{"location":"tutorials/12-workflows/#4-modular-design","title":"4. Modular Design","text":"<pre><code># Define reusable sub-workflows\n@workflow\nasync def data_prep_workflow(raw_data: str) -&gt; dict:\n    \"\"\"Reusable data preparation\"\"\"\n    cleaned = await cleaning_agent(raw_data)\n    normalized = await normalization_agent(cleaned)\n    return {\"cleaned\": cleaned, \"normalized\": normalized}\n\n@workflow\nasync def main_workflow(input_data: str) -&gt; dict:\n    \"\"\"Main workflow using sub-workflows\"\"\"\n    # Reuse data prep\n    prepared = await data_prep_workflow(input_data)\n\n    # Continue with analysis\n    analysis = await analysis_agent(prepared[\"normalized\"])\n\n    return {\n        \"prepared\": prepared,\n        \"analysis\": analysis\n    }\n</code></pre>"},{"location":"tutorials/12-workflows/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/12-workflows/#workflow-not-found-in-registry","title":"Workflow not found in registry","text":"<pre><code>from kagura.core.workflow_registry import workflow_registry\n\n# Check if workflow is registered\nif \"my_workflow\" not in workflow_registry.list_names():\n    print(\"Workflow not found!\")\n    print(\"Available workflows:\", workflow_registry.list_names())\n</code></pre>"},{"location":"tutorials/12-workflows/#workflow-name-conflicts","title":"Workflow name conflicts","text":"<pre><code># This will raise ValueError\n@workflow\ndef duplicate():\n    pass\n\n@workflow\ndef duplicate():  # Error: already registered!\n    pass\n\n# Solution: Use custom names\n@workflow(name=\"duplicate_v2\")\nasync def duplicate():\n    pass\n</code></pre>"},{"location":"tutorials/12-workflows/#asyncawait-issues","title":"Async/await issues","text":"<pre><code># \u274c Wrong: Forgot await\n@workflow\nasync def broken_workflow(query: str) -&gt; str:\n    result = search_agent(query)  # Missing await!\n    return result\n\n# \u2705 Correct: Always await agent calls\n@workflow\nasync def correct_workflow(query: str) -&gt; str:\n    result = await search_agent(query)\n    return result\n</code></pre>"},{"location":"tutorials/12-workflows/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about MCP Integration</li> <li>Explore Agent Routing</li> <li>Try Chat REPL</li> </ul>"},{"location":"tutorials/12-workflows/#further-reading","title":"Further Reading","text":"<ul> <li>Workflows API Reference</li> <li>Workflow Registry API</li> <li>MCP Workflows Integration</li> </ul>"},{"location":"tutorials/13-agent-builder/","title":"Tutorial 13: Agent Builder","text":"<p>Learn how to use the AgentBuilder fluent API to create complex agents with integrated features.</p>"},{"location":"tutorials/13-agent-builder/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed (<code>pip install kagura-ai</code>)</li> <li>Completion of Tutorial 1: Basic Agent</li> <li>OpenAI API key (or other LLM provider)</li> </ul>"},{"location":"tutorials/13-agent-builder/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand the AgentBuilder fluent API pattern - Build agents with memory, tools, and hooks - Configure LLM generation parameters - Create reusable agent configurations</p>"},{"location":"tutorials/13-agent-builder/#what-is-agentbuilder","title":"What is AgentBuilder?","text":"<p><code>AgentBuilder</code> is a fluent API that simplifies creating complex agents with multiple features. Instead of manually wiring together memory, tools, hooks, and routing, you can use method chaining to build agents declaratively.</p>"},{"location":"tutorials/13-agent-builder/#before-agentbuilder","title":"Before AgentBuilder","text":"<pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n# Manually configure everything\nmemory = MemoryManager(agent_name=\"my_agent\", enable_rag=True)\n\n@agent(model=\"gpt-4o-mini\", temperature=0.7)\nasync def my_agent(prompt: str) -&gt; str:\n    '''Process: {{ prompt }}'''\n    pass\n</code></pre>"},{"location":"tutorials/13-agent-builder/#with-agentbuilder","title":"With AgentBuilder","text":"<pre><code>from kagura import AgentBuilder\n\n# Declarative configuration\nagent = (\n    AgentBuilder(\"my_agent\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(type=\"rag\", enable_rag=True)\n    .with_context(temperature=0.7)\n    .build()\n)\n</code></pre>"},{"location":"tutorials/13-agent-builder/#step-1-basic-agent-creation","title":"Step 1: Basic Agent Creation","text":"<p>Create a file called <code>builder_demo.py</code>:</p> <pre><code>import asyncio\nfrom kagura import AgentBuilder\n\n\nasync def main():\n    # Create a basic agent with AgentBuilder\n    agent = (\n        AgentBuilder(\"greeter\")\n        .with_model(\"gpt-4o-mini\")\n        .build()\n    )\n\n    result = await agent(\"Say hello!\")\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Run it:</p> <pre><code>python builder_demo.py\n</code></pre> <p>Explanation: 1. <code>AgentBuilder(\"greeter\")</code> - Initialize builder with agent name 2. <code>.with_model(\"gpt-4o-mini\")</code> - Set the LLM model 3. <code>.build()</code> - Build the final agent</p>"},{"location":"tutorials/13-agent-builder/#step-2-adding-memory","title":"Step 2: Adding Memory","text":"<p>Let's add memory so the agent can remember conversation history:</p> <pre><code>agent = (\n    AgentBuilder(\"assistant\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(\n        type=\"working\",\n        max_messages=50,\n        enable_rag=False\n    )\n    .build()\n)\n\n# Agent can now access conversation history\nresult = await agent(\"My name is Alice\")\nprint(result)  # \"Nice to meet you, Alice!\"\n\nresult = await agent(\"What's my name?\")\nprint(result)  # \"Your name is Alice.\"\n</code></pre> <p>Memory Types: - <code>\"working\"</code> - In-memory storage (fast, temporary) - <code>\"context\"</code> - Conversation context (for LLM context window) - <code>\"persistent\"</code> - SQLite storage (survives restarts) - <code>\"rag\"</code> - Vector-based semantic search (requires ChromaDB)</p>"},{"location":"tutorials/13-agent-builder/#step-3-rag-semantic-memory","title":"Step 3: RAG (Semantic Memory)","text":"<p>For semantic search over conversation history:</p> <pre><code>agent = (\n    AgentBuilder(\"smart_assistant\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(\n        type=\"rag\",\n        enable_rag=True,\n        max_messages=100\n    )\n    .build()\n)\n\n# Store various facts\nawait agent(\"Python is a programming language created by Guido van Rossum\")\nawait agent(\"I love hiking in the mountains\")\nawait agent(\"My favorite food is sushi\")\n\n# Semantic search finds relevant context\nresult = await agent(\"Tell me about programming\")\n# Agent recalls: \"Python is a programming language...\"\n\nresult = await agent(\"What do I like to eat?\")\n# Agent recalls: \"My favorite food is sushi\"\n</code></pre> <p>Note: RAG requires ChromaDB installation: <pre><code>pip install chromadb\n</code></pre></p>"},{"location":"tutorials/13-agent-builder/#step-4-adding-tools","title":"Step 4: Adding Tools","text":"<p>Tools extend agents with external capabilities:</p> <pre><code>def search_web(query: str) -&gt; str:\n    \"\"\"Search the web for information.\"\"\"\n    # Simulate web search\n    return f\"Search results for: {query}\"\n\n\ndef calculate(expression: str) -&gt; float:\n    \"\"\"Evaluate a mathematical expression.\"\"\"\n    return eval(expression)  # Note: Use safely in production!\n\n\nagent = (\n    AgentBuilder(\"researcher\")\n    .with_model(\"gpt-4o-mini\")\n    .with_tools([search_web, calculate])\n    .build()\n)\n\n# Agent can now use tools\nresult = await agent(\"What is 15 * 23?\")\n# Agent calls calculate(\"15 * 23\") and returns: \"345\"\n\nresult = await agent(\"Search for Python tutorials\")\n# Agent calls search_web(\"Python tutorials\")\n</code></pre>"},{"location":"tutorials/13-agent-builder/#step-5-pre-and-post-hooks","title":"Step 5: Pre and Post Hooks","text":"<p>Hooks let you inject logic before and after agent execution:</p> <pre><code>def log_input(*args, **kwargs):\n    \"\"\"Log agent input.\"\"\"\n    print(f\"[PRE] Input: {args}, {kwargs}\")\n\n\ndef log_output(result):\n    \"\"\"Log agent output.\"\"\"\n    print(f\"[POST] Output: {result}\")\n\n\nagent = (\n    AgentBuilder(\"monitored_agent\")\n    .with_model(\"gpt-4o-mini\")\n    .with_hooks(\n        pre=[log_input],\n        post=[log_output]\n    )\n    .build()\n)\n\nresult = await agent(\"Hello!\")\n# Console output:\n# [PRE] Input: ('Hello!',), {}\n# [POST] Output: Hi there! How can I help you?\n</code></pre> <p>Use Cases for Hooks: - Logging and monitoring - Input validation - Output sanitization - Rate limiting - Caching</p>"},{"location":"tutorials/13-agent-builder/#step-6-llm-generation-parameters","title":"Step 6: LLM Generation Parameters","text":"<p>Control how the LLM generates responses:</p> <pre><code># More deterministic (factual tasks)\nfactual_agent = (\n    AgentBuilder(\"fact_checker\")\n    .with_model(\"gpt-4o-mini\")\n    .with_context(\n        temperature=0.2,\n        max_tokens=500\n    )\n    .build()\n)\n\n# More creative (story generation)\ncreative_agent = (\n    AgentBuilder(\"storyteller\")\n    .with_model(\"gpt-4o-mini\")\n    .with_context(\n        temperature=1.5,\n        max_tokens=1000,\n        top_p=0.9\n    )\n    .build()\n)\n</code></pre> <p>Common Parameters: - <code>temperature</code> (0.0-2.0): Randomness (lower = more deterministic) - <code>max_tokens</code>: Maximum response length - <code>top_p</code> (0.0-1.0): Nucleus sampling threshold - <code>frequency_penalty</code>: Discourage repetition - <code>presence_penalty</code>: Encourage new topics</p>"},{"location":"tutorials/13-agent-builder/#complete-example-multi-feature-agent","title":"Complete Example: Multi-Feature Agent","text":"<p>Here's an agent with all features combined:</p> <pre><code>import asyncio\nfrom pathlib import Path\nfrom kagura import AgentBuilder\n\n\ndef web_search(query: str) -&gt; str:\n    \"\"\"Search the web.\"\"\"\n    return f\"Results for: {query}\"\n\n\ndef log_execution(result):\n    \"\"\"Log each execution.\"\"\"\n    print(f\"[LOG] Agent returned: {result}\")\n\n\nasync def main():\n    # Build a powerful multi-feature agent\n    agent = (\n        AgentBuilder(\"advanced_assistant\")\n        .with_model(\"gpt-4o-mini\")\n        .with_memory(\n            type=\"persistent\",\n            persist_dir=Path.home() / \".kagura\" / \"agents\",\n            max_messages=100,\n            enable_rag=True\n        )\n        .with_tools([web_search])\n        .with_hooks(\n            post=[log_execution]\n        )\n        .with_context(\n            temperature=0.7,\n            max_tokens=800\n        )\n        .build()\n    )\n\n    # Test the agent\n    result = await agent(\"Search for Python tutorials\")\n    print(f\"Response: {result}\")\n\n    result = await agent(\"What did I just ask you?\")\n    print(f\"Response: {result}\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"tutorials/13-agent-builder/#agent-configuration-object","title":"Agent Configuration Object","text":"<p>You can also work with configuration separately:</p> <pre><code>from kagura import AgentBuilder\nfrom kagura.builder import AgentConfiguration, MemoryConfig\n\n# Create configuration\nconfig = AgentConfiguration(\n    name=\"my_agent\",\n    model=\"gpt-4o-mini\"\n)\n\n# Build agent from config\nbuilder = AgentBuilder(config.name)\nbuilder._config = config\nagent = builder.build()\n</code></pre>"},{"location":"tutorials/13-agent-builder/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/13-agent-builder/#1-descriptive-agent-names","title":"1. Descriptive Agent Names","text":"<pre><code># Good\nAgentBuilder(\"customer_support_chatbot\")\nAgentBuilder(\"data_analysis_assistant\")\n\n# Less clear\nAgentBuilder(\"agent1\")\nAgentBuilder(\"my_agent\")\n</code></pre>"},{"location":"tutorials/13-agent-builder/#2-choose-appropriate-memory-type","title":"2. Choose Appropriate Memory Type","text":"<pre><code># Short conversations - working memory\nAgentBuilder(\"quick_qa\").with_memory(type=\"working\")\n\n# Long-term knowledge - RAG\nAgentBuilder(\"knowledge_base\").with_memory(type=\"rag\", enable_rag=True)\n\n# Persistent storage - persistent memory\nAgentBuilder(\"assistant\").with_memory(\n    type=\"persistent\",\n    persist_dir=Path.home() / \".kagura\"\n)\n</code></pre>"},{"location":"tutorials/13-agent-builder/#3-model-selection","title":"3. Model Selection","text":"<pre><code># Fast, cheap tasks\n.with_model(\"gpt-4o-mini\")\n\n# Complex reasoning\n.with_model(\"gpt-4o\")\n.with_model(\"claude-3-5-sonnet-20241022\")\n\n# Local models\n.with_model(\"ollama/llama3.2\")\n</code></pre>"},{"location":"tutorials/13-agent-builder/#4-method-chaining-formatting","title":"4. Method Chaining Formatting","text":"<pre><code># Good - readable\nagent = (\n    AgentBuilder(\"name\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(type=\"rag\")\n    .with_tools([tool1, tool2])\n    .build()\n)\n\n# Less readable\nagent = AgentBuilder(\"name\").with_model(\"gpt-4o-mini\").with_memory(type=\"rag\").with_tools([tool1, tool2]).build()\n</code></pre>"},{"location":"tutorials/13-agent-builder/#common-patterns","title":"Common Patterns","text":""},{"location":"tutorials/13-agent-builder/#pattern-1-chatbot-with-memory","title":"Pattern 1: Chatbot with Memory","text":"<pre><code>chatbot = (\n    AgentBuilder(\"chatbot\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(type=\"context\", max_messages=20)\n    .with_context(temperature=0.8)\n    .build()\n)\n</code></pre>"},{"location":"tutorials/13-agent-builder/#pattern-2-researcher-with-tools","title":"Pattern 2: Researcher with Tools","text":"<pre><code>researcher = (\n    AgentBuilder(\"researcher\")\n    .with_model(\"gpt-4o\")\n    .with_tools([web_search, summarize, extract_facts])\n    .with_context(temperature=0.3)\n    .build()\n)\n</code></pre>"},{"location":"tutorials/13-agent-builder/#pattern-3-monitored-agent","title":"Pattern 3: Monitored Agent","text":"<pre><code>monitored = (\n    AgentBuilder(\"monitored\")\n    .with_model(\"gpt-4o-mini\")\n    .with_hooks(\n        pre=[validate_input, rate_limit],\n        post=[log_output, cache_result]\n    )\n    .build()\n)\n</code></pre>"},{"location":"tutorials/13-agent-builder/#common-mistakes","title":"Common Mistakes","text":""},{"location":"tutorials/13-agent-builder/#1-forgetting-build","title":"1. Forgetting <code>.build()</code>","text":"<pre><code># Wrong - returns AgentBuilder, not an agent\nagent = AgentBuilder(\"name\").with_model(\"gpt-4o-mini\")\n\n# Correct\nagent = AgentBuilder(\"name\").with_model(\"gpt-4o-mini\").build()\n</code></pre>"},{"location":"tutorials/13-agent-builder/#2-enabling-rag-without-chromadb","title":"2. Enabling RAG Without ChromaDB","text":"<pre><code># This will fail if chromadb is not installed\nagent = (\n    AgentBuilder(\"agent\")\n    .with_memory(enable_rag=True)\n    .build()\n)\n\n# Install first:\n# pip install chromadb\n</code></pre>"},{"location":"tutorials/13-agent-builder/#3-incompatible-memory-and-rag","title":"3. Incompatible Memory and RAG","text":"<pre><code># RAG should use \"rag\" or \"persistent\" memory type\nagent = (\n    AgentBuilder(\"agent\")\n    .with_memory(type=\"working\", enable_rag=True)  # Conflict!\n    .build()\n)\n\n# Better\nagent = (\n    AgentBuilder(\"agent\")\n    .with_memory(type=\"rag\", enable_rag=True)\n    .build()\n)\n</code></pre>"},{"location":"tutorials/13-agent-builder/#practice-exercises","title":"Practice Exercises","text":""},{"location":"tutorials/13-agent-builder/#exercise-1-build-a-knowledge-assistant","title":"Exercise 1: Build a Knowledge Assistant","text":"<p>Create an agent that: - Uses GPT-4o-mini - Has RAG-enabled memory - Logs all interactions</p> <pre><code># Your code here\nknowledge_assistant = (\n    AgentBuilder(\"knowledge_assistant\")\n    # Add configurations\n    .build()\n)\n\n# Test it\nawait knowledge_assistant(\"Python is a programming language\")\nawait knowledge_assistant(\"What did I tell you about Python?\")\n</code></pre>"},{"location":"tutorials/13-agent-builder/#exercise-2-tool-equipped-researcher","title":"Exercise 2: Tool-Equipped Researcher","text":"<p>Create an agent with: - GPT-4o model - Web search and calculator tools - Low temperature (0.2) for accuracy</p> <pre><code># Your code here\n</code></pre>"},{"location":"tutorials/13-agent-builder/#exercise-3-multi-agent-system","title":"Exercise 3: Multi-Agent System","text":"<p>Build two agents with different configurations and have them work together:</p> <pre><code># Analyst (factual)\nanalyst = AgentBuilder(\"analyst\")...\n\n# Storyteller (creative)\nstoryteller = AgentBuilder(\"storyteller\")...\n\n# Workflow\nfacts = await analyst(\"Analyze: quantum computing\")\nstory = await storyteller(f\"Write a story about: {facts}\")\n</code></pre>"},{"location":"tutorials/13-agent-builder/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"tutorials/13-agent-builder/#1-fluent-api-pattern","title":"1. Fluent API Pattern","text":"<p>Method chaining for readable configuration: <pre><code>builder.method1().method2().method3()\n</code></pre></p>"},{"location":"tutorials/13-agent-builder/#2-declarative-agent-configuration","title":"2. Declarative Agent Configuration","text":"<p>Specify what you want, not how to build it: <pre><code>AgentBuilder(\"name\").with_feature().build()\n</code></pre></p>"},{"location":"tutorials/13-agent-builder/#3-feature-integration","title":"3. Feature Integration","text":"<p>Combine memory, tools, and hooks seamlessly: <pre><code>.with_memory().with_tools().with_hooks()\n</code></pre></p>"},{"location":"tutorials/13-agent-builder/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial 14: Agent Testing - Learn to test your agents</li> <li>Tutorial 15: Observability - Monitor agent performance</li> <li>API Reference: Builder - Complete API documentation</li> </ul>"},{"location":"tutorials/13-agent-builder/#summary","title":"Summary","text":"<p>You learned: - \u2713 How to use AgentBuilder's fluent API - \u2713 How to add memory (working, persistent, RAG) - \u2713 How to integrate tools and hooks - \u2713 How to configure LLM generation parameters - \u2713 Best practices for agent configuration</p> <p>Continue to Tutorial 14: Agent Testing to learn how to test your agents!</p>"},{"location":"tutorials/13-multimodal-rag/","title":"Tutorial 13: Multimodal RAG - Search Images, Audio, Videos &amp; PDFs","text":"<p>Learn how to create AI agents that can search and understand multimodal content (images, audio, video, PDFs) from your directories using Retrieval-Augmented Generation (RAG).</p>"},{"location":"tutorials/13-multimodal-rag/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed with web support: <code>pip install kagura-ai[web]</code></li> <li>Google API key (for Gemini API)</li> <li>ChromaDB installed (included with multimodal extra)</li> </ul>"},{"location":"tutorials/13-multimodal-rag/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand what Multimodal RAG is and why it's useful - Set up a directory for multimodal content indexing - Create agents that can search across text, images, audio, videos, and PDFs - Build a documentation assistant that understands diagrams and screenshots</p>"},{"location":"tutorials/13-multimodal-rag/#what-is-multimodal-rag","title":"What is Multimodal RAG?","text":"<p>RAG (Retrieval-Augmented Generation) enhances AI agents by giving them access to external knowledge. Multimodal RAG extends this to work with:</p> <ul> <li>Images (PNG, JPG, GIF, WEBP)</li> <li>Audio (MP3, WAV, M4A)</li> <li>Video (MP4, MOV, AVI)</li> <li>PDFs (documents with text and images)</li> <li>Text files (MD, TXT, Python code, etc.)</li> </ul> <p>Instead of just searching text, your agent can: - Find relevant diagrams and screenshots - Transcribe and search audio recordings - Extract information from video content - Process PDF documentation</p>"},{"location":"tutorials/13-multimodal-rag/#step-1-set-up-your-environment","title":"Step 1: Set Up Your Environment","text":"<p>Set your Google API key (required for processing multimodal content):</p> <pre><code>export GOOGLE_API_KEY=\"your-gemini-api-key\"\n</code></pre> <p>Install Kagura AI with web support (includes multimodal features):</p> <pre><code>pip install kagura-ai[web]\n</code></pre> <p>This installs: - <code>google-generativeai</code> - For Gemini API (multimodal processing) - <code>chromadb</code> - Vector database for semantic search (included in <code>ai</code> extra) - <code>pillow</code> - Image processing</p>"},{"location":"tutorials/13-multimodal-rag/#step-2-prepare-your-content-directory","title":"Step 2: Prepare Your Content Directory","text":"<p>Create a project directory with mixed content:</p> <pre><code>mkdir my_project\ncd my_project\n\n# Create some documentation\necho \"# Authentication\\nOur app uses OAuth 2.0\" &gt; auth.md\n\n# Create a docs folder\nmkdir docs\necho \"User guide content here\" &gt; docs/guide.txt\n\n# Add some images (diagrams, screenshots, etc.)\nmkdir images\n# Add your actual images here\n</code></pre> <p>Your directory structure: <pre><code>my_project/\n\u251c\u2500\u2500 auth.md           # Text documentation\n\u251c\u2500\u2500 docs/\n\u2502   \u2514\u2500\u2500 guide.txt     # More docs\n\u2514\u2500\u2500 images/\n    \u251c\u2500\u2500 diagram.png   # Architecture diagram\n    \u2514\u2500\u2500 screenshot.jpg # UI screenshot\n</code></pre></p>"},{"location":"tutorials/13-multimodal-rag/#step-3-create-your-first-rag-agent","title":"Step 3: Create Your First RAG Agent","text":"<p>Create <code>rag_agent.py</code>:</p> <pre><code>import asyncio\nfrom pathlib import Path\nfrom kagura import agent\n\n\n@agent(\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./my_project\")\n)\nasync def docs_assistant(query: str, rag) -&gt; str:\n    '''Answer the question: {{ query }}\n\n    Use rag.query(query) to search documentation.\n    Include relevant details from the search results.'''\n    pass\n\n\nasync def main():\n    # First call: Builds index (may take a moment)\n    result = await docs_assistant(\"How does authentication work?\")\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Let's break this down:</p> <ol> <li><code>enable_multimodal_rag=True</code> - Enables RAG functionality</li> <li><code>rag_directory=Path(\"./my_project\")</code> - Directory to index</li> <li><code>rag</code> parameter - Auto-injected MultimodalRAG instance</li> <li><code>rag.query(query)</code> - Search for relevant content</li> </ol>"},{"location":"tutorials/13-multimodal-rag/#step-4-run-your-rag-agent","title":"Step 4: Run Your RAG Agent","text":"<p>Execute the script:</p> <pre><code>python rag_agent.py\n</code></pre> <p>First run: <pre><code>Building index from /path/to/my_project\nIndex built: 5 files (3 text, 2 multimodal)\nOur app uses OAuth 2.0 for authentication...\n</code></pre></p> <p>Subsequent runs: Much faster (uses cached index)</p> <p>\ud83c\udf89 Your agent can now search across all your documentation!</p>"},{"location":"tutorials/13-multimodal-rag/#how-it-works-behind-the-scenes","title":"How It Works: Behind the Scenes","text":""},{"location":"tutorials/13-multimodal-rag/#index-building","title":"Index Building","text":"<p>When you first call the agent:</p> <ol> <li>Directory Scanning: Recursively scans <code>my_project/</code></li> <li>File Type Detection: Identifies text, images, audio, video, PDFs</li> <li>Content Processing:</li> <li>Text files: Read directly</li> <li>Images: Analyzed with Gemini Vision API (describes content)</li> <li>Audio: Transcribed to text</li> <li>Video: Frames extracted and analyzed</li> <li>PDFs: Text and images extracted</li> <li>Vector Indexing: Stores in ChromaDB for semantic search</li> <li>Caching: Results cached for faster subsequent access</li> </ol>"},{"location":"tutorials/13-multimodal-rag/#query-time","title":"Query Time","text":"<p>When you search:</p> <ol> <li>Semantic Search: Finds relevant content using vector similarity</li> <li>Context Injection: Results available to the agent</li> <li>LLM Response: Agent synthesizes answer using search results</li> </ol>"},{"location":"tutorials/13-multimodal-rag/#step-5-advanced-usage-manual-search","title":"Step 5: Advanced Usage - Manual Search","text":"<p>You can manually control the search and response:</p> <pre><code>@agent(\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./my_project\")\n)\nasync def smart_assistant(query: str, rag) -&gt; str:\n    '''You are a helpful documentation assistant.\n\n    First, search for relevant information using: rag.query(\"{{ query }}\", n_results=3)\n    Then answer based on the search results: {{ query }}\n\n    If no relevant results found, say \"I couldn't find information about that.\"'''\n    pass\n</code></pre> <p>How this works: - The prompt tells the LLM to use <code>rag.query()</code> - The LLM calls it during generation (via tool calling) - Results are incorporated into the response</p>"},{"location":"tutorials/13-multimodal-rag/#step-6-building-the-index-explicitly","title":"Step 6: Building the Index Explicitly","text":"<p>For large directories, build the index ahead of time:</p> <pre><code>from pathlib import Path\nfrom kagura.core.memory import MultimodalRAG\nimport asyncio\n\n\nasync def build_index():\n    # Initialize RAG\n    rag = MultimodalRAG(\n        directory=Path(\"./my_project\"),\n        collection_name=\"my_docs\"\n    )\n\n    # Build index\n    stats = await rag.build_index(max_concurrent=3)\n\n    print(f\"Indexed {stats['total_files']} files\")\n    print(f\"  - Text: {stats['text_files']}\")\n    print(f\"  - Multimodal: {stats['multimodal_files']}\")\n    print(f\"  - Failed: {stats['failed_files']}\")\n    print(f\"Cache hit rate: {stats['cache_hit_rate']:.2%}\")\n\n\nasyncio.run(build_index())\n</code></pre> <p>Output: <pre><code>Building index from ./my_project\nIndexed 15 files\n  - Text: 10\n  - Multimodal: 5\n  - Failed: 0\nCache hit rate: 0.00%\n</code></pre></p>"},{"location":"tutorials/13-multimodal-rag/#step-7-search-by-file-type","title":"Step 7: Search by File Type","text":"<p>Filter results by content type:</p> <pre><code>from kagura.loaders.file_types import FileType\n\n# Search only images\nresults = rag.query(\"architecture diagram\", file_type=FileType.IMAGE)\n\n# Search only text\nresults = rag.query(\"authentication\", file_type=FileType.TEXT)\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#step-8-incremental-updates","title":"Step 8: Incremental Updates","text":"<p>Update the index when files change:</p> <pre><code># Add new files to my_project/\n# Then update incrementally (faster than full rebuild)\nstats = await rag.incremental_update()\nprint(f\"Updated {stats['total_files']} new/modified files\")\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#configuration-options","title":"Configuration Options","text":""},{"location":"tutorials/13-multimodal-rag/#rag-parameters","title":"RAG Parameters","text":"<pre><code>@agent(\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./docs\"),        # Required\n    rag_cache_size_mb=100,                # Cache size (default: 100MB)\n    persist_dir=Path(\"./.kagura\")         # ChromaDB storage location\n)\nasync def my_agent(query: str, rag) -&gt; str:\n    pass\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#multimodalrag-options","title":"MultimodalRAG Options","text":"<pre><code>from kagura.core.memory import MultimodalRAG\n\nrag = MultimodalRAG(\n    directory=Path(\"./project\"),\n    collection_name=\"my_docs\",         # ChromaDB collection name\n    persist_dir=Path(\"./.kagura\"),     # Storage directory\n    cache_size_mb=100,                 # File cache size\n    respect_gitignore=True,            # Honor .gitignore/.kaguraignore\n)\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#step-9-gitignore-support","title":"Step 9: Gitignore Support","text":"<p>Create <code>.kaguraignore</code> to exclude files:</p> <pre><code># .kaguraignore\nnode_modules/\n*.log\n.env\n__pycache__/\n</code></pre> <p>Files matching these patterns are automatically excluded from indexing.</p>"},{"location":"tutorials/13-multimodal-rag/#complete-example-documentation-assistant","title":"Complete Example: Documentation Assistant","text":"<p>Here's a full example with proper error handling:</p> <pre><code>import asyncio\nfrom pathlib import Path\nfrom kagura import agent\nfrom kagura.core.memory import MultimodalRAG\n\n\n@agent(\n    model=\"gpt-4o-mini\",\n    temperature=0.7,\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./my_project\")\n)\nasync def docs_bot(query: str, rag: MultimodalRAG) -&gt; str:\n    '''You are a documentation assistant.\n\n    Search relevant documentation: rag.query(\"{{ query }}\", n_results=5)\n    Answer based on results: {{ query }}\n\n    If you can't find relevant info, say so clearly.'''\n    pass\n\n\nasync def main():\n    print(\"Documentation Assistant\")\n    print(\"=\" * 40)\n\n    # Build index first (optional, but recommended)\n    print(\"Building knowledge base...\")\n\n    queries = [\n        \"How does authentication work?\",\n        \"Show me the architecture diagram\",\n        \"What's in the user guide?\",\n    ]\n\n    for query in queries:\n        print(f\"\\nQ: {query}\")\n        result = await docs_bot(query)\n        print(f\"A: {result}\\n\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#use-cases","title":"Use Cases","text":""},{"location":"tutorials/13-multimodal-rag/#1-technical-documentation","title":"1. Technical Documentation","text":"<pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./docs\"))\nasync def tech_support(question: str, rag) -&gt; str:\n    '''Answer technical questions using docs, diagrams, and screenshots.\n    Question: {{ question }}'''\n    pass\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#2-meeting-notes-search","title":"2. Meeting Notes Search","text":"<pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./meetings\"))\nasync def meeting_search(topic: str, rag) -&gt; str:\n    '''Search meeting recordings and notes for: {{ topic }}\n    Include timestamps and speakers.'''\n    pass\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#3-design-system-assistant","title":"3. Design System Assistant","text":"<pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./design_system\"))\nasync def design_helper(component: str, rag) -&gt; str:\n    '''Find design specs and screenshots for: {{ component }}'''\n    pass\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#performance-tips","title":"Performance Tips","text":""},{"location":"tutorials/13-multimodal-rag/#1-cache-sizing","title":"1. Cache Sizing","text":"<pre><code># For large projects\nrag_cache_size_mb=500  # 500MB cache\n\n# For small projects\nrag_cache_size_mb=50   # 50MB cache\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#2-concurrency-control","title":"2. Concurrency Control","text":"<pre><code># Build index with controlled concurrency\nawait rag.build_index(max_concurrent=5)  # Process 5 files at once\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#3-incremental-updates","title":"3. Incremental Updates","text":"<pre><code># Instead of full rebuild\nawait rag.build_index(force_rebuild=True)  # Slow\n\n# Use incremental update\nawait rag.incremental_update()             # Fast\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/13-multimodal-rag/#issue-google-api-key-not-found","title":"Issue: \"Google API key not found\"","text":"<p>Solution: Set the environment variable: <pre><code>export GOOGLE_API_KEY=\"your-key\"\n</code></pre></p>"},{"location":"tutorials/13-multimodal-rag/#issue-importerror-no-module-named-chromadb","title":"Issue: \"ImportError: No module named 'chromadb'\"","text":"<p>Solution: Install with web support (includes multimodal): <pre><code>pip install kagura-ai[web]\n</code></pre></p>"},{"location":"tutorials/13-multimodal-rag/#issue-index-build-is-slow","title":"Issue: Index build is slow","text":"<p>Solutions: 1. Reduce concurrency: <code>max_concurrent=2</code> 2. Exclude large files with <code>.kaguraignore</code> 3. Use smaller cache: <code>rag_cache_size_mb=50</code></p>"},{"location":"tutorials/13-multimodal-rag/#issue-out-of-memory","title":"Issue: Out of memory","text":"<p>Solutions: 1. Reduce cache size: <code>rag_cache_size_mb=50</code> 2. Process in batches with <code>incremental_update()</code> 3. Exclude large video files</p>"},{"location":"tutorials/13-multimodal-rag/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"tutorials/13-multimodal-rag/#1-multimodal-rag","title":"1. Multimodal RAG","text":"<p>Search and understand multiple content types: - Text, images, audio, video, PDFs - Automatic processing with Gemini API - Semantic vector search with ChromaDB</p>"},{"location":"tutorials/13-multimodal-rag/#2-agent-integration","title":"2. @agent Integration","text":"<pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./docs\"))\nasync def my_agent(query: str, rag: MultimodalRAG) -&gt; str:\n    pass\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#3-directory-scanning","title":"3. Directory Scanning","text":"<ul> <li>Recursive scanning with <code>.gitignore</code> support</li> <li>Automatic file type detection</li> <li>Parallel processing for speed</li> </ul>"},{"location":"tutorials/13-multimodal-rag/#4-caching-performance","title":"4. Caching &amp; Performance","text":"<ul> <li>File content caching (configurable size)</li> <li>Incremental updates (only new/modified files)</li> <li>Vector index persistence (no re-indexing on restart)</li> </ul>"},{"location":"tutorials/13-multimodal-rag/#next-steps","title":"Next Steps","text":"<p>Now that you understand Multimodal RAG:</p> <ol> <li>Combine with Memory - Use <code>enable_memory=True</code> for conversational RAG</li> <li>Add Tools - Combine RAG with custom tools for enhanced capabilities</li> <li>Deploy - Use RAG agents in production applications</li> </ol>"},{"location":"tutorials/13-multimodal-rag/#practice-exercises","title":"Practice Exercises","text":""},{"location":"tutorials/13-multimodal-rag/#exercise-1-image-search-agent","title":"Exercise 1: Image Search Agent","text":"<p>Create an agent that searches only images:</p> <pre><code>from kagura.loaders.file_types import FileType\n\n@agent(enable_multimodal_rag=True, rag_directory=Path(\"./images\"))\nasync def image_search(query: str, rag) -&gt; str:\n    '''Find images matching: {{ query }}\n    Use: rag.query(query, file_type=FileType.IMAGE)'''\n    pass\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#exercise-2-code-documentation","title":"Exercise 2: Code Documentation","text":"<p>Index a codebase and answer questions:</p> <pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./src\"))\nasync def code_qa(question: str, rag) -&gt; str:\n    '''Answer questions about the codebase: {{ question }}'''\n    pass\n\n# Test\nprint(await code_qa(\"How does the authentication module work?\"))\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#exercise-3-meeting-minutes-bot","title":"Exercise 3: Meeting Minutes Bot","text":"<p>Search meeting recordings and notes:</p> <pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./meetings\"))\nasync def meeting_bot(topic: str, rag) -&gt; str:\n    '''Summarize discussions about: {{ topic }}\n    Include meeting dates and key decisions.'''\n    pass\n</code></pre>"},{"location":"tutorials/13-multimodal-rag/#summary","title":"Summary","text":"<p>You learned: - \u2713 What Multimodal RAG is and its benefits - \u2713 How to set up content directories for indexing - \u2713 How to create RAG-enabled agents with <code>@agent</code> - \u2713 How to search across text, images, audio, video, PDFs - \u2713 Performance optimization and troubleshooting</p> <p>Continue exploring with Tutorial 14: Advanced Memory Management!</p>"},{"location":"tutorials/14-testing/","title":"Tutorial 14: Agent Testing","text":"<p>Learn how to test AI agents using Kagura's testing framework, designed to handle the non-deterministic nature of LLM outputs.</p>"},{"location":"tutorials/14-testing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed (<code>pip install kagura-ai</code>)</li> <li>pytest installed (<code>pip install pytest</code>)</li> <li>Completion of Tutorial 1: Basic Agent</li> </ul>"},{"location":"tutorials/14-testing/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand testing challenges with AI agents - Use AgentTestCase for agent testing - Write assertions for LLM behavior - Mock LLM responses for deterministic testing - Measure performance and cost</p>"},{"location":"tutorials/14-testing/#the-challenge-of-testing-ai-agents","title":"The Challenge of Testing AI Agents","text":"<p>Unlike traditional functions, AI agents are non-deterministic:</p> <pre><code># Traditional function - predictable\ndef add(a, b):\n    return a + b\n\nassert add(2, 3) == 5  # Always passes\n\n# AI agent - non-deterministic\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\nresult = await hello(\"Alice\")\n# Could be: \"Hello, Alice!\"\n# Could be: \"Hi Alice! How are you?\"\n# Could be: \"Hello there, Alice! Nice to meet you!\"\n</code></pre> <p>Solution: Test for patterns, not exact matches.</p>"},{"location":"tutorials/14-testing/#step-1-basic-test-setup","title":"Step 1: Basic Test Setup","text":"<p>Create a file called <code>test_agents.py</code>:</p> <pre><code>import pytest\nfrom kagura import agent\nfrom kagura.testing import AgentTestCase\n\n\n# Define agent to test\n@agent\nasync def greeter(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\n\n# Create test class\nclass TestGreeter(AgentTestCase):\n    agent = greeter\n\n    @pytest.mark.asyncio\n    async def test_basic_greeting(self):\n        \"\"\"Test that agent produces a greeting.\"\"\"\n        result = await self.agent(\"Alice\")\n\n        # Assert response is not empty\n        self.assert_not_empty(result)\n\n        # Assert response contains the name\n        self.assert_contains(result, \"Alice\")\n</code></pre> <p>Run the test:</p> <pre><code>pytest test_agents.py -v\n</code></pre>"},{"location":"tutorials/14-testing/#step-2-content-assertions","title":"Step 2: Content Assertions","text":"<p>AgentTestCase provides many assertion methods:</p>"},{"location":"tutorials/14-testing/#assert_contains","title":"assert_contains","text":"<pre><code>@pytest.mark.asyncio\nasync def test_contains_name(self):\n    result = await self.agent(\"Bob\")\n    self.assert_contains(result, \"Bob\")\n</code></pre>"},{"location":"tutorials/14-testing/#assert_contains_any","title":"assert_contains_any","text":"<pre><code>@pytest.mark.asyncio\nasync def test_greeting_style(self):\n    result = await self.agent(\"Charlie\")\n\n    # Accept any common greeting\n    self.assert_contains_any(result, [\n        \"Hello\",\n        \"Hi\",\n        \"Hey\",\n        \"Greetings\"\n    ])\n</code></pre>"},{"location":"tutorials/14-testing/#assert_not_contains","title":"assert_not_contains","text":"<pre><code>@pytest.mark.asyncio\nasync def test_no_profanity(self):\n    result = await self.agent(\"Test\")\n    self.assert_not_contains(result, \"bad_word\")\n</code></pre>"},{"location":"tutorials/14-testing/#assert_matches_pattern","title":"assert_matches_pattern","text":"<pre><code>@pytest.mark.asyncio\nasync def test_email_format(self):\n    @agent\n    async def email_extractor(text: str) -&gt; str:\n        '''Extract email from: {{ text }}'''\n        pass\n\n    result = await email_extractor(\"Contact: alice@example.com\")\n\n    # Use regex pattern\n    self.assert_matches_pattern(result, r'\\w+@\\w+\\.\\w+')\n</code></pre>"},{"location":"tutorials/14-testing/#step-3-language-detection","title":"Step 3: Language Detection","text":"<p>Test multilingual agents:</p> <pre><code>@agent\nasync def translator(text: str, target_lang: str) -&gt; str:\n    '''Translate \"{{ text }}\" to {{ target_lang }}'''\n    pass\n\n\nclass TestTranslator(AgentTestCase):\n    agent = translator\n\n    @pytest.mark.asyncio\n    async def test_japanese_translation(self):\n        result = await self.agent(\"Hello\", target_lang=\"Japanese\")\n\n        # Requires: pip install langdetect\n        self.assert_language(result, \"ja\")\n\n    @pytest.mark.asyncio\n    async def test_french_translation(self):\n        result = await self.agent(\"Hello\", target_lang=\"French\")\n        self.assert_language(result, \"fr\")\n</code></pre> <p>Note: Requires <code>langdetect</code>: <pre><code>pip install langdetect\n</code></pre></p>"},{"location":"tutorials/14-testing/#step-4-llm-behavior-assertions","title":"Step 4: LLM Behavior Assertions","text":"<p>Test LLM call characteristics:</p>"},{"location":"tutorials/14-testing/#assert_llm_calls","title":"assert_llm_calls","text":"<pre><code>@pytest.mark.asyncio\nasync def test_single_llm_call(self):\n    with self.record_llm_calls():\n        result = await self.agent(\"Test\")\n\n    # Assert exactly one LLM call was made\n    self.assert_llm_calls(count=1)\n\n\n@pytest.mark.asyncio\nasync def test_correct_model(self):\n    with self.record_llm_calls():\n        result = await self.agent(\"Test\")\n\n    # Assert specific model was used\n    self.assert_llm_calls(model=\"gpt-4o-mini\")\n</code></pre>"},{"location":"tutorials/14-testing/#assert_token_usage","title":"assert_token_usage","text":"<pre><code>@pytest.mark.asyncio\nasync def test_token_budget(self):\n    with self.record_llm_calls():\n        result = await self.agent(\"Test\")\n\n    # Assert token usage within limit\n    self.assert_token_usage(max_tokens=500)\n</code></pre>"},{"location":"tutorials/14-testing/#assert_tool_calls","title":"assert_tool_calls","text":"<pre><code>def search_web(query: str) -&gt; str:\n    return f\"Results for: {query}\"\n\n\n@agent(tools=[search_web])\nasync def researcher(query: str) -&gt; str:\n    '''Search for: {{ query }}'''\n    pass\n\n\nclass TestResearcher(AgentTestCase):\n    agent = researcher\n\n    @pytest.mark.asyncio\n    async def test_uses_search_tool(self):\n        result = await self.agent(\"Python tutorials\")\n\n        # Assert search tool was called\n        self.assert_tool_calls([\"search_web\"])\n</code></pre>"},{"location":"tutorials/14-testing/#step-5-performance-testing","title":"Step 5: Performance Testing","text":""},{"location":"tutorials/14-testing/#test-execution-duration","title":"Test Execution Duration","text":"<pre><code>@pytest.mark.asyncio\nasync def test_response_time(self):\n    with self.measure_time() as timer:\n        result = await self.agent(\"Test\")\n\n    # Assert response within 5 seconds\n    self.assert_duration(5.0)\n</code></pre>"},{"location":"tutorials/14-testing/#test-cost-budget","title":"Test Cost Budget","text":"<pre><code>@pytest.mark.asyncio\nasync def test_cost_budget(self):\n    with self.record_llm_calls():\n        result = await self.agent(\"Test\")\n\n    # Assert cost under $0.01\n    self.assert_cost(0.01)\n</code></pre>"},{"location":"tutorials/14-testing/#step-6-mocking-llm-responses","title":"Step 6: Mocking LLM Responses","text":"<p>For fast, deterministic testing, mock LLM responses:</p> <pre><code>@pytest.mark.asyncio\nasync def test_with_mock_llm(self):\n    with self.mock_llm(\"Mocked response\"):\n        result = await self.agent(\"Test\")\n\n    # Now we can assert exact match\n    assert result == \"Mocked response\"\n</code></pre>"},{"location":"tutorials/14-testing/#use-case-test-error-handling","title":"Use Case: Test Error Handling","text":"<pre><code>@agent\nasync def safe_agent(query: str) -&gt; str:\n    '''Process: {{ query }}'''\n    pass\n\n\nclass TestSafeAgent(AgentTestCase):\n    agent = safe_agent\n\n    @pytest.mark.asyncio\n    async def test_handles_empty_response(self):\n        with self.mock_llm(\"\"):\n            result = await self.agent(\"Test\")\n\n            # Agent should handle empty response gracefully\n            # (Implementation-dependent)\n</code></pre>"},{"location":"tutorials/14-testing/#step-7-structured-output-testing","title":"Step 7: Structured Output Testing","text":"<p>Test agents that return Pydantic models:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    '''Extract person info from: {{ text }}'''\n    pass\n\n\nclass TestPersonExtractor(AgentTestCase):\n    agent = extract_person\n\n    @pytest.mark.asyncio\n    async def test_extracts_person(self):\n        result = await self.agent(\n            \"Alice is 30 years old and works as a software engineer\"\n        )\n\n        # Assert result is valid Person model\n        self.assert_valid_model(result, Person)\n\n        # Assert specific field values\n        self.assert_field_value(result, \"name\", \"Alice\")\n        self.assert_field_value(result, \"age\", 30)\n        self.assert_field_value(result, \"occupation\", \"software engineer\")\n</code></pre>"},{"location":"tutorials/14-testing/#step-8-mocking-tools","title":"Step 8: Mocking Tools","text":"<p>Test agents with tools without executing real tools:</p> <pre><code>def expensive_api_call(query: str) -&gt; dict:\n    \"\"\"Simulate expensive API call.\"\"\"\n    # Real implementation would call external API\n    pass\n\n\n@agent(tools=[expensive_api_call])\nasync def api_agent(query: str) -&gt; str:\n    '''Query API: {{ query }}'''\n    pass\n\n\nclass TestAPIAgent(AgentTestCase):\n    agent = api_agent\n\n    @pytest.mark.asyncio\n    async def test_with_mocked_tool(self):\n        mock_data = {\"result\": \"mocked data\"}\n\n        with self.mock_tool(\"expensive_api_call\", return_value=mock_data):\n            result = await self.agent(\"test query\")\n\n            # Agent receives mocked data instead of real API call\n            self.assert_not_empty(result)\n</code></pre>"},{"location":"tutorials/14-testing/#complete-example-comprehensive-test-suite","title":"Complete Example: Comprehensive Test Suite","text":"<pre><code>import pytest\nfrom pydantic import BaseModel\nfrom kagura import agent\nfrom kagura.testing import AgentTestCase\n\n\n# Agent definition\n@agent(model=\"gpt-4o-mini\", temperature=0.7)\nasync def sentiment_analyzer(text: str) -&gt; str:\n    '''Analyze sentiment (positive/negative/neutral) of: {{ text }}'''\n    pass\n\n\n# Test suite\nclass TestSentimentAnalyzer(AgentTestCase):\n    agent = sentiment_analyzer\n\n    @pytest.mark.asyncio\n    async def test_positive_sentiment(self):\n        \"\"\"Test positive sentiment detection.\"\"\"\n        result = await self.agent(\"I love this product!\")\n\n        self.assert_not_empty(result)\n        self.assert_contains_any(result, [\"positive\", \"Positive\"])\n\n    @pytest.mark.asyncio\n    async def test_negative_sentiment(self):\n        \"\"\"Test negative sentiment detection.\"\"\"\n        result = await self.agent(\"This is terrible.\")\n\n        self.assert_not_empty(result)\n        self.assert_contains_any(result, [\"negative\", \"Negative\"])\n\n    @pytest.mark.asyncio\n    async def test_neutral_sentiment(self):\n        \"\"\"Test neutral sentiment detection.\"\"\"\n        result = await self.agent(\"It's okay.\")\n\n        self.assert_not_empty(result)\n        self.assert_contains_any(result, [\"neutral\", \"Neutral\"])\n\n    @pytest.mark.asyncio\n    async def test_uses_correct_model(self):\n        \"\"\"Test correct model is used.\"\"\"\n        with self.record_llm_calls():\n            result = await self.agent(\"Test\")\n\n        self.assert_llm_calls(count=1, model=\"gpt-4o-mini\")\n\n    @pytest.mark.asyncio\n    async def test_performance(self):\n        \"\"\"Test response time.\"\"\"\n        with self.measure_time():\n            result = await self.agent(\"Test\")\n\n        self.assert_duration(5.0)\n\n    @pytest.mark.asyncio\n    async def test_token_efficiency(self):\n        \"\"\"Test token usage.\"\"\"\n        with self.record_llm_calls():\n            result = await self.agent(\"Test\")\n\n        self.assert_token_usage(max_tokens=200)\n\n    @pytest.mark.asyncio\n    async def test_deterministic_with_mock(self):\n        \"\"\"Test with mocked LLM response.\"\"\"\n        with self.mock_llm(\"Positive sentiment detected\"):\n            result = await self.agent(\"Test\")\n\n        assert result == \"Positive sentiment detected\"\n</code></pre> <p>Run the suite:</p> <pre><code>pytest test_agents.py -v\n</code></pre>"},{"location":"tutorials/14-testing/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/14-testing/#1-test-patterns-not-exact-text","title":"1. Test Patterns, Not Exact Text","text":"<pre><code># Good\nself.assert_contains_any(result, [\"hello\", \"hi\", \"greetings\"])\n\n# Bad\nassert result == \"Hello, World!\"  # Too brittle\n</code></pre>"},{"location":"tutorials/14-testing/#2-use-mocks-for-fast-tests","title":"2. Use Mocks for Fast Tests","text":"<pre><code># Fast (mocked)\nwith self.mock_llm(\"Mocked\"):\n    result = await self.agent(\"Test\")\n\n# Slow (real LLM call)\nresult = await self.agent(\"Test\")\n</code></pre>"},{"location":"tutorials/14-testing/#3-test-edge-cases","title":"3. Test Edge Cases","text":"<pre><code>@pytest.mark.asyncio\nasync def test_empty_input(self):\n    result = await self.agent(\"\")\n    # Handle edge case\n\n@pytest.mark.asyncio\nasync def test_very_long_input(self):\n    long_text = \"word \" * 1000\n    result = await self.agent(long_text)\n    # Handle long input\n</code></pre>"},{"location":"tutorials/14-testing/#4-parametrize-tests","title":"4. Parametrize Tests","text":"<pre><code>@pytest.mark.asyncio\n@pytest.mark.parametrize(\"text,expected\", [\n    (\"I love it\", \"positive\"),\n    (\"I hate it\", \"negative\"),\n    (\"It's okay\", \"neutral\"),\n])\nasync def test_sentiment(self, text, expected):\n    result = await self.agent(text)\n    self.assert_contains(result.lower(), expected)\n</code></pre>"},{"location":"tutorials/14-testing/#common-testing-patterns","title":"Common Testing Patterns","text":""},{"location":"tutorials/14-testing/#pattern-1-golden-test","title":"Pattern 1: Golden Test","text":"<p>Store expected output and compare:</p> <pre><code>@pytest.mark.asyncio\nasync def test_golden_output(self):\n    with self.mock_llm(\"Expected output\"):\n        result = await self.agent(\"Test\")\n\n    # Load golden output from file\n    with open(\"golden_output.txt\") as f:\n        expected = f.read()\n\n    assert result == expected\n</code></pre>"},{"location":"tutorials/14-testing/#pattern-2-regression-test","title":"Pattern 2: Regression Test","text":"<p>Ensure behavior doesn't change:</p> <pre><code>@pytest.mark.asyncio\nasync def test_no_regression(self):\n    # Use fixed mock to ensure consistent behavior\n    with self.mock_llm(\"Previous version output\"):\n        result = await self.agent(\"Test\")\n\n    # Test should always pass\n    self.assert_not_empty(result)\n</code></pre>"},{"location":"tutorials/14-testing/#pattern-3-integration-test","title":"Pattern 3: Integration Test","text":"<p>Test multiple agents together:</p> <pre><code>@pytest.mark.asyncio\nasync def test_agent_pipeline(self):\n    @agent\n    async def analyzer(text: str) -&gt; str:\n        '''Analyze: {{ text }}'''\n        pass\n\n    @agent\n    async def summarizer(text: str) -&gt; str:\n        '''Summarize: {{ text }}'''\n        pass\n\n    # Test pipeline\n    analysis = await analyzer(\"Long text...\")\n    summary = await summarizer(analysis)\n\n    self.assert_not_empty(summary)\n</code></pre>"},{"location":"tutorials/14-testing/#common-mistakes","title":"Common Mistakes","text":""},{"location":"tutorials/14-testing/#1-testing-exact-llm-output","title":"1. Testing Exact LLM Output","text":"<pre><code># Wrong - LLM output varies\nassert result == \"Hello, World!\"\n\n# Correct - Test pattern\nself.assert_contains(result, \"World\")\n</code></pre>"},{"location":"tutorials/14-testing/#2-not-using-mocks","title":"2. Not Using Mocks","text":"<pre><code># Slow - Real LLM calls in every test\nresult = await self.agent(\"Test\")\n\n# Fast - Mocked responses\nwith self.mock_llm(\"Mocked\"):\n    result = await self.agent(\"Test\")\n</code></pre>"},{"location":"tutorials/14-testing/#3-missing-pytestmarkasyncio","title":"3. Missing @pytest.mark.asyncio","text":"<pre><code># Wrong - Async test without decorator\nasync def test_agent(self):\n    result = await self.agent(\"Test\")\n\n# Correct\n@pytest.mark.asyncio\nasync def test_agent(self):\n    result = await self.agent(\"Test\")\n</code></pre>"},{"location":"tutorials/14-testing/#practice-exercises","title":"Practice Exercises","text":""},{"location":"tutorials/14-testing/#exercise-1-test-translation-agent","title":"Exercise 1: Test Translation Agent","text":"<p>Create tests for a translation agent:</p> <pre><code>@agent\nasync def translator(text: str, target_lang: str) -&gt; str:\n    '''Translate to {{ target_lang }}: {{ text }}'''\n    pass\n\n# Your tests here:\nclass TestTranslator(AgentTestCase):\n    agent = translator\n\n    # TODO: Test Japanese translation\n    # TODO: Test French translation\n    # TODO: Test empty input\n    # TODO: Test performance\n</code></pre>"},{"location":"tutorials/14-testing/#exercise-2-test-with-multiple-assertions","title":"Exercise 2: Test with Multiple Assertions","text":"<p>Create a comprehensive test with multiple assertions:</p> <pre><code>@pytest.mark.asyncio\nasync def test_comprehensive(self):\n    with self.record_llm_calls():\n        with self.measure_time():\n            result = await self.agent(\"Test\")\n\n    # TODO: Add multiple assertions\n    # - Not empty\n    # - Contains specific text\n    # - LLM call count\n    # - Duration\n    # - Token usage\n</code></pre>"},{"location":"tutorials/14-testing/#exercise-3-mock-tool-testing","title":"Exercise 3: Mock Tool Testing","text":"<p>Test an agent with tools:</p> <pre><code>def calculator(expr: str) -&gt; float:\n    return eval(expr)\n\n@agent(tools=[calculator])\nasync def math_agent(question: str) -&gt; str:\n    '''Answer: {{ question }}'''\n    pass\n\n# TODO: Create tests with mocked calculator\n</code></pre>"},{"location":"tutorials/14-testing/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"tutorials/14-testing/#1-non-deterministic-testing","title":"1. Non-Deterministic Testing","text":"<p>Test patterns, not exact matches: <pre><code>self.assert_contains_any(result, [\"option1\", \"option2\"])\n</code></pre></p>"},{"location":"tutorials/14-testing/#2-llm-behavior-assertions","title":"2. LLM Behavior Assertions","text":"<p>Assert on LLM characteristics: <pre><code>self.assert_llm_calls(count=1, model=\"gpt-4o-mini\")\nself.assert_token_usage(max_tokens=500)\n</code></pre></p>"},{"location":"tutorials/14-testing/#3-mocking-for-determinism","title":"3. Mocking for Determinism","text":"<p>Use mocks for fast, predictable tests: <pre><code>with self.mock_llm(\"Fixed output\"):\n    result = await self.agent(\"Test\")\n</code></pre></p>"},{"location":"tutorials/14-testing/#4-performance-testing","title":"4. Performance Testing","text":"<p>Measure duration and cost: <pre><code>self.assert_duration(5.0)\nself.assert_cost(0.01)\n</code></pre></p>"},{"location":"tutorials/14-testing/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial 15: Observability - Monitor agent performance</li> <li>API Reference: Testing - Complete testing API</li> <li>Tutorial 13: Agent Builder - Build complex agents</li> </ul>"},{"location":"tutorials/14-testing/#summary","title":"Summary","text":"<p>You learned: - \u2713 How to test non-deterministic AI agents - \u2713 How to use AgentTestCase assertions - \u2713 How to mock LLM responses and tools - \u2713 How to test performance and cost - \u2713 How to test structured outputs</p> <p>Continue to Tutorial 15: Observability to learn agent monitoring!</p>"},{"location":"tutorials/15-observability/","title":"Tutorial 15: Observability &amp; Monitoring","text":"<p>Learn how to monitor agent execution telemetry, track performance, analyze costs, and debug issues using Kagura's observability tools.</p>"},{"location":"tutorials/15-observability/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed (<code>pip install kagura-ai</code>)</li> <li>Completion of Tutorial 1: Basic Agent</li> <li>Rich library (included with Kagura)</li> </ul>"},{"location":"tutorials/15-observability/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand agent telemetry and observability - Use the monitor CLI for live tracking - Analyze execution history and traces - Track performance metrics and costs - Build custom monitoring dashboards</p>"},{"location":"tutorials/15-observability/#what-is-observability","title":"What is Observability?","text":"<p>Observability means understanding what your agents are doing: - When did they run? - How long did they take? - What did they call (LLM, tools)? - How much did they cost? - Did they succeed or fail?</p> <p>Kagura automatically tracks telemetry for all agent executions.</p>"},{"location":"tutorials/15-observability/#step-1-enable-telemetry","title":"Step 1: Enable Telemetry","text":"<p>Telemetry is enabled by default. All agent executions are automatically recorded to:</p> <pre><code>~/.kagura/telemetry.db\n</code></pre> <p>No configuration needed!</p>"},{"location":"tutorials/15-observability/#step-2-live-monitoring","title":"Step 2: Live Monitoring","text":"<p>The simplest way to monitor agents is the <code>kagura monitor</code> command:</p> <pre><code># Start live monitoring\nkagura monitor\n</code></pre> <p>Output: <pre><code>\ud83d\udcca Kagura Agent Monitor\nTotal: 42 | Completed: 40 | Failed: 2\n\n\u250c\u2500 Recent Activity \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Time     Agent         Status      Duration  Cost     \u2502\n\u2502 14:32:15 translator    \u2713 COMPLETED 0.52s    $0.0003  \u2502\n\u2502 14:31:58 chatbot       \u2713 COMPLETED 1.23s    $0.0012  \u2502\n\u2502 14:30:41 researcher    \u2717 FAILED    2.11s    $0.0008  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"tutorials/15-observability/#monitor-specific-agent","title":"Monitor Specific Agent","text":"<pre><code># Monitor only \"translator\" agent\nkagura monitor --agent translator\n</code></pre>"},{"location":"tutorials/15-observability/#custom-refresh-rate","title":"Custom Refresh Rate","text":"<pre><code># Update every 2 seconds\nkagura monitor --refresh 2.0\n</code></pre>"},{"location":"tutorials/15-observability/#step-3-execution-history","title":"Step 3: Execution History","text":"<p>View past executions:</p> <pre><code># List recent executions\nkagura monitor list\n\n# Filter by agent\nkagura monitor list --agent my_agent\n\n# Filter by status (completed/failed)\nkagura monitor list --status failed\n\n# Limit results\nkagura monitor list --limit 50\n</code></pre> <p>Output: <pre><code>\u250c\u2500 Execution History \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Time     Agent         Status      Duration  Cost     \u2502\n\u2502 14:32:15 translator    \u2713 COMPLETED 0.52s    $0.0003  \u2502\n\u2502 14:31:58 chatbot       \u2713 COMPLETED 1.23s    $0.0012  \u2502\n\u2502 14:30:41 researcher    \u2717 FAILED    2.11s    $0.0008  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"tutorials/15-observability/#step-4-statistics","title":"Step 4: Statistics","text":"<p>Get aggregate statistics:</p> <pre><code># Overall statistics\nkagura monitor stats\n\n# Agent-specific stats\nkagura monitor stats --agent translator\n</code></pre> <p>Output: <pre><code>\ud83d\udcca Summary Statistics\n\nTotal Executions: 42\n  \u2022 Completed: 40\n  \u2022 Failed: 2\nAvg Duration: 1.34s\nTotal Cost: $0.0512\nTotal Tokens: 12,450\nLLM Calls: 45\nTool Calls: 12\n\nSuccess Rate: 95.2%\n</code></pre></p>"},{"location":"tutorials/15-observability/#step-5-detailed-traces","title":"Step 5: Detailed Traces","text":"<p>View detailed execution traces:</p> <pre><code># Get execution ID from list\nkagura monitor list\n\n# View detailed trace\nkagura monitor trace exec_abc123\n</code></pre> <p>Output: <pre><code>\ud83d\udccd Execution Trace: translator (exec_abc123)\n\nExecution Info\n\u251c\u2500\u2500 Started: 14:32:15\n\u251c\u2500\u2500 Status: \u2713 COMPLETED\n\u251c\u2500\u2500 Duration: 0.52s\n\nMetrics\n\u251c\u2500\u2500 total_cost: $0.0003\n\u251c\u2500\u2500 total_tokens: 85\n\u251c\u2500\u2500 llm_calls: 1\n\u2514\u2500\u2500 tool_calls: 0\n\nEvents Timeline (3 events)\n\u251c\u2500\u2500 [0.00s] LLM Call (gpt-4o-mini) - 85 tokens, $0.0003, 0.48s\n\u251c\u2500\u2500 [0.48s] Memory Op (store) - 0.02s\n\u2514\u2500\u2500 [0.50s] Completion\n</code></pre></p>"},{"location":"tutorials/15-observability/#step-6-cost-analysis","title":"Step 6: Cost Analysis","text":"<p>Track costs across agents:</p> <pre><code># Cost by agent\nkagura monitor cost\n\n# Cost by date\nkagura monitor cost --group-by date\n</code></pre> <p>Output (by agent): <pre><code>\u250c\u2500 Cost by Agent \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Agent          Calls  Tokens    Cost     \u2502\n\u2502 translator     23     5,123     $0.0234  \u2502\n\u2502 chatbot        15     4,892     $0.0189  \u2502\n\u2502 researcher     4      2,435     $0.0089  \u2502\n\u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502 Total          42     12,450    $0.0512  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nEstimated monthly cost: $1.54\n</code></pre></p>"},{"location":"tutorials/15-observability/#step-7-programmatic-access","title":"Step 7: Programmatic Access","text":"<p>Use EventStore and Dashboard in your Python code:</p> <pre><code>from pathlib import Path\nfrom kagura.observability import EventStore, Dashboard\n\n# Load event store\nstore = EventStore(Path.home() / \".kagura\" / \"telemetry.db\")\n\n# Get recent executions\nexecutions = store.get_executions(agent_name=\"translator\", limit=10)\n\nfor exec in executions:\n    print(f\"{exec['agent_name']}: {exec['status']} - {exec['duration']:.2f}s\")\n\n# Get statistics\nstats = store.get_summary_stats(agent_name=\"translator\")\nprint(f\"Total: {stats['total_executions']}\")\nprint(f\"Avg Duration: {stats['avg_duration']:.2f}s\")\n</code></pre>"},{"location":"tutorials/15-observability/#step-8-custom-dashboard","title":"Step 8: Custom Dashboard","text":"<p>Create a custom monitoring dashboard:</p> <pre><code>from kagura.observability import EventStore, Dashboard\n\n# Initialize\nstore = EventStore()\ndashboard = Dashboard(store)\n\n# Show live dashboard (refreshes every 1 second)\ndashboard.show_live(agent_name=\"my_agent\", refresh_rate=1.0)\n\n# Show execution list\ndashboard.show_list(agent_name=\"my_agent\", limit=20)\n\n# Show statistics\ndashboard.show_stats(agent_name=\"my_agent\")\n\n# Show specific trace\ndashboard.show_trace(execution_id=\"exec_abc123\")\n\n# Show cost summary\ndashboard.show_cost_summary(group_by=\"agent\")\n</code></pre>"},{"location":"tutorials/15-observability/#step-9-filtering-and-querying","title":"Step 9: Filtering and Querying","text":"<p>Filter executions programmatically:</p> <pre><code>import time\nfrom kagura.observability import EventStore\n\nstore = EventStore()\n\n# Get executions from last 24 hours\nsince = time.time() - 86400  # 24 hours ago\nrecent = store.get_executions(since=since)\n\n# Get failed executions only\nfailed = store.get_executions(status=\"failed\")\n\n# Get specific agent's executions\nagent_execs = store.get_executions(agent_name=\"translator\", limit=50)\n\n# Get single execution\nexecution = store.get_execution(\"exec_abc123\")\nif execution:\n    print(f\"Duration: {execution['duration']:.2f}s\")\n    print(f\"Status: {execution['status']}\")\n    print(f\"Error: {execution.get('error')}\")\n</code></pre>"},{"location":"tutorials/15-observability/#step-10-cleanup-old-data","title":"Step 10: Cleanup Old Data","text":"<p>Manage telemetry database size:</p> <pre><code>import time\nfrom kagura.observability import EventStore\n\nstore = EventStore()\n\n# Delete executions older than 30 days\nthirty_days_ago = time.time() - (30 * 86400)\ndeleted = store.delete_old_executions(older_than=thirty_days_ago)\nprint(f\"Deleted {deleted} old executions\")\n\n# Clear all data (use with caution!)\n# store.clear_all()\n</code></pre>"},{"location":"tutorials/15-observability/#complete-example-monitoring-integration","title":"Complete Example: Monitoring Integration","text":"<pre><code>import asyncio\nfrom kagura import agent\nfrom kagura.observability import EventStore, Dashboard\n\n\n@agent(model=\"gpt-4o-mini\")\nasync def translator(text: str, target_lang: str) -&gt; str:\n    '''Translate \"{{ text }}\" to {{ target_lang }}'''\n    pass\n\n\nasync def main():\n    # Run agent multiple times\n    translations = [\n        (\"Hello\", \"French\"),\n        (\"Goodbye\", \"Japanese\"),\n        (\"Thank you\", \"Spanish\"),\n    ]\n\n    for text, lang in translations:\n        result = await translator(text, target_lang=lang)\n        print(f\"{text} \u2192 {lang}: {result}\")\n\n    # Analyze telemetry\n    store = EventStore()\n    dashboard = Dashboard(store)\n\n    print(\"\\n\" + \"=\" * 50)\n    print(\"TELEMETRY ANALYSIS\")\n    print(\"=\" * 50 + \"\\n\")\n\n    # Show statistics\n    dashboard.show_stats(agent_name=\"translator\")\n\n    # Show execution list\n    dashboard.show_list(agent_name=\"translator\", limit=10)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"tutorials/15-observability/#use-cases","title":"Use Cases","text":""},{"location":"tutorials/15-observability/#use-case-1-performance-monitoring","title":"Use Case 1: Performance Monitoring","text":"<p>Track agent performance over time:</p> <pre><code>store = EventStore()\n\n# Get last 100 executions\nexecutions = store.get_executions(limit=100)\n\n# Calculate average duration per agent\nfrom collections import defaultdict\n\nagent_durations = defaultdict(list)\nfor exec in executions:\n    agent_durations[exec['agent_name']].append(exec['duration'])\n\nfor agent, durations in agent_durations.items():\n    avg = sum(durations) / len(durations)\n    print(f\"{agent}: {avg:.2f}s average\")\n</code></pre>"},{"location":"tutorials/15-observability/#use-case-2-cost-budget-alerts","title":"Use Case 2: Cost Budget Alerts","text":"<p>Monitor costs and alert when budget exceeded:</p> <pre><code>store = EventStore()\n\n# Get today's executions\nimport time\ntoday_start = time.time() - 86400\nexecutions = store.get_executions(since=today_start)\n\n# Calculate total cost\ntotal_cost = sum(\n    exec.get('metrics', {}).get('total_cost', 0.0)\n    for exec in executions\n)\n\n# Alert if over budget\nDAILY_BUDGET = 1.0  # $1.00\nif total_cost &gt; DAILY_BUDGET:\n    print(f\"\u26a0\ufe0f  ALERT: Daily cost ${total_cost:.2f} exceeds budget ${DAILY_BUDGET:.2f}\")\nelse:\n    print(f\"\u2713 Cost ${total_cost:.2f} within budget ${DAILY_BUDGET:.2f}\")\n</code></pre>"},{"location":"tutorials/15-observability/#use-case-3-error-tracking","title":"Use Case 3: Error Tracking","text":"<p>Track and analyze failures:</p> <pre><code>store = EventStore()\n\n# Get all failed executions\nfailed = store.get_executions(status=\"failed\", limit=100)\n\n# Group by error type\nfrom collections import Counter\n\nerror_types = Counter(\n    exec.get('error', 'Unknown error')\n    for exec in failed\n)\n\nprint(\"Top 5 Error Types:\")\nfor error, count in error_types.most_common(5):\n    print(f\"  {count}x: {error}\")\n</code></pre>"},{"location":"tutorials/15-observability/#use-case-4-custom-metrics-dashboard","title":"Use Case 4: Custom Metrics Dashboard","text":"<p>Build a real-time metrics dashboard:</p> <pre><code>import time\nfrom rich.console import Console\nfrom rich.table import Table\nfrom kagura.observability import EventStore\n\ndef show_realtime_metrics():\n    \"\"\"Display real-time metrics dashboard.\"\"\"\n    store = EventStore()\n    console = Console()\n\n    while True:\n        # Get recent executions\n        recent = store.get_executions(limit=50)\n\n        # Calculate metrics\n        total = len(recent)\n        completed = sum(1 for e in recent if e['status'] == 'completed')\n        failed = total - completed\n        avg_duration = sum(e['duration'] for e in recent) / total if total &gt; 0 else 0\n\n        # Create table\n        table = Table(title=\"Real-Time Metrics\")\n        table.add_column(\"Metric\", style=\"cyan\")\n        table.add_column(\"Value\", style=\"white\")\n\n        table.add_row(\"Total Executions\", str(total))\n        table.add_row(\"Completed\", str(completed))\n        table.add_row(\"Failed\", str(failed))\n        table.add_row(\"Avg Duration\", f\"{avg_duration:.2f}s\")\n\n        # Display\n        console.clear()\n        console.print(table)\n\n        time.sleep(2)  # Refresh every 2 seconds\n\n# show_realtime_metrics()\n</code></pre>"},{"location":"tutorials/15-observability/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/15-observability/#1-regular-monitoring","title":"1. Regular Monitoring","text":"<p>Check your agents regularly:</p> <pre><code># Daily health check\nkagura monitor stats\n\n# Weekly cost review\nkagura monitor cost\n</code></pre>"},{"location":"tutorials/15-observability/#2-set-up-alerts","title":"2. Set Up Alerts","text":"<p>Create scripts to alert on issues:</p> <pre><code>#!/bin/bash\n# daily_check.sh\n\n# Check for failed executions\nfailed_count=$(kagura monitor stats | grep \"Failed:\" | awk '{print $3}')\n\nif [ \"$failed_count\" -gt 10 ]; then\n  echo \"\u26a0\ufe0f  Alert: $failed_count failed executions\"\n  # Send notification (email, Slack, etc.)\nfi\n</code></pre>"},{"location":"tutorials/15-observability/#3-cost-tracking","title":"3. Cost Tracking","text":"<p>Track costs by project:</p> <pre><code># Tag agents by project\n@agent(model=\"gpt-4o-mini\")\nasync def project_a_agent(query: str) -&gt; str:\n    '''...'''\n    pass\n\n# Query costs by agent name prefix\nproject_a_execs = store.get_executions(agent_name=\"project_a_\")\n</code></pre>"},{"location":"tutorials/15-observability/#4-performance-baselines","title":"4. Performance Baselines","text":"<p>Establish performance baselines:</p> <pre><code># Record baseline\nbaseline_duration = 2.0  # seconds\n\n# Check if performance degraded\nrecent = store.get_executions(agent_name=\"my_agent\", limit=10)\navg_recent = sum(e['duration'] for e in recent) / len(recent)\n\nif avg_recent &gt; baseline_duration * 1.5:\n    print(f\"\u26a0\ufe0f  Performance degraded: {avg_recent:.2f}s (baseline: {baseline_duration:.2f}s)\")\n</code></pre>"},{"location":"tutorials/15-observability/#common-monitoring-patterns","title":"Common Monitoring Patterns","text":""},{"location":"tutorials/15-observability/#pattern-1-health-check","title":"Pattern 1: Health Check","text":"<pre><code>def health_check(agent_name: str) -&gt; dict:\n    \"\"\"Check agent health.\"\"\"\n    store = EventStore()\n    recent = store.get_executions(agent_name=agent_name, limit=20)\n\n    if not recent:\n        return {\"status\": \"unknown\", \"reason\": \"no executions\"}\n\n    failed = sum(1 for e in recent if e['status'] == 'failed')\n    failure_rate = failed / len(recent)\n\n    if failure_rate &gt; 0.5:\n        return {\"status\": \"unhealthy\", \"failure_rate\": failure_rate}\n    elif failure_rate &gt; 0.2:\n        return {\"status\": \"degraded\", \"failure_rate\": failure_rate}\n    else:\n        return {\"status\": \"healthy\", \"failure_rate\": failure_rate}\n</code></pre>"},{"location":"tutorials/15-observability/#pattern-2-performance-regression-detection","title":"Pattern 2: Performance Regression Detection","text":"<pre><code>def detect_regression(agent_name: str, threshold: float = 1.5) -&gt; bool:\n    \"\"\"Detect performance regression.\"\"\"\n    store = EventStore()\n\n    # Get baseline (last 100 executions)\n    baseline = store.get_executions(agent_name=agent_name, limit=100)\n    baseline_avg = sum(e['duration'] for e in baseline) / len(baseline)\n\n    # Get recent (last 10 executions)\n    recent = store.get_executions(agent_name=agent_name, limit=10)\n    recent_avg = sum(e['duration'] for e in recent) / len(recent)\n\n    # Check if recent is significantly slower\n    return recent_avg &gt; baseline_avg * threshold\n</code></pre>"},{"location":"tutorials/15-observability/#pattern-3-cost-tracking","title":"Pattern 3: Cost Tracking","text":"<pre><code>def get_cost_breakdown(since: float) -&gt; dict:\n    \"\"\"Get cost breakdown by agent.\"\"\"\n    store = EventStore()\n    executions = store.get_executions(since=since, limit=10000)\n\n    breakdown = {}\n    for exec in executions:\n        agent = exec['agent_name']\n        cost = exec.get('metrics', {}).get('total_cost', 0.0)\n\n        if agent not in breakdown:\n            breakdown[agent] = {\"cost\": 0.0, \"calls\": 0}\n\n        breakdown[agent][\"cost\"] += cost\n        breakdown[agent][\"calls\"] += 1\n\n    return breakdown\n</code></pre>"},{"location":"tutorials/15-observability/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/15-observability/#issue-no-telemetry-data","title":"Issue: No telemetry data","text":"<p>Solution: Check database location: <pre><code>ls ~/.kagura/telemetry.db\n</code></pre></p> <p>If missing, run an agent to initialize it.</p>"},{"location":"tutorials/15-observability/#issue-old-data-filling-disk","title":"Issue: Old data filling disk","text":"<p>Solution: Regularly clean old data: <pre><code>import time\nfrom kagura.observability import EventStore\n\nstore = EventStore()\nthirty_days_ago = time.time() - (30 * 86400)\nstore.delete_old_executions(older_than=thirty_days_ago)\n</code></pre></p>"},{"location":"tutorials/15-observability/#issue-slow-queries","title":"Issue: Slow queries","text":"<p>Solution: Use indexes and filters: <pre><code># Efficient - uses indexes\nstore.get_executions(agent_name=\"my_agent\", limit=100)\n\n# Less efficient - scans all data\nall_execs = store.get_executions(limit=100000)\n</code></pre></p>"},{"location":"tutorials/15-observability/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"tutorials/15-observability/#1-automatic-telemetry","title":"1. Automatic Telemetry","text":"<p>All executions are tracked automatically: <pre><code># Just use agents - telemetry is automatic\nresult = await my_agent(\"query\")\n</code></pre></p>"},{"location":"tutorials/15-observability/#2-cli-monitoring","title":"2. CLI Monitoring","text":"<p>Quick monitoring via CLI: <pre><code>kagura monitor        # Live view\nkagura monitor list   # History\nkagura monitor stats  # Statistics\nkagura monitor trace  # Detailed trace\n</code></pre></p>"},{"location":"tutorials/15-observability/#3-programmatic-access","title":"3. Programmatic Access","text":"<p>Build custom monitoring: <pre><code>store = EventStore()\nexecutions = store.get_executions(...)\n</code></pre></p>"},{"location":"tutorials/15-observability/#4-cost-tracking","title":"4. Cost Tracking","text":"<p>Monitor spending: <pre><code>kagura monitor cost\n</code></pre></p>"},{"location":"tutorials/15-observability/#next-steps","title":"Next Steps","text":"<ul> <li>API Reference: Observability - Complete observability API</li> <li>Tutorial 13: Agent Builder - Build advanced agents</li> <li>Tutorial 14: Testing - Test your agents</li> </ul>"},{"location":"tutorials/15-observability/#summary","title":"Summary","text":"<p>You learned: - \u2713 How to monitor agents with CLI commands - \u2713 How to access telemetry programmatically - \u2713 How to track performance and costs - \u2713 How to build custom dashboards - \u2713 Best practices for observability</p> <p>You now have the tools to monitor, debug, and optimize your AI agents!</p>"},{"location":"releases/v4.0.0/","title":"Kagura AI v4.0.0 - Universal AI Memory Platform","text":"<p>Release Date: October 29, 2025 Status: Stable Release</p>"},{"location":"releases/v4.0.0/#welcome-to-v40","title":"\ud83c\udf89 Welcome to v4.0!","text":"<p>After 4 months of development and Phase A/B/C completion, we're excited to announce Kagura AI v4.0.0 - a production-ready Universal AI Memory Platform that brings unified memory to Claude, ChatGPT, Gemini, and all your custom AI agents.</p> <p>Tagline: Own your memory. Bring it to every AI.</p>"},{"location":"releases/v4.0.0/#whats-new-in-v40","title":"\ud83c\udf1f What's New in v4.0","text":""},{"location":"releases/v4.0.0/#phase-a-mcp-first-foundation","title":"\ud83c\udfd7\ufe0f Phase A: MCP-First Foundation \u2705","text":"<p>REST API (FastAPI + OpenAPI): - Full-featured API server with automatic documentation - OpenAPI schema at <code>/docs</code> - Health checks, metrics, and observability</p> <p>34 MCP Tools (+19 from v3.0): - Memory: store, recall, search, feedback, delete - Graph: link, query, analyze - Web Search: Brave (web/news/local/video/image) - File Operations: read, write, edit, search - Shell: execute commands safely - Document: arXiv search, YouTube transcription - Monitoring: cost tracking, usage analytics</p> <p>MCP Tool Management: - <code>kagura mcp doctor</code> - Health diagnostics - <code>kagura mcp tools</code> - List available tools - <code>kagura mcp install</code> - Auto-configure Claude Desktop - <code>kagura mcp log</code> - Server log viewing</p>"},{"location":"releases/v4.0.0/#phase-b-graphmemory-user-patterns","title":"\ud83d\udd78\ufe0f Phase B: GraphMemory &amp; User Patterns \u2705","text":"<p>Knowledge Graph (NetworkX-based): - Explicit relationship tracking between memories - Multi-hop graph traversal - Centrality analysis, path finding - Topic clustering and pattern discovery</p> <p>User Pattern Analysis: - Interaction tracking across sessions - Topic frequency analysis - Temporal patterns (time-of-day, day-of-week) - Learning journey visualization</p> <p>MCP Tools for Graph: - <code>graph_link</code> - Create relationships - <code>graph_query</code> - Multi-hop traversal - <code>graph_analyze_patterns</code> - Discover user patterns</p>"},{"location":"releases/v4.0.0/#phase-c-remote-mcp-server-data-portability","title":"\ud83c\udf10 Phase C: Remote MCP Server &amp; Data Portability \u2705","text":"<p>Remote MCP Server (HTTP/SSE): - MCP over HTTP for ChatGPT support - Server-Sent Events (SSE) for real-time streaming - Compatible with any MCP-enabled platform</p> <p>API Key Authentication: - SHA256-hashed API keys - CLI management: <code>kagura api create-key</code>, <code>kagura api list-keys</code> - Fine-grained access control</p> <p>Tool Access Control: - 24/34 tools are \"remote-safe\" by default - Filesystem operations restricted to local mode - Security-first architecture</p> <p>Memory Export/Import: - JSONL format (human-readable) - Full data portability (no vendor lock-in) - CLI: <code>kagura memory export</code>, <code>kagura memory import</code> - Cross-instance migration support</p> <p>Production Docker Setup: - <code>docker-compose.prod.yml</code> with Caddy reverse proxy - HTTPS with automatic certificate management - PostgreSQL + pgvector, Redis - Production-hardened configuration</p>"},{"location":"releases/v4.0.0/#memory-accuracy-improvements-40-60","title":"\ud83c\udfaf Memory Accuracy Improvements (+40-60%)","text":"<p>Phase 1: Multilingual Embeddings: - Migrated from <code>all-MiniLM-L6-v2</code> (English-only) - To <code>multilingual-e5-large</code> (100+ languages, 1024 dims) - Result: Better semantic understanding, multilingual support</p> <p>Phase 2: Hybrid Search: - BM25 (lexical) + vector (semantic) fusion - Reciprocal Rank Fusion (RRF) for result merging - Configurable weights for precision/recall balance - Result: +20-30% precision improvement</p> <p>Phase 3: Cross-Encoder Reranking: - Two-stage retrieval: fast candidate generation \u2192 precise reranking - <code>cross-encoder/ms-marco-MiniLM-L-6-v2</code> - Multi-dimensional scoring (semantic, recency, importance, graph) - Result: +40-60% precision improvement</p> <p>Expected Total Improvement: +40-60% recall@5 precision</p>"},{"location":"releases/v4.0.0/#by-the-numbers","title":"\ud83d\udcca By the Numbers","text":"<ul> <li>34 MCP Tools (vs 15 in v3.0)</li> <li>1,451+ tests passing (90%+ coverage)</li> <li>Phase A/B/C: 100% complete</li> <li>6,100+ lines of code added</li> <li>120+ tests added in Phase C</li> <li>5 new documentation pages</li> </ul>"},{"location":"releases/v4.0.0/#key-features","title":"\ud83d\udd25 Key Features","text":""},{"location":"releases/v4.0.0/#for-individuals","title":"For Individuals","text":"<ul> <li>\ud83d\udd12 Privacy-first: Local storage or self-hosted</li> <li>\ud83e\udde0 Smart recall: Vector search + knowledge graph</li> <li>\ud83d\udcca Insights: Visualize learning patterns</li> <li>\ud83d\udeab No lock-in: Complete data export anytime</li> </ul>"},{"location":"releases/v4.0.0/#for-developers","title":"For Developers","text":"<ul> <li>\ud83d\udc0d Python SDK: Build agents with unified memory</li> <li>\ud83d\udd0c REST API: Access from any language/platform</li> <li>\ud83d\udce6 34 MCP Tools: Ready-to-use AI capabilities</li> <li>\ud83d\udee0\ufe0f Extensible: Custom connectors, tools, workflows</li> <li>\ud83c\udf10 MCP-native: Works with Claude, ChatGPT, custom agents</li> <li>\u2601\ufe0f Production-ready: Docker, API keys, full test coverage</li> </ul>"},{"location":"releases/v4.0.0/#for-teams-coming-v42","title":"For Teams (Coming v4.2)","text":"<ul> <li>\ud83d\udc65 Shared knowledge: Team-wide memory</li> <li>\ud83d\udd10 Enterprise features: SSO, BYOK, audit logs</li> <li>\ud83d\udcc8 Analytics: Track team AI usage</li> </ul>"},{"location":"releases/v4.0.0/#installation","title":"\u2699\ufe0f Installation","text":""},{"location":"releases/v4.0.0/#stable-release-v400","title":"Stable Release (v4.0.0)","text":"<pre><code>pip install kagura-ai[full]\n</code></pre>"},{"location":"releases/v4.0.0/#docker-production","title":"Docker (Production)","text":"<pre><code>git clone https://github.com/JFK/kagura-ai.git\ncd kagura-ai\ndocker compose -f docker-compose.prod.yml up -d\n</code></pre>"},{"location":"releases/v4.0.0/#mcp-with-claude-desktop","title":"MCP with Claude Desktop","text":"<pre><code>pip install kagura-ai[full]\nkagura mcp install\nkagura mcp serve\n</code></pre> <p>See: Installation Guide</p>"},{"location":"releases/v4.0.0/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"releases/v4.0.0/#example-1-store-recall-memory","title":"Example 1: Store &amp; Recall Memory","text":"<pre><code>from kagura.core.memory import MemoryManager\n\nasync def main():\n    memory = MemoryManager(user_id=\"alice\")\n\n    # Store\n    await memory.store(\n        key=\"python_tips\",\n        value=\"Always use type hints for better code quality\",\n        scope=\"persistent\",\n        tags=[\"python\", \"best-practices\"]\n    )\n\n    # Recall (semantic search)\n    results = await memory.recall(\"How to write better Python?\", top_k=5)\n    print(results)\n\nimport asyncio\nasyncio.run(main())\n</code></pre>"},{"location":"releases/v4.0.0/#example-2-knowledge-graph","title":"Example 2: Knowledge Graph","text":"<pre><code>async def main():\n    memory = MemoryManager(user_id=\"alice\", enable_graph=True)\n\n    # Create relationship\n    await memory.link(\n        src=\"python_tips\",\n        dst=\"fastapi_tutorial\",\n        rel_type=\"related_to\",\n        weight=0.8\n    )\n\n    # Multi-hop traversal\n    related = await memory.query_graph(\n        seed_ids=[\"python_tips\"],\n        hops=2\n    )\n    print(related)\n\nasyncio.run(main())\n</code></pre>"},{"location":"releases/v4.0.0/#example-3-remote-mcp-server","title":"Example 3: Remote MCP Server","text":"<pre><code># Start server\nkagura api serve --host 0.0.0.0 --port 8080\n\n# Create API key\nkagura api create-key --name \"chatgpt\"\n\n# Configure ChatGPT\n# URL: https://your-domain.com/mcp\n# Auth: Bearer &lt;api-key&gt;\n</code></pre>"},{"location":"releases/v4.0.0/#migration-from-v30","title":"\ud83d\udd04 Migration from v3.0","text":"<p>See Migration Guide for step-by-step instructions.</p> <p>Key Changes: 1. <code>user_id</code> now required in <code>MemoryManager()</code> 2. Embedding model changed (reindex required) 3. MCP tool names updated (<code>memory_save</code> \u2192 <code>memory_store</code>) 4. XDG-compliant directory structure</p> <p>Upgrade Command: <pre><code>pip install --upgrade kagura-ai[full]\nkagura config doctor\n</code></pre></p>"},{"location":"releases/v4.0.0/#resources","title":"\ud83d\udd17 Resources","text":"<ul> <li>Documentation: https://docs.kagura.ai</li> <li>GitHub: https://github.com/JFK/kagura-ai</li> <li>PyPI: https://pypi.org/project/kagura-ai/</li> <li>Changelog: CHANGELOG.md</li> <li>Roadmap: V4.0_IMPLEMENTATION_ROADMAP.md</li> </ul>"},{"location":"releases/v4.0.0/#known-issues","title":"\ud83d\udc1b Known Issues","text":"<ul> <li>Embedding model change requires reindexing (expected, see Migration Guide)</li> <li>Remote MCP server requires manual API key configuration</li> <li>Production Docker setup requires Caddy configuration for custom domains</li> </ul> <p>Report Issues: https://github.com/JFK/kagura-ai/issues</p>"},{"location":"releases/v4.0.0/#whats-next","title":"\ud83d\uddfa\ufe0f What's Next?","text":""},{"location":"releases/v4.0.0/#v410-q2-2026","title":"v4.1.0 (Q2 2026)","text":"<ul> <li>Smart Forgetting: Auto-maintenance with RecallScorer</li> <li>Auto-recall Intelligence: \"Unspoken Understanding\"</li> <li>PostgreSQL Backend: Cloud-ready GraphMemory</li> <li>Connectors: GitHub, Google Workspace</li> </ul>"},{"location":"releases/v4.0.0/#v420-q3-q4-2026","title":"v4.2.0 (Q3-Q4 2026)","text":"<ul> <li>Memory Curator: AI-driven memory management</li> <li>Cloud SaaS: Managed service</li> <li>Enterprise Features: SSO, BYOK, audit logs</li> </ul> <p>See: Roadmap for detailed plans.</p>"},{"location":"releases/v4.0.0/#acknowledgments","title":"\ud83d\ude4f Acknowledgments","text":"<p>Thanks to: - All beta testers and early adopters - Contributors who provided feedback and bug reports - The open-source community (FastAPI, ChromaDB, NetworkX, Pydantic) - Model Context Protocol (MCP) team at Anthropic</p> <p>Special thanks: - Phase A/B/C development: 4 months of intensive work - 120+ tests added in Phase C alone - Comprehensive documentation rewrite</p>"},{"location":"releases/v4.0.0/#license","title":"\ud83d\udcc4 License","text":"<p>Apache License 2.0</p> <p>You can use Kagura AI commercially, modify it, distribute it, and sublicense it.</p>"},{"location":"releases/v4.0.0/#about-kagura","title":"\ud83c\udf38 About Kagura","text":"<p>Kagura (\u795e\u697d) is traditional Japanese performing art that embodies harmony and creativity.</p> <p>Just as Kagura connects humans with the divine, Kagura AI connects you with all your AIs through a unified memory.</p> <p>Built with \u2764\ufe0f for developers who want to own their AI memory</p> <p>\ud83e\udd16 Generated with Claude Code</p> <p>Co-Authored-By: Claude noreply@anthropic.com</p>"},{"location":"ja/mcp-claude-code-setup/","title":"MCP\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u30ac\u30a4\u30c9 - Claude Code\u7d71\u5408","text":"<p>2\u5206\u3067Kagura\u3092Claude Code\u306b\u63a5\u7d9a</p> <p>\u3053\u306e\u30ac\u30a4\u30c9\u3067\u306f\u3001Model Context Protocol (MCP)\u3092\u4f7f\u7528\u3057\u3066\u3001Kagura\u306e\u30e6\u30cb\u30d0\u30fc\u30b5\u30eb\u30e1\u30e2\u30ea\u30fc\u3068Claude Code\uff08Anthropic\u516c\u5f0fCLI\uff09\u3092\u7d71\u5408\u3059\u308b\u65b9\u6cd5\u3092\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"ja/mcp-claude-code-setup/#_1","title":"\ud83d\udccb \u524d\u63d0\u6761\u4ef6","text":"<ul> <li>Kagura AI v4.0+\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308b\u3053\u3068</li> <li>Claude Code CLI\uff08Anthropic\u516c\u5f0fCLI\u30c4\u30fc\u30eb\uff09</li> </ul>"},{"location":"ja/mcp-claude-code-setup/#_2","title":"\u26a1 \u30af\u30a4\u30c3\u30af\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":""},{"location":"ja/mcp-claude-code-setup/#1-kagura","title":"\u30b9\u30c6\u30c3\u30d71: Kagura\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<pre><code># \u5168\u4f9d\u5b58\u95a2\u4fc2\u3092\u542b\u3081\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\npip install kagura-ai[full]\n\n# \u307e\u305f\u306f\u30bd\u30fc\u30b9\u304b\u3089\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\ngit clone https://github.com/JFK/kagura-ai.git\ncd kagura-ai\nuv sync --all-extras\n</code></pre>"},{"location":"ja/mcp-claude-code-setup/#2-claude-codemcp","title":"\u30b9\u30c6\u30c3\u30d72: Claude Code\u306bMCP\u30b5\u30fc\u30d0\u30fc\u3092\u8ffd\u52a0","text":"<pre><code># Kagura\u3092MCP\u30b5\u30fc\u30d0\u30fc\u3068\u3057\u3066\u8ffd\u52a0\nclaude mcp add --transport stdio kagura -- kagura mcp serve\n</code></pre> <p>\u51fa\u529b: <pre><code>Added stdio MCP server kagura with command: kagura mcp serve to local config\nFile modified: /home/user/.claude.json\n</code></pre></p>"},{"location":"ja/mcp-claude-code-setup/#3","title":"\u30b9\u30c6\u30c3\u30d73: \u63a5\u7d9a\u3092\u78ba\u8a8d","text":"<pre><code># MCP\u30b5\u30fc\u30d0\u30fc\u306e\u30b9\u30c6\u30fc\u30bf\u30b9\u3092\u78ba\u8a8d\nclaude mcp list\n</code></pre> <p>\u671f\u5f85\u3055\u308c\u308b\u51fa\u529b: <pre><code>Checking MCP server health...\n\nkagura: kagura mcp serve - \u2713 Connected\n</code></pre></p> <p>\u5b8c\u4e86\uff01 Kagura\u304cClaude Code\u306b\u63a5\u7d9a\u3055\u308c\u307e\u3057\u305f\u3002</p>"},{"location":"ja/mcp-claude-code-setup/#_3","title":"\ud83e\udde0 \u5229\u7528\u53ef\u80fd\u306a\u30c4\u30fc\u30eb","text":"<p>\u7d71\u5408\u304c\u5b8c\u4e86\u3059\u308b\u3068\u3001Claude Code\u306f\u4ee5\u4e0b\u306e\u30ab\u30c6\u30b4\u30ea\u30fc\u306b\u5206\u985e\u3055\u308c\u305f 31\u500b\u306eMCP\u30c4\u30fc\u30eb \u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u307e\u3059:</p>"},{"location":"ja/mcp-claude-code-setup/#4","title":"\u30b3\u30a2\u30e1\u30e2\u30ea\u30fc\u30c4\u30fc\u30eb (4)","text":"\u30c4\u30fc\u30eb \u76ee\u7684 \u4f7f\u7528\u4f8b <code>memory_store</code> \u60c5\u5831\u3092\u4fdd\u5b58 \"\u79c1\u306fPython\u3092\u597d\u3080\u3053\u3068\u3092\u899a\u3048\u3066\u304a\u3044\u3066\" <code>memory_recall</code> \u30ad\u30fc\u3067\u53d6\u5f97 \"\u79c1\u306ePython\u597d\u307f\u306f\u4f55\uff1f\" <code>memory_search</code> \u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u691c\u7d22 \"\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u306b\u95a2\u3059\u308b\u30e1\u30e2\u30ea\u30fc\u3092\u691c\u7d22\" <code>memory_delete</code> \u30e1\u30e2\u30ea\u30fc\u3092\u524a\u9664 \"X\u306b\u3064\u3044\u3066\u5fd8\u308c\u3066\""},{"location":"ja/mcp-claude-code-setup/#3_1","title":"\u30ca\u30ec\u30c3\u30b8\u30b0\u30e9\u30d5\u30c4\u30fc\u30eb (3)","text":"\u30c4\u30fc\u30eb \u76ee\u7684 <code>graph_add_node</code> \u6982\u5ff5\u3092\u8ffd\u52a0 <code>graph_link</code> \u30e1\u30e2\u30ea\u30fc\u3092\u63a5\u7d9a <code>graph_query</code> \u30de\u30eb\u30c1\u30db\u30c3\u30d7\u30c8\u30e9\u30d0\u30fc\u30b5\u30eb"},{"location":"ja/mcp-claude-code-setup/#6","title":"\u691c\u7d22\u30c4\u30fc\u30eb (6)","text":"\u30c4\u30fc\u30eb \u76ee\u7684 <code>search_memories</code> \u30cf\u30a4\u30d6\u30ea\u30c3\u30c9\u691c\u7d22\uff08BM25 + \u30d9\u30af\u30c8\u30eb\uff09 <code>search_brave</code> Brave API\u7d4c\u7531\u306eWeb\u691c\u7d22 <code>search_arxiv</code> \u5b66\u8853\u8ad6\u6587 ... ..."},{"location":"ja/mcp-claude-code-setup/#14","title":"\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30c4\u30fc\u30eb (14)","text":"\u30c4\u30fc\u30eb \u76ee\u7684 <code>coding_store_file_change</code> \u30d5\u30a1\u30a4\u30eb\u5909\u66f4\u3092\u8ffd\u8de1 <code>coding_store_error</code> \u30a8\u30e9\u30fc\u3092\u8a18\u9332 <code>coding_store_design_decision</code> \u8a2d\u8a08\u6c7a\u5b9a\u3092\u6587\u66f8\u5316 <code>coding_summary</code> AI\u99c6\u52d5\u306e\u30bb\u30c3\u30b7\u30e7\u30f3\u30b5\u30de\u30ea\u30fc ... ..."},{"location":"ja/mcp-claude-code-setup/#github-6","title":"GitHub\u30c4\u30fc\u30eb (6)","text":"\u30c4\u30fc\u30eb \u76ee\u7684 <code>github_shell_exec</code> \u5b89\u5168\u306a\u30b7\u30a7\u30eb\u5b9f\u884c <code>github_issue_*</code> Issue\u64cd\u4f5c <code>github_pr_*</code> PR\u7ba1\u7406 <p>\u5b8c\u5168\u306a\u30ea\u30b9\u30c8: <code>kagura mcp tools</code>\u3092\u5b9f\u884c\u3057\u3066\u3001\u516831\u30c4\u30fc\u30eb\u3092\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"ja/mcp-claude-code-setup/#_4","title":"\ud83c\udfaf \u4f7f\u7528\u4f8b","text":""},{"location":"ja/mcp-claude-code-setup/#_5","title":"\u57fa\u672c\u7684\u306a\u30e1\u30e2\u30ea\u30fc\u64cd\u4f5c","text":"<p>\u30e1\u30e2\u30ea\u30fc\u3092\u4fdd\u5b58: <pre><code>\u30e6\u30fc\u30b6\u30fc: \u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3067\u306fJavaScript\u3088\u308aPython\u3092\u597d\u3080\u3053\u3068\u3092\u899a\u3048\u3066\u304a\u3044\u3066\nClaude: [memory_store\u30c4\u30fc\u30eb\u3092\u4f7f\u7528]\n</code></pre></p> <p>\u30e1\u30e2\u30ea\u30fc\u3092\u547c\u3073\u51fa\u3057: <pre><code>\u30e6\u30fc\u30b6\u30fc: \u79c1\u304c\u597d\u3080\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u8a00\u8a9e\u306f\u4f55\uff1f\nClaude: [memory_recall/search\u3092\u4f7f\u7528\u3057\u3066\u60c5\u5831\u3092\u53d6\u5f97]\n</code></pre></p>"},{"location":"ja/mcp-claude-code-setup/#_6","title":"\u30ca\u30ec\u30c3\u30b8\u30b0\u30e9\u30d5","text":"<p>\u95a2\u9023\u3059\u308b\u30e1\u30e2\u30ea\u30fc\u3092\u30ea\u30f3\u30af: <pre><code>\u30e6\u30fc\u30b6\u30fc: \u79c1\u306ePython\u597d\u307f\u3068FastAPI\u306e\u77e5\u8b58\u3092\u63a5\u7d9a\u3057\u3066\nClaude: [graph_link\u3092\u4f7f\u7528\u3057\u3066\u95a2\u4fc2\u3092\u4f5c\u6210]\n</code></pre></p> <p>\u95a2\u9023\u3059\u308b\u6982\u5ff5\u3092\u691c\u7d22: <pre><code>\u30e6\u30fc\u30b6\u30fc: \u79c1\u306e\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u597d\u307f\u306b\u95a2\u9023\u3059\u308b\u3082\u306e\u306f\u4f55\uff1f\nClaude: [graph_query\u3092\u4f7f\u7528\u3057\u3066\u30de\u30eb\u30c1\u30db\u30c3\u30d7\u30c8\u30e9\u30d0\u30fc\u30b5\u30eb]\n</code></pre></p>"},{"location":"ja/mcp-claude-code-setup/#_7","title":"\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30bb\u30c3\u30b7\u30e7\u30f3","text":"<p>\u30d5\u30a1\u30a4\u30eb\u5909\u66f4\u3092\u8ffd\u8de1: <pre><code>Claude: [\u30d5\u30a1\u30a4\u30eb\u7de8\u96c6\u6642\u306bcoding_store_file_change\u3092\u81ea\u52d5\u4f7f\u7528]\n</code></pre></p> <p>\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u30b5\u30de\u30e9\u30a4\u30ba: <pre><code>\u30e6\u30fc\u30b6\u30fc: \u4eca\u65e5\u9054\u6210\u3057\u305f\u3053\u3068\u3092\u307e\u3068\u3081\u3066\nClaude: [coding_summary\u3092\u4f7f\u7528\u3057\u3066\u30bb\u30c3\u30b7\u30e7\u30f3\u5c65\u6b74\u3092\u5206\u6790]\n</code></pre></p>"},{"location":"ja/mcp-claude-code-setup/#_8","title":"\ud83d\udd27 \u9ad8\u5ea6\u306a\u8a2d\u5b9a","text":""},{"location":"ja/mcp-claude-code-setup/#_9","title":"\u30ea\u30e2\u30fc\u30c8\u30e2\u30fc\u30c9\uff08\u5b89\u5168\u306a\u30c4\u30fc\u30eb\u306e\u307f\uff09","text":"<p>\u30ea\u30e2\u30fc\u30c8Kagura API\u306b\u63a5\u7d9a\u3059\u308b\u5834\u5408:</p> <pre><code># \u30ea\u30e2\u30fc\u30c8\u63a5\u7d9a\u3092\u8a2d\u5b9a\nkagura mcp connect\n\n# \u30ea\u30e2\u30fc\u30c8MCP\u30b5\u30fc\u30d0\u30fc\u3092\u8ffd\u52a0\nclaude mcp add --transport stdio kagura-remote -- kagura mcp serve --remote\n</code></pre>"},{"location":"ja/mcp-claude-code-setup/#_10","title":"\u30ab\u30b9\u30bf\u30e0\u30b5\u30fc\u30d0\u30fc\u540d","text":"<pre><code># \u30ab\u30b9\u30bf\u30e0\u540d\u3092\u4f7f\u7528\nclaude mcp add --transport stdio my-kagura -- kagura mcp serve --name my-kagura\n</code></pre>"},{"location":"ja/mcp-claude-code-setup/#_11","title":"\u74b0\u5883\u5909\u6570","text":"<p>\u30aa\u30d7\u30b7\u30e7\u30f3\u6a5f\u80fd\u7528\u306eAPI\u30ad\u30fc\u3092\u8ffd\u52a0:</p> <pre><code># \u74b0\u5883\u5909\u6570\u3068\u5171\u306b\u8ffd\u52a0\nclaude mcp add --transport stdio kagura \\\n  --env OPENAI_API_KEY=sk-... \\\n  --env BRAVE_API_KEY=... \\\n  -- kagura mcp serve\n</code></pre>"},{"location":"ja/mcp-claude-code-setup/#_12","title":"\ud83d\udd0d \u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"ja/mcp-claude-code-setup/#kagura-command-not-found","title":"\"kagura command not found\"","text":"<p>\u89e3\u6c7a\u7b56: \u30d5\u30eb\u30d1\u30b9\u3092\u4f7f\u7528</p> <pre><code># kagura\u306e\u30d1\u30b9\u3092\u691c\u7d22\nwhich kagura\n# \u51fa\u529b: /home/user/.local/bin/kagura\n\n# \u30d5\u30eb\u30d1\u30b9\u3067\u8ffd\u52a0\nclaude mcp add --transport stdio kagura -- /home/user/.local/bin/kagura mcp serve\n</code></pre>"},{"location":"ja/mcp-claude-code-setup/#_13","title":"\u8a2d\u5b9a\u3092\u78ba\u8a8d","text":"<p>\u73fe\u5728\u306e\u8a2d\u5b9a\u3092\u8868\u793a: <pre><code>claude mcp get kagura\n</code></pre></p> <p>\u30ed\u30b0\u3092\u78ba\u8a8d: <pre><code># Kagura MCP\u30b5\u30fc\u30d0\u30fc\u30ed\u30b0\nkagura mcp log\n</code></pre></p>"},{"location":"ja/mcp-claude-code-setup/#_14","title":"\u524a\u9664\u3057\u3066\u518d\u8ffd\u52a0","text":"<pre><code># \u524a\u9664\nclaude mcp remove kagura\n\n# \u518d\u8ffd\u52a0\nclaude mcp add --transport stdio kagura -- kagura mcp serve\n</code></pre>"},{"location":"ja/mcp-claude-code-setup/#_15","title":"\ud83d\udcca \u76e3\u8996","text":""},{"location":"ja/mcp-claude-code-setup/#_16","title":"\u30c4\u30fc\u30eb\u4f7f\u7528\u7d71\u8a08\u3092\u8868\u793a","text":"<pre><code>kagura mcp stats\n</code></pre> <p>\u51fa\u529b\u4f8b: <pre><code>MCP Tool Usage Statistics\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal calls: 156\n\nTop tools:\n  memory_store: 45 calls\n  memory_search: 32 calls\n  coding_store_file_change: 28 calls\n  graph_link: 15 calls\n</code></pre></p>"},{"location":"ja/mcp-claude-code-setup/#_17","title":"\u30b5\u30fc\u30d0\u30fc\u30ed\u30b0\u3092\u8868\u793a","text":"<pre><code># \u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u30ed\u30b0\nkagura mcp log --tail\n\n# \u6700\u65b0100\u884c\nkagura mcp log --lines 100\n</code></pre>"},{"location":"ja/mcp-claude-code-setup/#_18","title":"\ud83d\udeab \u30a2\u30f3\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<p>Claude Code\u304b\u3089Kagura\u3092\u524a\u9664\u3059\u308b\u306b\u306f:</p> <pre><code>claude mcp remove kagura\n</code></pre> <p>\u3053\u308c\u306b\u3088\u308a\u8a2d\u5b9a\u306f\u524a\u9664\u3055\u308c\u307e\u3059\u304c\u3001\u4fdd\u5b58\u3055\u308c\u305f\u30e1\u30e2\u30ea\u30fc\u306f\u524a\u9664\u3055\u308c\u307e\u305b\u3093\u3002</p> <p>\u30e1\u30e2\u30ea\u30fc\u3092\u524a\u9664\u3059\u308b\u5834\u5408: <pre><code># \u307e\u305a\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\uff08\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\uff09\nkagura memory export --output=./backup\n\n# \u5168\u30e1\u30e2\u30ea\u30fc\u3092\u30af\u30ea\u30a2\nrm -rf ~/.local/share/kagura/\nrm -rf ~/.cache/kagura/\n</code></pre></p>"},{"location":"ja/mcp-claude-code-setup/#_19","title":"\ud83d\udd17 \u95a2\u9023\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li>MCP\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7 (Claude Desktop) - Claude Desktop\u7d71\u5408</li> <li>MCP over HTTP/SSE - \u30ea\u30e2\u30fc\u30c8MCP\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> <li>\u306f\u3058\u3081\u306b - \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u30ac\u30a4\u30c9</li> <li>API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9 - REST API\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8</li> </ul>"},{"location":"ja/mcp-claude-code-setup/#_20","title":"\ud83d\udcda \u8ffd\u52a0\u30ea\u30bd\u30fc\u30b9","text":""},{"location":"ja/mcp-claude-code-setup/#claude-code","title":"Claude Code\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li>Claude Code\u516c\u5f0f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8</li> <li>MCP\u30d7\u30ed\u30c8\u30b3\u30eb</li> </ul>"},{"location":"ja/mcp-claude-code-setup/#kagura","title":"Kagura\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li>GitHub\u30ea\u30dd\u30b8\u30c8\u30ea</li> <li>PyPI\u30d1\u30c3\u30b1\u30fc\u30b8</li> </ul> <p>\u30d0\u30fc\u30b8\u30e7\u30f3: 4.0.0 \u6700\u7d42\u66f4\u65b0: 2025-11-02</p>"},{"location":"ja/troubleshooting/","title":"\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u30ac\u30a4\u30c9","text":"<p>Kagura AI\u306e\u4e00\u822c\u7684\u306a\u554f\u984c\u3068\u89e3\u6c7a\u7b56</p> <p>\u3053\u306e\u30ac\u30a4\u30c9\u306f\u3001Kagura AI\u7d71\u5408\u306b\u95a2\u3059\u308b\u4e00\u822c\u7684\u306a\u554f\u984c\u306e\u8a3a\u65ad\u3068\u4fee\u6b63\u3092\u652f\u63f4\u3057\u307e\u3059\u3002</p>"},{"location":"ja/troubleshooting/#_2","title":"\ud83d\udd0d \u30af\u30a4\u30c3\u30af\u8a3a\u65ad","text":""},{"location":"ja/troubleshooting/#1-doctor","title":"\u30b9\u30c6\u30c3\u30d71: Doctor\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c","text":"<pre><code>kagura mcp doctor\n</code></pre> <p>\u671f\u5f85\u3055\u308c\u308b\u51fa\u529b: <pre><code>Kagura MCP Diagnostics\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\n\u2705 Python version: 3.11.5\n\u2705 Kagura installed: 4.0.0\n\u2705 MCP server: Configured\n\u2705 Database: Connected (342 memories)\n\u2705 Vector store: Healthy (ChromaDB)\n\nConfiguration:\n  Data dir: ~/.local/share/kagura\n  Cache dir: ~/.cache/kagura\n  Config dir: ~/.config/kagura\n</code></pre></p>"},{"location":"ja/troubleshooting/#2","title":"\u30b9\u30c6\u30c3\u30d72: \u30b5\u30fc\u30d0\u30fc\u30b9\u30c6\u30fc\u30bf\u30b9\u3092\u78ba\u8a8d","text":"<p>\u30ed\u30fc\u30ab\u30ebMCP\uff08Claude Desktop/Code\uff09: <pre><code># Claude Code\nclaude mcp list\n\n# Kagura\u30ed\u30b0\u3092\u78ba\u8a8d\nkagura mcp log --tail\n</code></pre></p> <p>\u30ea\u30e2\u30fc\u30c8MCP\uff08ChatGPT\uff09: <pre><code># API\u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af\ncurl http://localhost:8080/api/v1/health\n\n# MCP\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u3092\u78ba\u8a8d\ncurl http://localhost:8080/mcp\n\n# \u30ed\u30b0\u3092\u78ba\u8a8d\ndocker compose logs -f api\n</code></pre></p>"},{"location":"ja/troubleshooting/#_3","title":"\ud83d\udea8 \u4e00\u822c\u7684\u306a\u554f\u984c","text":""},{"location":"ja/troubleshooting/#1-mcp","title":"\u554f\u984c1: MCP\u30b5\u30fc\u30d0\u30fc\u304c\u63a5\u7d9a\u3067\u304d\u306a\u3044","text":"<p>\u75c7\u72b6: - Claude\u304cKagura\u30c4\u30fc\u30eb\u3092\u8a8d\u8b58\u3057\u306a\u3044 - \u300c\u30b5\u30fc\u30d0\u30fc\u304c\u5fdc\u7b54\u3057\u307e\u305b\u3093\u300d\u30a8\u30e9\u30fc - \u30c4\u30fc\u30eb\u30ea\u30b9\u30c8\u304c\u7a7a</p> <p>\u8a3a\u65ad:</p> <pre><code># Claude Code\nclaude mcp list\n# \u8868\u793a\u3055\u308c\u308b\u3079\u304d\u5185\u5bb9: kagura: \u2713 Connected\n\n# \u63a5\u7d9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u3001\u30ed\u30b0\u3092\u78ba\u8a8d\nkagura mcp log\n</code></pre> <p>\u89e3\u6c7a\u7b56:</p>"},{"location":"ja/troubleshooting/#a-mcp","title":"\u89e3\u6c7a\u7b56A: MCP\u30b5\u30fc\u30d0\u30fc\u3092\u518d\u8d77\u52d5\uff08\u30ed\u30fc\u30ab\u30eb\uff09","text":"<pre><code># Claude Desktop\n# 1. Claude Desktop\u3092\u5b8c\u5168\u306b\u7d42\u4e86\n# 2. Claude Desktop\u3092\u518d\u8d77\u52d5\n# 3. \u65b0\u3057\u3044\u4f1a\u8a71\u3092\u958b\u59cb\n\n# Claude Code\n# 1. \u30b5\u30fc\u30d0\u30fc\u3092\u524a\u9664\u3057\u3066\u518d\u8ffd\u52a0\nclaude mcp remove kagura\nclaude mcp add --transport stdio kagura -- kagura mcp serve\n\n# 2. \u78ba\u8a8d\nclaude mcp list\n</code></pre>"},{"location":"ja/troubleshooting/#b","title":"\u89e3\u6c7a\u7b56B: \u30b3\u30de\u30f3\u30c9\u30d1\u30b9\u3092\u78ba\u8a8d","text":"<p>\u554f\u984c: <code>kagura: command not found</code></p> <pre><code># kagura\u306e\u30d1\u30b9\u3092\u898b\u3064\u3051\u308b\nwhich kagura\n# \u51fa\u529b: /home/user/.local/bin/kagura\n\n# \u8a2d\u5b9a\u3067\u30d5\u30eb\u30d1\u30b9\u3092\u4f7f\u7528\nclaude mcp add --transport stdio kagura -- /home/user/.local/bin/kagura mcp serve\n</code></pre>"},{"location":"ja/troubleshooting/#c","title":"\u89e3\u6c7a\u7b56C: \u30d1\u30fc\u30df\u30c3\u30b7\u30e7\u30f3\u3092\u78ba\u8a8d","text":"<pre><code># kagura\u304c\u5b9f\u884c\u53ef\u80fd\u3067\u3042\u308b\u3053\u3068\u3092\u78ba\u8a8d\nchmod +x $(which kagura)\n\n# Python\u74b0\u5883\u3092\u78ba\u8a8d\npython --version  # 3.11\u4ee5\u4e0a\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\npip show kagura-ai  # \u30d0\u30fc\u30b8\u30e7\u30f34.0.0\u4ee5\u4e0a\u3092\u8868\u793a\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\n</code></pre>"},{"location":"ja/troubleshooting/#2_1","title":"\u554f\u984c2: \u30e1\u30e2\u30ea\u30fc\u304c\u4fdd\u6301\u3055\u308c\u306a\u3044","text":"<p>\u75c7\u72b6: - \u4f1a\u8a71\u7d42\u4e86\u5f8c\u306b\u30e1\u30e2\u30ea\u30fc\u304c\u6d88\u3048\u308b - \u6b21\u306e\u30bb\u30c3\u30b7\u30e7\u30f3\u3067\u300c\u30e1\u30e2\u30ea\u30fc\u304c\u898b\u3064\u304b\u308a\u307e\u305b\u3093\u300d - \u9032\u6357\u304c\u5931\u308f\u308c\u308b</p> <p>\u8a3a\u65ad:</p> <pre><code># \u30e1\u30e2\u30ea\u30fc\u7d71\u8a08\u3092\u78ba\u8a8d\nkagura mcp tools  # Claude\u3067\u5b9f\u884c: \"Show memory stats\"\n\n# \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3092\u78ba\u8a8d\nls -lh ~/.local/share/kagura/memory.db\n</code></pre> <p>\u89e3\u6c7a\u7b56:</p>"},{"location":"ja/troubleshooting/#a","title":"\u89e3\u6c7a\u7b56A: \u6c38\u7d9a\u7684\u306a\u30b9\u30b3\u30fc\u30d7\u3092\u4f7f\u7528","text":"<p>\u554f\u984c: \u30c7\u30d5\u30a9\u30eb\u30c8\u306e<code>scope=\"working\"</code>\uff08\u4e00\u6642\u7684\uff09\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b</p> <p>\u4fee\u6b63: \u660e\u793a\u7684\u306b\u6c38\u7d9a\u30b9\u30c8\u30ec\u30fc\u30b8\u3092\u30ea\u30af\u30a8\u30b9\u30c8</p> <pre><code>\u274c \"Remember that I prefer Python\"\n\u2705 \"Remember PERMANENTLY: I prefer Python\"\n\u2705 \"Save this with scope='persistent': I prefer Python\"\n</code></pre> <p>\u30d7\u30ed\u30f3\u30d7\u30c8\u5185\u3067: <pre><code>memory_store(\n    key=\"python_preference\",\n    value=\"FastAPI over Django\",\n    scope=\"persistent\"  # \u2190 \u91cd\u8981!\n)\n</code></pre></p>"},{"location":"ja/troubleshooting/#b-user_id","title":"\u89e3\u6c7a\u7b56B: user_id\u3092\u78ba\u8a8d","text":"<p>\u554f\u984c: \u5404\u30bb\u30c3\u30b7\u30e7\u30f3\u3067\u7570\u306a\u308b<code>user_id</code>\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b</p> <pre><code># \u30bb\u30c3\u30b7\u30e7\u30f31\n\"Remember for user_id='john': I prefer Python\"\n\n# \u30bb\u30c3\u30b7\u30e7\u30f32\uff08\u7570\u306a\u308buser_id\uff01\uff09\n\"What do I prefer?\"  # \u30c7\u30d5\u30a9\u30eb\u30c8\u306euser_id\u3092\u4f7f\u7528 \u2192 \u7d50\u679c\u306a\u3057\n</code></pre> <p>\u4fee\u6b63: \u4e00\u8cab\u3057\u305f<code>user_id</code>\u3092\u4f7f\u7528:</p> <pre><code># \u5e38\u306b\u540c\u3058user_id\u3092\u6307\u5b9a\n\"For user_id='john': What programming languages do I prefer?\"\n</code></pre>"},{"location":"ja/troubleshooting/#3-mcp","title":"\u554f\u984c3: \u30d5\u30a1\u30a4\u30eb\u64cd\u4f5c\u304c\u6a5f\u80fd\u3057\u306a\u3044\uff08\u30ea\u30e2\u30fc\u30c8MCP\uff09","text":"<p>\u75c7\u72b6: - \"file_read not found\" - \"\u30d5\u30a1\u30a4\u30eb\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u307e\u305b\u3093\" - \u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u304c\u6a5f\u80fd\u3057\u306a\u3044</p> <p>\u8a3a\u65ad:</p> <p>\u3053\u308c\u306f\u30ea\u30e2\u30fc\u30c8MCP\uff08ChatGPT\u3001Claude Chat\uff09\u306b\u304a\u3051\u308b\u671f\u5f85\u3055\u308c\u308b\u52d5\u4f5c\u3067\u3059\u3002</p> <p>\u7406\u7531: \u30ea\u30e2\u30fc\u30c8MCP\u306fHTTP/SSE\u7d4c\u7531\u3067\u5b9f\u884c\u3055\u308c\u3001\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u4e0a\u306e\u7406\u7531\u304b\u3089\u76f4\u63a5\u30d5\u30a1\u30a4\u30eb\u30b7\u30b9\u30c6\u30e0\u30a2\u30af\u30bb\u30b9\u3092\u6301\u3061\u307e\u305b\u3093\u3002</p> <p>\u89e3\u6c7a\u7b56:</p>"},{"location":"ja/troubleshooting/#a-mcp_1","title":"\u89e3\u6c7a\u7b56A: \u30d5\u30a1\u30a4\u30eb\u64cd\u4f5c\u306b\u306f\u30ed\u30fc\u30ab\u30ebMCP\u3092\u4f7f\u7528","text":"<p>Claude Desktop\u307e\u305f\u306fClaude Code\u306b\u5207\u308a\u66ff\u3048:</p> <pre><code># Claude Desktop\nkagura mcp install\n\n# Claude Code\nclaude mcp add --transport stdio kagura -- kagura mcp serve\n</code></pre> <p>\u3053\u308c\u3067\u4ee5\u4e0b\u304c\u4f7f\u7528\u3067\u304d\u307e\u3059: - <code>file_read</code> - <code>file_write</code> - <code>dir_list</code> - <code>media_open_*</code></p>"},{"location":"ja/troubleshooting/#b-mcp","title":"\u89e3\u6c7a\u7b56B: \u30b3\u30f3\u30c6\u30f3\u30c4\u3092\u30b3\u30d4\u30fc/\u30da\u30fc\u30b9\u30c8\uff08\u30ea\u30e2\u30fc\u30c8MCP\uff09","text":"<p>\u30ea\u30e2\u30fc\u30c8MCP\u3092\u4f7f\u7528\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u5834\u5408:</p> <pre><code># \"Read config.py\"\u306e\u4ee3\u308f\u308a\u306b\n# \u2192 \u30d5\u30a1\u30a4\u30eb\u306e\u5185\u5bb9\u3092\u30c1\u30e3\u30c3\u30c8\u306b\u30b3\u30d4\u30fc/\u30da\u30fc\u30b9\u30c8\n\n\u30e6\u30fc\u30b6\u30fc: \"\u3053\u308c\u304cconfig.py\u306e\u5185\u5bb9\u3067\u3059:\n      [\u5185\u5bb9\u3092\u30da\u30fc\u30b9\u30c8]\n\n      \u3053\u306e\u8a2d\u5b9a\u3092\u5206\u6790\u3057\u3066\u304f\u3060\u3055\u3044\"\n</code></pre>"},{"location":"ja/troubleshooting/#c-v41","title":"\u89e3\u6c7a\u7b56C: v4.1\u30d5\u30a1\u30a4\u30eb\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u3092\u5f85\u3064","text":"<p>\u5c06\u6765: \u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9API\u306fv4.1\u3067\u8a08\u753b\u3055\u308c\u3066\u3044\u307e\u3059</p> <p>\u53c2\u7167: Issue #462</p>"},{"location":"ja/troubleshooting/#4","title":"\u554f\u984c4: \u691c\u7d22\u7d50\u679c\u304c\u8fd4\u3055\u308c\u306a\u3044","text":"<p>\u75c7\u72b6: - <code>memory_search</code>\u304c\u7a7a\u3092\u8fd4\u3059 - \"\u30e1\u30e2\u30ea\u30fc\u304c\u898b\u3064\u304b\u308a\u307e\u305b\u3093\" - \u4fdd\u5b58\u3055\u308c\u305f\u60c5\u5831\u3092\u898b\u3064\u3051\u3089\u308c\u306a\u3044</p> <p>\u8a3a\u65ad:</p> <pre><code># Claude/ChatGPT\u3067:\n\"List all my memories\"\n[memory_list\u3092\u4f7f\u7528]\n\n\"Show memory statistics\"\n[memory_stats\u3092\u4f7f\u7528]\n</code></pre> <p>\u89e3\u6c7a\u7b56:</p>"},{"location":"ja/troubleshooting/#a_1","title":"\u89e3\u6c7a\u7b56A: \u30e1\u30e2\u30ea\u30fc\u306e\u5b58\u5728\u3092\u78ba\u8a8d","text":"<pre><code>\"List all memories\"\n\n# \u7a7a\u306e\u5834\u5408 \u2192 \u307e\u3060\u30e1\u30e2\u30ea\u30fc\u304c\u4fdd\u5b58\u3055\u308c\u3066\u3044\u306a\u3044\n# \u30e1\u30e2\u30ea\u30fc\u304c\u3042\u308b\u5834\u5408 \u2192 \u6b21\u306e\u89e3\u6c7a\u7b56\u306b\u9032\u3080\n</code></pre>"},{"location":"ja/troubleshooting/#b_1","title":"\u89e3\u6c7a\u7b56B: \u6b63\u3057\u3044\u691c\u7d22\u30bf\u30a4\u30d7\u3092\u4f7f\u7528","text":"<p>\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u691c\u7d22\uff08\u610f\u5473\u30d9\u30fc\u30b9\uff09: <pre><code>\u2705 \"Find memories about backend development\"\n\u2705 \"Search for information on API design\"\n</code></pre></p> <p>\u6b63\u78ba\u306a\u30ad\u30fc\u547c\u3073\u51fa\u3057: <pre><code>\u2705 \"Recall memory with key='python_preference'\"\n</code></pre></p> <p>\u8aa4\u3063\u305f\u30a2\u30d7\u30ed\u30fc\u30c1: <pre><code>\u274c \"Search for exact text 'I prefer FastAPI over Django'\"\n</code></pre></p>"},{"location":"ja/troubleshooting/#c_1","title":"\u89e3\u6c7a\u7b56C: \u30d5\u30a3\u30eb\u30bf\u30fc\u3092\u78ba\u8a8d","text":"<p>\u554f\u984c: \u5236\u9650\u304c\u53b3\u3057\u3059\u304e\u308b\u30d5\u30a3\u30eb\u30bf\u30fc</p> <pre><code># \u7279\u5b9a\u3057\u3059\u304e\uff08\u7d50\u679c\u306a\u3057\uff09\nmemory_search(\n    query=\"FastAPI\",\n    tags=[\"python\", \"web\", \"api\", \"backend\", \"2024\"]  # \u30bf\u30b0\u304c\u591a\u3059\u304e\u308b\n)\n\n# \u3088\u308a\u826f\u3044\uff08\u3088\u308a\u591a\u304f\u306e\u7d50\u679c\uff09\nmemory_search(\n    query=\"FastAPI\",\n    tags=[\"python\"]  # \u30bf\u30b0\u304c\u5c11\u306a\u3044\n)\n\n# \u6700\u826f\uff08\u6700\u3082\u591a\u304f\u306e\u7d50\u679c\uff09\nmemory_search(\n    query=\"FastAPI\"  # \u30d5\u30a3\u30eb\u30bf\u30fc\u306a\u3057\n)\n</code></pre>"},{"location":"ja/troubleshooting/#d-user_idagent_name","title":"\u89e3\u6c7a\u7b56D: user_id\u3068agent_name\u3092\u78ba\u8a8d","text":"<pre><code># \u4f55\u3092\u691c\u7d22\u3057\u3066\u3044\u308b\u304b\u78ba\u8a8d\n\"Search memories for user_id='john' with agent_name='global'\"\n\n# \u7d50\u679c\u304c\u306a\u3044\u5834\u5408\u3001\u7570\u306a\u308b\u7d44\u307f\u5408\u308f\u305b\u3092\u8a66\u3059\n\"Search all memories regardless of user_id\"\n</code></pre>"},{"location":"ja/troubleshooting/#5-api","title":"\u554f\u984c5: \u9ad8\u984d\u306aAPI\u30b3\u30b9\u30c8","text":"<p>\u75c7\u72b6: - \u4e88\u671f\u3057\u306a\u3044OpenAI/Anthropic\u306e\u8acb\u6c42 - \u57cb\u3081\u8fbc\u307fAPI\u306e\u30b3\u30b9\u30c8\u304c\u9ad8\u3059\u304e\u308b - \u30c8\u30fc\u30af\u30f3\u4f7f\u7528\u91cf\u306e\u8b66\u544a</p> <p>\u8a3a\u65ad:</p> <pre><code># \u30b3\u30b9\u30c8\u6982\u8981\u3092\u78ba\u8a8d\n\"Show telemetry cost summary\"\n[telemetry_cost\u3092\u4f7f\u7528]\n\n# \u30c4\u30fc\u30eb\u4f7f\u7528\u72b6\u6cc1\u3092\u78ba\u8a8d\nkagura mcp stats\n</code></pre> <p>\u89e3\u6c7a\u7b56:</p>"},{"location":"ja/troubleshooting/#a_2","title":"\u89e3\u6c7a\u7b56A: \u30ed\u30fc\u30ab\u30eb\u57cb\u3081\u8fbc\u307f\u3092\u4f7f\u7528","text":"<p>\u554f\u984c: \u57cb\u3081\u8fbc\u307f\u306bOpenAI API\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b</p> <p>\u4fee\u6b63: \u30ed\u30fc\u30ab\u30eb\u306esentence-transformers\u306b\u5207\u308a\u66ff\u3048</p> <pre><code># AI\u30a8\u30af\u30b9\u30c8\u30e9\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff08sentence-transformers\u3092\u542b\u3080\uff09\npip install kagura-ai[ai]\n\n# \u30ed\u30fc\u30ab\u30eb\u57cb\u3081\u8fbc\u307f\u3092\u4f7f\u7528\u3059\u308b\u3088\u3046\u306b\u8a2d\u5b9a\n# .env\u307e\u305f\u306f\u74b0\u5883\u5909\u6570\u3067:\nKAGURA_EMBEDDING_MODEL=local  # E5\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\uff08\u7121\u6599\u3001\u30ed\u30fc\u30ab\u30eb\uff09\n</code></pre> <p>\u30b3\u30b9\u30c8\u6bd4\u8f03: - OpenAI\u57cb\u3081\u8fbc\u307f: 1K\u30c8\u30fc\u30af\u30f3\u3042\u305f\u308a$0.0001 - \u30ed\u30fc\u30ab\u30ebE5\u57cb\u3081\u8fbc\u307f: $0\uff08\u30de\u30b7\u30f3\u4e0a\u3067\u5b9f\u884c\uff09</p>"},{"location":"ja/troubleshooting/#b_2","title":"\u89e3\u6c7a\u7b56B: \u4f4e\u30c8\u30fc\u30af\u30f3\u691c\u7d22\u3092\u4f7f\u7528","text":"<p><code>memory_search</code>\uff08\u5b8c\u5168\u306a\u5185\u5bb9\u3092\u8fd4\u3059\uff09\u306e\u4ee3\u308f\u308a\u306b\u3001<code>memory_search_ids</code>\u3092\u4f7f\u7528:</p> <pre><code># \u9ad8\u30c8\u30fc\u30af\u30f3\u4f7f\u7528\u91cf\nmemory_search(query=\"FastAPI\", k=10)\n# 10\u500b\u306e\u5b8c\u5168\u306a\u30e1\u30e2\u30ea\u30fc\u3092\u8fd4\u3059 \u2192 \u7d045000\u30c8\u30fc\u30af\u30f3\n\n# \u4f4e\u30c8\u30fc\u30af\u30f3\u4f7f\u7528\u91cf\nmemory_search_ids(query=\"FastAPI\", k=10)\n# 10\u500b\u306eID + \u30d7\u30ec\u30d3\u30e5\u30fc\u3092\u8fd4\u3059 \u2192 \u7d04500\u30c8\u30fc\u30af\u30f3\n</code></pre>"},{"location":"ja/troubleshooting/#c_2","title":"\u89e3\u6c7a\u7b56C: \u691c\u7d22\u983b\u5ea6\u3092\u6e1b\u3089\u3059","text":"<p>\u691c\u7d22\u7d50\u679c\u3092\u30ad\u30e3\u30c3\u30b7\u30e5:</p> <pre><code># \u8907\u6570\u56de\u691c\u7d22\u3059\u308b\u4ee3\u308f\u308a\u306b\n\"Find memories about Python\"  # \u691c\u7d221\n\"Find memories about Python\"  # \u691c\u7d222\uff08\u91cd\u8907\uff01\uff09\n\n# \u3088\u308a\u826f\u3044: \u4e00\u5ea6\u691c\u7d22\u3057\u3066\u3001\u305d\u306e\u5f8c\u53c2\u7167\n\"Find memories about Python\"  # \u4e00\u5ea6\u691c\u7d22\n\"Based on those memories, what should I use for backend?\"  # \u691c\u7d22\u306a\u3057\n</code></pre>"},{"location":"ja/troubleshooting/#d","title":"\u89e3\u6c7a\u7b56D: \u30b3\u30b9\u30c8\u3092\u76e3\u8996","text":"<pre><code># \u5b9a\u671f\u7684\u306a\u30b3\u30b9\u30c8\u30c1\u30a7\u30c3\u30af\n\"Show me telemetry cost for the last week\"\n\n# \u4e88\u7b97\u30a2\u30e9\u30fc\u30c8\u3092\u8a2d\u5b9a\uff08\u5c06\u6765\u306e\u6a5f\u80fd\uff09\n</code></pre>"},{"location":"ja/troubleshooting/#6","title":"\u554f\u984c6: \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u304c\u9045\u3044","text":"<p>\u75c7\u72b6: - \u691c\u7d22\u306b5\u79d2\u4ee5\u4e0a\u304b\u304b\u308b - \u30e1\u30e2\u30ea\u30fc\u64cd\u4f5c\u304c\u30bf\u30a4\u30e0\u30a2\u30a6\u30c8 - API\u30ec\u30b9\u30dd\u30f3\u30b9\u304c\u9045\u3044</p> <p>\u8a3a\u65ad:</p> <pre><code># \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30b5\u30a4\u30ba\u3092\u78ba\u8a8d\ndu -sh ~/.local/share/kagura/\n\n# \u30e1\u30e2\u30ea\u30fc\u6570\u3092\u78ba\u8a8d\nkagura mcp tools  # \u305d\u306e\u5f8c: \"Show memory stats\"\n\n# \u30b7\u30b9\u30c6\u30e0\u30ea\u30bd\u30fc\u30b9\u3092\u78ba\u8a8d\ntop  # \u9ad8\u3044CPU/\u30e1\u30e2\u30ea\u30fc\u4f7f\u7528\u7387\u3092\u78ba\u8a8d\n</code></pre> <p>\u89e3\u6c7a\u7b56:</p>"},{"location":"ja/troubleshooting/#a_3","title":"\u89e3\u6c7a\u7b56A: \u53e4\u3044\u30e1\u30e2\u30ea\u30fc\u3092\u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7","text":"<pre><code># \u307e\u305a\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\uff08\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\uff09\nkagura memory export --output=./backup\n\n# \u53e4\u3044/\u672a\u4f7f\u7528\u306e\u30e1\u30e2\u30ea\u30fc\u3092\u524a\u9664\n# Claude/ChatGPT\u3067:\n\"Delete memories older than 6 months with usefulness score &lt; 0.3\"\n</code></pre>"},{"location":"ja/troubleshooting/#b-chromadb","title":"\u89e3\u6c7a\u7b56B: ChromaDB\u3092\u6700\u9069\u5316","text":"<pre><code># \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3092\u5727\u7e2e\ncd ~/.cache/kagura/chromadb\n# ChromaDB\u306f\u81ea\u52d5\u5727\u7e2e\u3057\u307e\u3059\u304c\u3001\u5f37\u5236\u3059\u308b\u305f\u3081\u306b\u518d\u8d77\u52d5\u3067\u304d\u307e\u3059\n\n# \u307e\u305f\u306f\u6700\u521d\u304b\u3089\u518d\u69cb\u7bc9\nkagura memory export --output=./backup\nrm -rf ~/.cache/kagura/chromadb\nkagura memory import --input=./backup\n</code></pre>"},{"location":"ja/troubleshooting/#c-bm25","title":"\u89e3\u6c7a\u7b56C: \u5b8c\u5168\u4e00\u81f4\u306b\u306fBM25\u3092\u4f7f\u7528","text":"<p>\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u691c\u7d22\uff08\u5927\u898f\u6a21\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u306f\u9045\u3044\uff09: <pre><code>memory_search(query=\"FastAPI\", mode=\"vector\")  # 10K\u4ee5\u4e0a\u306e\u30e1\u30e2\u30ea\u30fc\u3067\u306f\u9045\u3044\n</code></pre></p> <p>BM25\u5b57\u53e5\u691c\u7d22\uff08\u9ad8\u901f\uff09: <pre><code>memory_search(query=\"FastAPI\", mode=\"bm25\")  # 100K\u4ee5\u4e0a\u306e\u30e1\u30e2\u30ea\u30fc\u3067\u3082\u9ad8\u901f\n</code></pre></p> <p>\u30cf\u30a4\u30d6\u30ea\u30c3\u30c9\uff08\u6700\u826f\u306e\u7cbe\u5ea6 + \u901f\u5ea6\uff09: <pre><code>memory_search(query=\"FastAPI\", mode=\"hybrid\")  # \u30d0\u30e9\u30f3\u30b9\n</code></pre></p>"},{"location":"ja/troubleshooting/#7-mcp","title":"\u554f\u984c7: \u8a8d\u8a3c\u30a8\u30e9\u30fc\uff08\u30ea\u30e2\u30fc\u30c8MCP\uff09","text":"<p>\u75c7\u72b6: - \"401 Unauthorized\" - \"Invalid API key\" - \"Authentication required\"</p> <p>\u8a3a\u65ad:</p> <pre><code># API\u30ad\u30fc\u304c\u5b58\u5728\u3059\u308b\u304b\u78ba\u8a8d\nkagura api list-keys\n\n# \u8a8d\u8a3c\u3092\u30c6\u30b9\u30c8\ncurl -H \"Authorization: Bearer YOUR_KEY\" \\\n     http://localhost:8080/api/v1/health\n</code></pre> <p>\u89e3\u6c7a\u7b56:</p>"},{"location":"ja/troubleshooting/#a-api","title":"\u89e3\u6c7a\u7b56A: API\u30ad\u30fc\u3092\u4f5c\u6210","text":"<pre><code># \u65b0\u3057\u3044API\u30ad\u30fc\u3092\u751f\u6210\nkagura api create-key --name \"chatgpt-integration\"\n\n# \u51fa\u529b:\n# Created API key: kg_xxxxxxxxxxxxxxxxxxxxxxxx\n# Save this key securely!\n</code></pre>"},{"location":"ja/troubleshooting/#b-apimcp","title":"\u89e3\u6c7a\u7b56B: API\u30ad\u30fc\u3067MCP\u3092\u8a2d\u5b9a","text":"<p>ChatGPT MCP\u8a2d\u5b9a: <pre><code>{\n  \"url\": \"https://your-domain.com/mcp\",\n  \"headers\": {\n    \"Authorization\": \"Bearer kg_xxxxxxxxxxxxxxxxxxxxxxxx\"\n  }\n}\n</code></pre></p>"},{"location":"ja/troubleshooting/#c_3","title":"\u89e3\u6c7a\u7b56C: \u30ad\u30fc\u306e\u30d1\u30fc\u30df\u30c3\u30b7\u30e7\u30f3\u3092\u78ba\u8a8d","text":"<pre><code># \u30ad\u30fc\u306e\u8a73\u7d30\u3092\u8868\u793a\nkagura api get-key kg_xxxxxxxx\n\n# \u4fb5\u5bb3\u3055\u308c\u305f\u5834\u5408\u306f\u30ed\u30fc\u30c6\u30fc\u30b7\u30e7\u30f3\nkagura api rotate-key kg_xxxxxxxx\n\n# \u5fc5\u8981\u306b\u5fdc\u3058\u3066\u53d6\u308a\u6d88\u3057\nkagura api revoke-key kg_xxxxxxxx\n</code></pre>"},{"location":"ja/troubleshooting/#8-docker","title":"\u554f\u984c8: Docker\u306e\u554f\u984c","text":"<p>\u75c7\u72b6: - \"Cannot connect to Docker daemon\" - \u30b3\u30f3\u30c6\u30ca\u304c\u8d77\u52d5\u3057\u306a\u3044 - \u30dd\u30fc\u30c8\u306e\u7af6\u5408</p> <p>\u8a3a\u65ad:</p> <pre><code># Docker\u30b9\u30c6\u30fc\u30bf\u30b9\u3092\u78ba\u8a8d\ndocker ps\n\n# \u30ed\u30b0\u3092\u78ba\u8a8d\ndocker compose logs -f\n\n# \u30dd\u30fc\u30c8\u3092\u78ba\u8a8d\nlsof -i :8080  # API\u30dd\u30fc\u30c8\nlsof -i :5432  # PostgreSQL\u30dd\u30fc\u30c8\nlsof -i :6379  # Redis\u30dd\u30fc\u30c8\n</code></pre> <p>\u89e3\u6c7a\u7b56:</p>"},{"location":"ja/troubleshooting/#a-docker","title":"\u89e3\u6c7a\u7b56A: Docker\u3092\u8d77\u52d5","text":"<pre><code># Linux\nsudo systemctl start docker\n\n# macOS\n# Docker Desktop\u3092\u958b\u304f\n\n# \u78ba\u8a8d\ndocker ps\n</code></pre>"},{"location":"ja/troubleshooting/#b_3","title":"\u89e3\u6c7a\u7b56B: \u30dd\u30fc\u30c8\u7af6\u5408\u3092\u4fee\u6b63","text":"<p>\u554f\u984c: \u30dd\u30fc\u30c88080\u304c\u65e2\u306b\u4f7f\u7528\u4e2d</p> <pre><code># \u30dd\u30fc\u30c8\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u3082\u306e\u3092\u898b\u3064\u3051\u308b\nlsof -i :8080\n\n# \u30d7\u30ed\u30bb\u30b9\u3092\u7d42\u4e86\nkill -9 &lt;PID&gt;\n\n# \u307e\u305f\u306fdocker-compose.yml\u3067Kagura\u306e\u30dd\u30fc\u30c8\u3092\u5909\u66f4\nports:\n  - \"8090:8080\"  # \u4ee3\u308f\u308a\u306b8090\u3092\u4f7f\u7528\n</code></pre>"},{"location":"ja/troubleshooting/#c-docker","title":"\u89e3\u6c7a\u7b56C: Docker\u74b0\u5883\u3092\u30ea\u30bb\u30c3\u30c8","text":"<pre><code># \u3059\u3079\u3066\u306e\u30b3\u30f3\u30c6\u30ca\u3092\u505c\u6b62\ndocker compose down\n\n# \u30dc\u30ea\u30e5\u30fc\u30e0\u3092\u524a\u9664\uff08\u26a0\ufe0f \u30c7\u30fc\u30bf\u3092\u524a\u9664\u3057\u307e\u3059\uff01\uff09\ndocker compose down -v\n\n# \u518d\u30d3\u30eb\u30c9\ndocker compose up -d --build\n\n# \u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af\ncurl http://localhost:8080/api/v1/health\n</code></pre>"},{"location":"ja/troubleshooting/#_4","title":"\ud83d\udd27 \u9ad8\u5ea6\u306a\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"ja/troubleshooting/#_5","title":"\u30c7\u30d0\u30c3\u30b0\u30ed\u30b0\u3092\u6709\u52b9\u5316","text":"<pre><code># \u30ed\u30b0\u30ec\u30d9\u30eb\u3092\u8a2d\u5b9a\nexport KAGURA_LOG_LEVEL=DEBUG\n\n# \u30c7\u30d0\u30c3\u30b0\u30ed\u30b0\u3067MCP\u30b5\u30fc\u30d0\u30fc\u3092\u8d77\u52d5\nkagura mcp serve\n\n# \u307e\u305f\u306fAPI\u7528\nuvicorn kagura.api.server:app --log-level debug\n</code></pre>"},{"location":"ja/troubleshooting/#_6","title":"\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u6574\u5408\u6027\u3092\u78ba\u8a8d","text":"<pre><code># SQLite\u6574\u5408\u6027\u30c1\u30a7\u30c3\u30af\nsqlite3 ~/.local/share/kagura/memory.db \"PRAGMA integrity_check;\"\n\n# \u671f\u5f85\u3055\u308c\u308b\u51fa\u529b: ok\n</code></pre>"},{"location":"ja/troubleshooting/#_7","title":"\u30d9\u30af\u30c8\u30eb\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u518d\u69cb\u7bc9","text":"<pre><code># \u30e1\u30e2\u30ea\u30fc\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\nkagura memory export --output=./backup\n\n# \u30d9\u30af\u30c8\u30eb\u30b9\u30c8\u30a2\u3092\u30af\u30ea\u30a2\nrm -rf ~/.cache/kagura/chromadb\n\n# \u518d\u30a4\u30f3\u30dd\u30fc\u30c8\uff08\u30d9\u30af\u30c8\u30eb\u3092\u518d\u69cb\u7bc9\uff09\nkagura memory import --input=./backup\n</code></pre>"},{"location":"ja/troubleshooting/#mcp","title":"MCP\u30c4\u30fc\u30eb\u3092\u624b\u52d5\u3067\u30c6\u30b9\u30c8","text":"<pre><code># API\u7d4c\u7531\u3067\u500b\u3005\u306e\u30c4\u30fc\u30eb\u3092\u30c6\u30b9\u30c8\ncurl -X POST http://localhost:8080/api/v1/memory/store \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"key\": \"test\",\n    \"value\": \"test value\",\n    \"scope\": \"working\"\n  }'\n\n# \u4fdd\u5b58\u3055\u308c\u305f\u304b\u78ba\u8a8d\ncurl http://localhost:8080/api/v1/memory/list\n</code></pre>"},{"location":"ja/troubleshooting/#_8","title":"\ud83d\udcda \u30b5\u30dd\u30fc\u30c8\u3092\u53d7\u3051\u308b","text":""},{"location":"ja/troubleshooting/#1","title":"1. \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u78ba\u8a8d","text":"<ul> <li>\u30c1\u30e3\u30c3\u30c8\u7d71\u5408\u306e\u30d2\u30f3\u30c8</li> <li>MCP\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u30ac\u30a4\u30c9</li> <li>API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9</li> <li>\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3</li> </ul>"},{"location":"ja/troubleshooting/#2_2","title":"2. \u65e2\u5b58\u306e\u554f\u984c\u3092\u691c\u7d22","text":"<p>GitHub Issues</p>"},{"location":"ja/troubleshooting/#3","title":"3. \u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u306b\u8cea\u554f","text":"<p>GitHub Discussions</p>"},{"location":"ja/troubleshooting/#4_1","title":"4. \u30d0\u30b0\u3092\u5831\u544a","text":"<pre><code># \u8a3a\u65ad\u60c5\u5831\u3092\u542b\u3080\u65b0\u3057\u3044issue\u3092\u4f5c\u6210\nkagura mcp doctor &gt; diagnostics.txt\n\n# issue\u3092\u4f5c\u6210\u3059\u308b\u969b\u306bdiagnostics.txt\u3092\u6dfb\u4ed8\ngh issue create --title \"Bug: [\u554f\u984c\u3092\u8a18\u8ff0]\" \\\n                --body \"\u6dfb\u4ed8\u306ediagnostics.txt\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\"\n</code></pre>"},{"location":"ja/troubleshooting/#_9","title":"\ud83d\udcca \u8a3a\u65ad\u30c1\u30a7\u30c3\u30af\u30ea\u30b9\u30c8","text":"<p>\u554f\u984c\u3092\u5831\u544a\u3059\u308b\u524d\u306b\u3001\u4ee5\u4e0b\u306e\u60c5\u5831\u3092\u53ce\u96c6\u3057\u3066\u304f\u3060\u3055\u3044:</p> <pre><code># 1. \u30d0\u30fc\u30b8\u30e7\u30f3\u60c5\u5831\nkagura --version\npython --version\npip show kagura-ai\n\n# 2. \u30b7\u30b9\u30c6\u30e0\u60c5\u5831\nuname -a  # Linux/macOS\ncat /etc/os-release  # Linux\u30c7\u30a3\u30b9\u30c8\u30ea\u30d3\u30e5\u30fc\u30b7\u30e7\u30f3\n\n# 3. \u8a3a\u65ad\u30ec\u30dd\u30fc\u30c8\nkagura mcp doctor\n\n# 4. \u6700\u8fd1\u306e\u30ed\u30b0\nkagura mcp log --lines 100\n\n# 5. \u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8\n# \u5b8c\u5168\u306a\u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8 + \u30b9\u30bf\u30c3\u30af\u30c8\u30ec\u30fc\u30b9\u3092\u30b3\u30d4\u30fc\n\n# 6. \u518d\u73fe\u624b\u9806\n# \u554f\u984c\u3092\u5f15\u304d\u8d77\u3053\u3059\u6b63\u78ba\u306a\u624b\u9806\u3092\u8a18\u8ff0\n</code></pre> <p>\u30d0\u30fc\u30b8\u30e7\u30f3: 4.0.0 \u6700\u7d42\u66f4\u65b0: 2025-11-02</p>"}]}