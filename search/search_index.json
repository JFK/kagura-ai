{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Kagura AI","text":"<p>Universal AI Memory Platform</p> <p>Own your memory. Bring it to every AI.</p> <p>MCP-native memory infrastructure that connects Claude Desktop, ChatGPT, Gemini, and all your AI platforms with shared context and memory.</p>"},{"location":"#what-is-kagura-ai-v40","title":"What is Kagura AI v4.0?","text":"<p>A universal memory layer that makes every AI remember your preferences, context, and history across all platforms.</p> <pre><code>Morning: ChatGPT helps you plan your day\n         \u2193 (remembers your preferences)\n\nAfternoon: Claude Desktop writes code with you\n           \u2193 (knows your coding style)\n\nEvening: Gemini analyzes your documents\n         \u2193 (recalls your project context)\n</code></pre> <p>One memory. Every AI.</p>"},{"location":"#why-kagura-ai","title":"Why Kagura AI?","text":""},{"location":"#for-individuals","title":"For Individuals","text":"<ul> <li>\ud83d\udd12 Privacy-first: Local storage or self-hosted</li> <li>\ud83d\udeab No vendor lock-in: Complete data export anytime</li> <li>\ud83e\udde0 Smart recall: Vector search + Knowledge graph</li> <li>\ud83c\udf10 Universal: Works with Claude, ChatGPT, Gemini, Cursor, Cline</li> </ul>"},{"location":"#for-developers","title":"For Developers","text":"<ul> <li>\ud83d\udcbb MCP-native: 31 tools via Model Context Protocol</li> <li>\ud83d\udd0c Easy integration: <code>kagura mcp install</code> for Claude Desktop</li> <li>\ud83d\udee0\ufe0f REST API: FastAPI server with OpenAPI</li> <li>\ud83d\udce6 Production-ready: Docker, authentication, monitoring</li> </ul>"},{"location":"#for-teams-coming-soon","title":"For Teams (Coming Soon)","text":"<ul> <li>\ud83d\udc65 Shared knowledge: Team-wide memory</li> <li>\ud83d\udd10 Enterprise features: SSO, BYOK, audit logs</li> <li>\ud83d\udcc8 Analytics: Track team AI usage patterns</li> </ul>"},{"location":"#core-features","title":"Core Features","text":""},{"location":"#1-universal-memory","title":"1. Universal Memory","text":"<p>Store once, access from any AI:</p> <pre><code># Via MCP tool (works in Claude Desktop, ChatGPT, etc.)\nmemory_store(\n    user_id=\"jfk\",\n    agent_name=\"global\",\n    key=\"coding_style\",\n    value=\"Always use type hints in Python\",\n    scope=\"persistent\",\n    tags='[\"python\", \"best-practices\"]'\n)\n</code></pre>"},{"location":"#2-mcp-integration","title":"2. MCP Integration","text":"<p>Claude Desktop (local, all 31 tools): <pre><code>kagura mcp install  # Auto-configure\n# All tools available: memory, files, web, shell, etc.\n</code></pre></p> <p>ChatGPT Connector (remote, 24 safe tools): <pre><code>docker compose up -d\n# Connect ChatGPT to http://localhost:8080/mcp\n# Safe tools only (no file ops, no shell)\n</code></pre></p>"},{"location":"#3-knowledge-graph","title":"3. Knowledge Graph","text":"<p>Track relationships and patterns: - AI-User interaction history - Memory relationships - Learning patterns analysis - Topic clustering</p>"},{"location":"#4-complete-data-portability","title":"4. Complete Data Portability","text":"<pre><code># Export everything\nkagura memory export --output ./backup\n\n# Import anywhere\nkagura memory import --input ./backup\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#option-1-claude-desktop-user","title":"Option 1: Claude Desktop User","text":"<pre><code>pip install kagura-ai[full]\nkagura mcp install\n# Restart Claude Desktop - Done!\n</code></pre> <p>Claude Desktop Setup \u2192</p>"},{"location":"#option-2-chatgpt-user","title":"Option 2: ChatGPT User","text":"<pre><code>docker compose up -d\n# Configure ChatGPT Connector: http://localhost:8080/mcp\n</code></pre> <p>ChatGPT Connector Setup \u2192</p>"},{"location":"#option-3-self-hosted-production","title":"Option 3: Self-Hosted Production","text":"<pre><code>git clone https://github.com/JFK/kagura-ai.git\ncd kagura-ai\ncp .env.example .env  # Configure DOMAIN, POSTGRES_PASSWORD\ndocker compose -f docker-compose.prod.yml up -d\n</code></pre> <p>Self-Hosting Guide \u2192</p>"},{"location":"#available-tools-mcp","title":"Available Tools (MCP)","text":"<p>Memory (6 tools): - memory_store, memory_recall, memory_search - memory_list, memory_delete, memory_feedback</p> <p>Graph (3 tools): - memory_record_interaction - memory_get_related - memory_get_user_pattern</p> <p>Web/API (10+ tools): - web_search, web_scrape - youtube_summarize, get_youtube_transcript - brave_web_search, fact_check_claim</p> <p>File Operations (local only): - file_read, file_write, dir_list</p> <p>System: - shell_exec (local only) - telemetry_stats, telemetry_cost</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Getting Started - 10-minute setup</li> <li>API Reference - REST API + MCP tools</li> <li>Architecture - System design</li> <li>Self-Hosting - Production deployment</li> <li>Memory Export/Import - Backup guide</li> </ul>"},{"location":"#community","title":"Community","text":"<ul> <li>GitHub - Source code &amp; issues</li> <li>PyPI - Package downloads</li> <li>Examples - Usage examples</li> </ul>"},{"location":"#status-v400-phase-c-complete","title":"Status: v4.0.0 (Phase C Complete)","text":"<p>Recently Completed: - \u2705 Phase A: MCP-First Foundation - \u2705 Phase B: Graph Memory - \u2705 Phase C: Remote MCP Server + Export/Import</p> <p>Features: - \u2705 31 MCP tools - \u2705 REST API (FastAPI) - \u2705 MCP over HTTP/SSE (ChatGPT Connector) - \u2705 API Key authentication - \u2705 Memory export/import (JSONL) - \u2705 Production Docker setup</p> <p>Coming Next: v4.0.0 stable release</p> <p>Built with \u2764\ufe0f for universal AI memory</p>"},{"location":"api-reference/","title":"API Reference - Kagura v4.0","text":"<p>REST API &amp; MCP Tools Documentation</p> <p>Comprehensive reference for Kagura's REST API and MCP tools.</p>"},{"location":"api-reference/#table-of-contents","title":"\ud83d\udcda Table of Contents","text":"<ol> <li>REST API - HTTP endpoints</li> <li>MCP over HTTP/SSE - ChatGPT Connector</li> <li>MCP Tools - Claude Desktop, stdio</li> <li>Authentication - API Keys</li> <li>OpenAPI Specification</li> </ol>"},{"location":"api-reference/#rest-api","title":"\ud83c\udf10 REST API","text":"<p>Base URL: <code>http://localhost:8080</code> (default)</p> <p>Interactive Docs: http://localhost:8080/docs</p>"},{"location":"api-reference/#authentication","title":"Authentication","text":"<p>v4.0.0: Optional API Key authentication</p> <pre><code># With API key\ncurl -H \"Authorization: Bearer kagura_abc123...\" \\\n     http://localhost:8080/api/v1/memory\n\n# Without (uses default_user)\ncurl http://localhost:8080/api/v1/memory\n</code></pre> <p>Headers: - <code>Authorization: Bearer &lt;api_key&gt;</code> - Optional API key - <code>X-User-ID: &lt;user_id&gt;</code> - Optional user identifier</p>"},{"location":"api-reference/#memory-operations","title":"Memory Operations","text":""},{"location":"api-reference/#post-apiv1memory","title":"POST /api/v1/memory","text":"<p>Create or update a memory.</p> <p>Request: <pre><code>{\n  \"key\": \"python_tips\",\n  \"value\": \"Always use type hints\",\n  \"scope\": \"persistent\",\n  \"tags\": [\"python\"],\n  \"importance\": 0.8\n}\n</code></pre></p> <p>Response (201 Created): <pre><code>{\n  \"key\": \"python_tips\",\n  \"value\": \"Always use type hints\",\n  \"scope\": \"persistent\",\n  \"tags\": [\"python\"],\n  \"importance\": 0.8\n}\n</code></pre></p>"},{"location":"api-reference/#get-apiv1memorykey","title":"GET /api/v1/memory/{key}","text":"<p>Retrieve a memory by key.</p> <p>Response (200 OK): <pre><code>{\n  \"key\": \"python_tips\",\n  \"value\": \"Always use type hints\",\n  \"scope\": \"persistent\"\n}\n</code></pre></p>"},{"location":"api-reference/#delete-apiv1memorykey","title":"DELETE /api/v1/memory/{key}","text":"<p>Delete a memory.</p> <p>Response (204 No Content)</p>"},{"location":"api-reference/#search-recall","title":"Search &amp; Recall","text":""},{"location":"api-reference/#post-apiv1recall","title":"POST /api/v1/recall","text":"<p>Semantic search using RAG.</p> <p>Request: <pre><code>{\n  \"query\": \"Python coding tips\",\n  \"k\": 5,\n  \"scope\": \"all\"\n}\n</code></pre></p> <p>Response (200 OK): <pre><code>{\n  \"results\": [\n    {\"key\": \"python_tips\", \"value\": \"...\", \"score\": 0.95}\n  ]\n}\n</code></pre></p>"},{"location":"api-reference/#get-apiv1search","title":"GET /api/v1/search","text":"<p>Full-text search.</p> <p>Query params: - <code>q</code>: Search query - <code>limit</code>: Max results (default: 10)</p>"},{"location":"api-reference/#graph-operations","title":"Graph Operations","text":""},{"location":"api-reference/#post-apiv1graphinteraction","title":"POST /api/v1/graph/interaction","text":"<p>Record AI-User interaction.</p> <p>Request: <pre><code>{\n  \"user_id\": \"jfk\",\n  \"query\": \"How do I use async?\",\n  \"response\": \"...\",\n  \"metadata\": {\"topic\": \"python\"}\n}\n</code></pre></p>"},{"location":"api-reference/#get-apiv1graphpatternuser_id","title":"GET /api/v1/graph/pattern/{user_id}","text":"<p>Analyze user patterns.</p> <p>Response: <pre><code>{\n  \"user_id\": \"jfk\",\n  \"total_interactions\": 150,\n  \"topics\": {\"python\": 45, \"docker\": 20},\n  \"learning_trajectory\": [...]\n}\n</code></pre></p>"},{"location":"api-reference/#system-endpoints","title":"System Endpoints","text":""},{"location":"api-reference/#get-apiv1health","title":"GET /api/v1/health","text":"<p>Health check.</p> <p>Response: <pre><code>{\n  \"status\": \"healthy\",\n  \"services\": {\n    \"database\": \"healthy\",\n    \"redis\": \"healthy\"\n  }\n}\n</code></pre></p>"},{"location":"api-reference/#get-apiv1metrics","title":"GET /api/v1/metrics","text":"<p>System metrics.</p> <p>Response: <pre><code>{\n  \"memories_count\": 150,\n  \"graph_nodes\": 87,\n  \"graph_edges\": 42,\n  \"storage_size_mb\": 12.5\n}\n</code></pre></p>"},{"location":"api-reference/#mcp-over-httpsse","title":"\ud83d\udd0c MCP over HTTP/SSE","text":"<p>Endpoint: <code>/mcp</code></p> <p>Protocol: MCP (Model Context Protocol) over HTTP/SSE</p> <p>Methods: - <code>GET /mcp</code> - SSE streaming (server \u2192 client) - <code>POST /mcp</code> - JSON-RPC requests (client \u2192 server) - <code>DELETE /mcp</code> - Session termination</p> <p>Authentication: <pre><code>curl -H \"Authorization: Bearer kagura_abc123...\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}' \\\n     http://localhost:8080/mcp\n</code></pre></p> <p>See: MCP over HTTP/SSE Guide</p>"},{"location":"api-reference/#mcp-tools","title":"\ud83d\udee0\ufe0f MCP Tools","text":"<p>Available via: Claude Desktop, stdio transport, HTTP/SSE</p>"},{"location":"api-reference/#memory-tools","title":"Memory Tools","text":""},{"location":"api-reference/#memory_store","title":"memory_store","text":"<p>Store information in memory.</p> <p>Parameters: - <code>user_id</code> (string, required) - User identifier - <code>agent_name</code> (string, required) - Agent name (\"global\" for cross-thread) - <code>key</code> (string, required) - Memory key - <code>value</code> (string, required) - Value to store - <code>scope</code> (string) - \"working\" or \"persistent\" (default: \"working\") - <code>tags</code> (string) - JSON array of tags (e.g., '[\"python\"]') - <code>importance</code> (number) - 0.0-1.0 (default: 0.5)</p> <p>Example: <pre><code>{\n  \"user_id\": \"jfk\",\n  \"agent_name\": \"global\",\n  \"key\": \"pref_language\",\n  \"value\": \"Python\",\n  \"scope\": \"persistent\",\n  \"tags\": \"[\\\"preferences\\\"]\",\n  \"importance\": 0.8\n}\n</code></pre></p>"},{"location":"api-reference/#memory_recall","title":"memory_recall","text":"<p>Search memories semantically.</p> <p>Parameters: - <code>user_id</code> (string, required) - <code>agent_name</code> (string, required) - <code>query</code> (string, required) - Search query - <code>k</code> (number) - Number of results (default: 5) - <code>scope</code> (string) - \"working\", \"persistent\", or \"all\"</p>"},{"location":"api-reference/#memory_search","title":"memory_search","text":"<p>Full-text + semantic search.</p> <p>Parameters: - <code>user_id</code>, <code>agent_name</code> (required) - <code>query</code> (string, required) - <code>limit</code> (number) - Max results</p>"},{"location":"api-reference/#memory_list","title":"memory_list","text":"<p>List all memories.</p>"},{"location":"api-reference/#memory_delete","title":"memory_delete","text":"<p>Delete a memory with audit logging.</p>"},{"location":"api-reference/#memory_feedback","title":"memory_feedback","text":"<p>Provide feedback on memory usefulness.</p> <p>Parameters: - <code>user_id</code>, <code>agent_name</code> (required) - <code>node_id</code> (string) - Memory to rate - <code>label</code> (string) - \"useful\", \"irrelevant\", or \"outdated\" - <code>weight</code> (number) - -1.0 to 1.0</p>"},{"location":"api-reference/#graph-tools","title":"Graph Tools","text":""},{"location":"api-reference/#memory_record_interaction","title":"memory_record_interaction","text":"<p>Record AI-User interaction.</p> <p>Parameters: - <code>user_id</code> (required) - <code>query</code>, <code>response</code> (required) - <code>metadata</code> (object) - Optional metadata</p>"},{"location":"api-reference/#memory_get_related","title":"memory_get_related","text":"<p>Get related memories via graph.</p> <p>Parameters: - <code>user_id</code>, <code>agent_name</code> (required) - <code>key</code> (string) - Starting memory - <code>depth</code> (number) - Traversal depth (default: 2)</p>"},{"location":"api-reference/#memory_get_user_pattern","title":"memory_get_user_pattern","text":"<p>Analyze user's interaction patterns.</p>"},{"location":"api-reference/#webapi-tools-safe-for-remote","title":"Web/API Tools (Safe for Remote)","text":"<ul> <li><code>brave_web_search</code> - Brave Search integration (replaces deprecated <code>web_search</code>)</li> <li><code>brave_local_search</code> - Brave Local Search for businesses/places</li> <li><code>brave_news_search</code> - Brave News Search</li> <li><code>brave_image_search</code> - Brave Image Search</li> <li><code>brave_video_search</code> - Brave Video Search</li> <li><code>web_scrape</code> - Scrape web pages</li> <li><code>youtube_summarize</code> - Summarize YouTube videos</li> <li><code>get_youtube_transcript</code> - Get video transcript</li> </ul>"},{"location":"api-reference/#file-tools-local-only","title":"File Tools (Local Only)","text":"<p>\u26d4 Blocked remotely for security: - <code>file_read</code> - Read local files - <code>file_write</code> - Write local files - <code>dir_list</code> - List directory contents - <code>shell_exec</code> - Execute shell commands</p> <p>Note: These tools are only available via local stdio MCP server (<code>kagura mcp serve</code>), NOT via HTTP/SSE (<code>/mcp</code> endpoint).</p>"},{"location":"api-reference/#authentication_1","title":"\ud83d\udd10 Authentication","text":""},{"location":"api-reference/#api-key-management","title":"API Key Management","text":"<pre><code># Create API key\nkagura api create-key --name \"my-key\"\n\n# List keys\nkagura api list-keys\n\n# Revoke key\nkagura api revoke-key --name \"my-key\"\n</code></pre>"},{"location":"api-reference/#using-api-keys","title":"Using API Keys","text":"<p>REST API: <pre><code>curl -H \"Authorization: Bearer kagura_abc123...\" \\\n     http://localhost:8080/api/v1/memory\n</code></pre></p> <p>MCP over HTTP/SSE: <pre><code>curl -H \"Authorization: Bearer kagura_abc123...\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\"}' \\\n     http://localhost:8080/mcp\n</code></pre></p> <p>User ID Extraction: - API keys are associated with <code>user_id</code> - Authenticated requests automatically use the key's <code>user_id</code> - Fallback to <code>default_user</code> if no authentication</p>"},{"location":"api-reference/#openapi-specification","title":"\ud83d\udcc4 OpenAPI Specification","text":"<p>Interactive Docs: http://localhost:8080/docs</p> <p>OpenAPI JSON: http://localhost:8080/openapi.json</p> <p>Download: <pre><code>curl http://localhost:8080/openapi.json &gt; openapi.json\n</code></pre></p>"},{"location":"api-reference/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>MCP Setup Guide - Claude Desktop</li> <li>MCP over HTTP/SSE - ChatGPT Connector</li> <li>Self-Hosting Guide - Production deployment</li> <li>Memory Export/Import - Backup and migration</li> <li>Architecture - System design</li> </ul> <p>Last Updated: 2025-10-27 Version: 4.0.0 API Version: v1</p>"},{"location":"architecture/","title":"Architecture - Kagura v4.0","text":"<p>Universal AI Memory Platform - System Design</p> <p>This document describes the architecture of Kagura v4.0 after Phase C completion.</p>"},{"location":"architecture/#high-level-overview","title":"\ud83c\udfd7\ufe0f High-Level Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  AI Platforms (MCP Clients)                     \u2502\n\u2502      Claude Desktop \u2022 ChatGPT \u2022 Gemini \u2022 Cursor \u2022 Cline         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 stdio (local)                    HTTP/SSE (remote)\u2502\n       \u2502                                                   \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  MCP Server        \u2502                    \u2502  MCP over HTTP/SSE    \u2502\n\u2502  (Local)           \u2502                    \u2502  (/mcp endpoint)      \u2502\n\u2502                    \u2502                    \u2502                       \u2502\n\u2502  All 31 tools \u2705   \u2502                    \u2502  24 safe tools only   \u2502\n\u2502  File ops \u2705       \u2502                    \u2502  File ops \u274c          \u2502\n\u2502  Shell exec \u2705     \u2502                    \u2502  Shell exec \u274c        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                                   \u2502\n       \u2502              Internal Python API                  \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502         Memory Manager                   \u2502\n          \u2502   (src/kagura/core/memory/manager.py)    \u2502\n          \u2502                                          \u2502\n          \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n          \u2502  \u2502 Working  \u2502 Context   \u2502 Persistent  \u2502 \u2502\n          \u2502  \u2502 Memory   \u2502 Memory    \u2502 Memory      \u2502 \u2502\n          \u2502  \u2502(In-Mem)  \u2502(Messages) \u2502(SQLite)     \u2502 \u2502\n          \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n          \u2502                                          \u2502\n          \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n          \u2502  \u2502  RAG (ChromaDB)                    \u2502 \u2502\n          \u2502  \u2502  \u2022 Working RAG                     \u2502 \u2502\n          \u2502  \u2502  \u2022 Persistent RAG                  \u2502 \u2502\n          \u2502  \u2502  \u2022 Semantic search                 \u2502 \u2502\n          \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n          \u2502                                          \u2502\n          \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n          \u2502  \u2502  Graph Memory (NetworkX)           \u2502 \u2502\n          \u2502  \u2502  \u2022 Relationships                   \u2502 \u2502\n          \u2502  \u2502  \u2022 Interaction history             \u2502 \u2502\n          \u2502  \u2502  \u2022 User patterns                   \u2502 \u2502\n          \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                  \u2502    Storage      \u2502\n                  \u2502  \u2022 SQLite       \u2502\n                  \u2502  \u2022 ChromaDB     \u2502\n                  \u2502  \u2022 Pickle files \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#phase-c-architecture-remote-mcp-server","title":"\ud83c\udd95 Phase C Architecture (Remote MCP Server)","text":""},{"location":"architecture/#remote-access-flow","title":"Remote Access Flow","text":"<pre><code>ChatGPT                         Your Server\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ChatGPT \u2502  HTTPS/SSE          \u2502    Caddy     \u2502\n\u2502Connector\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 (Port 443)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                       \u2502\n                               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                               \u2502  Kagura API   \u2502\n                               \u2502  (Port 8080)  \u2502\n                               \u2502               \u2502\n                               \u2502  /mcp         \u2502\u25c4\u2500 HTTP/SSE\n                               \u2502  /api/v1/*    \u2502\u25c4\u2500 REST\n                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                       \u2502\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                              \u2502 Memory Manager  \u2502\n                              \u2502  + Graph        \u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                       \u2502\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                              \u2502 PostgreSQL      \u2502\n                              \u2502 + pgvector      \u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#security-layers","title":"Security Layers","text":"<pre><code>1. API Key Authentication\n   \u251c\u2500 SHA256 hashed storage\n   \u251c\u2500 Optional expiration\n   \u2514\u2500 Audit trail (last_used_at)\n\n2. Tool Access Control\n   \u251c\u2500 Local context: All 31 tools \u2705\n   \u251c\u2500 Remote context: 24 safe tools only\n   \u2514\u2500 Dangerous tools filtered:\n      \u2022 file_read, file_write\n      \u2022 shell_exec\n      \u2022 media_open_*\n\n3. Network Security\n   \u251c\u2500 Caddy reverse proxy\n   \u251c\u2500 Automatic HTTPS (Let's Encrypt)\n   \u251c\u2500 CORS configuration\n   \u2514\u2500 Security headers (HSTS, XSS)\n</code></pre>"},{"location":"architecture/#component-details","title":"\ud83d\udce6 Component Details","text":""},{"location":"architecture/#1-mcp-server-srckaguramcp","title":"1. MCP Server (src/kagura/mcp/)","text":"<p>stdio Transport (local): - File: <code>src/kagura/cli/mcp.py</code> - Command: <code>kagura mcp serve</code> - Context: <code>local</code> (all tools available) - Clients: Claude Desktop, Cursor, Cline</p> <p>HTTP/SSE Transport (remote): - File: <code>src/kagura/api/routes/mcp_transport.py</code> - Endpoint: <code>/mcp</code> - Context: <code>remote</code> (safe tools only) - Clients: ChatGPT Connector, web browsers</p> <p>Tool Permissions: - File: <code>src/kagura/mcp/permissions.py</code> - Logic: <code>is_tool_allowed(tool_name, context)</code> - Default: Deny unknown tools (fail-safe)</p>"},{"location":"architecture/#2-memory-manager-srckaguracorememory","title":"2. Memory Manager (src/kagura/core/memory/)","text":"<p>Components: - <code>manager.py</code> - Main coordinator - <code>working.py</code> - In-memory temporary storage - <code>persistent.py</code> - SQLite-based long-term storage - <code>rag.py</code> - ChromaDB vector search - <code>export.py</code> - JSONL export/import</p> <p>Storage Scopes: - Working: Session-only, cleared after use - Persistent: Survives restarts, SQLite storage - Both: Indexed in RAG for semantic search</p>"},{"location":"architecture/#3-graph-memory-srckaguracoregraph","title":"3. Graph Memory (src/kagura/core/graph/)","text":"<p>Implementation: NetworkX-based</p> <p>Node Types: - <code>user</code> - User profiles - <code>topic</code> - Discussion topics - <code>memory</code> - Memory references - <code>interaction</code> - AI-User interactions</p> <p>Edge Types: - <code>related_to</code> - Related memories - <code>depends_on</code> - Dependencies - <code>learned_from</code> - Learning relationships - <code>works_on</code> - User activities</p> <p>Storage: Pickle files (<code>~/.kagura/graph.pkl</code>)</p>"},{"location":"architecture/#4-rest-api-srckaguraapi","title":"4. REST API (src/kagura/api/)","text":"<p>Framework: FastAPI</p> <p>Endpoints: - <code>/api/v1/memory</code> - Memory CRUD - <code>/api/v1/recall</code> - Semantic search - <code>/api/v1/search</code> - Full-text search - <code>/api/v1/graph/*</code> - Graph operations - <code>/api/v1/health</code> - Health check - <code>/api/v1/metrics</code> - System metrics - <code>/mcp</code> - MCP over HTTP/SSE \u2b50 NEW</p> <p>Authentication: - File: <code>src/kagura/api/auth.py</code> - Method: Bearer token (API keys) - Storage: SQLite (<code>~/.kagura/api_keys.db</code>) - Hashing: SHA256</p>"},{"location":"architecture/#data-flow","title":"\ud83d\udd04 Data Flow","text":""},{"location":"architecture/#memory-store-flow","title":"Memory Store Flow","text":"<pre><code>1. MCP Client (Claude/ChatGPT)\n   \u2514\u2500\u25ba MCP Tool Call: memory_store(...)\n\n2. MCP Server (stdio or HTTP/SSE)\n   \u2514\u2500\u25ba Route to tool_registry\n\n3. Built-in Tool (src/kagura/mcp/builtin/memory.py)\n   \u2514\u2500\u25ba Call MemoryManager.store()\n\n4. Memory Manager\n   \u251c\u2500\u25ba Working memory (if scope=\"working\")\n   \u251c\u2500\u25ba Persistent memory (if scope=\"persistent\")\n   \u2514\u2500\u25ba RAG indexing (both scopes)\n\n5. Storage\n   \u251c\u2500\u25ba SQLite (persistent)\n   \u251c\u2500\u25ba ChromaDB (vectors)\n   \u2514\u2500\u25ba In-memory dict (working)\n</code></pre>"},{"location":"architecture/#memory-recall-flow","title":"Memory Recall Flow","text":"<pre><code>1. MCP Tool Call: memory_recall(query=\"Python tips\", k=5)\n\n2. Memory Manager\n   \u2514\u2500\u25ba Query RAG (vector similarity)\n\n3. RAG Search\n   \u251c\u2500\u25ba Embed query (text-embedding-3-small)\n   \u251c\u2500\u25ba Search ChromaDB collections\n   \u2514\u2500\u25ba Return top-k results\n\n4. Return to client\n   \u2514\u2500\u25ba Formatted results with scores\n</code></pre>"},{"location":"architecture/#security-architecture","title":"\ud83d\udd10 Security Architecture","text":""},{"location":"architecture/#authentication-flow","title":"Authentication Flow","text":"<pre><code>1. Client Request\n   \u2514\u2500\u25ba Authorization: Bearer kagura_abc123...\n\n2. API Gateway (/mcp or /api/v1/*)\n   \u2514\u2500\u25ba Extract Bearer token\n\n3. API Key Manager (src/kagura/api/auth.py)\n   \u251c\u2500\u25ba Hash provided key (SHA256)\n   \u251c\u2500\u25ba Query api_keys.db\n   \u251c\u2500\u25ba Check expiration &amp; revocation\n   \u2514\u2500\u25ba Extract user_id\n\n4. Request Processing\n   \u2514\u2500\u25ba Use authenticated user_id for memory operations\n</code></pre>"},{"location":"architecture/#tool-filtering-remote-context","title":"Tool Filtering (Remote Context)","text":"<pre><code>1. create_mcp_server(context=\"remote\")\n\n2. handle_list_tools()\n   \u251c\u2500\u25ba Get all registered tools (31 total)\n   \u251c\u2500\u25ba Filter by TOOL_PERMISSIONS\n   \u2514\u2500\u25ba Return safe tools only (24)\n\n3. Client sees:\n   \u2705 memory_* tools\n   \u2705 web_* tools\n   \u274c file_* tools (blocked)\n   \u274c shell_exec (blocked)\n</code></pre>"},{"location":"architecture/#data-model","title":"\ud83d\udcbe Data Model","text":""},{"location":"architecture/#memory-record","title":"Memory Record","text":"<pre><code>{\n    \"key\": str,                  # Unique identifier\n    \"value\": Any,                # Stored data (JSON serializable)\n    \"user_id\": str,              # Owner (v4.0+)\n    \"agent_name\": str,           # Agent scope\n    \"scope\": \"working|persistent\",\n    \"tags\": List[str],           # Categorization\n    \"importance\": float,         # 0.0-1.0\n    \"created_at\": datetime,\n    \"updated_at\": datetime,\n    \"metadata\": Dict[str, Any]   # Additional metadata\n}\n</code></pre>"},{"location":"architecture/#graph-node","title":"Graph Node","text":"<pre><code>{\n    \"id\": str,                   # Node identifier\n    \"type\": str,                 # Node type (user, topic, memory, interaction)\n    \"data\": Dict[str, Any],      # Node attributes\n}\n</code></pre>"},{"location":"architecture/#graph-edge","title":"Graph Edge","text":"<pre><code>{\n    \"src\": str,                  # Source node ID\n    \"dst\": str,                  # Destination node ID\n    \"type\": str,                 # Relationship type\n    \"weight\": float,             # 0.0-1.0\n}\n</code></pre>"},{"location":"architecture/#deployment-architecture","title":"\ud83d\udcca Deployment Architecture","text":""},{"location":"architecture/#local-development","title":"Local Development","text":"<pre><code>Developer Machine\n\u251c\u2500\u2500 SQLite (~/.kagura/memory.db)\n\u251c\u2500\u2500 ChromaDB (~/.kagura/chromadb/)\n\u251c\u2500\u2500 Graph pickle (~/.kagura/graph.pkl)\n\u2514\u2500\u2500 API Keys (~/.kagura/api_keys.db)\n</code></pre>"},{"location":"architecture/#production-deployment","title":"Production Deployment","text":"<pre><code>Docker Stack (docker-compose.prod.yml)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            Caddy (Port 443)             \u2502\n\u2502     Automatic HTTPS, Reverse Proxy      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       Kagura API (Port 8080)            \u2502\n\u2502    FastAPI + MCP over HTTP/SSE          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                      \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   PostgreSQL    \u2502   \u2502     Redis       \u2502\n\u2502   + pgvector    \u2502   \u2502   (Caching)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nVolumes:\n\u251c\u2500\u2500 postgres_data  - Database persistence\n\u251c\u2500\u2500 redis_data     - Redis persistence\n\u251c\u2500\u2500 kagura_data    - Memory exports, etc.\n\u2514\u2500\u2500 caddy_data     - SSL certificates\n</code></pre>"},{"location":"architecture/#exportimport-system","title":"\ud83d\udd04 Export/Import System","text":""},{"location":"architecture/#export-format-jsonl","title":"Export Format (JSONL)","text":"<pre><code>backup/\n\u251c\u2500\u2500 memories.jsonl      # All memory records\n\u251c\u2500\u2500 graph.jsonl         # Graph nodes &amp; edges\n\u2514\u2500\u2500 metadata.json       # Export metadata\n</code></pre> <p>Example record: <pre><code>{\"type\":\"memory\",\"scope\":\"persistent\",\"key\":\"python_tips\",\"value\":\"Use type hints\",\"user_id\":\"jfk\",\"agent_name\":\"global\",\"tags\":[\"python\"],\"importance\":0.8,\"exported_at\":\"2025-10-27T10:00:00Z\"}\n</code></pre></p>"},{"location":"architecture/#design-principles","title":"\ud83d\udcd0 Design Principles","text":""},{"location":"architecture/#1-mcp-first","title":"1. MCP-First","text":"<p>All functionality exposed via MCP tools first, then REST API.</p>"},{"location":"architecture/#2-multi-user-from-day-1","title":"2. Multi-User from Day 1","text":"<p>All operations scoped by <code>user_id</code> (Phase C foundation).</p>"},{"location":"architecture/#3-security-by-default","title":"3. Security by Default","text":"<p>Remote access auto-filtered for safety.</p>"},{"location":"architecture/#4-data-portability","title":"4. Data Portability","text":"<p>Complete export/import in human-readable JSONL.</p>"},{"location":"architecture/#5-fail-safe","title":"5. Fail-Safe","text":"<p>Unknown tools denied by default in remote context.</p>"},{"location":"architecture/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>Getting Started</li> <li>MCP Setup Guide</li> <li>MCP over HTTP/SSE</li> <li>Self-Hosting Guide</li> <li>API Reference</li> </ul> <p>Last Updated: 2025-10-27 Version: 4.0.0 Phase: C Complete</p>"},{"location":"getting-started/","title":"Getting Started with Kagura AI v4.0","text":"<p>Universal AI Memory Platform - 10-minute setup</p> <p>Kagura is a universal memory layer that connects all your AI platforms (Claude, ChatGPT, Gemini, etc.) with shared context and memory.</p>"},{"location":"getting-started/#what-is-kagura-v40","title":"\ud83d\udccb What is Kagura v4.0?","text":"<p>Kagura v4.0 = MCP-native Universal Memory</p> <ul> <li>For Claude Desktop: Local MCP server with all 31 tools</li> <li>For ChatGPT: HTTP/SSE connector with memory access</li> <li>For Teams: Self-hosted API with authentication</li> <li>For Developers: REST API + Python SDK</li> </ul>"},{"location":"getting-started/#quick-start-choose-your-path","title":"\ud83d\ude80 Quick Start (Choose Your Path)","text":""},{"location":"getting-started/#path-1-claude-desktop-user-recommended","title":"Path 1: Claude Desktop User (Recommended)","text":"<p>Setup time: 5 minutes</p> <pre><code># Install Kagura\npip install kagura-ai[full]\n\n# Auto-configure Claude Desktop\nkagura mcp install\n\n# Restart Claude Desktop\n# That's it! Kagura is now available in Claude\n</code></pre> <p>Try it in Claude Desktop: <pre><code>\"Remember: I prefer Python for backend development\"\n\"What do you know about my preferences?\"\n</code></pre></p> <p>See: MCP Setup Guide</p>"},{"location":"getting-started/#path-2-chatgpt-connector-user","title":"Path 2: ChatGPT Connector User","text":"<p>Setup time: 10 minutes</p> <ol> <li> <p>Start Kagura API:    <pre><code># Using Docker\ndocker compose up -d\n\n# Or local\npip install kagura-ai[api]\nuvicorn kagura.api.server:app --port 8000\n</code></pre></p> </li> <li> <p>Expose with ngrok (for testing):    <pre><code>ngrok http 8000\n# Get URL: https://abc123.ngrok.app\n</code></pre></p> </li> <li> <p>Configure ChatGPT:</p> </li> <li>Enable Developer Mode</li> <li>Add Connector:<ul> <li>URL: <code>https://abc123.ngrok.app/mcp</code></li> <li>Name: Kagura Memory</li> </ul> </li> </ol> <p>See: MCP over HTTP/SSE Guide</p>"},{"location":"getting-started/#path-3-self-hosted-production","title":"Path 3: Self-Hosted Production","text":"<p>Setup time: 30 minutes</p> <pre><code># Clone repository\ngit clone https://github.com/JFK/kagura-ai.git\ncd kagura-ai\n\n# Configure\ncp .env.example .env\nnano .env  # Set DOMAIN and POSTGRES_PASSWORD\n\n# Deploy\ndocker compose -f docker-compose.prod.yml up -d\n\n# Generate API key\ndocker compose -f docker-compose.prod.yml exec api \\\n  kagura api create-key --name \"production\"\n\n# Verify\ncurl https://your-domain.com/api/v1/health\n</code></pre> <p>See: Self-Hosting Guide</p>"},{"location":"getting-started/#key-features","title":"\ud83e\udde9 Key Features","text":""},{"location":"getting-started/#1-universal-memory","title":"1. Universal Memory","text":"<p>Store memories once, access from any AI:</p> <pre><code># Via MCP tool (Claude Desktop, ChatGPT, etc.)\nmemory_store(\n    user_id=\"jfk\",\n    agent_name=\"global\",\n    key=\"coding_style\",\n    value=\"Always use type hints in Python\",\n    scope=\"persistent\",\n    tags='[\"python\", \"best-practices\"]'\n)\n</code></pre>"},{"location":"getting-started/#2-graph-memory","title":"2. Graph Memory","text":"<p>Track relationships and patterns:</p> <pre><code># Record interaction\nmemory_record_interaction(\n    user_id=\"jfk\",\n    query=\"How do I write async functions?\",\n    response=\"...\",\n    metadata={\"topic\": \"python\", \"skill_level\": \"intermediate\"}\n)\n\n# Analyze patterns\nmemory_get_user_pattern(user_id=\"jfk\")\n</code></pre>"},{"location":"getting-started/#3-remote-access","title":"3. Remote Access","text":"<p>Access your memory from anywhere:</p> <ul> <li>ChatGPT Connector: HTTP/SSE transport</li> <li>API Keys: Secure authentication</li> <li>Tool Filtering: Automatic security (no file ops remotely)</li> </ul>"},{"location":"getting-started/#4-exportimport","title":"4. Export/Import","text":"<p>Own your data completely:</p> <pre><code># Backup\nkagura memory export --output ./backup\n\n# Restore\nkagura memory import --input ./backup\n</code></pre>"},{"location":"getting-started/#next-steps","title":"\ud83d\udcda Next Steps","text":""},{"location":"getting-started/#for-claude-desktop-users","title":"For Claude Desktop Users","text":"<ol> <li>Complete MCP Setup</li> <li>Try built-in tools: <code>kagura mcp tools</code></li> <li>Explore memory operations</li> </ol>"},{"location":"getting-started/#for-chatgpt-users","title":"For ChatGPT Users","text":"<ol> <li>Setup HTTP/SSE Connector</li> <li>Generate API key: <code>kagura api create-key</code></li> <li>Connect and test</li> </ol>"},{"location":"getting-started/#for-self-hosters","title":"For Self-Hosters","text":"<ol> <li>Follow Self-Hosting Guide</li> <li>Configure SSL/TLS with Caddy</li> <li>Set up backups</li> </ol>"},{"location":"getting-started/#for-developers","title":"For Developers","text":"<ol> <li>REST API Reference</li> <li>Architecture Overview</li> <li>Memory Export/Import</li> </ol>"},{"location":"getting-started/#available-commands","title":"\ud83d\udd0d Available Commands","text":"<pre><code># MCP Management\nkagura mcp serve           # Start MCP server (Claude Desktop)\nkagura mcp install         # Auto-configure Claude Desktop\nkagura mcp tools           # List available tools\nkagura mcp doctor          # Run diagnostics\nkagura mcp connect         # Configure remote connection\nkagura mcp test-remote     # Test remote API\n\n# API Key Management\nkagura api create-key      # Generate API key\nkagura api list-keys       # List all keys\nkagura api revoke-key      # Revoke key\n\n# Memory Management\nkagura memory export       # Export to JSONL\nkagura memory import       # Import from JSONL\n\n# System\nkagura --version           # Show version\n</code></pre>"},{"location":"getting-started/#support","title":"\ud83d\udcac Support","text":"<ul> <li>Documentation: https://kagura-ai.com/docs</li> <li>GitHub Issues: https://github.com/JFK/kagura-ai/issues</li> <li>Discussions: https://github.com/JFK/kagura-ai/discussions</li> </ul> <p>Version: 4.0.0 Protocol: MCP (Model Context Protocol) License: Apache 2.0</p>"},{"location":"mcp-http-setup/","title":"MCP over HTTP/SSE Setup Guide","text":"<p>Kagura AI v4.0.0 - Universal AI Memory Platform</p> <p>This guide explains how to connect to Kagura Memory via HTTP/SSE transport using the MCP (Model Context Protocol).</p>"},{"location":"mcp-http-setup/#overview","title":"\ud83d\udccb Overview","text":"<p>Kagura AI provides an HTTP/SSE endpoint at <code>/mcp</code> that implements the MCP protocol, enabling:</p> <ul> <li>ChatGPT Connectors: Connect ChatGPT to Kagura memory</li> <li>Other HTTP-based MCP clients: Any MCP client that supports HTTP transport</li> <li>Remote access: Access Kagura memory from anywhere</li> </ul> <p>Supported Operations: - GET <code>/mcp</code> - SSE streaming (server \u2192 client messages) - POST <code>/mcp</code> - JSON-RPC requests (client \u2192 server messages) - DELETE <code>/mcp</code> - Session termination</p>"},{"location":"mcp-http-setup/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"mcp-http-setup/#1-start-kagura-api-server","title":"1. Start Kagura API Server","text":"<pre><code># Install Kagura with API extras\npip install kagura-ai[api]\n\n# Start the API server\nuvicorn kagura.api.server:app --host 0.0.0.0 --port 8000\n</code></pre> <p>The <code>/mcp</code> endpoint will be available at <code>http://localhost:8000/mcp</code>.</p>"},{"location":"mcp-http-setup/#2-connect-chatgpt-developer-mode","title":"2. Connect ChatGPT (Developer Mode)","text":"<p>Note: ChatGPT Connector support is currently in developer preview.</p>"},{"location":"mcp-http-setup/#step-1-enable-developer-mode","title":"Step 1: Enable Developer Mode","text":"<ol> <li>Open ChatGPT settings</li> <li>Navigate to: Settings \u2192 Connectors \u2192 Advanced \u2192 Developer Mode</li> <li>Enable Developer Mode</li> </ol>"},{"location":"mcp-http-setup/#step-2-add-kagura-connector","title":"Step 2: Add Kagura Connector","text":"<p>Add a custom connector with the following settings:</p> <pre><code>{\n  \"name\": \"Kagura Memory\",\n  \"url\": \"http://localhost:8000/mcp\",\n  \"description\": \"Universal AI Memory Platform\",\n  \"authentication\": \"none\"\n}\n</code></pre> <p>For remote access (using ngrok):</p> <pre><code># Expose local server\nngrok http 8000\n\n# Use the ngrok URL in ChatGPT\n# Example: https://abc123.ngrok.app/mcp\n</code></pre>"},{"location":"mcp-http-setup/#step-3-test-the-connection","title":"Step 3: Test the Connection","text":"<p>In ChatGPT, try:</p> <pre><code>\"Remember: I prefer Python for backend development\"\n\"What do you know about my preferences?\"\n</code></pre> <p>Kagura will store and recall your preferences across all AI platforms!</p>"},{"location":"mcp-http-setup/#advanced-configuration","title":"\ud83d\udd27 Advanced Configuration","text":""},{"location":"mcp-http-setup/#api-authentication-phase-c-task-2","title":"API Authentication (Phase C Task 2 \u2705)","text":"<p>Kagura API now supports API Key authentication for secure remote access.</p>"},{"location":"mcp-http-setup/#generate-api-key","title":"Generate API Key","text":"<pre><code># Create a new API key\nkagura api create-key --name \"chatgpt-connector\"\n\n# Output:\n# \u2713 API key created successfully!\n# \u26a0\ufe0f  Save this key securely - it won't be shown again:\n#\n#   kagura_abc123xyz789...\n</code></pre> <p>\u26a0\ufe0f Important: The API key is only shown once during creation. Save it securely!</p>"},{"location":"mcp-http-setup/#use-api-key-in-requests","title":"Use API Key in Requests","text":"<pre><code># Use in HTTP requests\ncurl -H \"Authorization: Bearer kagura_abc123xyz789...\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}' \\\n     http://localhost:8000/mcp\n</code></pre>"},{"location":"mcp-http-setup/#manage-api-keys","title":"Manage API Keys","text":"<pre><code># List all API keys\nkagura api list-keys\n\n# List keys for specific user\nkagura api list-keys --user-id user_alice\n\n# Revoke a key (keeps audit history)\nkagura api revoke-key --name \"old-key\"\n\n# Permanently delete a key\nkagura api delete-key --name \"unused-key\"\n</code></pre>"},{"location":"mcp-http-setup/#api-key-options","title":"API Key Options","text":"<pre><code># Create key with expiration (90 days)\nkagura api create-key --name \"temp-key\" --expires 90\n\n# Create key for specific user\nkagura api create-key --name \"alice-key\" --user-id user_alice\n</code></pre>"},{"location":"mcp-http-setup/#tool-access-control-phase-c-task-3","title":"Tool Access Control (Phase C Task 3 \u2705)","text":"<p>Kagura automatically filters dangerous tools when accessed remotely via HTTP/SSE.</p>"},{"location":"mcp-http-setup/#safe-vs-dangerous-tools","title":"Safe vs. Dangerous Tools","text":"<p>\u2705 Safe for Remote Access (allowed via <code>/mcp</code>): - Memory tools: <code>memory_store</code>, <code>memory_recall</code>, <code>memory_search</code>, etc. - Web/API tools: <code>web_search</code>, <code>brave_web_search</code>, <code>youtube_summarize</code>, etc. - Multimodal tools: <code>multimodal_index</code>, <code>multimodal_search</code> - Telemetry tools: <code>telemetry_stats</code>, <code>telemetry_cost</code></p> <p>\u26d4 Dangerous - Local Only (blocked via <code>/mcp</code>): - File operations: <code>file_read</code>, <code>file_write</code>, <code>dir_list</code> - Shell execution: <code>shell_exec</code> - Local app execution: <code>media_open_audio</code>, <code>media_open_image</code>, <code>media_open_video</code></p>"},{"location":"mcp-http-setup/#why-tool-filtering","title":"Why Tool Filtering?","text":"<p>Remote access to file operations or shell commands would allow: - Reading sensitive files (<code>/etc/passwd</code>, API keys, etc.) - Writing malicious files - Executing arbitrary commands on your server</p> <p>Solution: The <code>/mcp</code> endpoint automatically filters out dangerous tools.</p>"},{"location":"mcp-http-setup/#checking-tool-permissions","title":"Checking Tool Permissions","text":"<pre><code># List all available tools (via HTTP/SSE)\ncurl -X POST http://localhost:8000/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}'\n\n# file_read, shell_exec, etc. will NOT appear in the list\n</code></pre>"},{"location":"mcp-http-setup/#local-vs-remote-context","title":"Local vs. Remote Context","text":"<pre><code># Local MCP server (stdio) - ALL tools available\nkagura mcp serve  # Exposes all 31 tools\n\n# Remote HTTP/SSE server - Only safe tools\nuvicorn kagura.api.server:app  # Exposes ~24 safe tools\n</code></pre>"},{"location":"mcp-http-setup/#user-id-header","title":"User ID Header","text":"<p>Specify which user's memory to access:</p> <pre><code># Request with user ID\ncurl -H \"X-User-ID: user_alice\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}' \\\n     http://localhost:8000/mcp\n</code></pre> <p>Default: If no <code>X-User-ID</code> header is provided, <code>default_user</code> is used.</p>"},{"location":"mcp-http-setup/#cors-configuration","title":"CORS Configuration","text":"<p>For production deployments, configure CORS in <code>src/kagura/api/server.py</code>:</p> <pre><code>app.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"https://chat.openai.com\"],  # Specify origins\n    allow_credentials=True,\n    allow_methods=[\"GET\", \"POST\", \"DELETE\"],\n    allow_headers=[\"*\"],\n)\n</code></pre>"},{"location":"mcp-http-setup/#testing-the-endpoint","title":"\ud83e\uddea Testing the Endpoint","text":""},{"location":"mcp-http-setup/#1-health-check","title":"1. Health Check","text":"<pre><code>curl http://localhost:8000/\n# Expected: {\"name\":\"Kagura Memory API\",\"version\":\"4.0.0\",...}\n</code></pre>"},{"location":"mcp-http-setup/#2-mcp-protocol-test","title":"2. MCP Protocol Test","text":""},{"location":"mcp-http-setup/#initialize-session","title":"Initialize Session","text":"<pre><code>curl -X POST http://localhost:8000/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"jsonrpc\": \"2.0\",\n    \"id\": 1,\n    \"method\": \"initialize\",\n    \"params\": {\n      \"protocolVersion\": \"2024-11-05\",\n      \"capabilities\": {},\n      \"clientInfo\": {\"name\": \"test-client\", \"version\": \"1.0.0\"}\n    }\n  }'\n</code></pre>"},{"location":"mcp-http-setup/#list-available-tools","title":"List Available Tools","text":"<pre><code>curl -X POST http://localhost:8000/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"jsonrpc\": \"2.0\",\n    \"id\": 2,\n    \"method\": \"tools/list\",\n    \"params\": {}\n  }'\n</code></pre>"},{"location":"mcp-http-setup/#store-a-memory","title":"Store a Memory","text":"<pre><code>curl -X POST http://localhost:8000/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-User-ID: test_user\" \\\n  -d '{\n    \"jsonrpc\": \"2.0\",\n    \"id\": 3,\n    \"method\": \"tools/call\",\n    \"params\": {\n      \"name\": \"kagura_tool_memory_store\",\n      \"arguments\": {\n        \"user_id\": \"test_user\",\n        \"agent_name\": \"global\",\n        \"key\": \"my_preference\",\n        \"value\": \"I prefer Python for backend\",\n        \"scope\": \"persistent\",\n        \"tags\": \"[\\\"preferences\\\"]\",\n        \"importance\": 0.8\n      }\n    }\n  }'\n</code></pre>"},{"location":"mcp-http-setup/#remote-connection-management-phase-c-task-4","title":"\ud83d\udd0c Remote Connection Management (Phase C Task 4 \u2705)","text":"<p>Kagura provides CLI commands to configure and test remote MCP connections.</p>"},{"location":"mcp-http-setup/#configure-remote-connection","title":"Configure Remote Connection","text":"<pre><code># Configure connection to remote Kagura API\nkagura mcp connect \\\n  --api-base https://my-kagura.example.com \\\n  --api-key kagura_abc123xyz789...\n\n# With custom user ID\nkagura mcp connect \\\n  --api-base https://api.kagura.io \\\n  --api-key kagura_xyz... \\\n  --user-id user_alice\n</code></pre> <p>Config saved to: <code>~/.kagura/remote-config.json</code></p>"},{"location":"mcp-http-setup/#test-remote-connection","title":"Test Remote Connection","text":"<pre><code># Verify remote connection works\nkagura mcp test-remote\n\n# Output:\n# Testing Remote MCP Connection\n#\n# 1. Testing API health...\n#    \u2713 API server is reachable\n#\n# 2. Testing /mcp endpoint...\n#    \u2713 MCP endpoint is accessible\n#\n# 3. Testing authentication...\n#    \u2713 API key configured: ***xyz789\n#\n# \u2713 All tests passed!\n</code></pre>"},{"location":"mcp-http-setup/#usage-notes","title":"Usage Notes","text":"<ul> <li><code>kagura mcp serve --remote</code> is planned for future releases (stdio \u2192 HTTP proxy)</li> <li>For now, use direct HTTP/SSE connection from ChatGPT Connector</li> <li>The <code>connect</code> and <code>test-remote</code> commands help manage remote credentials</li> </ul>"},{"location":"mcp-http-setup/#production-deployment","title":"\ud83c\udf10 Production Deployment","text":""},{"location":"mcp-http-setup/#docker-compose","title":"Docker Compose","text":"<pre><code>version: '3.8'\n\nservices:\n  kagura-api:\n    image: kagura-ai:4.0.0\n    ports:\n      - \"8000:8000\"\n    environment:\n      - KAGURA_API_KEY=${KAGURA_API_KEY}\n    command: uvicorn kagura.api.server:app --host 0.0.0.0 --port 8000\n    restart: always\n\n  nginx:\n    image: nginx:alpine\n    ports:\n      - \"443:443\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf\n      - ./ssl:/etc/ssl\n    depends_on:\n      - kagura-api\n</code></pre>"},{"location":"mcp-http-setup/#nginx-configuration","title":"Nginx Configuration","text":"<pre><code>server {\n    listen 443 ssl;\n    server_name your-domain.com;\n\n    ssl_certificate /etc/ssl/cert.pem;\n    ssl_certificate_key /etc/ssl/key.pem;\n\n    location /mcp {\n        proxy_pass http://kagura-api:8000/mcp;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n\n        # SSE support\n        proxy_buffering off;\n        proxy_set_header X-Accel-Buffering no;\n    }\n}\n</code></pre>"},{"location":"mcp-http-setup/#troubleshooting","title":"\ud83d\udd0d Troubleshooting","text":""},{"location":"mcp-http-setup/#connection-refused","title":"Connection Refused","text":"<p>Problem: Cannot connect to <code>/mcp</code> endpoint</p> <p>Solutions: 1. Verify API server is running: <code>curl http://localhost:8000/</code> 2. Check firewall rules 3. Verify port 8000 is not in use</p>"},{"location":"mcp-http-setup/#406-not-acceptable","title":"406 Not Acceptable","text":"<p>Problem: Receiving HTTP 406 errors</p> <p>Cause: Missing <code>Accept</code> header for MCP protocol</p> <p>Solution: Include proper MCP headers in requests</p>"},{"location":"mcp-http-setup/#background-task-not-starting","title":"Background Task Not Starting","text":"<p>Problem: MCP server background task fails to start</p> <p>Cause: Event loop not available</p> <p>Solution: Ensure the first request to <code>/mcp</code> is made after the API server has fully started</p>"},{"location":"mcp-http-setup/#api-reference","title":"\ud83d\udcda API Reference","text":""},{"location":"mcp-http-setup/#available-mcp-tools","title":"Available MCP Tools","text":"<p>When connected via <code>/mcp</code>, the following tools are available:</p>"},{"location":"mcp-http-setup/#memory-tools","title":"Memory Tools","text":"<ul> <li><code>kagura_tool_memory_store</code> - Store information</li> <li><code>kagura_tool_memory_recall</code> - Semantic search</li> <li><code>kagura_tool_memory_search</code> - Full-text search</li> <li><code>kagura_tool_memory_list</code> - List all memories</li> <li><code>kagura_tool_memory_delete</code> - Delete memory</li> </ul>"},{"location":"mcp-http-setup/#graph-tools-if-enabled","title":"Graph Tools (if enabled)","text":"<ul> <li><code>kagura_tool_graph_link</code> - Link memories</li> <li><code>kagura_tool_graph_query</code> - Query knowledge graph</li> </ul> <p>For full tool documentation, call <code>tools/list</code> via the MCP protocol.</p>"},{"location":"mcp-http-setup/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>MCP Protocol Specification</li> <li>Kagura API Reference</li> <li>ChatGPT Connectors Documentation</li> <li>Self-Hosting Guide (coming soon)</li> </ul>"},{"location":"mcp-http-setup/#support","title":"\ud83d\udcac Support","text":"<ul> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> </ul> <p>Last Updated: 2025-10-27 Version: 4.0.0</p>"},{"location":"mcp-setup/","title":"MCP Setup Guide - Claude Desktop Integration","text":"<p>Connect Kagura to Claude Desktop in 2 minutes</p> <p>This guide shows how to integrate Kagura's universal memory with Claude Desktop using the Model Context Protocol (MCP).</p>"},{"location":"mcp-setup/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<ul> <li>Kagura AI v4.0+ installed</li> <li>Claude Desktop (supports MCP)</li> </ul>"},{"location":"mcp-setup/#automatic-setup-recommended","title":"\u26a1 Automatic Setup (Recommended)","text":"<p>Kagura can automatically configure Claude Desktop for you:</p> <pre><code># Install Kagura MCP server to Claude Desktop\nkagura mcp install\n</code></pre> <p>Output: <pre><code>\u2705 Successfully installed!\n\nConfiguration:\n  Server name: kagura-memory\n  Command: kagura mcp serve\n  Config file: ~/.config/claude/claude_desktop_config.json\n\nNext steps:\n  1. Restart Claude Desktop\n  2. Start a new conversation\n  3. Try: 'Remember that I prefer Python'\n</code></pre></p> <p>That's it! Kagura is now connected to Claude Desktop.</p>"},{"location":"mcp-setup/#manual-setup-alternative","title":"\ud83d\udd27 Manual Setup (Alternative)","text":"<p>If automatic setup doesn't work, you can manually edit the config file.</p>"},{"location":"mcp-setup/#step-1-locate-claude-desktop-config","title":"Step 1: Locate Claude Desktop Config","text":"<p>macOS/Linux: <pre><code>~/.config/claude/claude_desktop_config.json\n</code></pre></p> <p>Windows: <pre><code>%APPDATA%\\Claude\\claude_desktop_config.json\n</code></pre></p>"},{"location":"mcp-setup/#step-2-edit-configuration","title":"Step 2: Edit Configuration","text":"<p>Add Kagura to the <code>mcpServers</code> section:</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura-memory\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {}\n    }\n  }\n}\n</code></pre> <p>Full example: <pre><code>{\n  \"mcpServers\": {\n    \"kagura-memory\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {}\n    },\n    \"other-server\": {\n      \"command\": \"other-command\",\n      \"args\": [\"serve\"]\n    }\n  }\n}\n</code></pre></p>"},{"location":"mcp-setup/#step-3-restart-claude-desktop","title":"Step 3: Restart Claude Desktop","text":"<p>Close and reopen Claude Desktop to apply changes.</p>"},{"location":"mcp-setup/#verify-integration","title":"\u2705 Verify Integration","text":""},{"location":"mcp-setup/#method-1-ask-claude","title":"Method 1: Ask Claude","text":"<p>Start a new conversation in Claude Desktop and try:</p> <p>You: \"Remember that I prefer Python over JavaScript for backend projects\"</p> <p>Claude will use the <code>memory_store</code> tool to save this.</p> <p>You: \"What programming languages do I prefer?\"</p> <p>Claude will use <code>memory_recall</code> or <code>memory_search</code> to retrieve the information.</p>"},{"location":"mcp-setup/#method-2-check-diagnostics","title":"Method 2: Check Diagnostics","text":"<pre><code>kagura mcp doctor\n</code></pre> <p>Look for: <pre><code>Claude Desktop \u2502 \u2705 configured \u2502 Kagura MCP server configured\n</code></pre></p>"},{"location":"mcp-setup/#available-memory-tools","title":"\ud83e\udde0 Available Memory Tools","text":"<p>Once integrated, Claude has access to these memory tools:</p>"},{"location":"mcp-setup/#core-tools","title":"Core Tools","text":"Tool Purpose Example memory_store Save information \"Remember X\" memory_recall Get by key \"What did I say about Y?\" memory_search Semantic search \"Find memories about Z\" memory_list List all memories \"What do you remember about me?\" memory_feedback Mark useful/outdated Automatic memory_delete Forget information \"Forget about X\""},{"location":"mcp-setup/#memory-scopes","title":"Memory Scopes","text":"<ul> <li>working: Temporary, session-only (default)</li> <li>persistent: Saved to disk, survives restart</li> </ul>"},{"location":"mcp-setup/#example-interactions","title":"Example Interactions","text":"<p>Store persistent memory:</p> <p>\"Remember that my favorite Python library is FastAPI. This is important and should be persistent.\"</p> <p>Search memories:</p> <p>\"What do you know about my coding preferences?\"</p> <p>Feedback (automatic):</p> <p>Claude automatically marks memories as \"useful\" when they help answer your questions.</p> <p>Delete:</p> <p>\"Forget about my old JavaScript preference\"</p>"},{"location":"mcp-setup/#troubleshooting","title":"\ud83d\udd0d Troubleshooting","text":""},{"location":"mcp-setup/#claude-desktop-doesnt-see-kagura-tools","title":"Claude Desktop doesn't see Kagura tools","text":"<p>Check 1: Verify installation <pre><code>kagura mcp doctor\n</code></pre></p> <p>Check 2: Restart Claude Desktop - Quit Claude Desktop completely - Reopen it - Start a new conversation</p> <p>Check 3: Check logs <pre><code># Claude Desktop logs (macOS)\ntail -f ~/Library/Logs/Claude/mcp*.log\n</code></pre></p>"},{"location":"mcp-setup/#kagura-command-not-found","title":"\"kagura command not found\"","text":"<p>Solution: Use full path in config</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura-memory\": {\n      \"command\": \"/full/path/to/kagura\",\n      \"args\": [\"mcp\", \"serve\"]\n    }\n  }\n}\n</code></pre> <p>Find full path: <pre><code>which kagura\n# Output: /home/user/.local/bin/kagura\n</code></pre></p>"},{"location":"mcp-setup/#memory-not-persisting-across-conversations","title":"Memory not persisting across conversations","text":"<p>Cause: Using <code>scope=\"working\"</code> (default)</p> <p>Solution: Explicitly use <code>scope=\"persistent\"</code></p> <p>Or tell Claude:</p> <p>\"Remember this permanently: I prefer Python\"</p>"},{"location":"mcp-setup/#uninstall","title":"\ud83d\udeab Uninstall","text":"<p>To remove Kagura from Claude Desktop:</p> <pre><code>kagura mcp uninstall\n</code></pre> <p>This removes the configuration but does not delete your stored memories.</p>"},{"location":"mcp-setup/#related","title":"\ud83d\udd17 Related","text":"<ul> <li>Getting Started - Installation guide</li> <li>API Reference - REST API docs</li> <li>Architecture - System design</li> </ul> <p>Version: 4.0.0a Last updated: 2025-10-26</p>"},{"location":"memory-export/","title":"Memory Export/Import Guide","text":"<p>Kagura AI v4.0.0 - Universal AI Memory Platform</p> <p>This guide explains how to export and import your Kagura memory data for backup, migration, or GDPR compliance.</p>"},{"location":"memory-export/#overview","title":"\ud83d\udccb Overview","text":"<p>Kagura provides export/import functionality in JSONL (JSON Lines) format:</p> <ul> <li>Human-readable - Plain text JSON, one record per line</li> <li>Portable - Works across different machines and versions</li> <li>Comprehensive - Exports memories, graph data, and metadata</li> <li>GDPR-compliant - Complete data export for user requests</li> </ul>"},{"location":"memory-export/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"memory-export/#export-all-data","title":"Export All Data","text":"<pre><code># Export everything to ./backup directory\nkagura memory export --output ./backup\n\n# Output:\n# \u2713 Export completed successfully!\n#\n# Exported:\n#   \u2022 Memories: 150\n#   \u2022 Graph nodes: 87\n#   \u2022 Graph edges: 42\n#\n# Files created:\n#   \u2022 memories.jsonl\n#   \u2022 graph.jsonl\n#   \u2022 metadata.json\n</code></pre>"},{"location":"memory-export/#import-from-backup","title":"Import from Backup","text":"<pre><code># Import from backup directory\nkagura memory import --input ./backup\n\n# Output:\n# \u2713 Import completed successfully!\n#\n# Imported:\n#   \u2022 Memories: 150\n#   \u2022 Graph nodes: 87\n#   \u2022 Graph edges: 42\n</code></pre>"},{"location":"memory-export/#export-options","title":"\ud83d\udd27 Export Options","text":""},{"location":"memory-export/#selective-export","title":"Selective Export","text":"<pre><code># Export only persistent memory (skip working memory)\nkagura memory export --output ./backup --no-working\n\n# Export only working memory (skip persistent)\nkagura memory export --output ./backup --no-persistent\n\n# Export without graph data\nkagura memory export --output ./backup --no-graph\n</code></pre>"},{"location":"memory-export/#user-specific-export","title":"User-Specific Export","text":"<pre><code># Export for specific user\nkagura memory export --output ./alice-backup --user-id user_alice\n\n# Export for specific agent\nkagura memory export --output ./backup --agent-name my_agent\n</code></pre>"},{"location":"memory-export/#import-options","title":"\ud83d\udce5 Import Options","text":""},{"location":"memory-export/#clear-existing-data","title":"Clear Existing Data","text":"<pre><code># Clear existing data before import (\u26a0\ufe0f DESTRUCTIVE)\nkagura memory import --input ./backup --clear\n\n# WARNING: This will delete all existing memory data!\n</code></pre>"},{"location":"memory-export/#import-for-specific-user","title":"Import for Specific User","text":"<pre><code># Import into specific user's memory\nkagura memory import --input ./backup --user-id user_alice --agent-name global\n</code></pre>"},{"location":"memory-export/#export-format","title":"\ud83d\udcc1 Export Format","text":""},{"location":"memory-export/#directory-structure","title":"Directory Structure","text":"<pre><code>backup/\n\u251c\u2500\u2500 memories.jsonl       # All memory records\n\u251c\u2500\u2500 graph.jsonl          # Graph nodes and edges (if enabled)\n\u2514\u2500\u2500 metadata.json        # Export metadata\n</code></pre>"},{"location":"memory-export/#jsonl-format","title":"JSONL Format","text":""},{"location":"memory-export/#memory-records-memoriesjsonl","title":"Memory Records (<code>memories.jsonl</code>)","text":"<pre><code>{\"type\":\"memory\",\"scope\":\"working\",\"key\":\"user_preference\",\"value\":\"Python backend\",\"user_id\":\"user_jfk\",\"agent_name\":\"global\",\"exported_at\":\"2025-10-27T10:30:00Z\"}\n{\"type\":\"memory\",\"scope\":\"persistent\",\"key\":\"api_key\",\"value\":\"***\",\"user_id\":\"user_jfk\",\"agent_name\":\"global\",\"created_at\":\"2025-10-26T12:00:00Z\",\"updated_at\":\"2025-10-27T10:00:00Z\",\"metadata\":{\"tags\":[\"config\"],\"importance\":0.9},\"exported_at\":\"2025-10-27T10:30:00Z\"}\n</code></pre> <p>Fields: - <code>type</code>: Always \"memory\" - <code>scope</code>: \"working\" or \"persistent\" - <code>key</code>: Memory key - <code>value</code>: Stored value (any JSON type) - <code>user_id</code>: User identifier - <code>agent_name</code>: Agent name - <code>created_at</code>, <code>updated_at</code>: Timestamps (persistent only) - <code>metadata</code>: Optional metadata dict - <code>exported_at</code>: Export timestamp</p>"},{"location":"memory-export/#graph-records-graphjsonl","title":"Graph Records (<code>graph.jsonl</code>)","text":"<pre><code>{\"type\":\"node\",\"id\":\"mem_001\",\"node_type\":\"memory\",\"data\":{\"key\":\"user_preference\"},\"exported_at\":\"2025-10-27T10:30:00Z\"}\n{\"type\":\"edge\",\"src\":\"mem_001\",\"dst\":\"mem_002\",\"rel_type\":\"related_to\",\"weight\":0.8,\"data\":{},\"exported_at\":\"2025-10-27T10:30:00Z\"}\n</code></pre> <p>Node Fields: - <code>type</code>: \"node\" - <code>id</code>: Node identifier - <code>node_type</code>: Node type (e.g., \"memory\", \"user\", \"topic\") - <code>data</code>: Node attributes</p> <p>Edge Fields: - <code>type</code>: \"edge\" - <code>src</code>: Source node ID - <code>dst</code>: Destination node ID - <code>rel_type</code>: Relationship type - <code>weight</code>: Edge weight (0.0-1.0)</p>"},{"location":"memory-export/#metadata-metadatajson","title":"Metadata (<code>metadata.json</code>)","text":"<pre><code>{\n  \"exported_at\": \"2025-10-27T10:30:00Z\",\n  \"user_id\": \"user_jfk\",\n  \"agent_name\": \"global\",\n  \"stats\": {\n    \"memories\": 150,\n    \"graph_nodes\": 87,\n    \"graph_edges\": 42\n  },\n  \"format_version\": \"1.0\"\n}\n</code></pre>"},{"location":"memory-export/#use-cases","title":"\ud83d\udd04 Use Cases","text":""},{"location":"memory-export/#1-backup-before-major-changes","title":"1. Backup Before Major Changes","text":"<pre><code># Before upgrading Kagura\nkagura memory export --output ./backup-before-upgrade\n\n# Upgrade Kagura\npip install --upgrade kagura-ai\n\n# If something goes wrong, restore\nkagura memory import --input ./backup-before-upgrade --clear\n</code></pre>"},{"location":"memory-export/#2-migration-to-new-machine","title":"2. Migration to New Machine","text":"<pre><code># On old machine\nkagura memory export --output ./kagura-backup\n\n# Copy ./kagura-backup to new machine\n\n# On new machine\npip install kagura-ai\nkagura memory import --input ./kagura-backup\n</code></pre>"},{"location":"memory-export/#3-gdpr-data-export","title":"3. GDPR Data Export","text":"<pre><code># Export all user data for GDPR request\nkagura memory export --output ./gdpr-export --user-id user_alice\n\n# Provide ./gdpr-export to user\n</code></pre>"},{"location":"memory-export/#4-selective-backup","title":"4. Selective Backup","text":"<pre><code># Daily backup (working memory only)\nkagura memory export --output ./daily-backup-$(date +%Y%m%d) --no-persistent\n\n# Weekly full backup\nkagura memory export --output ./weekly-backup-$(date +%Y%m%d)\n</code></pre>"},{"location":"memory-export/#important-notes","title":"\u26a0\ufe0f Important Notes","text":""},{"location":"memory-export/#data-loss-prevention","title":"Data Loss Prevention","text":"<ul> <li>Always backup before using <code>--clear</code> flag</li> <li>Test import on a copy first</li> <li>Verify roundtrip with critical data</li> </ul>"},{"location":"memory-export/#large-exports","title":"Large Exports","text":"<p>For large memory databases (&gt;10,000 records): - Export may take several minutes - JSONL files can be large (100MB+) - Consider selective exports by user or scope</p>"},{"location":"memory-export/#version-compatibility","title":"Version Compatibility","text":"<ul> <li>Format version 1.0 (current)</li> <li>Future versions will maintain backward compatibility</li> <li>Metadata includes <code>format_version</code> for validation</li> </ul>"},{"location":"memory-export/#testing-exportimport","title":"\ud83e\uddea Testing Export/Import","text":""},{"location":"memory-export/#verify-export","title":"Verify Export","text":"<pre><code># Export\nkagura memory export --output ./test-export\n\n# Check files exist\nls -lh ./test-export/\n\n# Expected:\n# memories.jsonl\n# graph.jsonl\n# metadata.json\n</code></pre>"},{"location":"memory-export/#verify-roundtrip","title":"Verify Roundtrip","text":"<pre><code># Store test data\necho 'manager.working.set(\"test\", \"value\")' | python -c \"...\"\n\n# Export\nkagura memory export --output ./roundtrip-test\n\n# Clear (\u26a0\ufe0f for testing only)\nrm ~/.kagura/memory.db\n\n# Import\nkagura memory import --input ./roundtrip-test\n\n# Verify data restored\n# (check with kagura mcp tools)\n</code></pre>"},{"location":"memory-export/#api-reference","title":"\ud83d\udcda API Reference","text":""},{"location":"memory-export/#python-api","title":"Python API","text":"<pre><code>from kagura.core.memory import MemoryManager\nfrom kagura.core.memory.export import MemoryExporter, MemoryImporter\n\n# Create manager\nmanager = MemoryManager(user_id=\"user_jfk\", agent_name=\"global\")\n\n# Export\nexporter = MemoryExporter(manager)\nstats = await exporter.export_all(\n    output_dir=\"./backup\",\n    include_working=True,\n    include_persistent=True,\n    include_graph=True,\n)\nprint(f\"Exported {stats['memories']} memories\")\n\n# Import\nimporter = MemoryImporter(manager)\nstats = await importer.import_all(\n    input_dir=\"./backup\",\n    clear_existing=False,  # Merge with existing data\n)\nprint(f\"Imported {stats['memories']} memories\")\n</code></pre>"},{"location":"memory-export/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>API Reference</li> <li>Memory Management</li> <li>Graph Memory</li> </ul> <p>Last Updated: 2025-10-27 Version: 4.0.0</p>"},{"location":"quickstart/","title":"Quick Start - Kagura AI","text":"<p>Get started with Kagura AI in 5 minutes.</p>"},{"location":"quickstart/#installation","title":"Installation","text":"<pre><code>pip install kagura-ai[full]\n</code></pre>"},{"location":"quickstart/#setup-api-key","title":"Setup API Key","text":"<pre><code>export OPENAI_API_KEY=sk-...\n</code></pre>"},{"location":"quickstart/#your-first-agent-30-seconds","title":"Your First Agent (30 seconds)","text":"<pre><code>from kagura import agent\n\n@agent\nasync def translator(text: str, lang: str = \"ja\") -&gt; str:\n    '''Translate to {{ lang }}: {{ text }}'''\n\n# Use it\nresult = await translator(\"Hello World\", lang=\"ja\")\nprint(result)  # \"\u3053\u3093\u306b\u3061\u306f\u4e16\u754c\"\n</code></pre>"},{"location":"quickstart/#type-safe-output","title":"Type-Safe Output","text":"<pre><code>from kagura import agent\nfrom pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    '''Extract person info from: {{ text }}'''\n\nperson = await extract_person(\"Alice is 30 and works as an engineer\")\nprint(person.name)  # \"Alice\" - fully typed!\n</code></pre>"},{"location":"quickstart/#with-built-in-tools","title":"With Built-in Tools","text":"<pre><code>@agent(tools=[\"web_search\"])\nasync def researcher(topic: str) -&gt; str:\n    '''Research {{ topic }} using web_search(query) tool.'''\n\nresult = await researcher(\"Latest Python frameworks\")\n# Uses Brave Search automatically\n</code></pre>"},{"location":"quickstart/#try-interactive-chat","title":"Try Interactive Chat","text":"<pre><code>kagura chat\n</code></pre> <p>Then try: <pre><code>[You] &gt; Read report.pdf and summarize\n[AI] &gt; (analyzes PDF, provides summary)\n\n[You] &gt; Search for similar reports\n[AI] &gt; (searches web, finds content)\n</code></pre></p> <p>All features work automatically.</p>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>SDK Guide - Learn @agent, @tool, memory</li> <li>Examples - 30+ code examples</li> <li>Chat Guide - Interactive chat features</li> </ul>"},{"location":"rest-api-usage/","title":"REST API Usage Guide","text":"<p>Kagura AI v4.0 - REST API\u6d3b\u7528\u30ac\u30a4\u30c9</p> <p>REST API\u306f\u3001MCP\u4ee5\u5916\u306e\u65b9\u6cd5\u3067Kagura\u30e1\u30e2\u30ea\u30fc\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b\u305f\u3081\u306e\u91cd\u8981\u306a\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3067\u3059\u3002</p>"},{"location":"rest-api-usage/#rest-api","title":"\ud83c\udfaf REST API\u306e\u6d3b\u7528\u30b7\u30fc\u30f3","text":""},{"location":"rest-api-usage/#1-agenttool","title":"1. \u30ab\u30b9\u30bf\u30e0Agent/Tool\u304b\u3089\u306e\u5229\u7528","text":"<p>Kagura\u306e<code>@agent</code>\u3084<code>@tool</code>\u304b\u3089\u3001REST API\u7d4c\u7531\u3067\u30e1\u30e2\u30ea\u30fc\u64cd\u4f5c\uff1a</p> <pre><code>import httpx\nfrom kagura import tool\n\n@tool\nasync def store_to_kagura(key: str, value: str) -&gt; str:\n    \"\"\"Store data to Kagura Memory via REST API\"\"\"\n    async with httpx.AsyncClient() as client:\n        response = await client.post(\n            \"http://localhost:8080/api/v1/memory\",\n            json={\n                \"key\": key,\n                \"value\": value,\n                \"scope\": \"persistent\",\n                \"tags\": [\"custom_tool\"]\n            },\n            headers={\"X-User-ID\": \"my_agent\"}\n        )\n        return f\"Stored: {response.json()}\"\n</code></pre> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - \u30ab\u30b9\u30bf\u30e0\u30c4\u30fc\u30eb\u304b\u3089\u30e1\u30e2\u30ea\u30fc\u4fdd\u5b58 - \u5916\u90e8\u30b7\u30b9\u30c6\u30e0\u3068\u306e\u7d71\u5408 - \u8907\u96d1\u306a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc</p>"},{"location":"rest-api-usage/#2","title":"2. \u4ed6\u306e\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u8a00\u8a9e\u304b\u3089\u306e\u5229\u7528","text":"<p>Node.js: <pre><code>// Node.js \u304b\u3089Kagura\u30e1\u30e2\u30ea\u30fc\u306b\u30a2\u30af\u30bb\u30b9\nconst axios = require('axios');\n\nasync function storeMemory(key, value) {\n  const response = await axios.post('http://localhost:8080/api/v1/memory', {\n    key: key,\n    value: value,\n    scope: 'persistent'\n  }, {\n    headers: {\n      'X-User-ID': 'nodejs_client',\n      'Authorization': 'Bearer kagura_your_api_key'\n    }\n  });\n  return response.data;\n}\n</code></pre></p> <p>Go: <pre><code>// Go \u304b\u3089Kagura\u30e1\u30e2\u30ea\u30fc\u306b\u30a2\u30af\u30bb\u30b9\npackage main\n\nimport (\n    \"bytes\"\n    \"encoding/json\"\n    \"net/http\"\n)\n\nfunc storeMemory(key, value string) error {\n    payload := map[string]interface{}{\n        \"key\": key,\n        \"value\": value,\n        \"scope\": \"persistent\",\n    }\n\n    body, _ := json.Marshal(payload)\n    req, _ := http.NewRequest(\"POST\",\n        \"http://localhost:8080/api/v1/memory\",\n        bytes.NewBuffer(body))\n    req.Header.Set(\"Content-Type\", \"application/json\")\n    req.Header.Set(\"X-User-ID\", \"go_client\")\n\n    client := &amp;http.Client{}\n    resp, err := client.Do(req)\n    return err\n}\n</code></pre></p> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - \u30de\u30eb\u30c1\u8a00\u8a9e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8 - \u65e2\u5b58\u306eNode.js/Go/Rust\u30a2\u30d7\u30ea\u3068\u306e\u7d71\u5408 - \u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3</p>"},{"location":"rest-api-usage/#3-web-ui","title":"3. Web UI\u30d5\u30ed\u30f3\u30c8\u30a8\u30f3\u30c9\u304b\u3089\u306e\u5229\u7528","text":"<p>React Example: <pre><code>// React \u30d5\u30ed\u30f3\u30c8\u30a8\u30f3\u30c9\u304b\u3089Kagura API\nimport axios from 'axios';\n\nconst KaguraClient = axios.create({\n  baseURL: 'http://localhost:8080/api/v1',\n  headers: {\n    'X-User-ID': 'web_user_123',\n    'Authorization': `Bearer ${localStorage.getItem('kagura_api_key')}`\n  }\n});\n\n// Memory\u4e00\u89a7\u53d6\u5f97\nasync function fetchMemories() {\n  const response = await KaguraClient.get('/memory');\n  return response.data;\n}\n\n// Semantic\u691c\u7d22\nasync function searchMemories(query: string) {\n  const response = await KaguraClient.post('/recall', {\n    query: query,\n    k: 10\n  });\n  return response.data.results;\n}\n</code></pre></p> <p>Vue Example: <pre><code>&lt;template&gt;\n  &lt;div&gt;\n    &lt;input v-model=\"query\" @keyup.enter=\"search\" /&gt;\n    &lt;div v-for=\"result in results\" :key=\"result.key\"&gt;\n      {{ result.value }}\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/template&gt;\n\n&lt;script setup&gt;\nimport { ref } from 'vue';\nimport axios from 'axios';\n\nconst query = ref('');\nconst results = ref([]);\n\nasync function search() {\n  const response = await axios.post(\n    'http://localhost:8080/api/v1/recall',\n    { query: query.value, k: 5 }\n  );\n  results.value = response.data.results;\n}\n&lt;/script&gt;\n</code></pre></p> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - \u30e1\u30e2\u30ea\u30fc\u7ba1\u7406Web UI - \u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9 - \u691c\u7d22\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9 - \u30b0\u30e9\u30d5\u30d3\u30b8\u30e5\u30a2\u30e9\u30a4\u30bc\u30fc\u30b7\u30e7\u30f3</p>"},{"location":"rest-api-usage/#4-webhook","title":"4. Webhook/\u81ea\u52d5\u5316\u30b9\u30af\u30ea\u30d7\u30c8\u304b\u3089\u306e\u5229\u7528","text":"<p>GitHub Webhook: <pre><code># GitHub webhook\u3067commit\u3092\u30e1\u30e2\u30ea\u30fc\u306b\u4fdd\u5b58\nfrom fastapi import FastAPI, Request\nimport httpx\n\napp = FastAPI()\n\n@app.post(\"/webhook/github\")\nasync def github_webhook(request: Request):\n    payload = await request.json()\n\n    if payload.get(\"commits\"):\n        for commit in payload[\"commits\"]:\n            # Kagura API\u306b\u4fdd\u5b58\n            async with httpx.AsyncClient() as client:\n                await client.post(\n                    \"http://localhost:8080/api/v1/memory\",\n                    json={\n                        \"key\": f\"commit_{commit['id']}\",\n                        \"value\": commit['message'],\n                        \"scope\": \"persistent\",\n                        \"tags\": [\"github\", \"commit\"]\n                    },\n                    headers={\"X-User-ID\": \"github_bot\"}\n                )\n\n    return {\"status\": \"ok\"}\n</code></pre></p> <p>\u5b9a\u671f\u30d0\u30c3\u30c1\u51e6\u7406: <pre><code># cron\u3067\u5b9a\u671f\u5b9f\u884c\u3057\u3066\u30e1\u30e2\u30ea\u30fc\u7d71\u8a08\u3092\u4fdd\u5b58\nimport httpx\nfrom datetime import datetime\n\nasync def daily_memory_snapshot():\n    async with httpx.AsyncClient() as client:\n        # \u30e1\u30c8\u30ea\u30af\u30b9\u53d6\u5f97\n        metrics = await client.get(\"http://localhost:8080/api/v1/metrics\")\n\n        # \u30b9\u30ca\u30c3\u30d7\u30b7\u30e7\u30c3\u30c8\u4fdd\u5b58\n        await client.post(\n            \"http://localhost:8080/api/v1/memory\",\n            json={\n                \"key\": f\"snapshot_{datetime.now().isoformat()}\",\n                \"value\": metrics.json(),\n                \"scope\": \"persistent\",\n                \"tags\": [\"metrics\", \"snapshot\"]\n            }\n        )\n</code></pre></p> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - CI/CD\u7d71\u5408\uff08\u30c6\u30b9\u30c8\u7d50\u679c\u4fdd\u5b58\u7b49\uff09 - \u76e3\u8996\u30b7\u30b9\u30c6\u30e0\u7d71\u5408 - \u30c7\u30fc\u30bf\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3 - \u30b9\u30b1\u30b8\u30e5\u30fc\u30e9\u30fc\u9023\u643a</p>"},{"location":"rest-api-usage/#5","title":"5. \u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\u9593\u901a\u4fe1","text":"<p>\u30b5\u30fc\u30d3\u30b9A \u2192 Kagura \u2192 \u30b5\u30fc\u30d3\u30b9B:</p> <pre><code># Service A: \u30c7\u30fc\u30bf\u3092Kagura\u306b\u4fdd\u5b58\nasync def process_and_store(data):\n    async with httpx.AsyncClient() as client:\n        await client.post(\n            \"http://kagura-api:8080/api/v1/memory\",\n            json={\n                \"key\": f\"user_{user_id}_preference\",\n                \"value\": data,\n                \"scope\": \"persistent\"\n            }\n        )\n\n# Service B: Kagura\u304b\u3089\u30c7\u30fc\u30bf\u53d6\u5f97\nasync def fetch_user_preference(user_id):\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\n            f\"http://kagura-api:8080/api/v1/memory/user_{user_id}_preference\"\n        )\n        return response.json()\n</code></pre> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - \u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\u9593\u306e\u72b6\u614b\u5171\u6709 - \u30bb\u30c3\u30b7\u30e7\u30f3\u7ba1\u7406 - \u30e6\u30fc\u30b6\u30fc\u30d7\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9\u5171\u6709</p>"},{"location":"rest-api-usage/#rest-api-vs-mcp","title":"\ud83d\udcca REST API vs MCP \u306e\u4f7f\u3044\u5206\u3051","text":"\u30b7\u30fc\u30f3 \u63a8\u5968 \u7406\u7531 Claude Desktop MCP (stdio) \u30cd\u30a4\u30c6\u30a3\u30d6\u7d71\u5408\u3001\u5168\u30c4\u30fc\u30eb\u5229\u7528\u53ef ChatGPT Connector MCP (HTTP/SSE) \u6a19\u6e96\u30d7\u30ed\u30c8\u30b3\u30eb\u3001\u7c21\u5358\u8a2d\u5b9a Python Agent REST API httpx\u7c21\u5358\u3001\u975e\u540c\u671f\u5bfe\u5fdc Web UI REST API \u30d5\u30ed\u30f3\u30c8\u30a8\u30f3\u30c9\u304b\u3089\u76f4\u63a5\u30a2\u30af\u30bb\u30b9 \u4ed6\u8a00\u8a9e REST API \u8a00\u8a9e\u975e\u4f9d\u5b58\u3001HTTP\u6a19\u6e96 Webhook REST API HTTP POST\u7c21\u5358 \u30d0\u30c3\u30c1\u51e6\u7406 REST API curl/httpx\u3067\u7c21\u5358"},{"location":"rest-api-usage/#python-sdkrest-api","title":"\ud83d\udee0\ufe0f Python SDK\u4f8b\uff08REST API\u6d3b\u7528\uff09","text":"<pre><code># Kagura REST API Client wrapper\nimport httpx\nfrom typing import Optional, List, Dict, Any\n\nclass KaguraClient:\n    \"\"\"Kagura Memory API Client\"\"\"\n\n    def __init__(\n        self,\n        base_url: str = \"http://localhost:8080\",\n        api_key: Optional[str] = None,\n        user_id: str = \"default_user\"\n    ):\n        self.base_url = base_url\n        self.headers = {\"X-User-ID\": user_id}\n        if api_key:\n            self.headers[\"Authorization\"] = f\"Bearer {api_key}\"\n\n    async def store(\n        self,\n        key: str,\n        value: str,\n        scope: str = \"persistent\",\n        tags: Optional[List[str]] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Store memory\"\"\"\n        async with httpx.AsyncClient() as client:\n            response = await client.post(\n                f\"{self.base_url}/api/v1/memory\",\n                json={\n                    \"key\": key,\n                    \"value\": value,\n                    \"scope\": scope,\n                    \"tags\": tags or []\n                },\n                headers=self.headers\n            )\n            response.raise_for_status()\n            return response.json()\n\n    async def recall(\n        self,\n        query: str,\n        k: int = 5\n    ) -&gt; List[Dict[str, Any]]:\n        \"\"\"Semantic search\"\"\"\n        async with httpx.AsyncClient() as client:\n            response = await client.post(\n                f\"{self.base_url}/api/v1/recall\",\n                json={\"query\": query, \"k\": k},\n                headers=self.headers\n            )\n            response.raise_for_status()\n            return response.json().get(\"results\", [])\n\n    async def get(self, key: str) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Get memory by key\"\"\"\n        async with httpx.AsyncClient() as client:\n            response = await client.get(\n                f\"{self.base_url}/api/v1/memory/{key}\",\n                headers=self.headers\n            )\n            if response.status_code == 404:\n                return None\n            response.raise_for_status()\n            return response.json()\n\n# Usage\nclient = KaguraClient(user_id=\"my_app\")\nawait client.store(\"pref\", \"Python\")\nresults = await client.recall(\"what's my preference?\")\n</code></pre> <p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9: - FastAPI/Flask \u30a2\u30d7\u30ea\u304b\u3089\u306e\u5229\u7528 - \u30c7\u30fc\u30bf\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3 - \u30ab\u30b9\u30bf\u30e0Agent</p>"},{"location":"rest-api-usage/#rest-api_1","title":"\ud83c\udf10 REST API \u306e\u5f37\u307f","text":""},{"location":"rest-api-usage/#vs-mcp","title":"vs MCP","text":"<p>REST API\u306e\u5229\u70b9: - \u2705 \u8a00\u8a9e\u975e\u4f9d\u5b58 - \u3069\u3093\u306a\u8a00\u8a9e\u304b\u3089\u3067\u3082\u30a2\u30af\u30bb\u30b9\u53ef - \u2705 \u6a19\u6e96\u7684 - HTTP/JSON\u3001\u5168\u958b\u767a\u8005\u304c\u7406\u89e3 - \u2705 \u30b7\u30f3\u30d7\u30eb - curl 1\u884c\u3067\u52d5\u4f5c\u78ba\u8a8d - \u2705 OpenAPI - \u81ea\u52d5\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u751f\u6210 - \u2705 Web\u7d71\u5408 - \u30d5\u30ed\u30f3\u30c8\u30a8\u30f3\u30c9\u304b\u3089\u76f4\u63a5\u30a2\u30af\u30bb\u30b9</p> <p>MCP\u306e\u5229\u70b9: - \u2705 \u6a19\u6e96\u5316 - AI\u30c4\u30fc\u30eb\u9023\u643a\u306e\u6a19\u6e96\u30d7\u30ed\u30c8\u30b3\u30eb - \u2705 \u30cd\u30a4\u30c6\u30a3\u30d6\u7d71\u5408 - Claude Desktop\u7b49\u3067\u81ea\u52d5\u8a8d\u8b58 - \u2705 \u30ea\u30c3\u30c1\u30c4\u30fc\u30eb - \u8907\u96d1\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u30fb\u30b9\u30ad\u30fc\u30de</p> <p>\u7d50\u8ad6: \u4e21\u65b9\u3092\u4f75\u7528\u3059\u308b\u306e\u304c\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9</p>"},{"location":"rest-api-usage/#rest-apiexamples","title":"\ud83d\udcdd \u63a8\u5968: REST API\u6d3b\u7528\u4f8b\u3092Examples\u306b\u8ffd\u52a0","text":"<p>\u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3092 <code>examples/</code> \u306b\u8ffd\u52a0\u3059\u308b\u3053\u3068\u3092\u63a8\u5968\uff1a</p> <ol> <li><code>examples/09_rest_api/</code></li> <li><code>python_client.py</code> - Python REST client\u4f8b</li> <li><code>fastapi_integration.py</code> - FastAPI\u30a2\u30d7\u30ea\u7d71\u5408</li> <li><code>webhook_example.py</code> - Webhook\u7d71\u5408</li> <li> <p><code>batch_processing.py</code> - \u30d0\u30c3\u30c1\u51e6\u7406\u4f8b</p> </li> <li> <p><code>examples/10_frontend/</code></p> </li> <li><code>react_example/</code> - React Web UI</li> <li> <p><code>vue_example/</code> - Vue.js\u4f8b</p> </li> <li> <p><code>examples/11_multi_language/</code></p> </li> <li><code>nodejs_client.js</code> - Node.js client</li> <li><code>go_client.go</code> - Go client</li> <li><code>rust_client.rs</code> - Rust client</li> </ol>"},{"location":"rest-api-usage/#_1","title":"\ud83d\udd17 \u95a2\u9023\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li>API Reference - \u5168\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8</li> <li>Getting Started</li> <li>MCP Setup - MCP vs REST\u6bd4\u8f03</li> </ul> <p>\u7d50\u8ad6: REST API\u306f\u524a\u9664\u305b\u305a\u3001\u7a4d\u6975\u7684\u306b\u6d3b\u7528\u3059\u3079\u304d\u91cd\u8981\u306a\u6a5f\u80fd\u3067\u3059\u3002</p> <p>Last Updated: 2025-10-27 Version: 4.0.0</p>"},{"location":"self-hosting/","title":"Self-Hosting Guide","text":"<p>Kagura AI v4.0.0 - Universal AI Memory Platform</p> <p>This guide explains how to self-host Kagura AI for production use with Docker.</p>"},{"location":"self-hosting/#overview","title":"\ud83d\udccb Overview","text":"<p>Self-hosting Kagura AI gives you: - Full control over your data - Multi-user support with authentication - Remote access from any MCP client - Production-ready setup with SSL/TLS</p> <p>Stack: - Kagura API - FastAPI server with MCP endpoint - PostgreSQL - Persistent storage with pgvector - Redis - Caching and job queue - Caddy - Reverse proxy with automatic HTTPS</p>"},{"location":"self-hosting/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"self-hosting/#prerequisites","title":"Prerequisites","text":"<ul> <li>Server: Ubuntu 22.04 LTS (or similar)</li> <li>Docker: 20.10+ and Docker Compose v2</li> <li>Domain: A domain name pointing to your server</li> <li>Ports: 80, 443 open</li> </ul>"},{"location":"self-hosting/#1-install-docker","title":"1. Install Docker","text":"<pre><code># Install Docker\ncurl -fsSL https://get.docker.com | sh\n\n# Install Docker Compose\nsudo apt-get update\nsudo apt-get install docker-compose-plugin\n\n# Verify\ndocker --version\ndocker compose version\n</code></pre>"},{"location":"self-hosting/#2-clone-repository","title":"2. Clone Repository","text":"<pre><code>git clone https://github.com/YourUsername/kagura-ai.git\ncd kagura-ai\n</code></pre>"},{"location":"self-hosting/#3-configure-environment","title":"3. Configure Environment","text":"<pre><code># Copy example env file\ncp .env.example .env\n\n# Edit .env\nnano .env\n</code></pre> <p>Required settings in <code>.env</code>:</p> <pre><code># Domain name (required for HTTPS)\nDOMAIN=your-domain.com\n\n# PostgreSQL password (required)\nPOSTGRES_PASSWORD=your_secure_password_here\n\n# Optional: API Key requirement\nAPI_KEY_REQUIRED=false  # Set to true to require API keys\n\n# Optional: CORS origins\nCORS_ORIGINS=https://chat.openai.com,https://claude.ai\n</code></pre>"},{"location":"self-hosting/#4-start-services","title":"4. Start Services","text":"<pre><code># Build and start\ndocker compose -f docker-compose.prod.yml up -d\n\n# Check logs\ndocker compose -f docker-compose.prod.yml logs -f\n\n# Check health\ncurl https://your-domain.com/api/v1/health\n</code></pre>"},{"location":"self-hosting/#configuration","title":"\ud83d\udd27 Configuration","text":""},{"location":"self-hosting/#environment-variables","title":"Environment Variables","text":"Variable Required Default Description <code>DOMAIN</code> \u2705 Yes - Your domain name <code>POSTGRES_PASSWORD</code> \u2705 Yes - Database password <code>POSTGRES_DB</code> No <code>kagura</code> Database name <code>POSTGRES_USER</code> No <code>kagura</code> Database user <code>LOG_LEVEL</code> No <code>warning</code> Log level (debug/info/warning/error) <code>CORS_ORIGINS</code> No * Allowed CORS origins (comma-separated) <code>API_KEY_REQUIRED</code> No <code>false</code> Require API key for all requests"},{"location":"self-hosting/#ssltls-configuration","title":"SSL/TLS Configuration","text":"<p>Caddy automatically obtains SSL certificates from Let's Encrypt.</p> <p>Requirements: 1. Domain must resolve to your server 2. Ports 80 and 443 must be accessible 3. Valid email for Let's Encrypt (Caddy will prompt)</p> <p>Manual SSL (if needed):</p> <p>Edit <code>Caddyfile</code>: <pre><code>your-domain.com {\n    tls your-email@example.com\n    # ... rest of config\n}\n</code></pre></p>"},{"location":"self-hosting/#security","title":"\ud83d\udd10 Security","text":""},{"location":"self-hosting/#1-api-key-authentication","title":"1. API Key Authentication","text":"<pre><code># Generate API key\ndocker compose -f docker-compose.prod.yml exec api kagura api create-key --name \"production\"\n\n# Output:\n# kagura_abc123xyz789...\n\n# Save securely and use in requests\ncurl -H \"Authorization: Bearer kagura_abc123...\" \\\n     https://your-domain.com/mcp\n</code></pre>"},{"location":"self-hosting/#2-firewall-configuration","title":"2. Firewall Configuration","text":"<pre><code># Allow HTTP/HTTPS only\nsudo ufw allow 80/tcp\nsudo ufw allow 443/tcp\nsudo ufw enable\n\n# Block direct database access\nsudo ufw deny 5432/tcp\n</code></pre>"},{"location":"self-hosting/#3-regular-updates","title":"3. Regular Updates","text":"<pre><code># Update Kagura\ncd kagura-ai\ngit pull\ndocker compose -f docker-compose.prod.yml build\ndocker compose -f docker-compose.prod.yml up -d\n\n# Update system packages\nsudo apt-get update &amp;&amp; sudo apt-get upgrade -y\n</code></pre>"},{"location":"self-hosting/#backup-restore","title":"\ud83d\udcbe Backup &amp; Restore","text":""},{"location":"self-hosting/#automated-backup","title":"Automated Backup","text":"<p>Create backup script <code>backup.sh</code>:</p> <pre><code>#!/bin/bash\nBACKUP_DIR=\"/backups/kagura-$(date +%Y%m%d)\"\nmkdir -p \"$BACKUP_DIR\"\n\n# Export memory data\ndocker compose -f docker-compose.prod.yml exec -T api \\\n  kagura memory export --output /app/data/export\n\n# Copy export from container\ndocker cp kagura-api-prod:/app/data/export \"$BACKUP_DIR/\"\n\n# Backup PostgreSQL\ndocker compose -f docker-compose.prod.yml exec -T postgres \\\n  pg_dump -U kagura kagura &gt; \"$BACKUP_DIR/postgres.sql\"\n\n# Compress\ntar -czf \"$BACKUP_DIR.tar.gz\" \"$BACKUP_DIR\"\nrm -rf \"$BACKUP_DIR\"\n\necho \"Backup saved to $BACKUP_DIR.tar.gz\"\n</code></pre> <p>Schedule with cron:</p> <pre><code># Run daily at 2 AM\n0 2 * * * /path/to/backup.sh\n</code></pre>"},{"location":"self-hosting/#restore-from-backup","title":"Restore from Backup","text":"<pre><code># Extract backup\ntar -xzf kagura-20251027.tar.gz\n\n# Import memory data\ndocker compose -f docker-compose.prod.yml exec api \\\n  kagura memory import --input /app/data/export\n\n# Restore PostgreSQL (if needed)\ndocker compose -f docker-compose.prod.yml exec -T postgres \\\n  psql -U kagura kagura &lt; postgres.sql\n</code></pre>"},{"location":"self-hosting/#monitoring","title":"\ud83d\udcca Monitoring","text":""},{"location":"self-hosting/#health-checks","title":"Health Checks","text":"<pre><code># API health\ncurl https://your-domain.com/api/v1/health\n\n# Expected:\n# {\"status\":\"healthy\",\"services\":{\"database\":\"healthy\",\"redis\":\"healthy\"}}\n\n# Service status\ndocker compose -f docker-compose.prod.yml ps\n</code></pre>"},{"location":"self-hosting/#logs","title":"Logs","text":"<pre><code># All services\ndocker compose -f docker-compose.prod.yml logs -f\n\n# API only\ndocker compose -f docker-compose.prod.yml logs -f api\n\n# Caddy access logs\ndocker compose -f docker-compose.prod.yml exec caddy \\\n  tail -f /var/log/caddy/access.log\n</code></pre>"},{"location":"self-hosting/#metrics","title":"Metrics","text":"<pre><code># Memory usage\ncurl https://your-domain.com/api/v1/metrics\n\n# Expected:\n# {\n#   \"memories_count\": 1500,\n#   \"graph_nodes\": 800,\n#   \"graph_edges\": 450,\n#   \"storage_size_mb\": 25.3\n# }\n</code></pre>"},{"location":"self-hosting/#maintenance","title":"\ud83d\udd27 Maintenance","text":""},{"location":"self-hosting/#update-kagura","title":"Update Kagura","text":"<pre><code>cd kagura-ai\ngit pull\ndocker compose -f docker-compose.prod.yml build api\ndocker compose -f docker-compose.prod.yml up -d api\n</code></pre>"},{"location":"self-hosting/#restart-services","title":"Restart Services","text":"<pre><code># Restart all\ndocker compose -f docker-compose.prod.yml restart\n\n# Restart API only\ndocker compose -f docker-compose.prod.yml restart api\n</code></pre>"},{"location":"self-hosting/#database-maintenance","title":"Database Maintenance","text":"<pre><code># Vacuum database (cleanup)\ndocker compose -f docker-compose.prod.yml exec postgres \\\n  psql -U kagura -c \"VACUUM ANALYZE;\"\n\n# Check database size\ndocker compose -f docker-compose.prod.yml exec postgres \\\n  psql -U kagura -c \"SELECT pg_size_pretty(pg_database_size('kagura'));\"\n</code></pre>"},{"location":"self-hosting/#connecting-clients","title":"\ud83c\udf10 Connecting Clients","text":""},{"location":"self-hosting/#chatgpt-connector","title":"ChatGPT Connector","text":"<ol> <li>Enable Developer Mode in ChatGPT</li> <li>Add connector:</li> <li>Name: Kagura Memory</li> <li>URL: <code>https://your-domain.com/mcp</code></li> <li>Authentication: Bearer token (if API key required)</li> </ol>"},{"location":"self-hosting/#claude-desktop-remote","title":"Claude Desktop (Remote)","text":"<p>Coming soon - stdio \u2192 HTTP proxy connector</p>"},{"location":"self-hosting/#custom-mcp-clients","title":"Custom MCP Clients","text":"<pre><code>import httpx\n\n# MCP over HTTP/SSE\nresponse = httpx.post(\n    \"https://your-domain.com/mcp\",\n    json={\n        \"jsonrpc\": \"2.0\",\n        \"id\": 1,\n        \"method\": \"tools/list\",\n        \"params\": {}\n    },\n    headers={\"Authorization\": \"Bearer kagura_your_api_key\"}\n)\n</code></pre>"},{"location":"self-hosting/#troubleshooting","title":"\ud83d\udc1b Troubleshooting","text":""},{"location":"self-hosting/#issue-caddy-cannot-obtain-ssl-certificate","title":"Issue: Caddy cannot obtain SSL certificate","text":"<p>Symptoms: HTTP works but HTTPS fails</p> <p>Solutions: 1. Verify domain DNS points to server: <code>nslookup your-domain.com</code> 2. Check ports 80/443 are accessible: <code>telnet your-domain.com 80</code> 3. Check Caddy logs: <code>docker logs kagura-caddy-prod</code> 4. Verify email is valid for Let's Encrypt</p>"},{"location":"self-hosting/#issue-api-returns-503-service-unavailable","title":"Issue: API returns 503 Service Unavailable","text":"<p>Symptoms: <code>/api/v1/health</code> returns 503</p> <p>Solutions: 1. Check database is healthy: <code>docker compose -f docker-compose.prod.yml ps postgres</code> 2. Check logs: <code>docker logs kagura-api-prod</code> 3. Verify DATABASE_URL is correct in <code>.env</code></p>"},{"location":"self-hosting/#issue-high-memory-usage","title":"Issue: High memory usage","text":"<p>Symptoms: Container using &gt;2GB RAM</p> <p>Solutions: 1. Enable Redis caching 2. Limit RAG vector database size 3. Run memory consolidation: <code>kagura memory export</code> then clear old data</p>"},{"location":"self-hosting/#issue-cannot-connect-from-chatgpt","title":"Issue: Cannot connect from ChatGPT","text":"<p>Symptoms: 401 Unauthorized or CORS errors</p> <p>Solutions: 1. Verify API key is valid: <code>kagura api list-keys</code> 2. Check CORS_ORIGINS includes <code>https://chat.openai.com</code> 3. Verify domain is accessible: <code>curl https://your-domain.com/mcp</code></p>"},{"location":"self-hosting/#performance-tuning","title":"\ud83d\udcc8 Performance Tuning","text":""},{"location":"self-hosting/#database-optimization","title":"Database Optimization","text":"<pre><code># Increase connection pool\n# Add to docker-compose.prod.yml api environment:\nDATABASE_POOL_SIZE=20\nDATABASE_MAX_OVERFLOW=10\n</code></pre>"},{"location":"self-hosting/#redis-caching","title":"Redis Caching","text":"<pre><code># Configure Redis for caching\n# Add to docker-compose.prod.yml redis command:\ncommand: redis-server --maxmemory 512mb --maxmemory-policy allkeys-lru\n</code></pre>"},{"location":"self-hosting/#api-workers","title":"API Workers","text":"<pre><code># Use gunicorn for multiple workers\n# Update api command in docker-compose.prod.yml:\ncommand: gunicorn kagura.api.server:app -w 4 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8080\n</code></pre>"},{"location":"self-hosting/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>MCP over HTTP/SSE Setup</li> <li>API Authentication (coming soon)</li> <li>Memory Export/Import</li> <li>API Reference</li> </ul>"},{"location":"self-hosting/#support","title":"\ud83d\udcac Support","text":"<ul> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> </ul> <p>Last Updated: 2025-10-27 Version: 4.0.0</p>"},{"location":"api/","title":"OpenAPI Specification","text":"<p>Kagura Memory API v4.0 - Complete OpenAPI Reference</p>"},{"location":"api/#overview","title":"\ud83d\udccb Overview","text":"<p>Kagura Memory API provides RESTful endpoints for memory management, graph operations, and system monitoring.</p> <p>OpenAPI Version: 3.1.0 API Version: 4.0.0</p>"},{"location":"api/#interactive-documentation","title":"\ud83d\udd17 Interactive Documentation","text":""},{"location":"api/#1-redocly-documentation-recommended","title":"1. Redocly Documentation (Recommended) \u2b50","text":"<p>Static HTML: index.html - Beautiful, interactive API explorer - Generated from <code>reference.yaml</code> using Redocly - No server required - open in browser - Build: <code>make build_docs</code></p>"},{"location":"api/#2-live-api-documentation-server-required","title":"2. Live API Documentation (Server Required)","text":"<p>When running the Kagura API server:</p> <p>Swagger UI: http://localhost:8080/docs - Interactive API testing - Try endpoints directly from browser - See request/response examples - Execute requests with authentication</p> <p>ReDoc: http://localhost:8080/redoc - Clean, readable API documentation - Search functionality - Code samples</p>"},{"location":"api/#3-openapi-yaml","title":"3. OpenAPI YAML","text":"<p>Spec File: reference.yaml - Source of truth for API specification - Use for client SDK generation - Import into Postman, Insomnia, etc.</p>"},{"location":"api/#openapi-specification-file","title":"\ud83d\udcc4 OpenAPI Specification File","text":"<p>File: <code>reference.yaml</code></p> <p>Download and use with your favorite tools:</p> <pre><code># Download spec\ncurl http://localhost:8080/openapi.json &gt; openapi.json\n\n# Generate client SDK\nnpx @openapitools/openapi-generator-cli generate \\\n  -i openapi.json \\\n  -g python \\\n  -o ./kagura-client\n\n# Validate spec\nnpx @stoplight/spectral-cli lint openapi.json\n</code></pre>"},{"location":"api/#api-endpoints","title":"\ud83c\udf10 API Endpoints","text":""},{"location":"api/#memory-operations","title":"Memory Operations","text":"Method Endpoint Description POST <code>/api/v1/memory</code> Create/update memory GET <code>/api/v1/memory</code> List memories GET <code>/api/v1/memory/{key}</code> Get memory by key PUT <code>/api/v1/memory/{key}</code> Update memory DELETE <code>/api/v1/memory/{key}</code> Delete memory"},{"location":"api/#search-recall","title":"Search &amp; Recall","text":"Method Endpoint Description GET <code>/api/v1/search</code> Full-text search POST <code>/api/v1/recall</code> Semantic search (RAG)"},{"location":"api/#graph-operations","title":"Graph Operations","text":"Method Endpoint Description POST <code>/api/v1/graph/interactions</code> Record AI-User interaction GET <code>/api/v1/graph/{node_id}/related</code> Get related nodes GET <code>/api/v1/graph/users/{user_id}/pattern</code> Analyze user pattern"},{"location":"api/#system","title":"System","text":"Method Endpoint Description GET <code>/</code> API root information GET <code>/api/v1/health</code> Health check GET <code>/api/v1/metrics</code> System metrics"},{"location":"api/#mcp-transport-phase-c","title":"MCP Transport (Phase C)","text":"Method Endpoint Description GET <code>/mcp</code> SSE streaming (server \u2192 client) POST <code>/mcp</code> JSON-RPC requests (client \u2192 server) DELETE <code>/mcp</code> Session termination"},{"location":"api/#authentication","title":"\ud83d\udd10 Authentication","text":""},{"location":"api/#headers","title":"Headers","text":"<p>X-User-ID (optional): <pre><code>X-User-ID: user_jfk\n</code></pre> Specifies which user's memory to access. Defaults to <code>default_user</code>.</p> <p>Authorization (optional, Phase C): <pre><code>Authorization: Bearer kagura_abc123xyz789...\n</code></pre> API Key for authentication. User ID is extracted from validated key.</p>"},{"location":"api/#schemas","title":"\ud83d\udce6 Schemas","text":""},{"location":"api/#memory","title":"Memory","text":"<p>MemoryCreate: <pre><code>type: object\nrequired: [key, value]\nproperties:\n  key: string\n  value: string\n  scope: string (working|persistent)\n  tags: array of strings\n  importance: number (0.0-1.0)\n  metadata: object\n</code></pre></p> <p>MemoryResponse: <pre><code>type: object\nproperties:\n  key: string\n  value: string\n  scope: string\n  tags: array\n  importance: number\n  created_at: string (datetime)\n  updated_at: string (datetime)\n</code></pre></p>"},{"location":"api/#search","title":"Search","text":"<p>RecallRequest: <pre><code>type: object\nrequired: [query]\nproperties:\n  query: string\n  k: integer (default: 5)\n  scope: string (all|working|persistent)\n</code></pre></p> <p>RecallResponse: <pre><code>type: object\nproperties:\n  results: array\n    items:\n      key: string\n      value: string\n      score: number\n</code></pre></p>"},{"location":"api/#graph","title":"Graph","text":"<p>InteractionCreate: <pre><code>type: object\nrequired: [user_id, query, response]\nproperties:\n  user_id: string\n  query: string\n  response: string\n  metadata: object\n  ai_platform: string (optional)\n</code></pre></p> <p>UserPattern: <pre><code>type: object\nproperties:\n  user_id: string\n  total_interactions: integer\n  topics: object (topic \u2192 count)\n  platforms: object (platform \u2192 count)\n  learning_trajectory: array\n</code></pre></p>"},{"location":"api/#tools-sdks","title":"\ud83d\udee0\ufe0f Tools &amp; SDKs","text":""},{"location":"api/#official-tools","title":"Official Tools","text":"<p>Python (httpx): <pre><code>import httpx\n\nasync with httpx.AsyncClient() as client:\n    response = await client.post(\n        \"http://localhost:8080/api/v1/memory\",\n        json={\"key\": \"test\", \"value\": \"data\"},\n        headers={\"X-User-ID\": \"user_jfk\"}\n    )\n</code></pre></p> <p>cURL: <pre><code>curl -X POST http://localhost:8080/api/v1/memory \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-User-ID: user_jfk\" \\\n  -d '{\"key\":\"test\",\"value\":\"data\",\"scope\":\"persistent\"}'\n</code></pre></p>"},{"location":"api/#client-sdk-generation","title":"Client SDK Generation","text":"<p>Generate clients for any language using OpenAPI Generator:</p> <pre><code># Python\nopenapi-generator-cli generate -i reference.yaml -g python -o ./client-python\n\n# TypeScript/Axios\nopenapi-generator-cli generate -i reference.yaml -g typescript-axios -o ./client-ts\n\n# Go\nopenapi-generator-cli generate -i reference.yaml -g go -o ./client-go\n\n# Rust\nopenapi-generator-cli generate -i reference.yaml -g rust -o ./client-rust\n</code></pre>"},{"location":"api/#related-documentation","title":"\ud83d\udcda Related Documentation","text":"<ul> <li>API Reference Guide - Human-readable API guide</li> <li>REST API Usage - Usage examples and patterns</li> <li>MCP over HTTP/SSE - MCP protocol endpoint</li> <li>Getting Started</li> </ul>"},{"location":"api/#keeping-spec-updated","title":"\ud83d\udd04 Keeping Spec Updated","text":"<p>The OpenAPI spec can be regenerated from the running server:</p> <pre><code># Start server\nuvicorn kagura.api.server:app --port 8080\n\n# Download current spec\ncurl http://localhost:8080/openapi.json &gt; docs/api/reference.json\n\n# Convert to YAML (optional)\npython -c \"import json, yaml; print(yaml.dump(json.load(open('docs/api/reference.json'))))\" &gt; docs/api/reference.yaml\n</code></pre> <p>Last Updated: 2025-10-27 API Version: 4.0.0 OpenAPI Version: 3.1.0</p>"},{"location":"en/installation/","title":"Installation","text":""},{"location":"en/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.11 or higher</li> <li>pip or uv package manager</li> </ul>"},{"location":"en/installation/#install-from-pypi","title":"Install from PyPI","text":""},{"location":"en/installation/#using-pip","title":"Using pip","text":"<pre><code>pip install kagura-ai\n</code></pre>"},{"location":"en/installation/#using-uv-recommended","title":"Using uv (recommended)","text":"<pre><code>uv add kagura-ai\n</code></pre>"},{"location":"en/installation/#verify-installation","title":"Verify Installation","text":"<p>Check that Kagura AI is installed correctly:</p> <pre><code>kagura version\n</code></pre> <p>You should see output like:</p> <pre><code>Kagura AI v3.0\n</code></pre>"},{"location":"en/installation/#set-api-key","title":"Set API Key","text":"<p>Kagura AI uses LiteLLM, which supports multiple LLM providers. You need to set the appropriate API key for your chosen provider.</p> <p>\ud83d\udca1 Quick Start Tip</p> <p>The fastest way to get started with Gemini: 1. Visit Google AI Studio 2. Click \"Create API Key\" 3. Copy the key and set: <code>export GOOGLE_API_KEY=\"your-key\"</code></p> <p>No Google Cloud Console setup needed! OAuth2 is an advanced feature for specific use cases. See OAuth2 Authentication Guide for details.</p>"},{"location":"en/installation/#openai","title":"OpenAI","text":"<pre><code>export OPENAI_API_KEY=\"your-key-here\"\n</code></pre> <p>Or in Python: <pre><code>import os\nos.environ[\"OPENAI_API_KEY\"] = \"your-key-here\"\n</code></pre></p>"},{"location":"en/installation/#anthropic-claude","title":"Anthropic (Claude)","text":"<pre><code>export ANTHROPIC_API_KEY=\"your-key-here\"\n</code></pre>"},{"location":"en/installation/#google-gemini","title":"Google (Gemini)","text":"<pre><code>export GOOGLE_API_KEY=\"your-key-here\"\n</code></pre>"},{"location":"en/installation/#azure-openai","title":"Azure OpenAI","text":"<pre><code>export AZURE_API_KEY=\"your-key-here\"\nexport AZURE_API_BASE=\"https://your-endpoint.openai.azure.com/\"\nexport AZURE_API_VERSION=\"2023-05-15\"\n</code></pre>"},{"location":"en/installation/#test-your-installation","title":"Test Your Installation","text":"<p>Create a simple test file:</p> <pre><code># test_kagura.py\nfrom kagura import agent\n\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    async def main():\n        result = await hello(\"Kagura AI\")\n        print(result)\n\n    asyncio.run(main())\n</code></pre> <p>Run it:</p> <pre><code>python test_kagura.py\n</code></pre> <p>If successful, you should see a greeting message.</p>"},{"location":"en/installation/#development-installation","title":"Development Installation","text":"<p>For contributing to Kagura AI or running from source:</p>"},{"location":"en/installation/#clone-repository","title":"Clone Repository","text":"<pre><code>git clone https://github.com/JFK/kagura-ai.git\ncd kagura-ai\n</code></pre>"},{"location":"en/installation/#install-dependencies","title":"Install Dependencies","text":"<p>Using uv (recommended):</p> <pre><code>uv sync --dev\n</code></pre> <p>This will install: - All runtime dependencies - Development dependencies (pytest, pyright, ruff, etc.)</p>"},{"location":"en/installation/#run-tests","title":"Run Tests","text":"<pre><code>pytest\n</code></pre>"},{"location":"en/installation/#type-checking","title":"Type Checking","text":"<pre><code>pyright\n</code></pre>"},{"location":"en/installation/#code-formatting","title":"Code Formatting","text":"<pre><code>ruff check src/\n</code></pre>"},{"location":"en/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>Kagura AI provides several optional feature presets to install only what you need.</p>"},{"location":"en/installation/#user-facing-presets","title":"\ud83d\udce6 User-Facing Presets","text":""},{"location":"en/installation/#ai-features-kagura-aiai","title":"AI Features (<code>kagura-ai[ai]</code>)","text":"<p>Core AI capabilities: Memory, Routing, Context Compression</p> <pre><code>pip install kagura-ai[ai]\n# or\nuv add \"kagura-ai[ai]\"\n</code></pre> <p>Includes: - <code>chromadb</code> - Vector storage for memory &amp; RAG - <code>semantic-router</code> - Semantic routing - <code>tiktoken</code> - Token counting for context compression</p> <p>Use cases: - Agents with long-term memory - Semantic routing between agents - Context-aware conversation management</p>"},{"location":"en/installation/#web-multimodal-kagura-aiweb","title":"Web &amp; Multimodal (<code>kagura-ai[web]</code>)","text":"<p>Web search, scraping, and multimodal (image/audio/video) processing</p> <pre><code>pip install kagura-ai[web]\n# or\nuv add \"kagura-ai[web]\"\n</code></pre> <p>Includes: - <code>google-generativeai</code> - Gemini API for multimodal - <code>pillow</code> - Image processing - <code>httpx</code> - HTTP client - <code>brave-search-python-client</code> - Brave Search API - <code>beautifulsoup4</code> - HTML parsing</p> <p>Use cases: - Web search agents - Image/audio/video analysis - Web scraping and data extraction</p>"},{"location":"en/installation/#oauth2-authentication-kagura-aiauth","title":"OAuth2 Authentication (<code>kagura-ai[auth]</code>)","text":"<p>OAuth2 authentication with Google/Gemini (advanced feature)</p> <pre><code>pip install kagura-ai[auth]\n# or\nuv add \"kagura-ai[auth]\"\n</code></pre> <p>Includes: - <code>google-auth</code> - Google authentication library - <code>google-auth-oauthlib</code> - OAuth2 flow - <code>google-auth-httplib2</code> - HTTP library - <code>cryptography</code> - Credential encryption</p> <p>Note: OAuth2 is an advanced feature. For most users, using API Keys is recommended as it's simpler. See OAuth2 Authentication Guide for when to use OAuth2.</p>"},{"location":"en/installation/#mcp-integration-kagura-aimcp","title":"MCP Integration (<code>kagura-ai[mcp]</code>)","text":"<p>Use Kagura agents with Claude Desktop, Claude Code, and other MCP clients</p> <pre><code>pip install kagura-ai[mcp]\n# or\nuv add \"kagura-ai[mcp]\"\n</code></pre> <p>Includes: - <code>mcp</code> - Model Context Protocol SDK - <code>jsonschema</code> - JSON Schema validation</p> <p>See MCP Integration Tutorial for setup guide.</p>"},{"location":"en/installation/#combined-presets-recommended","title":"\ud83c\udf81 Combined Presets (Recommended)","text":""},{"location":"en/installation/#full-features-kagura-aifull","title":"Full Features (<code>kagura-ai[full]</code>)","text":"<p>All user-facing features in one install</p> <pre><code>pip install kagura-ai[full]\n# or\nuv add \"kagura-ai[full]\"\n</code></pre> <p>Includes: <code>ai</code> + <code>web</code> + <code>auth</code> + <code>mcp</code></p> <p>Recommended for: Most users who want to explore all Kagura AI capabilities</p>"},{"location":"en/installation/#everything-kagura-aiall","title":"Everything (<code>kagura-ai[all]</code>)","text":"<p>All features including development tools</p> <pre><code>pip install kagura-ai[all]\n# or\nuv add \"kagura-ai[all]\"\n</code></pre> <p>Includes: <code>full</code> + <code>dev</code> + <code>docs</code></p> <p>Recommended for: Contributors and advanced users</p>"},{"location":"en/installation/#development-presets","title":"\ud83d\udee0\ufe0f Development Presets","text":""},{"location":"en/installation/#development-tools-kagura-aidev","title":"Development Tools (<code>kagura-ai[dev]</code>)","text":"<p>Testing and linting tools (included with <code>uv sync --dev</code>)</p> <pre><code>pip install kagura-ai[dev]\n# or\nuv add \"kagura-ai[dev]\"\n</code></pre> <p>Includes: - <code>pytest</code> - Testing framework - <code>pytest-asyncio</code> - Async test support - <code>pytest-cov</code> - Code coverage - <code>pytest-timeout</code> - Test timeout - <code>langdetect</code> - For agent testing - <code>pyright</code> - Type checker - <code>ruff</code> - Linter and formatter</p>"},{"location":"en/installation/#documentation-tools-kagura-aidocs","title":"Documentation Tools (<code>kagura-ai[docs]</code>)","text":"<p>Build documentation locally</p> <pre><code>pip install kagura-ai[docs]\n# or\nuv add \"kagura-ai[docs]\"\n</code></pre> <p>Includes: - <code>mkdocs</code> - Documentation generator - <code>mkdocs-material</code> - Material theme - <code>pymdown-extensions</code> - Markdown extensions</p> <p>Then run: <pre><code>mkdocs serve\n</code></pre></p> <p>Visit <code>http://localhost:8000</code> to view docs.</p>"},{"location":"en/installation/#installation-size-comparison","title":"\ud83d\udcca Installation Size Comparison","text":"Preset Dependencies Approximate Size Use Case <code>base</code> 8 packages ~50 MB Basic agents only <code>ai</code> +3 packages +150 MB AI features <code>web</code> +7 packages +200 MB Web &amp; Multimodal <code>auth</code> +4 packages +20 MB OAuth2 <code>mcp</code> +2 packages +10 MB MCP integration <code>full</code> +16 packages +380 MB All features <code>all</code> +23 packages +420 MB Everything"},{"location":"en/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/installation/#import-error","title":"Import Error","text":"<p>If you get import errors:</p> <pre><code>ImportError: cannot import name 'agent' from 'kagura'\n</code></pre> <p>Make sure you're using Python 3.11+:</p> <pre><code>python --version\n</code></pre>"},{"location":"en/installation/#api-key-not-found","title":"API Key Not Found","text":"<p>If you see authentication errors:</p> <pre><code>AuthenticationError: The api_key client option must be set\n</code></pre> <p>Set your API key as described above. The key must be set before importing kagura.</p>"},{"location":"en/installation/#type-errors","title":"Type Errors","text":"<p>If pyright shows errors in your IDE:</p> <ol> <li>Make sure your Python interpreter is set to 3.11+</li> <li>Ensure kagura-ai is installed in your environment</li> <li>Restart your IDE/language server</li> </ol>"},{"location":"en/installation/#upgrading","title":"Upgrading","text":""},{"location":"en/installation/#from-pypi","title":"From PyPI","text":"<pre><code>pip install --upgrade kagura-ai\n</code></pre> <p>or with uv:</p> <pre><code>uv add kagura-ai --upgrade\n</code></pre>"},{"location":"en/installation/#from-git","title":"From Git","text":"<pre><code>cd kagura-ai\ngit pull\nuv sync --dev\n</code></pre>"},{"location":"en/installation/#uninstalling","title":"Uninstalling","text":"<pre><code>pip uninstall kagura-ai\n</code></pre> <p>or with uv:</p> <pre><code>uv remove kagura-ai\n</code></pre>"},{"location":"en/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start - Build your first agent</li> <li>API Reference - Detailed API documentation</li> <li>Examples - Example code</li> </ul>"},{"location":"en/quickstart/","title":"Quick Start","text":"<p>Get started with Kagura AI in 5 minutes.</p>"},{"location":"en/quickstart/#installation","title":"Installation","text":"<pre><code>pip install kagura-ai[full]\n</code></pre>"},{"location":"en/quickstart/#set-api-key","title":"Set API Key","text":"<pre><code>export OPENAI_API_KEY=sk-...\n</code></pre> <p>Supports OpenAI, Anthropic, Google, and 100+ providers via LiteLLM.</p>"},{"location":"en/quickstart/#your-first-agent-30-seconds","title":"Your First Agent (30 seconds)","text":"<pre><code>from kagura import agent\n\n@agent\nasync def translator(text: str, lang: str = \"ja\") -&gt; str:\n    '''Translate to {{ lang }}: {{ text }}'''\n\n# Use it\nimport asyncio\n\nasync def main():\n    result = await translator(\"Hello World\", lang=\"ja\")\n    print(result)  # \"\u3053\u3093\u306b\u3061\u306f\u4e16\u754c\"\n\nasyncio.run(main())\n</code></pre> <p>Save as <code>hello.py</code> and run:</p> <pre><code>python hello.py\n</code></pre> <p>That's it. One decorator, done.</p>"},{"location":"en/quickstart/#type-safe-structured-output","title":"Type-Safe Structured Output","text":"<pre><code>from kagura import agent\nfrom pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    '''Extract person info from: {{ text }}'''\n\n# Use it\nasync def main():\n    person = await extract_person(\n        \"Alice is 30 and works as an engineer\"\n    )\n    print(f\"{person.name}, {person.age}, {person.occupation}\")\n    # \"Alice, 30, engineer\"\n\nasyncio.run(main())\n</code></pre> <p>Fully typed. IDE autocomplete works.</p>"},{"location":"en/quickstart/#with-built-in-tools","title":"With Built-in Tools","text":"<pre><code>@agent(tools=[\"web_search\"])\nasync def researcher(topic: str) -&gt; str:\n    '''Research {{ topic }} using web_search(query) tool.'''\n\n# Environment variable needed:\n# export BRAVE_SEARCH_API_KEY=...\n\nasync def main():\n    result = await researcher(\"Python 3.13 features\")\n    print(result)\n\nasyncio.run(main())\n</code></pre> <p>Built-in tools: <code>web_search</code>, <code>web_fetch</code>, <code>file_read</code>, <code>file_write</code>, <code>execute_python</code>, and more.</p>"},{"location":"en/quickstart/#with-memory","title":"With Memory","text":"<pre><code>@agent(enable_memory=True)\nasync def assistant(message: str) -&gt; str:\n    '''Remember our conversation. User says: {{ message }}'''\n\nasync def main():\n    # First message\n    await assistant(\"My favorite color is blue\")\n\n    # Second message - remembers!\n    response = await assistant(\"What's my favorite color?\")\n    print(response)  # \"Your favorite color is blue\"\n\nasyncio.run(main())\n</code></pre>"},{"location":"en/quickstart/#real-world-fastapi-integration","title":"Real-World: FastAPI Integration","text":"<pre><code>from fastapi import FastAPI\nfrom kagura import agent\n\napp = FastAPI()\n\n@agent\nasync def support_bot(question: str) -&gt; str:\n    '''Answer customer support question: {{ question }}'''\n\n@app.post(\"/api/support\")\nasync def handle_support(question: str):\n    response = await support_bot(question)\n    return {\"answer\": response}\n\n# Run with: uvicorn main:app\n</code></pre>"},{"location":"en/quickstart/#bonus-interactive-chat","title":"Bonus: Interactive Chat","text":"<p>Don't want to write code yet?</p> <pre><code>kagura chat\n</code></pre> <p>Try all SDK features interactively:</p> <pre><code>[You] &gt; Read design.pdf and extract requirements\n\n[AI] &gt; (Analyzes PDF, extracts info)\n\n[You] &gt; Search for best practices\n\n[AI] &gt; (Uses web search, finds resources)\n</code></pre> <p>All SDK features work automatically in chat.</p>"},{"location":"en/quickstart/#next-steps","title":"Next Steps","text":""},{"location":"en/quickstart/#sdk-integration","title":"SDK Integration","text":"<ul> <li>SDK Guide - Complete guide to @agent, @tool, memory</li> <li>Examples - 30+ code examples</li> <li>API Reference - Detailed API docs</li> </ul>"},{"location":"en/quickstart/#interactive-exploration","title":"Interactive Exploration","text":"<ul> <li>Chat Guide - Full chat features guide</li> <li>MCP Integration - Use in Claude Desktop</li> </ul> <p>Ready to build? Start with the SDK Guide</p>"},{"location":"en/api/","title":"API Reference","text":"<p>Complete API documentation for Kagura AI SDK.</p>"},{"location":"en/api/#core-decorators","title":"Core Decorators","text":""},{"location":"en/api/#agent","title":"@agent","text":"<p>Convert async functions into AI agents.</p> <pre><code>from kagura import agent\n\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n</code></pre> <p>Features: - One-line agent creation - Type-based response parsing - Jinja2 template support - Multi-LLM support</p> <p>Full documentation \u2192</p>"},{"location":"en/api/#tool","title":"@tool","text":"<p>Turn Python functions into agent tools.</p> <pre><code>from kagura import tool\n\n@tool\nasync def search_db(query: str) -&gt; list[dict]:\n    '''Search database'''\n    return db.query(query)\n</code></pre> <p>Features: - Auto-registration to tool_registry - Type validation - Docstring-based descriptions</p> <p>Full documentation \u2192</p>"},{"location":"en/api/#workflow","title":"@workflow","text":"<p>Orchestrate multi-agent workflows.</p> <pre><code>from kagura import workflow\n\n@workflow.chain\nasync def pipeline(data: str):\n    step1 = await agent1(data)\n    step2 = await agent2(step1)\n    return step2\n</code></pre> <p>Features: - Sequential chains - Parallel execution - Stateful workflows</p> <p>Full documentation \u2192</p>"},{"location":"en/api/#features","title":"Features","text":""},{"location":"en/api/#memory-system","title":"Memory System","text":"<p>3-tier memory management for context-aware agents.</p> <pre><code>@agent(enable_memory=True)\nasync def assistant(message: str) -&gt; str:\n    '''Remember conversation: {{ message }}'''\n</code></pre> <p>Types: - Context Memory: Current conversation - Persistent Memory: Long-term storage - RAG Memory: Semantic search</p> <p>Full documentation \u2192</p>"},{"location":"en/api/#agent-builder","title":"Agent Builder","text":"<p>Fluent API for building complex agents.</p> <pre><code>from kagura.builder import AgentBuilder\n\nagent = (\n    AgentBuilder()\n    .with_memory()\n    .with_tools([\"web_search\"])\n    .build()\n)\n</code></pre> <p>Full documentation \u2192</p>"},{"location":"en/api/#testing-framework","title":"Testing Framework","text":"<p>Built-in testing utilities for AI agents.</p> <pre><code>from kagura.testing import AgentTestCase\n\nclass TestMyAgent(AgentTestCase):\n    async def test_sentiment(self):\n        result = await analyzer(\"I love this!\")\n        self.assert_semantic_match(result, \"positive\")\n</code></pre> <p>Full documentation \u2192</p>"},{"location":"en/api/#integrations","title":"Integrations","text":""},{"location":"en/api/#chat-session","title":"Chat Session","text":"<p>Interactive chat interface (bonus feature).</p> <pre><code>from kagura.chat import ChatSession\n\nsession = ChatSession()\nawait session.run()\n</code></pre> <p>Full documentation \u2192</p>"},{"location":"en/api/#mcp-integration","title":"MCP Integration","text":"<p>Use agents in Claude Desktop via Model Context Protocol.</p> <pre><code>kagura mcp serve\n</code></pre> <p>Full documentation \u2192</p>"},{"location":"en/api/#authentication","title":"Authentication","text":"<p>OAuth2 authentication support (advanced).</p> <pre><code>from kagura.auth import OAuth2Manager\n\noauth = OAuth2Manager(provider=\"google\")\nawait oauth.authenticate()\n</code></pre> <p>Full documentation \u2192</p>"},{"location":"en/api/#advanced","title":"Advanced","text":""},{"location":"en/api/#code-executor","title":"Code Executor","text":"<p>Deep dive into code execution engine.</p> <p>Full documentation \u2192</p>"},{"location":"en/api/#context-compression","title":"Context Compression","text":"<p>Token management for long conversations.</p> <pre><code>@agent(enable_compression=True)\nasync def assistant(message: str) -&gt; str:\n    '''{{ message }}'''\n</code></pre> <p>Full documentation \u2192</p>"},{"location":"en/api/#observability","title":"Observability","text":"<p>Cost tracking and performance monitoring.</p> <pre><code>kagura monitor stats\n</code></pre> <p>Full documentation \u2192</p>"},{"location":"en/api/#quick-reference","title":"Quick Reference","text":""},{"location":"en/api/#environment-variables","title":"Environment Variables","text":"Variable Purpose <code>OPENAI_API_KEY</code> OpenAI API key <code>ANTHROPIC_API_KEY</code> Anthropic API key <code>GOOGLE_API_KEY</code> Google API key <code>BRAVE_SEARCH_API_KEY</code> Web search (optional)"},{"location":"en/api/#type-support","title":"Type Support","text":"Return Type Example <code>str</code> <code>-&gt; str</code> <code>int</code>, <code>float</code>, <code>bool</code> <code>-&gt; int</code> <code>list[T]</code> <code>-&gt; list[str]</code> <code>dict</code> <code>-&gt; dict</code> <code>BaseModel</code> <code>-&gt; Person</code> <code>Optional[T]</code> <code>-&gt; Optional[str]</code>"},{"location":"en/api/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start - Get started in 5 minutes</li> <li>SDK Guide - Complete SDK guide</li> <li>Examples - Code examples</li> </ul>"},{"location":"en/api/agent/","title":"@agent Decorator","text":"<p>The <code>@agent</code> decorator is the core of Kagura AI, converting any async function into an AI agent with automatic LLM integration.</p>"},{"location":"en/api/agent/#overview","title":"Overview","text":"<p>The decorator: 1. Extracts function signature and parameters 2. Uses the docstring as a Jinja2 template 3. Calls the LLM with the rendered prompt 4. Parses the response based on return type hints 5. Returns a properly typed result</p>"},{"location":"en/api/agent/#signature","title":"Signature","text":"<pre><code>def agent(\n    fn: Callable = None,\n    *,\n    model: str = \"gpt-4o-mini\",\n    temperature: float = 0.7,\n    max_tokens: int | None = None,\n    **kwargs\n) -&gt; Callable\n</code></pre>"},{"location":"en/api/agent/#parameters","title":"Parameters","text":""},{"location":"en/api/agent/#required-parameters","title":"Required Parameters","text":"<ul> <li>fn (<code>Callable</code>): The async function to convert into an agent. When using <code>@agent</code> without parentheses, this is automatically passed.</li> </ul>"},{"location":"en/api/agent/#optional-parameters","title":"Optional Parameters","text":"<ul> <li>model (<code>str</code>, default: <code>\"gpt-4o-mini\"</code>): The LLM model to use. Supports any model from LiteLLM:</li> <li>OpenAI: <code>\"gpt-4o\"</code>, <code>\"gpt-4o-mini\"</code>, <code>\"gpt-3.5-turbo\"</code></li> <li>Anthropic: <code>\"claude-3-5-sonnet-20241022\"</code>, <code>\"claude-3-haiku-20240307\"</code></li> <li>Google: <code>\"gemini/gemini-pro\"</code>, <code>\"gemini/gemini-1.5-flash\"</code></li> <li> <p>Ollama: <code>\"ollama/llama3.2\"</code>, <code>\"ollama/gemma2\"</code></p> </li> <li> <p>temperature (<code>float</code>, default: <code>0.7</code>): Sampling temperature (0.0 to 2.0). Lower values make output more focused and deterministic.</p> </li> <li> <p>max_tokens (<code>int | None</code>, default: <code>None</code>): Maximum tokens in the response. If not specified, uses the model's default.</p> </li> <li> <p>kwargs: Additional parameters passed to LiteLLM's <code>completion()</code> function.</p> </li> </ul>"},{"location":"en/api/agent/#return-value","title":"Return Value","text":"<p>Returns a wrapped async function with the same signature as the original, but with AI-powered behavior.</p>"},{"location":"en/api/agent/#usage","title":"Usage","text":""},{"location":"en/api/agent/#basic-usage","title":"Basic Usage","text":"<pre><code>from kagura import agent\n\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\nresult = await hello(\"World\")\nprint(result)  # \"Hello, World! How can I help you today?\"\n</code></pre>"},{"location":"en/api/agent/#with-custom-model","title":"With Custom Model","text":"<pre><code>@agent(model=\"gpt-4o\")\nasync def analyze(text: str) -&gt; str:\n    '''Analyze the sentiment of: {{ text }}'''\n    pass\n\nresult = await analyze(\"I love this product!\")\nprint(result)  # \"Positive sentiment...\"\n</code></pre>"},{"location":"en/api/agent/#with-temperature-control","title":"With Temperature Control","text":"<pre><code># More deterministic (lower temperature)\n@agent(temperature=0.2)\nasync def translate(text: str, lang: str) -&gt; str:\n    '''Translate to {{ lang }}: {{ text }}'''\n    pass\n\n# More creative (higher temperature)\n@agent(temperature=1.5)\nasync def creative_story(topic: str) -&gt; str:\n    '''Write a creative story about: {{ topic }}'''\n    pass\n</code></pre>"},{"location":"en/api/agent/#with-pydantic-models","title":"With Pydantic Models","text":"<pre><code>from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    '''Extract person information from: {{ text }}'''\n    pass\n\nperson = await extract_person(\"Alice is 30 years old and works as a software engineer\")\nprint(f\"{person.name}, {person.age}, {person.occupation}\")\n# Output: Alice, 30, software engineer\n</code></pre>"},{"location":"en/api/agent/#with-list-return-types","title":"With List Return Types","text":"<pre><code>@agent\nasync def extract_keywords(text: str) -&gt; list[str]:\n    '''Extract keywords from: {{ text }}'''\n    pass\n\nkeywords = await extract_keywords(\"Python is a programming language for AI\")\nprint(keywords)\n# Output: ['Python', 'programming language', 'AI']\n</code></pre>"},{"location":"en/api/agent/#multiple-parameters","title":"Multiple Parameters","text":"<pre><code>@agent\nasync def summarize(text: str, max_words: int = 50) -&gt; str:\n    '''Summarize in {{ max_words }} words or less: {{ text }}'''\n    pass\n\nsummary = await summarize(\"Long text here...\", max_words=30)\n</code></pre>"},{"location":"en/api/agent/#docstring-templates","title":"Docstring Templates","text":"<p>The docstring is treated as a Jinja2 template. All function parameters are available as template variables.</p>"},{"location":"en/api/agent/#simple-variable-interpolation","title":"Simple Variable Interpolation","text":"<pre><code>@agent\nasync def greet(name: str, greeting: str = \"Hello\") -&gt; str:\n    '''{{ greeting }}, {{ name }}! How are you?'''\n    pass\n</code></pre>"},{"location":"en/api/agent/#conditional-logic","title":"Conditional Logic","text":"<pre><code>@agent\nasync def format_response(query: str, formal: bool = False) -&gt; str:\n    '''\n    {% if formal %}\n    Respond formally to: {{ query }}\n    {% else %}\n    Respond casually to: {{ query }}\n    {% endif %}\n    '''\n    pass\n</code></pre>"},{"location":"en/api/agent/#loops","title":"Loops","text":"<pre><code>@agent\nasync def process_items(items: list[str]) -&gt; str:\n    '''\n    Process the following items:\n    {% for item in items %}\n    - {{ item }}\n    {% endfor %}\n    '''\n    pass\n</code></pre>"},{"location":"en/api/agent/#type-based-response-parsing","title":"Type-Based Response Parsing","text":"<p>The decorator automatically parses LLM responses based on the return type annotation:</p> Return Type Parsing Behavior <code>str</code> Returns raw response <code>int</code> Parses as integer <code>float</code> Parses as float <code>bool</code> Parses as boolean <code>list[T]</code> Parses as list of type T <code>dict[K, V]</code> Parses as dictionary <code>Pydantic Model</code> Validates and returns model instance <code>Optional[T]</code> Allows None values"},{"location":"en/api/agent/#error-handling","title":"Error Handling","text":""},{"location":"en/api/agent/#llm-api-errors","title":"LLM API Errors","text":"<pre><code>from litellm import APIError\n\n@agent\nasync def my_agent(query: str) -&gt; str:\n    '''Process: {{ query }}'''\n    pass\n\ntry:\n    result = await my_agent(\"test\")\nexcept APIError as e:\n    print(f\"LLM API error: {e}\")\n</code></pre>"},{"location":"en/api/agent/#parsing-errors","title":"Parsing Errors","text":"<pre><code>from pydantic import ValidationError\n\n@agent\nasync def extract_data(text: str) -&gt; Person:\n    '''Extract person from: {{ text }}'''\n    pass\n\ntry:\n    result = await extract_data(\"invalid text\")\nexcept ValidationError as e:\n    print(f\"Failed to parse response: {e}\")\n</code></pre>"},{"location":"en/api/agent/#advanced-features","title":"Advanced Features","text":""},{"location":"en/api/agent/#accessing-agent-metadata","title":"Accessing Agent Metadata","text":"<pre><code>@agent(model=\"gpt-4o\", temperature=0.5)\nasync def my_agent(query: str) -&gt; str:\n    '''Answer: {{ query }}'''\n    pass\n\n# Check if function is an agent\nprint(hasattr(my_agent, '_is_agent'))  # True\n\n# Access configuration\nprint(my_agent._model)  # \"gpt-4o\"\n</code></pre>"},{"location":"en/api/agent/#agent-composition","title":"Agent Composition","text":"<p>Agents can call other agents:</p> <pre><code>@agent\nasync def extract_topic(text: str) -&gt; str:\n    '''Extract the main topic from: {{ text }}'''\n    pass\n\n@agent\nasync def elaborate(topic: str) -&gt; str:\n    '''Elaborate on: {{ topic }}'''\n    pass\n\n# Compose agents\ntext = \"Quantum computing is revolutionary\"\ntopic = await extract_topic(text)\nelaboration = await elaborate(topic)\n</code></pre>"},{"location":"en/api/agent/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Clear Docstrings: Write explicit instructions in the docstring    <pre><code># Good\n'''Extract the person's name, age, and occupation from: {{ text }}'''\n\n# Less clear\n'''Process {{ text }}'''\n</code></pre></p> </li> <li> <p>Appropriate Return Types: Use the most specific type possible    <pre><code># Good\nasync def extract_person(text: str) -&gt; Person:\n\n# Less good\nasync def extract_person(text: str) -&gt; dict:\n</code></pre></p> </li> <li> <p>Temperature Selection:</p> </li> <li>Use low temperature (0.0-0.3) for factual, deterministic tasks</li> <li>Use medium temperature (0.7-1.0) for balanced responses</li> <li> <p>Use high temperature (1.0-2.0) for creative tasks</p> </li> <li> <p>Model Selection:</p> </li> <li>Use <code>gpt-4o-mini</code> for simple tasks (faster, cheaper)</li> <li>Use <code>gpt-4o</code> or <code>claude-3-5-sonnet</code> for complex reasoning</li> <li>Use <code>claude-3-haiku</code> for fast, cost-effective responses</li> </ol>"},{"location":"en/api/agent/#related","title":"Related","text":"<ul> <li>Template Engine - Jinja2 templating details</li> <li>Type Parser - Response parsing details</li> <li>Quick Start - Getting started guide</li> </ul>"},{"location":"en/api/auth/","title":"Authentication API Reference","text":"<p>API reference for Kagura AI's OAuth2 authentication system.</p> <p>\ud83d\udccc Important Note</p> <p>OAuth2 is an advanced feature for Google/Gemini only.</p> <p>For most use cases, API Keys are recommended: - Simpler setup (no Google Cloud Console required) - Works with all LLMs (OpenAI, Claude, Gemini) - Faster to get started</p> <p>OAuth2 is designed for: - Multi-user applications - Production environments with strict access controls - Per-user quota management</p> <p>See OAuth2 Authentication Guide for when to use each method.</p>"},{"location":"en/api/auth/#oauth2manager","title":"OAuth2Manager","text":"<p>Main class for managing OAuth2 authentication with Google services.</p>"},{"location":"en/api/auth/#class-definition","title":"Class Definition","text":"<pre><code>from kagura.auth import OAuth2Manager\n\nclass OAuth2Manager:\n    \"\"\"OAuth2 authentication manager for Google services\n\n    Handles OAuth2 authentication flow, token management, and secure credential storage.\n\n    Args:\n        provider: OAuth2 provider name (default: \"google\")\n        config: Optional AuthConfig instance\n\n    Example:\n        &gt;&gt;&gt; auth = OAuth2Manager(provider=\"google\")\n        &gt;&gt;&gt; auth.login()  # Opens browser for authentication\n        &gt;&gt;&gt; creds = auth.get_credentials()  # Returns valid credentials\n        &gt;&gt;&gt; token = auth.get_token()  # Returns access token\n\n    Security:\n        - Credentials are encrypted using Fernet (AES-128)\n        - Encryption key stored separately with 0o600 permissions\n        - Credentials file has 0o600 permissions\n        - Automatic token refresh when expired\n    \"\"\"\n</code></pre>"},{"location":"en/api/auth/#methods","title":"Methods","text":""},{"location":"en/api/auth/#__init__providergoogle-confignone","title":"<code>__init__(provider=\"google\", config=None)</code>","text":"<p>Initialize OAuth2 manager.</p> <p>Parameters: - <code>provider</code> (str): OAuth2 provider name (default: \"google\") - <code>config</code> (AuthConfig | None): Optional authentication configuration</p> <p>Example: <pre><code>auth = OAuth2Manager(provider=\"google\")\n</code></pre></p>"},{"location":"en/api/auth/#login","title":"<code>login()</code>","text":"<p>Launch browser for OAuth2 authentication.</p> <p>Raises: - <code>FileNotFoundError</code>: If client_secrets.json not found - <code>InvalidCredentialsError</code>: If authentication fails</p> <p>Example: <pre><code>auth = OAuth2Manager()\nauth.login()  # Opens browser, saves credentials\n</code></pre></p>"},{"location":"en/api/auth/#logout","title":"<code>logout()</code>","text":"<p>Remove stored credentials.</p> <p>Raises: - <code>NotAuthenticatedError</code>: If not authenticated</p> <p>Example: <pre><code>auth = OAuth2Manager()\nauth.logout()  # Removes ~/.kagura/credentials.json.enc\n</code></pre></p>"},{"location":"en/api/auth/#is_authenticated-bool","title":"<code>is_authenticated() -&gt; bool</code>","text":"<p>Check if user is authenticated.</p> <p>Returns: - <code>bool</code>: True if valid credentials exist</p> <p>Example: <pre><code>auth = OAuth2Manager()\nif auth.is_authenticated():\n    print(\"Already logged in\")\nelse:\n    auth.login()\n</code></pre></p>"},{"location":"en/api/auth/#get_credentials-credentials","title":"<code>get_credentials() -&gt; Credentials</code>","text":"<p>Get valid credentials with automatic refresh.</p> <p>Returns: - <code>google.oauth2.credentials.Credentials</code>: Valid Google OAuth2 credentials</p> <p>Raises: - <code>NotAuthenticatedError</code>: If not authenticated - <code>TokenRefreshError</code>: If token refresh fails</p> <p>Example: <pre><code>auth = OAuth2Manager()\ncreds = auth.get_credentials()\nprint(creds.token)  # Access token\n</code></pre></p>"},{"location":"en/api/auth/#get_token-str","title":"<code>get_token() -&gt; str</code>","text":"<p>Get access token for API calls.</p> <p>Returns: - <code>str</code>: Access token string</p> <p>Raises: - <code>NotAuthenticatedError</code>: If not authenticated - <code>TokenRefreshError</code>: If token refresh fails</p> <p>Example: <pre><code>auth = OAuth2Manager()\ntoken = auth.get_token()\n# Use token in API calls\n</code></pre></p>"},{"location":"en/api/auth/#attributes","title":"Attributes","text":""},{"location":"en/api/auth/#scopes","title":"<code>SCOPES</code>","text":"<p>Default OAuth2 scopes for each provider.</p> <pre><code>SCOPES = {\n    \"google\": [\n        \"https://www.googleapis.com/auth/generative-language\",\n        \"openid\",\n    ]\n}\n</code></pre>"},{"location":"en/api/auth/#authconfig","title":"AuthConfig","text":"<p>Configuration for OAuth2 authentication.</p>"},{"location":"en/api/auth/#class-definition_1","title":"Class Definition","text":"<pre><code>from kagura.auth import AuthConfig\nfrom pathlib import Path\n\nclass AuthConfig(BaseModel):\n    \"\"\"OAuth2 authentication configuration\n\n    Configuration for OAuth2 authentication manager.\n\n    Args:\n        provider: OAuth2 provider name (e.g., \"google\")\n        scopes: Optional list of OAuth2 scopes\n        client_secrets_path: Optional path to client_secrets.json\n\n    Example:\n        &gt;&gt;&gt; config = AuthConfig(\n        ...     provider=\"google\",\n        ...     client_secrets_path=Path(\"/custom/path/client_secrets.json\")\n        ... )\n        &gt;&gt;&gt; auth = OAuth2Manager(config=config)\n    \"\"\"\n</code></pre>"},{"location":"en/api/auth/#fields","title":"Fields","text":""},{"location":"en/api/auth/#provider-str-google","title":"<code>provider: str = \"google\"</code>","text":"<p>OAuth2 provider name.</p> <p>Default: <code>\"google\"</code></p> <p>Example: <pre><code>config = AuthConfig(provider=\"google\")\n</code></pre></p>"},{"location":"en/api/auth/#scopes-liststr-none-none","title":"<code>scopes: list[str] | None = None</code>","text":"<p>Custom OAuth2 scopes. If None, uses default scopes from <code>OAuth2Manager.SCOPES</code>.</p> <p>Default: <code>None</code></p> <p>Example: <pre><code>config = AuthConfig(\n    provider=\"google\",\n    scopes=[\n        \"https://www.googleapis.com/auth/generative-language\",\n        \"openid\",\n        \"https://www.googleapis.com/auth/userinfo.email\"\n    ]\n)\n</code></pre></p>"},{"location":"en/api/auth/#client_secrets_path-path-none-none","title":"<code>client_secrets_path: Path | None = None</code>","text":"<p>Custom path to <code>client_secrets.json</code>. If None, uses <code>~/.kagura/client_secrets.json</code>.</p> <p>Default: <code>None</code></p> <p>Example: <pre><code>from pathlib import Path\n\nconfig = AuthConfig(\n    provider=\"google\",\n    client_secrets_path=Path(\"/custom/path/client_secrets.json\")\n)\n</code></pre></p>"},{"location":"en/api/auth/#exceptions","title":"Exceptions","text":""},{"location":"en/api/auth/#authenticationerror","title":"AuthenticationError","text":"<p>Base exception for authentication errors.</p> <pre><code>from kagura.auth.exceptions import AuthenticationError\n\nclass AuthenticationError(Exception):\n    \"\"\"Base exception for authentication errors\"\"\"\n</code></pre> <p>Example: <pre><code>try:\n    auth.login()\nexcept AuthenticationError as e:\n    print(f\"Authentication failed: {e}\")\n</code></pre></p>"},{"location":"en/api/auth/#notauthenticatederror","title":"NotAuthenticatedError","text":"<p>Raised when user is not authenticated.</p> <pre><code>from kagura.auth.exceptions import NotAuthenticatedError\n\nclass NotAuthenticatedError(AuthenticationError):\n    \"\"\"Raised when user is not authenticated with OAuth2 provider\"\"\"\n</code></pre> <p>Message Format: <pre><code>Not authenticated with {provider}. Please run: kagura auth login --provider {provider}\n</code></pre></p> <p>Example: <pre><code>try:\n    token = auth.get_token()\nexcept NotAuthenticatedError as e:\n    print(f\"Please login first: {e}\")\n    auth.login()\n</code></pre></p>"},{"location":"en/api/auth/#invalidcredentialserror","title":"InvalidCredentialsError","text":"<p>Raised when credentials are invalid or corrupted.</p> <pre><code>from kagura.auth.exceptions import InvalidCredentialsError\n\nclass InvalidCredentialsError(AuthenticationError):\n    \"\"\"Raised when credentials are invalid or fail validation\"\"\"\n</code></pre> <p>Example: <pre><code>try:\n    creds = auth.get_credentials()\nexcept InvalidCredentialsError as e:\n    print(f\"Credentials invalid: {e}\")\n    auth.logout()  # Remove corrupted credentials\n    auth.login()   # Re-authenticate\n</code></pre></p>"},{"location":"en/api/auth/#tokenrefresherror","title":"TokenRefreshError","text":"<p>Raised when token refresh fails.</p> <pre><code>from kagura.auth.exceptions import TokenRefreshError\n\nclass TokenRefreshError(AuthenticationError):\n    \"\"\"Raised when OAuth2 token refresh fails\"\"\"\n</code></pre> <p>Example: <pre><code>try:\n    creds = auth.get_credentials()\nexcept TokenRefreshError as e:\n    print(f\"Token refresh failed: {e}\")\n    auth.logout()\n    auth.login()\n</code></pre></p>"},{"location":"en/api/auth/#llmconfig-oauth2-integration","title":"LLMConfig OAuth2 Integration","text":"<p>OAuth2 authentication is integrated into <code>LLMConfig</code> for seamless use with LLM calls.</p>"},{"location":"en/api/auth/#oauth2-fields","title":"OAuth2 Fields","text":""},{"location":"en/api/auth/#auth_type-literalapi_key-oauth2-api_key","title":"<code>auth_type: Literal[\"api_key\", \"oauth2\"] = \"api_key\"</code>","text":"<p>Authentication type for LLM calls.</p> <p>Options: - <code>\"api_key\"</code>: Use environment variables (default) - <code>\"oauth2\"</code>: Use OAuth2 token from OAuth2Manager</p> <p>Example: <pre><code>from kagura.core.llm import LLMConfig\n\n# OAuth2 authentication\nconfig = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\"\n)\n\n# API key authentication (default)\nconfig = LLMConfig(\n    model=\"gpt-4o-mini\",\n    auth_type=\"api_key\"  # Uses OPENAI_API_KEY env var\n)\n</code></pre></p>"},{"location":"en/api/auth/#oauth_provider-str-none-none","title":"<code>oauth_provider: str | None = None</code>","text":"<p>OAuth2 provider name when <code>auth_type=\"oauth2\"</code>.</p> <p>Required when: <code>auth_type=\"oauth2\"</code></p> <p>Example: <pre><code>config = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\"  # Required for OAuth2\n)\n</code></pre></p>"},{"location":"en/api/auth/#methods_1","title":"Methods","text":""},{"location":"en/api/auth/#get_api_key-str-none","title":"<code>get_api_key() -&gt; str | None</code>","text":"<p>Get API key or OAuth2 token based on <code>auth_type</code>.</p> <p>Returns: - <code>str | None</code>: API key or OAuth2 access token</p> <p>Raises: - <code>ValueError</code>: If OAuth2 is requested but auth module not installed - <code>NotAuthenticatedError</code>: If OAuth2 auth required but not logged in</p> <p>Example: <pre><code>config = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\"\n)\n\n# Get OAuth2 token automatically\ntoken = config.get_api_key()  # Returns OAuth2 access token\n</code></pre></p>"},{"location":"en/api/auth/#cli-commands","title":"CLI Commands","text":""},{"location":"en/api/auth/#kagura-auth-login","title":"kagura auth login","text":"<p>Authenticate with OAuth2 provider.</p> <p>Usage: <pre><code>kagura auth login [OPTIONS]\n</code></pre></p> <p>Options: - <code>--provider TEXT</code>: OAuth2 provider name (default: <code>google</code>)</p> <p>Example: <pre><code>kagura auth login --provider google\n</code></pre></p> <p>Output: <pre><code>\u2713 Authentication successful!\n\u2713 Credentials saved to: /home/user/.kagura/credentials.json.enc\n</code></pre></p>"},{"location":"en/api/auth/#kagura-auth-logout","title":"kagura auth logout","text":"<p>Remove stored OAuth2 credentials.</p> <p>Usage: <pre><code>kagura auth logout [OPTIONS]\n</code></pre></p> <p>Options: - <code>--provider TEXT</code>: OAuth2 provider name (default: <code>google</code>)</p> <p>Example: <pre><code>kagura auth logout --provider google\n</code></pre></p> <p>Output: <pre><code>\u2713 Logged out from google\n</code></pre></p>"},{"location":"en/api/auth/#kagura-auth-status","title":"kagura auth status","text":"<p>Check OAuth2 authentication status.</p> <p>Usage: <pre><code>kagura auth status [OPTIONS]\n</code></pre></p> <p>Options: - <code>--provider TEXT</code>: OAuth2 provider name (default: <code>google</code>)</p> <p>Example: <pre><code>kagura auth status --provider google\n</code></pre></p> <p>Output (authenticated): <pre><code>\u2713 Authenticated with google\nToken expires: 2025-10-13 15:30:00 UTC\n</code></pre></p> <p>Output (not authenticated): <pre><code>\u2717 Not authenticated with google\nRun: kagura auth login --provider google\n</code></pre></p>"},{"location":"en/api/auth/#complete-example","title":"Complete Example","text":"<p>Here's a complete example using OAuth2 authentication:</p> <pre><code>from kagura import agent\nfrom kagura.core.llm import LLMConfig\nfrom kagura.auth import OAuth2Manager\nfrom kagura.auth.exceptions import NotAuthenticatedError\n\n# Check if authenticated\nauth = OAuth2Manager(provider=\"google\")\nif not auth.is_authenticated():\n    print(\"Not authenticated. Please run: kagura auth login --provider google\")\n    exit(1)\n\n# Create OAuth2 LLM config\ngemini_config = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\",\n    temperature=0.7,\n    max_tokens=1000\n)\n\n# Define agent with OAuth2\n@agent(\n    name=\"gemini_assistant\",\n    template=\"Answer the question: {{ question }}\",\n    llm_config=gemini_config\n)\ndef ask_gemini(question: str) -&gt; str:\n    pass\n\n# Use the agent\ntry:\n    response = ask_gemini(\"What is the capital of France?\")\n    print(response)  # \"The capital of France is Paris.\"\nexcept NotAuthenticatedError:\n    print(\"Please authenticate: kagura auth login --provider google\")\n</code></pre>"},{"location":"en/api/auth/#see-also","title":"See Also","text":"<ul> <li>OAuth2 Authentication Guide</li> <li>LLM API Reference</li> <li>Installation Guide</li> </ul>"},{"location":"en/api/builder/","title":"AgentBuilder API","text":"<p>Fluent API for building agents with integrated features like memory, tools, and hooks.</p>"},{"location":"en/api/builder/#overview","title":"Overview","text":"<p><code>AgentBuilder</code> provides a declarative, method-chaining interface for creating complex agents. Instead of manually wiring together components, you specify what features you want, and the builder handles the integration.</p> <p>Key Features: - Fluent API with method chaining - Memory configuration (working, persistent, RAG) - Tool integration - Pre/post execution hooks - LLM parameter configuration - Agent routing</p>"},{"location":"en/api/builder/#class-agentbuilder","title":"Class: AgentBuilder","text":"<pre><code>from kagura import AgentBuilder\n\nbuilder = AgentBuilder(name=\"my_agent\")\n</code></pre>"},{"location":"en/api/builder/#constructor","title":"Constructor","text":"<pre><code>def __init__(self, name: str) -&gt; None\n</code></pre> <p>Parameters: - name (<code>str</code>, required): Agent name used for identification and logging</p> <p>Returns: <code>AgentBuilder</code> instance</p> <p>Example: <pre><code>builder = AgentBuilder(\"customer_support_bot\")\n</code></pre></p>"},{"location":"en/api/builder/#methods","title":"Methods","text":""},{"location":"en/api/builder/#with_model","title":"with_model()","text":"<p>Set the LLM model to use.</p> <pre><code>def with_model(self, model: str) -&gt; AgentBuilder\n</code></pre> <p>Parameters: - model (<code>str</code>): Model identifier (e.g., <code>\"gpt-4o-mini\"</code>, <code>\"claude-3-5-sonnet-20241022\"</code>)</p> <p>Returns: Self for method chaining</p> <p>Supported Models: - OpenAI: <code>\"gpt-4o\"</code>, <code>\"gpt-4o-mini\"</code>, <code>\"gpt-3.5-turbo\"</code> - Anthropic: <code>\"claude-3-5-sonnet-20241022\"</code>, <code>\"claude-3-haiku-20240307\"</code> - Google: <code>\"gemini/gemini-pro\"</code>, <code>\"gemini/gemini-1.5-flash\"</code> - Ollama: <code>\"ollama/llama3.2\"</code>, <code>\"ollama/gemma2\"</code></p> <p>Example: <pre><code>agent = (\n    AgentBuilder(\"translator\")\n    .with_model(\"gpt-4o-mini\")\n    .build()\n)\n</code></pre></p>"},{"location":"en/api/builder/#with_memory","title":"with_memory()","text":"<p>Configure the memory system.</p> <pre><code>def with_memory(\n    self,\n    type: str = \"working\",\n    persist_dir: Optional[Path] = None,\n    max_messages: int = 100,\n    enable_rag: bool = False,\n) -&gt; AgentBuilder\n</code></pre> <p>Parameters: - type (<code>str</code>, default: <code>\"working\"</code>): Memory type   - <code>\"working\"</code>: In-memory storage (fast, temporary)   - <code>\"context\"</code>: Conversation context for LLM   - <code>\"persistent\"</code>: SQLite storage (survives restarts)   - <code>\"rag\"</code>: Vector-based semantic search - persist_dir (<code>Optional[Path]</code>, default: <code>None</code>): Directory for persistent storage - max_messages (<code>int</code>, default: <code>100</code>): Maximum messages to store - enable_rag (<code>bool</code>, default: <code>False</code>): Enable RAG (requires ChromaDB)</p> <p>Returns: Self for method chaining</p> <p>Example: <pre><code># In-memory working memory\nagent = (\n    AgentBuilder(\"chatbot\")\n    .with_memory(type=\"working\", max_messages=50)\n    .build()\n)\n\n# Persistent memory with RAG\nagent = (\n    AgentBuilder(\"knowledge_bot\")\n    .with_memory(\n        type=\"persistent\",\n        persist_dir=Path.home() / \".kagura\" / \"memory\",\n        enable_rag=True,\n        max_messages=200\n    )\n    .build()\n)\n</code></pre></p>"},{"location":"en/api/builder/#with_routing","title":"with_routing()","text":"<p>Configure agent routing strategies.</p> <pre><code>def with_routing(\n    self,\n    strategy: str = \"semantic\",\n    routes: Optional[dict] = None,\n) -&gt; AgentBuilder\n</code></pre> <p>Parameters: - strategy (<code>str</code>, default: <code>\"semantic\"</code>): Routing strategy   - <code>\"keyword\"</code>: Keyword-based routing   - <code>\"llm\"</code>: LLM-powered routing   - <code>\"semantic\"</code>: Semantic similarity routing - routes (<code>Optional[dict]</code>, default: <code>None</code>): Route definitions mapping route names to agents</p> <p>Returns: Self for method chaining</p> <p>Example: <pre><code>routes = {\n    \"translate\": translator_agent,\n    \"summarize\": summarizer_agent,\n}\n\nagent = (\n    AgentBuilder(\"router\")\n    .with_routing(strategy=\"semantic\", routes=routes)\n    .build()\n)\n</code></pre></p>"},{"location":"en/api/builder/#with_tools","title":"with_tools()","text":"<p>Add tools to the agent.</p> <pre><code>def with_tools(self, tools: list[Callable]) -&gt; AgentBuilder\n</code></pre> <p>Parameters: - tools (<code>list[Callable]</code>): List of tool functions</p> <p>Returns: Self for method chaining</p> <p>Example: <pre><code>def search_web(query: str) -&gt; str:\n    \"\"\"Search the web.\"\"\"\n    return f\"Results for: {query}\"\n\ndef calculate(expression: str) -&gt; float:\n    \"\"\"Calculate math expression.\"\"\"\n    return eval(expression)\n\nagent = (\n    AgentBuilder(\"assistant\")\n    .with_tools([search_web, calculate])\n    .build()\n)\n</code></pre></p>"},{"location":"en/api/builder/#with_hooks","title":"with_hooks()","text":"<p>Add pre and post execution hooks.</p> <pre><code>def with_hooks(\n    self,\n    pre: Optional[list[Callable]] = None,\n    post: Optional[list[Callable]] = None,\n) -&gt; AgentBuilder\n</code></pre> <p>Parameters: - pre (<code>Optional[list[Callable]]</code>, default: <code>None</code>): Pre-execution hooks - post (<code>Optional[list[Callable]]</code>, default: <code>None</code>): Post-execution hooks</p> <p>Returns: Self for method chaining</p> <p>Hook Signatures: - Pre-hook: <code>def pre_hook(*args, **kwargs) -&gt; None</code> - Post-hook: <code>def post_hook(result: Any) -&gt; None</code></p> <p>Example: <pre><code>def log_input(*args, **kwargs):\n    print(f\"Input: {args}, {kwargs}\")\n\ndef log_output(result):\n    print(f\"Output: {result}\")\n\nagent = (\n    AgentBuilder(\"monitored_agent\")\n    .with_hooks(\n        pre=[log_input],\n        post=[log_output]\n    )\n    .build()\n)\n</code></pre></p>"},{"location":"en/api/builder/#with_context","title":"with_context()","text":"<p>Set LLM generation parameters.</p> <pre><code>def with_context(self, **kwargs: Any) -&gt; AgentBuilder\n</code></pre> <p>Parameters: - kwargs: LLM generation parameters   - <code>temperature</code> (<code>float</code>): Sampling temperature (0.0-2.0)   - <code>max_tokens</code> (<code>int</code>): Maximum response tokens   - <code>top_p</code> (<code>float</code>): Nucleus sampling threshold   - <code>frequency_penalty</code> (<code>float</code>): Repetition penalty   - <code>presence_penalty</code> (<code>float</code>): Topic diversity penalty   - Other LiteLLM-supported parameters</p> <p>Returns: Self for method chaining</p> <p>Example: <pre><code># Deterministic agent (factual tasks)\nfactual = (\n    AgentBuilder(\"fact_checker\")\n    .with_context(\n        temperature=0.2,\n        max_tokens=500\n    )\n    .build()\n)\n\n# Creative agent (story generation)\ncreative = (\n    AgentBuilder(\"storyteller\")\n    .with_context(\n        temperature=1.5,\n        max_tokens=2000,\n        top_p=0.9\n    )\n    .build()\n)\n</code></pre></p>"},{"location":"en/api/builder/#build","title":"build()","text":"<p>Build and return the final agent.</p> <pre><code>def build(self) -&gt; Callable\n</code></pre> <p>Returns: Callable agent function</p> <p>Raises: - <code>ValueError</code>: If configuration is invalid</p> <p>Example: <pre><code>agent = (\n    AgentBuilder(\"my_agent\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(type=\"working\")\n    .build()\n)\n\n# Use the agent\nresult = await agent(\"Hello!\")\n</code></pre></p>"},{"location":"en/api/builder/#complete-example","title":"Complete Example","text":"<pre><code>import asyncio\nfrom pathlib import Path\nfrom kagura import AgentBuilder\n\n\ndef search_web(query: str) -&gt; str:\n    \"\"\"Search the web.\"\"\"\n    return f\"Search results for: {query}\"\n\n\ndef log_execution(result):\n    \"\"\"Log agent executions.\"\"\"\n    print(f\"[LOG] Result: {result}\")\n\n\nasync def main():\n    # Build a complex agent\n    agent = (\n        AgentBuilder(\"advanced_assistant\")\n        .with_model(\"gpt-4o-mini\")\n        .with_memory(\n            type=\"persistent\",\n            persist_dir=Path.home() / \".kagura\" / \"agents\",\n            max_messages=100,\n            enable_rag=True\n        )\n        .with_tools([search_web])\n        .with_hooks(post=[log_execution])\n        .with_context(\n            temperature=0.7,\n            max_tokens=800\n        )\n        .build()\n    )\n\n    # Use the agent\n    result = await agent(\"Search for Python tutorials\")\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/api/builder/#configuration-classes","title":"Configuration Classes","text":""},{"location":"en/api/builder/#agentconfiguration","title":"AgentConfiguration","text":"<pre><code>from kagura.builder import AgentConfiguration\n\nconfig = AgentConfiguration(\n    name=\"my_agent\",\n    model=\"gpt-4o-mini\"\n)\n</code></pre> <p>Fields: - name (<code>str</code>): Agent name - model (<code>str</code>): LLM model - memory (<code>Optional[MemoryConfig]</code>): Memory configuration - routing (<code>Optional[RoutingConfig]</code>): Routing configuration - tools (<code>list[Callable]</code>): Tool functions - hooks (<code>Optional[HooksConfig]</code>): Hook configuration - context (<code>dict[str, Any]</code>): LLM parameters</p>"},{"location":"en/api/builder/#memoryconfig","title":"MemoryConfig","text":"<pre><code>from kagura.builder import MemoryConfig\n\nmemory = MemoryConfig(\n    type=\"persistent\",\n    persist_dir=Path(\".kagura\"),\n    max_messages=100,\n    enable_rag=True\n)\n</code></pre> <p>Fields: - type (<code>str</code>): Memory type - persist_dir (<code>Optional[Path]</code>): Storage directory - max_messages (<code>int</code>): Message limit - enable_rag (<code>bool</code>): Enable RAG</p>"},{"location":"en/api/builder/#routingconfig","title":"RoutingConfig","text":"<pre><code>from kagura.builder import RoutingConfig\n\nrouting = RoutingConfig(\n    strategy=\"semantic\",\n    routes={\"translate\": translator_agent}\n)\n</code></pre> <p>Fields: - strategy (<code>str</code>): Routing strategy - routes (<code>dict</code>): Route mappings</p>"},{"location":"en/api/builder/#hooksconfig","title":"HooksConfig","text":"<pre><code>from kagura.builder import HooksConfig\n\nhooks = HooksConfig(\n    pre=[pre_hook1, pre_hook2],\n    post=[post_hook1, post_hook2]\n)\n</code></pre> <p>Fields: - pre (<code>list[Callable]</code>): Pre-execution hooks - post (<code>list[Callable]</code>): Post-execution hooks</p>"},{"location":"en/api/builder/#best-practices","title":"Best Practices","text":""},{"location":"en/api/builder/#1-use-descriptive-names","title":"1. Use Descriptive Names","text":"<pre><code># Good\nAgentBuilder(\"customer_support_chatbot\")\n\n# Less clear\nAgentBuilder(\"agent1\")\n</code></pre>"},{"location":"en/api/builder/#2-chain-methods-vertically","title":"2. Chain Methods Vertically","text":"<pre><code># Good - readable\nagent = (\n    AgentBuilder(\"name\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(type=\"rag\")\n    .build()\n)\n\n# Less readable\nagent = AgentBuilder(\"name\").with_model(\"gpt-4o-mini\").with_memory(type=\"rag\").build()\n</code></pre>"},{"location":"en/api/builder/#3-choose-appropriate-memory-type","title":"3. Choose Appropriate Memory Type","text":"<pre><code># Short conversations\n.with_memory(type=\"working\")\n\n# Long-term knowledge\n.with_memory(type=\"persistent\", enable_rag=True)\n\n# Context-aware\n.with_memory(type=\"context\", max_messages=20)\n</code></pre>"},{"location":"en/api/builder/#4-temperature-selection","title":"4. Temperature Selection","text":"<pre><code># Factual tasks (low temperature)\n.with_context(temperature=0.2)\n\n# Balanced (medium temperature)\n.with_context(temperature=0.7)\n\n# Creative tasks (high temperature)\n.with_context(temperature=1.5)\n</code></pre>"},{"location":"en/api/builder/#error-handling","title":"Error Handling","text":"<pre><code>from kagura import AgentBuilder\n\ntry:\n    agent = (\n        AgentBuilder(\"my_agent\")\n        .with_model(\"invalid-model\")\n        .build()\n    )\nexcept ValueError as e:\n    print(f\"Configuration error: {e}\")\n\ntry:\n    agent = (\n        AgentBuilder(\"my_agent\")\n        .with_memory(enable_rag=True)  # Without ChromaDB\n        .build()\n    )\nexcept ImportError as e:\n    print(f\"Missing dependency: {e}\")\n</code></pre>"},{"location":"en/api/builder/#related","title":"Related","text":"<ul> <li>Tutorial: Agent Builder - Step-by-step guide</li> <li>@agent Decorator - Core agent decorator</li> <li>Memory Management - Memory system details</li> <li>Agent Routing - Routing strategies</li> </ul>"},{"location":"en/api/builder/#see-also","title":"See Also","text":"<ul> <li>Quick Start - Getting started guide</li> <li>Tutorial: Testing - Testing agents</li> <li>Tutorial: Observability - Monitoring agents</li> </ul>"},{"location":"en/api/chat/","title":"Chat API Reference","text":"<p>API documentation for the Kagura Chat REPL system.</p>"},{"location":"en/api/chat/#chatsession","title":"ChatSession","text":"<p>The main class for managing interactive chat sessions.</p>"},{"location":"en/api/chat/#constructor","title":"Constructor","text":"<pre><code>from kagura.chat import ChatSession\n\nsession = ChatSession(\n    model=\"gpt-4o-mini\",\n    session_dir=None\n)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>model</code> <code>str</code> <code>\"gpt-4o-mini\"</code> LLM model to use for chat <code>session_dir</code> <code>Path \\| None</code> <code>~/.kagura/sessions</code> Directory for session storage"},{"location":"en/api/chat/#methods","title":"Methods","text":""},{"location":"en/api/chat/#run","title":"<code>run()</code>","text":"<p>Start the interactive chat loop.</p> <pre><code>async def run() -&gt; None\n</code></pre> <p>Example:</p> <pre><code>session = ChatSession()\nawait session.run()\n</code></pre>"},{"location":"en/api/chat/#chatuser_input","title":"<code>chat(user_input)</code>","text":"<p>Handle a single chat interaction.</p> <pre><code>async def chat(user_input: str) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>user_input</code> (<code>str</code>): User message</li> </ul> <p>Example:</p> <pre><code>await session.chat(\"What is Python?\")\n</code></pre>"},{"location":"en/api/chat/#save_sessionname","title":"<code>save_session(name)</code>","text":"<p>Save the current conversation session.</p> <pre><code>async def save_session(name: str = \"\") -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>name</code> (<code>str</code>, optional): Session name. If empty, uses timestamp.</li> </ul> <p>Example:</p> <pre><code># Save with custom name\nawait session.save_session(\"my_session\")\n\n# Save with auto-generated name\nawait session.save_session()\n</code></pre>"},{"location":"en/api/chat/#load_sessionname","title":"<code>load_session(name)</code>","text":"<p>Load a previously saved session.</p> <pre><code>async def load_session(name: str) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>name</code> (<code>str</code>): Session name to load</li> </ul> <p>Example:</p> <pre><code>await session.load_session(\"my_session\")\n</code></pre>"},{"location":"en/api/chat/#clear_history","title":"<code>clear_history()</code>","text":"<p>Clear the conversation history.</p> <pre><code>def clear_history() -&gt; None\n</code></pre> <p>Example:</p> <pre><code>session.clear_history()\n</code></pre>"},{"location":"en/api/chat/#show_welcome","title":"<code>show_welcome()</code>","text":"<p>Display the welcome message.</p> <pre><code>def show_welcome() -&gt; None\n</code></pre>"},{"location":"en/api/chat/#show_help","title":"<code>show_help()</code>","text":"<p>Display the help message.</p> <pre><code>def show_help() -&gt; None\n</code></pre>"},{"location":"en/api/chat/#preset-commands","title":"Preset Commands","text":""},{"location":"en/api/chat/#preset_translateargs","title":"<code>preset_translate(args)</code>","text":"<p>Translate text using the built-in translation agent.</p> <pre><code>async def preset_translate(args: str) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>args</code> (<code>str</code>): Translation arguments in format: <code>\"text [to language]\"</code></li> </ul> <p>Example:</p> <pre><code>await session.preset_translate(\"Hello to ja\")\nawait session.preset_translate(\"Bonjour to en\")\n</code></pre>"},{"location":"en/api/chat/#preset_summarizeargs","title":"<code>preset_summarize(args)</code>","text":"<p>Summarize text using the built-in summarization agent.</p> <pre><code>async def preset_summarize(args: str) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>args</code> (<code>str</code>): Text to summarize</li> </ul> <p>Example:</p> <pre><code>await session.preset_summarize(\"Long text here...\")\n</code></pre>"},{"location":"en/api/chat/#preset_reviewargs","title":"<code>preset_review(args)</code>","text":"<p>Review code using the built-in code review agent.</p> <pre><code>async def preset_review(args: str) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>args</code> (<code>str</code>): Code to review (or empty to prompt for input)</li> </ul> <p>Example:</p> <pre><code>code = \"\"\"\ndef divide(a, b):\n    return a / b\n\"\"\"\nawait session.preset_review(code)\n</code></pre>"},{"location":"en/api/chat/#preset-agents","title":"Preset Agents","text":""},{"location":"en/api/chat/#translateagent","title":"TranslateAgent","text":"<p>Translate text to a target language.</p> <pre><code>from kagura.chat import TranslateAgent\n\nresult = await TranslateAgent(\n    text=\"Hello World\",\n    target_language=\"ja\"\n)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>text</code> <code>str</code> - Text to translate <code>target_language</code> <code>str</code> <code>\"ja\"</code> Target language code <p>Returns: <code>str</code> - Translated text</p> <p>Example:</p> <pre><code># Translate to Japanese (default)\nresult = await TranslateAgent(\"Good morning\")\n# Output: \"\u304a\u306f\u3088\u3046\u3054\u3056\u3044\u307e\u3059\"\n\n# Translate to Spanish\nresult = await TranslateAgent(\"Hello\", target_language=\"es\")\n# Output: \"Hola\"\n\n# Translate to French\nresult = await TranslateAgent(\"Thank you\", target_language=\"fr\")\n# Output: \"Merci\"\n</code></pre>"},{"location":"en/api/chat/#summarizeagent","title":"SummarizeAgent","text":"<p>Summarize long text into a concise summary.</p> <pre><code>from kagura.chat import SummarizeAgent\n\nresult = await SummarizeAgent(\n    text=\"Long text here...\",\n    max_sentences=3\n)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>text</code> <code>str</code> - Text to summarize <code>max_sentences</code> <code>int</code> <code>3</code> Maximum sentences in summary <p>Returns: <code>str</code> - Summarized text</p> <p>Example:</p> <pre><code>long_text = \"\"\"\nArtificial intelligence (AI) is intelligence demonstrated by machines,\nas opposed to natural intelligence displayed by animals including humans.\nAI research has been defined as the field of study of intelligent agents,\nwhich refers to any system that perceives its environment and takes actions\nthat maximize its chance of achieving its goals.\n\"\"\"\n\nsummary = await SummarizeAgent(long_text, max_sentences=2)\n# Output: \"AI is machine intelligence. It studies intelligent\n#          agents that perceive and act to achieve goals.\"\n</code></pre>"},{"location":"en/api/chat/#codereviewagent","title":"CodeReviewAgent","text":"<p>Review code and provide feedback on issues, improvements, and best practices.</p> <pre><code>from kagura.chat import CodeReviewAgent\n\nresult = await CodeReviewAgent(\n    code=\"def add(a, b): return a + b\",\n    language=\"python\"\n)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>code</code> <code>str</code> - Code to review <code>language</code> <code>str</code> <code>\"python\"</code> Programming language <p>Returns: <code>str</code> - Code review in markdown format</p> <p>Example:</p> <pre><code>code = \"\"\"\ndef divide(a, b):\n    return a / b\n\"\"\"\n\nreview = await CodeReviewAgent(code)\n# Output: Detailed markdown review with:\n# - Issues found (division by zero, missing type hints)\n# - Improvement suggestions\n# - Best practices recommendations\n</code></pre>"},{"location":"en/api/chat/#cli-command","title":"CLI Command","text":""},{"location":"en/api/chat/#kagura-chat","title":"<code>kagura chat</code>","text":"<p>Start an interactive chat session.</p> <pre><code>kagura chat [OPTIONS]\n</code></pre> <p>Options:</p> Option Short Type Default Description <code>--model</code> <code>-m</code> <code>str</code> <code>gpt-4o-mini</code> LLM model to use <p>Examples:</p> <pre><code># Start with default model\nkagura chat\n\n# Use GPT-4o\nkagura chat --model gpt-4o\n\n# Use Claude\nkagura chat -m claude-3-5-sonnet-20241022\n\n# Use Gemini\nkagura chat -m gemini/gemini-2.0-flash-exp\n</code></pre>"},{"location":"en/api/chat/#session-file-format","title":"Session File Format","text":"<p>Session files are stored as JSON in <code>~/.kagura/sessions/</code>.</p> <p>Format:</p> <pre><code>{\n  \"name\": \"my_session\",\n  \"created_at\": \"2025-10-10T14:30:15.123456\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"What is Python?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"Python is a high-level programming language...\"\n    }\n  ]\n}\n</code></pre> <p>Fields:</p> Field Type Description <code>name</code> <code>str</code> Session name <code>created_at</code> <code>str</code> ISO 8601 timestamp <code>messages</code> <code>list[dict]</code> List of messages <p>Message format:</p> Field Type Description <code>role</code> <code>str</code> Message role (<code>user</code>, <code>assistant</code>, <code>system</code>) <code>content</code> <code>str</code> Message content"},{"location":"en/api/chat/#configuration","title":"Configuration","text":""},{"location":"en/api/chat/#environment-variables","title":"Environment Variables","text":"Variable Description Default <code>OPENAI_API_KEY</code> OpenAI API key Required for OpenAI models <code>ANTHROPIC_API_KEY</code> Anthropic API key Required for Claude models <code>GOOGLE_API_KEY</code> Google API key Required for Gemini models"},{"location":"en/api/chat/#session-directory","title":"Session Directory","text":"<p>Default: <code>~/.kagura/sessions/</code></p> <p>Override with <code>ChatSession(session_dir=Path(\"/custom/path\"))</code></p>"},{"location":"en/api/chat/#history-file","title":"History File","text":"<p>Chat history is stored in: <code>~/.kagura/sessions/chat_history.txt</code></p> <p>Accessible via up/down arrows in the chat interface.</p>"},{"location":"en/api/chat/#integration-examples","title":"Integration Examples","text":""},{"location":"en/api/chat/#programmatic-chat","title":"Programmatic Chat","text":"<pre><code>from kagura.chat import ChatSession\n\nasync def automated_chat():\n    session = ChatSession(model=\"gpt-4o-mini\")\n\n    # Simulate chat interactions\n    await session.chat(\"Explain recursion\")\n    await session.chat(\"Give me an example in Python\")\n\n    # Save session\n    await session.save_session(\"recursion_tutorial\")\n\n# Run\nimport asyncio\nasyncio.run(automated_chat())\n</code></pre>"},{"location":"en/api/chat/#custom-preset-agent","title":"Custom Preset Agent","text":"<pre><code>from kagura import agent\n\n@agent(model=\"gpt-4o-mini\", temperature=0.3)\nasync def CustomPresetAgent(text: str, task: str) -&gt; str:\n    \"\"\"\n    Perform {{ task }} on the following text:\n\n    {{ text }}\n\n    Provide a concise result.\n    \"\"\"\n    pass\n\n# Use in Chat Session\nsession = ChatSession()\nresult = await CustomPresetAgent(\n    text=\"Sample text\",\n    task=\"sentiment analysis\"\n)\n</code></pre>"},{"location":"en/api/chat/#session-management","title":"Session Management","text":"<pre><code>from pathlib import Path\nfrom kagura.chat import ChatSession\n\n# Use custom session directory\nsession_dir = Path(\"./my_sessions\")\nsession = ChatSession(session_dir=session_dir)\n\n# Save multiple sessions\nawait session.chat(\"Python tutorial\")\nawait session.save_session(\"python_basics\")\n\nsession.clear_history()\n\nawait session.chat(\"JavaScript tutorial\")\nawait session.save_session(\"js_basics\")\n\n# List all sessions\nsessions = list(session_dir.glob(\"*.json\"))\nprint(f\"Available sessions: {[s.stem for s in sessions]}\")\n</code></pre>"},{"location":"en/api/chat/#error-handling","title":"Error Handling","text":""},{"location":"en/api/chat/#api-key-missing","title":"API Key Missing","text":"<pre><code># Raises: openai.error.AuthenticationError\nsession = ChatSession()\nawait session.run()\n</code></pre> <p>Solution: Set environment variable</p> <pre><code>export OPENAI_API_KEY=your_key_here\n</code></pre>"},{"location":"en/api/chat/#session-not-found","title":"Session Not Found","text":"<pre><code>await session.load_session(\"nonexistent\")\n# Prints: \"Session not found: nonexistent\"\n</code></pre>"},{"location":"en/api/chat/#invalid-model","title":"Invalid Model","text":"<pre><code>session = ChatSession(model=\"invalid-model\")\n# Raises: litellm.exceptions.BadRequestError\n</code></pre>"},{"location":"en/api/chat/#best-practices","title":"Best Practices","text":""},{"location":"en/api/chat/#1-save-important-conversations","title":"1. Save Important Conversations","text":"<pre><code># Before exiting, save valuable sessions\nawait session.save_session(\"important_discussion\")\n</code></pre>"},{"location":"en/api/chat/#2-use-appropriate-models","title":"2. Use Appropriate Models","text":"<pre><code># Fast responses for simple tasks\nsession = ChatSession(model=\"gpt-4o-mini\")\n\n# Higher quality for complex tasks\nsession = ChatSession(model=\"gpt-4o\")\n</code></pre>"},{"location":"en/api/chat/#3-clear-history-for-new-topics","title":"3. Clear History for New Topics","text":"<pre><code># Start fresh conversation\nsession.clear_history()\nawait session.chat(\"New topic...\")\n</code></pre>"},{"location":"en/api/chat/#4-organize-sessions","title":"4. Organize Sessions","text":"<pre><code># Use descriptive names\nawait session.save_session(\"python_debugging_2025-10-10\")\nawait session.save_session(\"code_review_auth_module\")\n</code></pre>"},{"location":"en/api/chat/#see-also","title":"See Also","text":"<ul> <li>Chat REPL Tutorial</li> <li>Memory Management API</li> <li>Agent Decorator</li> <li>CLI Reference</li> </ul>"},{"location":"en/api/compression/","title":"Context Compression API","text":"<p>RFC-024 Phase 1: Token Management</p> <p>Status: Phase 1 Implemented Since: v2.5.0</p>"},{"location":"en/api/compression/#overview","title":"Overview","text":"<p>The compression module provides token counting and context window management for efficient long-form conversations.</p> <p>Key Components: - <code>TokenCounter</code>: Accurate token counting for all major LLM models - <code>ContextMonitor</code>: Real-time context window usage monitoring - <code>ContextUsage</code>: Usage statistics dataclass</p>"},{"location":"en/api/compression/#tokencounter","title":"TokenCounter","text":"<p>Count tokens for various LLM models using tiktoken.</p>"},{"location":"en/api/compression/#constructor","title":"Constructor","text":"<pre><code>TokenCounter(model: str = \"gpt-4o-mini\")\n</code></pre> <p>Parameters: - <code>model</code> (str): LLM model name. Supported models:   - OpenAI: <code>gpt-4o-mini</code>, <code>gpt-4o</code>, <code>gpt-4-turbo</code>, <code>gpt-3.5-turbo</code>   - Anthropic: <code>claude-3-5-sonnet</code>, <code>claude-3-opus</code>, <code>claude-3-sonnet</code>   - Google: <code>gemini-1.5-pro</code>, <code>gemini-1.5-flash</code></p> <p>Example: <pre><code>from kagura.core.compression import TokenCounter\n\ncounter = TokenCounter(model=\"gpt-4o-mini\")\n</code></pre></p>"},{"location":"en/api/compression/#methods","title":"Methods","text":""},{"location":"en/api/compression/#count_tokens","title":"count_tokens","text":"<p>Count tokens in text.</p> <pre><code>def count_tokens(text: str) -&gt; int\n</code></pre> <p>Parameters: - <code>text</code> (str): Text to count</p> <p>Returns: - <code>int</code>: Number of tokens</p> <p>Example: <pre><code>counter = TokenCounter()\ntokens = counter.count_tokens(\"Hello, world!\")\nprint(f\"Tokens: {tokens}\")  # Tokens: 4\n</code></pre></p>"},{"location":"en/api/compression/#count_tokens_messages","title":"count_tokens_messages","text":"<p>Count tokens in message list (OpenAI format).</p> <p>Includes overhead for message formatting (3 tokens per message + 3 tokens reply priming).</p> <pre><code>def count_tokens_messages(messages: list[dict[str, Any]]) -&gt; int\n</code></pre> <p>Parameters: - <code>messages</code> (list[dict]): List of messages with <code>role</code> and <code>content</code> fields</p> <p>Returns: - <code>int</code>: Total token count including overhead</p> <p>Example: <pre><code>messages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Hello!\"},\n    {\"role\": \"assistant\", \"content\": \"Hi there!\"}\n]\n\ntokens = counter.count_tokens_messages(messages)\nprint(f\"Total tokens: {tokens}\")\n</code></pre></p>"},{"location":"en/api/compression/#estimate_context_size","title":"estimate_context_size","text":"<p>Estimate total context window usage.</p> <pre><code>def estimate_context_size(\n    messages: list[dict[str, Any]],\n    system_prompt: str = \"\",\n    max_tokens: int = 1000\n) -&gt; dict[str, int]\n</code></pre> <p>Parameters: - <code>messages</code>: Conversation history - <code>system_prompt</code>: System prompt (default: \"\") - <code>max_tokens</code>: Max completion tokens (default: 1000)</p> <p>Returns: - Dictionary with keys:   - <code>prompt_tokens</code> (int): Tokens in prompts   - <code>completion_tokens</code> (int): Reserved for completion   - <code>total_tokens</code> (int): Total tokens</p> <p>Example: <pre><code>estimate = counter.estimate_context_size(\n    messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n    system_prompt=\"Be helpful.\",\n    max_tokens=1000\n)\n\nprint(f\"Prompt tokens: {estimate['prompt_tokens']}\")\nprint(f\"Total tokens: {estimate['total_tokens']}\")\n</code></pre></p>"},{"location":"en/api/compression/#should_compress","title":"should_compress","text":"<p>Decide if compression is needed.</p> <pre><code>def should_compress(\n    current_tokens: int,\n    max_tokens: int,\n    threshold: float = 0.8\n) -&gt; bool\n</code></pre> <p>Parameters: - <code>current_tokens</code>: Current token count - <code>max_tokens</code>: Maximum allowed tokens - <code>threshold</code>: Trigger compression at this ratio (default: 0.8 = 80%)</p> <p>Returns: - <code>bool</code>: True if compression should be triggered</p> <p>Example: <pre><code># Check if compression needed\nif counter.should_compress(current_tokens=9000, max_tokens=10000):\n    print(\"Time to compress!\")\n</code></pre></p>"},{"location":"en/api/compression/#get_model_limits","title":"get_model_limits","text":"<p>Get token limits for specific model.</p> <pre><code>def get_model_limits(model: str) -&gt; dict[str, int]\n</code></pre> <p>Parameters: - <code>model</code> (str): Model name</p> <p>Returns: - Dictionary with keys:   - <code>context_window</code> (int): Maximum context window size   - <code>max_completion</code> (int): Maximum completion tokens</p> <p>Example: <pre><code>limits = counter.get_model_limits(\"gpt-4o-mini\")\nprint(f\"Context window: {limits['context_window']:,}\")  # 128,000\nprint(f\"Max completion: {limits['max_completion']:,}\")  # 16,384\n</code></pre></p> <p>Supported Models:</p> Model Context Window Max Completion gpt-4o-mini 128,000 16,384 gpt-4o 128,000 16,384 gpt-4-turbo 128,000 4,096 gpt-3.5-turbo 16,385 4,096 claude-3-5-sonnet 200,000 8,192 claude-3-opus 200,000 4,096 gemini-1.5-pro 2,000,000 8,192 gemini-1.5-flash 1,000,000 8,192 unknown 8,000 2,000"},{"location":"en/api/compression/#contextmonitor","title":"ContextMonitor","text":"<p>Monitor context window usage and recommend compression.</p>"},{"location":"en/api/compression/#constructor_1","title":"Constructor","text":"<pre><code>ContextMonitor(\n    token_counter: TokenCounter,\n    max_tokens: Optional[int] = None\n)\n</code></pre> <p>Parameters: - <code>token_counter</code>: TokenCounter instance - <code>max_tokens</code>: Max context window (if None, auto-detect from model)</p> <p>Auto-detection: When <code>max_tokens=None</code>, the monitor automatically calculates the safe limit as: <pre><code>max_tokens = model_context_window - 4000\n</code></pre></p> <p>This reserves 4000 tokens for completion.</p> <p>Example: <pre><code>from kagura.core.compression import TokenCounter, ContextMonitor\n\ncounter = TokenCounter(model=\"gpt-4o-mini\")\n\n# Explicit limit\nmonitor = ContextMonitor(counter, max_tokens=10000)\n\n# Auto-detect (128k - 4k = 124k for gpt-4o-mini)\nmonitor_auto = ContextMonitor(counter, max_tokens=None)\n</code></pre></p>"},{"location":"en/api/compression/#methods_1","title":"Methods","text":""},{"location":"en/api/compression/#check_usage","title":"check_usage","text":"<p>Check current context usage.</p> <pre><code>def check_usage(\n    messages: list[dict[str, Any]],\n    system_prompt: str = \"\"\n) -&gt; ContextUsage\n</code></pre> <p>Parameters: - <code>messages</code>: Message history - <code>system_prompt</code>: System prompt (default: \"\")</p> <p>Returns: - <code>ContextUsage</code>: Usage statistics</p> <p>Example: <pre><code>messages = [\n    {\"role\": \"user\", \"content\": \"Hello\"},\n    {\"role\": \"assistant\", \"content\": \"Hi!\"}\n]\n\nusage = monitor.check_usage(messages, system_prompt=\"Be helpful.\")\n\nprint(f\"Usage: {usage.usage_ratio:.1%}\")  # e.g., 5.2%\nprint(f\"Tokens: {usage.total_tokens} / {usage.max_tokens}\")\n\nif usage.should_compress:\n    print(\"\u26a0\ufe0f Context is getting full. Compression recommended!\")\n</code></pre></p>"},{"location":"en/api/compression/#contextusage","title":"ContextUsage","text":"<p>Context usage statistics (dataclass).</p>"},{"location":"en/api/compression/#attributes","title":"Attributes","text":"<ul> <li><code>prompt_tokens</code> (int): Tokens in prompts (messages + system prompt)</li> <li><code>completion_tokens</code> (int): Reserved for completion</li> <li><code>total_tokens</code> (int): Total tokens (prompt + completion)</li> <li><code>max_tokens</code> (int): Maximum allowed tokens</li> <li><code>usage_ratio</code> (float): Usage ratio (0.0 - 1.0)</li> <li><code>should_compress</code> (bool): Whether compression is recommended</li> </ul> <p>Example: <pre><code>&gt;&gt;&gt; usage = monitor.check_usage(messages)\n&gt;&gt;&gt; usage\nContextUsage(\n    prompt_tokens=500,\n    completion_tokens=4000,\n    total_tokens=4500,\n    max_tokens=10000,\n    usage_ratio=0.45,\n    should_compress=False\n)\n</code></pre></p>"},{"location":"en/api/compression/#exceptions","title":"Exceptions","text":""},{"location":"en/api/compression/#compressionerror","title":"CompressionError","text":"<p>Base exception for compression errors.</p> <pre><code>class CompressionError(Exception)\n</code></pre>"},{"location":"en/api/compression/#tokencounterror","title":"TokenCountError","text":"<p>Error during token counting.</p> <pre><code>class TokenCountError(CompressionError)\n</code></pre> <p>Example: <pre><code>from kagura.core.compression import TokenCountError\n\ntry:\n    tokens = counter.count_tokens(text)\nexcept TokenCountError as e:\n    print(f\"Failed to count tokens: {e}\")\n</code></pre></p>"},{"location":"en/api/compression/#modelnotsupportederror","title":"ModelNotSupportedError","text":"<p>Model is not supported.</p> <pre><code>class ModelNotSupportedError(CompressionError)\n</code></pre>"},{"location":"en/api/compression/#installation","title":"Installation","text":"<p>Install with compression support:</p> <pre><code>pip install kagura-ai[ai]\n\n# Or install all features\npip install kagura-ai[all]\n</code></pre>"},{"location":"en/api/compression/#see-also","title":"See Also","text":"<ul> <li>Context Compression Guide - User guide with examples</li> <li>RFC-024 - Full specification</li> <li>Memory Management API - Memory system (will integrate in Phase 4)</li> </ul> <p>Phase 1 provides token counting and monitoring. Phases 2-4 will add trimming, summarization, and automatic compression.</p>"},{"location":"en/api/executor/","title":"Code Executor","text":"<p>The Code Executor provides safe Python code generation and execution capabilities in Kagura AI.</p>"},{"location":"en/api/executor/#overview","title":"Overview","text":"<p>The code execution system consists of: 1. CodeExecutor: Low-level code execution with security constraints 2. execute_code(): High-level agent that generates and executes code from natural language</p>"},{"location":"en/api/executor/#execute_code-function","title":"execute_code() Function","text":"<p>The simplest way to use code execution is through the <code>execute_code()</code> convenience function.</p>"},{"location":"en/api/executor/#signature","title":"Signature","text":"<pre><code>async def execute_code(task: str, *, model: str = \"gpt-4o-mini\") -&gt; dict\n</code></pre>"},{"location":"en/api/executor/#parameters","title":"Parameters","text":"<ul> <li>task (<code>str</code>): Natural language description of what to calculate or compute</li> <li>model (<code>str</code>, optional): LLM model to use for code generation</li> </ul>"},{"location":"en/api/executor/#return-value","title":"Return Value","text":"<p>Returns a dictionary with the following keys:</p> <pre><code>{\n    \"success\": bool,          # True if execution succeeded\n    \"code\": str,              # Generated Python code\n    \"result\": Any,            # Value of the 'result' variable\n    \"error\": str | None,      # Error message if failed\n}\n</code></pre>"},{"location":"en/api/executor/#examples","title":"Examples","text":""},{"location":"en/api/executor/#basic-calculation","title":"Basic Calculation","text":"<pre><code>from kagura.agents import execute_code\n\nresult = await execute_code(\"Calculate the factorial of 10\")\n\nif result[\"success\"]:\n    print(f\"Code:\\n{result['code']}\\n\")\n    print(f\"Result: {result['result']}\")\n    # Code:\n    # import math\n    # result = math.factorial(10)\n    #\n    # Result: 3628800\nelse:\n    print(f\"Error: {result['error']}\")\n</code></pre>"},{"location":"en/api/executor/#string-processing","title":"String Processing","text":"<pre><code>result = await execute_code(\"Reverse the string 'Hello, World!' and make it uppercase\")\n\nif result[\"success\"]:\n    print(result['result'])  # \"!DLROW ,OLLEH\"\n</code></pre>"},{"location":"en/api/executor/#list-operations","title":"List Operations","text":"<pre><code>result = await execute_code(\"Create a list of squares of numbers from 1 to 10\")\n\nif result[\"success\"]:\n    print(result['result'])  # [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n</code></pre>"},{"location":"en/api/executor/#statistical-analysis","title":"Statistical Analysis","text":"<pre><code>result = await execute_code(\n    \"Calculate the mean and standard deviation of [10, 20, 30, 40, 50]\"\n)\n\nif result[\"success\"]:\n    print(result['result'])\n    # {'mean': 30.0, 'stdev': 15.811388300841896}\n</code></pre>"},{"location":"en/api/executor/#error-handling","title":"Error Handling","text":"<pre><code>result = await execute_code(\"Divide 100 by 0\")\n\nif not result[\"success\"]:\n    print(f\"Error: {result['error']}\")\n    # Error: division by zero\n</code></pre>"},{"location":"en/api/executor/#codeexecutor-class","title":"CodeExecutor Class","text":"<p>For more control, use the <code>CodeExecutor</code> class directly.</p>"},{"location":"en/api/executor/#signature_1","title":"Signature","text":"<pre><code>class CodeExecutor:\n    def __init__(\n        self,\n        timeout: float = 30.0,\n        max_memory: int = 512 * 1024 * 1024,  # 512MB\n        allowed_imports: set[str] | None = None\n    )\n</code></pre>"},{"location":"en/api/executor/#parameters_1","title":"Parameters","text":"<ul> <li>timeout (<code>float</code>, default: <code>30.0</code>): Maximum execution time in seconds</li> <li>max_memory (<code>int</code>, default: <code>512MB</code>): Maximum memory usage in bytes</li> <li>allowed_imports (<code>set[str] | None</code>): Set of allowed import modules. If <code>None</code>, uses default safe list.</li> </ul>"},{"location":"en/api/executor/#methods","title":"Methods","text":""},{"location":"en/api/executor/#execute","title":"execute()","text":"<pre><code>async def execute(self, code: str) -&gt; ExecutionResult\n</code></pre> <p>Executes Python code and returns the result.</p> <p>Parameters: - code (<code>str</code>): Python code to execute. Must set a variable named <code>result</code>.</p> <p>Returns: - <code>ExecutionResult</code> object with fields:   - <code>success</code> (<code>bool</code>): Whether execution succeeded   - <code>result</code> (<code>Any</code>): Value of the <code>result</code> variable   - <code>error</code> (<code>str | None</code>): Error message if failed   - <code>stdout</code> (<code>str</code>): Captured stdout output   - <code>stderr</code> (<code>str</code>): Captured stderr output</p>"},{"location":"en/api/executor/#examples_1","title":"Examples","text":""},{"location":"en/api/executor/#basic-usage","title":"Basic Usage","text":"<pre><code>from kagura.core.executor import CodeExecutor\n\nexecutor = CodeExecutor()\n\nresult = await executor.execute(\"\"\"\nimport math\nresult = math.sqrt(16)\n\"\"\")\n\nprint(result.success)  # True\nprint(result.result)   # 4.0\n</code></pre>"},{"location":"en/api/executor/#custom-timeout","title":"Custom Timeout","text":"<pre><code>executor = CodeExecutor(timeout=60.0)\n\nresult = await executor.execute(\"\"\"\nimport time\ntime.sleep(2)\nresult = \"completed\"\n\"\"\")\n</code></pre>"},{"location":"en/api/executor/#capturing-output","title":"Capturing Output","text":"<pre><code>result = await executor.execute(\"\"\"\nprint(\"Debug message\")\nresult = 42\n\"\"\")\n\nprint(result.stdout)  # \"Debug message\\n\"\nprint(result.result)  # 42\n</code></pre>"},{"location":"en/api/executor/#security-features","title":"Security Features","text":"<p>The Code Executor has built-in security constraints to prevent malicious code execution.</p>"},{"location":"en/api/executor/#forbidden-imports","title":"Forbidden Imports","text":"<p>The following modules are blocked by default:</p> <ul> <li>System Access: <code>os</code>, <code>sys</code>, <code>subprocess</code>, <code>shutil</code></li> <li>File I/O: <code>open</code> (built-in), <code>io</code> (restricted)</li> <li>Network: <code>socket</code>, <code>urllib</code>, <code>requests</code>, <code>http</code></li> <li>Process Control: <code>multiprocessing</code>, <code>threading</code> (restricted)</li> <li>Code Execution: <code>eval</code>, <code>exec</code>, <code>compile</code> (built-in)</li> <li>Dangerous Modules: <code>pickle</code>, <code>ctypes</code>, <code>importlib</code></li> </ul>"},{"location":"en/api/executor/#allowed-imports","title":"Allowed Imports","text":"<p>Safe modules that are allowed by default:</p> <pre><code>ALLOWED_IMPORTS = {\n    \"math\",\n    \"statistics\",\n    \"random\",\n    \"datetime\",\n    \"json\",\n    \"re\",\n    \"collections\",\n    \"itertools\",\n    \"functools\",\n    \"typing\",\n}\n</code></pre>"},{"location":"en/api/executor/#ast-validation","title":"AST Validation","text":"<p>Before execution, code is analyzed using Python's Abstract Syntax Tree (AST) to detect:</p> <ul> <li>Forbidden function calls (<code>eval</code>, <code>exec</code>, <code>open</code>, etc.)</li> <li>Forbidden imports</li> <li>Dangerous operations</li> </ul> <p>Example validation error:</p> <pre><code>result = await executor.execute(\"\"\"\nimport os\nresult = os.system('ls')\n\"\"\")\n\nprint(result.error)\n# \"Forbidden import: os\"\n</code></pre>"},{"location":"en/api/executor/#resource-limits","title":"Resource Limits","text":"<ul> <li>Timeout: Code execution is terminated after the timeout period</li> <li>Memory: Process memory is monitored (platform-dependent)</li> <li>CPU: No infinite loops allowed (enforced via timeout)</li> </ul>"},{"location":"en/api/executor/#advanced-usage","title":"Advanced Usage","text":""},{"location":"en/api/executor/#custom-allowed-imports","title":"Custom Allowed Imports","text":"<pre><code>executor = CodeExecutor(\n    allowed_imports={\"math\", \"numpy\", \"pandas\"}\n)\n\nresult = await executor.execute(\"\"\"\nimport numpy as np\nresult = np.array([1, 2, 3]).mean()\n\"\"\")\n</code></pre>"},{"location":"en/api/executor/#error-recovery","title":"Error Recovery","text":"<pre><code>executor = CodeExecutor()\n\ncode = \"\"\"\nimport math\nresult = math.factorial(10)\n\"\"\"\n\ntry:\n    result = await executor.execute(code)\n    if result.success:\n        print(f\"Success: {result.result}\")\n    else:\n        print(f\"Execution error: {result.error}\")\nexcept TimeoutError:\n    print(\"Code execution timed out\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"en/api/executor/#combining-with-agents","title":"Combining with Agents","text":"<pre><code>from kagura import agent\nfrom kagura.core.executor import CodeExecutor\n\nexecutor = CodeExecutor()\n\n@agent\nasync def generate_code(task: str) -&gt; str:\n    '''Generate Python code to: {{ task }}\n\n    Return only the code, nothing else.\n    '''\n    pass\n\nasync def run_task(task: str):\n    # Generate code\n    code = await generate_code(task)\n\n    # Execute code\n    result = await executor.execute(code)\n\n    return result\n\n# Use it\nresult = await run_task(\"Calculate fibonacci(15)\")\nprint(result.result)\n</code></pre>"},{"location":"en/api/executor/#best-practices","title":"Best Practices","text":""},{"location":"en/api/executor/#1-always-check-success","title":"1. Always Check Success","text":"<pre><code>result = await execute_code(\"some task\")\n\nif result[\"success\"]:\n    # Use result[\"result\"]\n    process(result[\"result\"])\nelse:\n    # Handle error\n    log_error(result[\"error\"])\n</code></pre>"},{"location":"en/api/executor/#2-set-appropriate-timeouts","title":"2. Set Appropriate Timeouts","text":"<pre><code># Short tasks\nexecutor = CodeExecutor(timeout=5.0)\n\n# Long computations\nexecutor = CodeExecutor(timeout=300.0)\n</code></pre>"},{"location":"en/api/executor/#3-use-result-variable","title":"3. Use result Variable","text":"<p>The executor looks for a variable named <code>result</code>:</p> <pre><code># Good\nresult = await executor.execute(\"\"\"\nx = 10\ny = 20\nresult = x + y\n\"\"\")\n\n# Won't work - no 'result' variable\nresult = await executor.execute(\"\"\"\nx = 10\ny = 20\nprint(x + y)\n\"\"\")\n</code></pre>"},{"location":"en/api/executor/#4-handle-errors-gracefully","title":"4. Handle Errors Gracefully","text":"<pre><code>result = await execute_code(task)\n\nif not result[\"success\"]:\n    # Retry with more explicit instructions\n    task = f\"{task}. Show step by step.\"\n    result = await execute_code(task)\n</code></pre>"},{"location":"en/api/executor/#limitations","title":"Limitations","text":"<ol> <li>No File I/O: Cannot read or write files</li> <li>No Network Access: Cannot make HTTP requests</li> <li>No System Commands: Cannot execute shell commands</li> <li>Limited Libraries: Only safe, pre-approved libraries</li> <li>Memory Constraints: Large data structures may fail</li> <li>Execution Time: Long-running code will timeout</li> </ol>"},{"location":"en/api/executor/#security-considerations","title":"Security Considerations","text":"<p>\u26a0\ufe0f Important: While the Code Executor has security constraints, it should still be used with caution:</p> <ol> <li>User Input: Be careful with untrusted user input</li> <li>Production Use: Consider additional sandboxing for production</li> <li>Resource Limits: Set appropriate timeouts and memory limits</li> <li>Monitoring: Log all code execution for auditing</li> </ol>"},{"location":"en/api/executor/#related","title":"Related","text":"<ul> <li>@agent Decorator - Creating AI agents</li> <li>Code Generator Example - Full example</li> <li>Quick Start - Getting started</li> </ul>"},{"location":"en/api/mcp/","title":"MCP API Reference","text":""},{"location":"en/api/mcp/#overview","title":"Overview","text":"<p>The MCP (Model Context Protocol) module enables Kagura agents to be exposed as MCP tools, allowing integration with Claude Desktop, Claude Code, Cline, and other MCP-compatible clients.</p>"},{"location":"en/api/mcp/#module-kaguramcp","title":"Module: <code>kagura.mcp</code>","text":""},{"location":"en/api/mcp/#create_mcp_servername-str-kagura-ai-server","title":"<code>create_mcp_server(name: str = \"kagura-ai\") -&gt; Server</code>","text":"<p>Creates an MCP server instance that exposes registered Kagura agents as tools.</p> <p>Parameters: - <code>name</code> (str, optional): Server name. Defaults to \"kagura-ai\".</p> <p>Returns: - <code>Server</code>: Configured MCP server instance</p> <p>Example: <pre><code>from kagura.mcp import create_mcp_server\n\nserver = create_mcp_server(\"my-server\")\n</code></pre></p>"},{"location":"en/api/mcp/#module-kaguramcpschema","title":"Module: <code>kagura.mcp.schema</code>","text":""},{"location":"en/api/mcp/#generate_json_schemafunc-callable-dict","title":"<code>generate_json_schema(func: Callable) -&gt; dict</code>","text":"<p>Generates JSON Schema from a Python function signature.</p> <p>Parameters: - <code>func</code> (Callable): Function to generate schema for</p> <p>Returns: - <code>dict</code>: JSON Schema with <code>type</code>, <code>properties</code>, and optionally <code>required</code></p> <p>Example: <pre><code>from kagura.mcp.schema import generate_json_schema\n\ndef my_func(name: str, age: int = 18) -&gt; str:\n    \"\"\"Sample function\n\n    name: Person's name\n    age: Person's age\n    \"\"\"\n    pass\n\nschema = generate_json_schema(my_func)\n# {\n#     \"type\": \"object\",\n#     \"properties\": {\n#         \"name\": {\"type\": \"string\", \"description\": \"Person's name\"},\n#         \"age\": {\"type\": \"integer\", \"description\": \"Person's age\"}\n#     },\n#     \"required\": [\"name\"]\n# }\n</code></pre></p>"},{"location":"en/api/mcp/#python_type_to_json_schemapy_type-type-dict","title":"<code>python_type_to_json_schema(py_type: type) -&gt; dict</code>","text":"<p>Converts a Python type to JSON Schema format.</p> <p>Parameters: - <code>py_type</code> (type): Python type annotation</p> <p>Returns: - <code>dict</code>: JSON Schema representation</p> <p>Supported Types: - Basic: <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code> - Collections: <code>list[T]</code>, <code>dict[K, V]</code> - Optional: <code>T | None</code>, <code>Optional[T]</code> - Pydantic: <code>BaseModel</code> subclasses</p> <p>Example: <pre><code>from kagura.mcp.schema import python_type_to_json_schema\n\n# Basic types\npython_type_to_json_schema(str)\n# {\"type\": \"string\"}\n\n# Lists\npython_type_to_json_schema(list[int])\n# {\"type\": \"array\", \"items\": {\"type\": \"integer\"}}\n\n# Dicts\npython_type_to_json_schema(dict[str, float])\n# {\"type\": \"object\", \"additionalProperties\": {\"type\": \"number\"}}\n\n# Optional\npython_type_to_json_schema(str | None)\n# {\"type\": [\"string\", \"null\"]}\n</code></pre></p>"},{"location":"en/api/mcp/#module-kaguracoreregistry","title":"Module: <code>kagura.core.registry</code>","text":""},{"location":"en/api/mcp/#class-agentregistry","title":"<code>class AgentRegistry</code>","text":"<p>Global registry for all Kagura agents.</p>"},{"location":"en/api/mcp/#methods","title":"Methods","text":""},{"location":"en/api/mcp/#registername-str-func-callable-none","title":"<code>register(name: str, func: Callable) -&gt; None</code>","text":"<p>Register an agent.</p> <p>Parameters: - <code>name</code> (str): Agent name (must be unique) - <code>func</code> (Callable): Agent function</p> <p>Raises: - <code>ValueError</code>: If agent name is already registered</p> <p>Example: <pre><code>from kagura.core.registry import agent_registry\n\ndef my_agent():\n    pass\n\nagent_registry.register(\"my_agent\", my_agent)\n</code></pre></p>"},{"location":"en/api/mcp/#getname-str-callable-none","title":"<code>get(name: str) -&gt; Callable | None</code>","text":"<p>Get agent by name.</p> <p>Parameters: - <code>name</code> (str): Agent name</p> <p>Returns: - <code>Callable | None</code>: Agent function, or None if not found</p> <p>Example: <pre><code>agent_func = agent_registry.get(\"my_agent\")\nif agent_func:\n    result = await agent_func()\n</code></pre></p>"},{"location":"en/api/mcp/#get_all-dictstr-callable","title":"<code>get_all() -&gt; dict[str, Callable]</code>","text":"<p>Get all registered agents.</p> <p>Returns: - <code>dict[str, Callable]</code>: Dictionary of agent_name -&gt; agent_function</p> <p>Example: <pre><code>agents = agent_registry.get_all()\nfor name, func in agents.items():\n    print(f\"Agent: {name}\")\n</code></pre></p>"},{"location":"en/api/mcp/#list_names-liststr","title":"<code>list_names() -&gt; list[str]</code>","text":"<p>List all agent names.</p> <p>Returns: - <code>list[str]</code>: List of agent names</p> <p>Example: <pre><code>names = agent_registry.list_names()\nprint(f\"Registered agents: {', '.join(names)}\")\n</code></pre></p>"},{"location":"en/api/mcp/#unregistername-str-none","title":"<code>unregister(name: str) -&gt; None</code>","text":"<p>Unregister an agent.</p> <p>Parameters: - <code>name</code> (str): Agent name to remove</p> <p>Raises: - <code>KeyError</code>: If agent name is not registered</p>"},{"location":"en/api/mcp/#clear-none","title":"<code>clear() -&gt; None</code>","text":"<p>Clear all agents from registry.</p>"},{"location":"en/api/mcp/#auto_discovermodule_path-str-none","title":"<code>auto_discover(module_path: str) -&gt; None</code>","text":"<p>Auto-discover agents in a module.</p> <p>Parameters: - <code>module_path</code> (str): Python module path (e.g., \"my_package.agents\")</p> <p>Raises: - <code>ValueError</code>: If module is not found</p> <p>Example: <pre><code># Discover all agents in a module\nagent_registry.auto_discover(\"my_package.agents\")\n\n# All @agent decorated functions in the module are now registered\n</code></pre></p>"},{"location":"en/api/mcp/#global-instance-agent_registry","title":"Global Instance: <code>agent_registry</code>","text":"<p>A global <code>AgentRegistry</code> instance is available for use:</p> <pre><code>from kagura.core.registry import agent_registry\n\n# Agents decorated with @agent are automatically registered here\n</code></pre>"},{"location":"en/api/mcp/#cli-commands","title":"CLI Commands","text":""},{"location":"en/api/mcp/#kagura-mcp-serve","title":"<code>kagura mcp serve</code>","text":"<p>Start MCP server using stdio transport.</p> <p>Usage: <pre><code>kagura mcp serve [OPTIONS]\n</code></pre></p> <p>Options: - <code>--name TEXT</code>: Server name (default: \"kagura-ai\")</p> <p>Example: <pre><code># Start server\nkagura mcp serve\n\n# Custom server name\nkagura mcp serve --name my-server\n\n# Verbose logging\nkagura -v mcp serve\n</code></pre></p>"},{"location":"en/api/mcp/#kagura-mcp-list","title":"<code>kagura mcp list</code>","text":"<p>List all registered agents.</p> <p>Usage: <pre><code>kagura mcp list\n</code></pre></p> <p>Output: <pre><code>Registered agents (3):\n\n  \u2022 analyze_code\n    Analyze code quality and suggest improvements\n\n  \u2022 review_code\n    Review code and provide feedback\n\n  \u2022 generate_tests\n    Generate unit tests for the code\n</code></pre></p>"},{"location":"en/api/mcp/#agent-metadata","title":"Agent Metadata","text":"<p>Agents decorated with <code>@agent</code> have special attributes for MCP integration:</p>"},{"location":"en/api/mcp/#_is_agent-bool","title":"<code>_is_agent: bool</code>","text":"<p>Flag indicating this is a Kagura agent.</p> <pre><code>from kagura import agent\n\n@agent\nasync def my_agent():\n    pass\n\nprint(my_agent._is_agent)  # True\n</code></pre>"},{"location":"en/api/mcp/#_agent_config-llmconfig","title":"<code>_agent_config: LLMConfig</code>","text":"<p>LLM configuration for the agent.</p> <pre><code>print(my_agent._agent_config.model)  # \"gpt-4o-mini\"\nprint(my_agent._agent_config.temperature)  # 0.7\n</code></pre>"},{"location":"en/api/mcp/#_agent_template-str","title":"<code>_agent_template: str</code>","text":"<p>Jinja2 template extracted from docstring.</p> <pre><code>@agent\nasync def greet(name: str):\n    \"\"\"Say hello to {{ name }}\"\"\"\n    pass\n\nprint(greet._agent_template)  # \"Say hello to {{ name }}\"\n</code></pre>"},{"location":"en/api/mcp/#mcp-tool-naming","title":"MCP Tool Naming","text":"<p>Agents are exposed to MCP clients with the <code>kagura_</code> prefix:</p> Agent Function Name MCP Tool Name <code>analyze_code</code> <code>kagura_analyze_code</code> <code>review_code</code> <code>kagura_review_code</code> <code>translate</code> <code>kagura_translate</code> <p>This prefix prevents naming conflicts with other MCP tools.</p>"},{"location":"en/api/mcp/#type-conversion-table","title":"Type Conversion Table","text":""},{"location":"en/api/mcp/#python-json-schema","title":"Python \u2192 JSON Schema","text":"Python Type JSON Schema <code>str</code> <code>{\"type\": \"string\"}</code> <code>int</code> <code>{\"type\": \"integer\"}</code> <code>float</code> <code>{\"type\": \"number\"}</code> <code>bool</code> <code>{\"type\": \"boolean\"}</code> <code>list[T]</code> <code>{\"type\": \"array\", \"items\": {...}}</code> <code>dict[str, T]</code> <code>{\"type\": \"object\", \"additionalProperties\": {...}}</code> <code>T \\| None</code> <code>{\"type\": [\"T\", \"null\"]}</code> <code>BaseModel</code> Pydantic's <code>model_json_schema()</code>"},{"location":"en/api/mcp/#complete-example","title":"Complete Example","text":"<pre><code>from kagura import agent\nfrom kagura.core.registry import agent_registry\nfrom kagura.mcp import create_mcp_server\nfrom kagura.mcp.schema import generate_json_schema\n\n# Define agent\n@agent\nasync def analyze_sentiment(text: str, detailed: bool = False) -&gt; dict:\n    \"\"\"\n    Analyze sentiment of text\n\n    text: Text to analyze\n    detailed: Include detailed breakdown\n    \"\"\"\n    pass\n\n# Agent is automatically registered\nprint(agent_registry.get(\"analyze_sentiment\"))  # &lt;function ...&gt;\n\n# Generate schema\nschema = generate_json_schema(analyze_sentiment)\nprint(schema)\n# {\n#     \"type\": \"object\",\n#     \"properties\": {\n#         \"text\": {\"type\": \"string\", \"description\": \"Text to analyze\"},\n#         \"detailed\": {\"type\": \"boolean\", \"description\": \"Include detailed breakdown\"}\n#     },\n#     \"required\": [\"text\"]\n# }\n\n# Create MCP server\nserver = create_mcp_server()\n\n# Server exposes agent as \"kagura_analyze_sentiment\" tool\n</code></pre>"},{"location":"en/api/mcp/#see-also","title":"See Also","text":"<ul> <li>MCP Integration Tutorial</li> <li>CLI Reference</li> <li>Agent Decorator</li> <li>MCP Specification</li> </ul>"},{"location":"en/api/memory/","title":"Memory Management API","text":"<p>Kagura AI provides a comprehensive memory management system for building agents with persistent knowledge and context awareness.</p>"},{"location":"en/api/memory/#overview","title":"Overview","text":"<p>The memory system consists of four main components:</p> <ul> <li>WorkingMemory: Temporary storage during agent execution</li> <li>ContextMemory: Conversation history and session management</li> <li>PersistentMemory: Long-term storage using SQLite</li> <li>MemoryManager: Unified interface to all memory types</li> </ul>"},{"location":"en/api/memory/#memorymanager","title":"MemoryManager","text":"<p>The main interface for memory operations.</p>"},{"location":"en/api/memory/#constructor","title":"Constructor","text":"<pre><code>MemoryManager(\n    agent_name: Optional[str] = None,\n    persist_dir: Optional[Path] = None,\n    max_messages: int = 100,\n    enable_rag: Optional[bool] = None\n)\n</code></pre> <p>Parameters:</p> <ul> <li><code>agent_name</code>: Optional agent name for scoping persistent memory</li> <li><code>persist_dir</code>: Directory for persistent storage (default: <code>~/.kagura</code>)</li> <li><code>max_messages</code>: Maximum messages to keep in context</li> <li><code>enable_rag</code>: Enable RAG (semantic search) with ChromaDB</li> <li><code>None</code> (default): Auto-detect - enables if chromadb is available</li> <li><code>True</code>: Explicitly enable RAG (requires chromadb)</li> <li><code>False</code>: Explicitly disable RAG</li> </ul>"},{"location":"en/api/memory/#working-memory-methods","title":"Working Memory Methods","text":"<p>Temporary storage that's cleared when agent execution completes.</p>"},{"location":"en/api/memory/#set_temp","title":"set_temp","text":"<pre><code>manager.set_temp(key: str, value: Any) -&gt; None\n</code></pre> <p>Store temporary data.</p> <p>Example:</p> <pre><code>manager.set_temp(\"current_task\", \"summarization\")\nmanager.set_temp(\"retry_count\", 3)\n</code></pre>"},{"location":"en/api/memory/#get_temp","title":"get_temp","text":"<pre><code>manager.get_temp(key: str, default: Any = None) -&gt; Any\n</code></pre> <p>Retrieve temporary data.</p> <p>Example:</p> <pre><code>task = manager.get_temp(\"current_task\")  # Returns \"summarization\"\ncount = manager.get_temp(\"retry_count\", 0)  # Returns 3\nmissing = manager.get_temp(\"nonexistent\", \"default\")  # Returns \"default\"\n</code></pre>"},{"location":"en/api/memory/#has_temp","title":"has_temp","text":"<pre><code>manager.has_temp(key: str) -&gt; bool\n</code></pre> <p>Check if temporary key exists.</p>"},{"location":"en/api/memory/#delete_temp","title":"delete_temp","text":"<pre><code>manager.delete_temp(key: str) -&gt; None\n</code></pre> <p>Delete temporary data.</p>"},{"location":"en/api/memory/#context-memory-methods","title":"Context Memory Methods","text":"<p>Manages conversation history with automatic pruning.</p>"},{"location":"en/api/memory/#add_message","title":"add_message","text":"<pre><code>manager.add_message(\n    role: str,\n    content: str,\n    metadata: Optional[dict] = None\n) -&gt; None\n</code></pre> <p>Add message to conversation context.</p> <p>Parameters:</p> <ul> <li><code>role</code>: Message role (<code>\"user\"</code>, <code>\"assistant\"</code>, <code>\"system\"</code>)</li> <li><code>content</code>: Message content</li> <li><code>metadata</code>: Optional metadata dictionary</li> </ul> <p>Example:</p> <pre><code>manager.add_message(\"user\", \"What is machine learning?\")\nmanager.add_message(\n    \"assistant\",\n    \"Machine learning is...\",\n    metadata={\"confidence\": 0.95}\n)\n</code></pre>"},{"location":"en/api/memory/#get_context","title":"get_context","text":"<pre><code>manager.get_context(last_n: Optional[int] = None) -&gt; list[Message]\n</code></pre> <p>Get conversation context as Message objects.</p> <p>Example:</p> <pre><code># Get all messages\nall_messages = manager.get_context()\n\n# Get last 5 messages\nrecent = manager.get_context(last_n=5)\n</code></pre>"},{"location":"en/api/memory/#get_llm_context","title":"get_llm_context","text":"<pre><code>manager.get_llm_context(last_n: Optional[int] = None) -&gt; list[dict]\n</code></pre> <p>Get context formatted for LLM API.</p> <p>Returns: List of <code>{\"role\": str, \"content\": str}</code> dictionaries.</p> <p>Example:</p> <pre><code>context = manager.get_llm_context(last_n=10)\n# [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]\n</code></pre>"},{"location":"en/api/memory/#get_last_message","title":"get_last_message","text":"<pre><code>manager.get_last_message(role: Optional[str] = None) -&gt; Optional[Message]\n</code></pre> <p>Get the last message, optionally filtered by role.</p> <p>Example:</p> <pre><code>last_msg = manager.get_last_message()\nlast_user_msg = manager.get_last_message(role=\"user\")\n</code></pre>"},{"location":"en/api/memory/#set_session_id-get_session_id","title":"set_session_id / get_session_id","text":"<pre><code>manager.set_session_id(session_id: str) -&gt; None\nmanager.get_session_id() -&gt; Optional[str]\n</code></pre> <p>Manage session identifiers.</p>"},{"location":"en/api/memory/#persistent-memory-methods","title":"Persistent Memory Methods","text":"<p>Long-term storage using SQLite with optional agent scoping.</p>"},{"location":"en/api/memory/#remember","title":"remember","text":"<pre><code>manager.remember(\n    key: str,\n    value: Any,\n    metadata: Optional[dict] = None\n) -&gt; None\n</code></pre> <p>Store persistent memory.</p> <p>Example:</p> <pre><code>manager.remember(\"user_preferences\", {\n    \"theme\": \"dark\",\n    \"language\": \"en\"\n})\n\nmanager.remember(\n    \"api_key\",\n    \"sk-...\",\n    metadata={\"created\": \"2025-01-01\"}\n)\n</code></pre>"},{"location":"en/api/memory/#recall","title":"recall","text":"<pre><code>manager.recall(key: str) -&gt; Optional[Any]\n</code></pre> <p>Retrieve persistent memory.</p> <p>Example:</p> <pre><code>prefs = manager.recall(\"user_preferences\")\napi_key = manager.recall(\"api_key\")\n</code></pre>"},{"location":"en/api/memory/#search_memory","title":"search_memory","text":"<pre><code>manager.search_memory(query: str, limit: int = 10) -&gt; list[dict]\n</code></pre> <p>Search persistent memory using SQL LIKE pattern.</p> <p>Example:</p> <pre><code># Find all user-related memories\nresults = manager.search_memory(\"user\")\n\n# Each result contains: key, value, created_at, updated_at, metadata\nfor mem in results:\n    print(f\"{mem['key']}: {mem['value']}\")\n</code></pre>"},{"location":"en/api/memory/#forget","title":"forget","text":"<pre><code>manager.forget(key: str) -&gt; None\n</code></pre> <p>Delete persistent memory.</p> <p>Example:</p> <pre><code>manager.forget(\"api_key\")\n</code></pre>"},{"location":"en/api/memory/#prune_old","title":"prune_old","text":"<pre><code>manager.prune_old(older_than_days: int = 90) -&gt; int\n</code></pre> <p>Remove old memories.</p> <p>Returns: Number of deleted memories.</p> <p>Example:</p> <pre><code># Delete memories older than 30 days\ndeleted = manager.prune_old(older_than_days=30)\nprint(f\"Deleted {deleted} old memories\")\n</code></pre>"},{"location":"en/api/memory/#session-management","title":"Session Management","text":""},{"location":"en/api/memory/#save_session","title":"save_session","text":"<pre><code>manager.save_session(session_name: str) -&gt; None\n</code></pre> <p>Save current session (working + context memory) to persistent storage.</p> <p>Example:</p> <pre><code>manager.add_message(\"user\", \"Hello\")\nmanager.set_temp(\"step\", 1)\nmanager.save_session(\"my_session\")\n</code></pre>"},{"location":"en/api/memory/#load_session","title":"load_session","text":"<pre><code>manager.load_session(session_name: str) -&gt; bool\n</code></pre> <p>Load saved session.</p> <p>Returns: <code>True</code> if session was loaded successfully.</p> <p>Example:</p> <pre><code>if manager.load_session(\"my_session\"):\n    print(\"Session restored\")\n    messages = manager.get_context()\n</code></pre>"},{"location":"en/api/memory/#clear_all","title":"clear_all","text":"<pre><code>manager.clear_all() -&gt; None\n</code></pre> <p>Clear all temporary and context memory (does not clear persistent memory).</p> <p>Example:</p> <pre><code>manager.clear_all()\n</code></pre>"},{"location":"en/api/memory/#message-class","title":"Message Class","text":"<p>Represents a single message in conversation context.</p>"},{"location":"en/api/memory/#attributes","title":"Attributes","text":"<pre><code>@dataclass\nclass Message:\n    role: str              # \"user\", \"assistant\", \"system\"\n    content: str           # Message content\n    timestamp: datetime    # When message was created\n    metadata: Optional[dict] = None  # Optional metadata\n</code></pre>"},{"location":"en/api/memory/#methods","title":"Methods","text":""},{"location":"en/api/memory/#to_dict","title":"to_dict","text":"<pre><code>message.to_dict() -&gt; dict\n</code></pre> <p>Convert to dictionary representation.</p>"},{"location":"en/api/memory/#workingmemory","title":"WorkingMemory","text":"<p>Direct access to working memory (also available via <code>MemoryManager.working</code>).</p>"},{"location":"en/api/memory/#methods_1","title":"Methods","text":"<ul> <li><code>set(key: str, value: Any) -&gt; None</code></li> <li><code>get(key: str, default: Any = None) -&gt; Any</code></li> <li><code>has(key: str) -&gt; bool</code></li> <li><code>delete(key: str) -&gt; None</code></li> <li><code>clear() -&gt; None</code></li> <li><code>keys() -&gt; list[str]</code></li> <li><code>to_dict() -&gt; dict</code></li> </ul>"},{"location":"en/api/memory/#contextmemory","title":"ContextMemory","text":"<p>Direct access to context memory (also available via <code>MemoryManager.context</code>).</p>"},{"location":"en/api/memory/#methods_2","title":"Methods","text":"<ul> <li><code>add_message(role: str, content: str, metadata: Optional[dict] = None) -&gt; None</code></li> <li><code>get_messages(last_n: Optional[int] = None, role: Optional[str] = None) -&gt; list[Message]</code></li> <li><code>get_last_message(role: Optional[str] = None) -&gt; Optional[Message]</code></li> <li><code>clear() -&gt; None</code></li> <li><code>set_session_id(session_id: str) -&gt; None</code></li> <li><code>get_session_id() -&gt; Optional[str]</code></li> <li><code>to_llm_format(last_n: Optional[int] = None) -&gt; list[dict]</code></li> <li><code>to_dict() -&gt; dict</code></li> </ul>"},{"location":"en/api/memory/#persistentmemory","title":"PersistentMemory","text":"<p>Direct access to persistent memory (also available via <code>MemoryManager.persistent</code>).</p>"},{"location":"en/api/memory/#methods_3","title":"Methods","text":"<ul> <li><code>store(key: str, value: Any, agent_name: Optional[str] = None, metadata: Optional[dict] = None) -&gt; None</code></li> <li><code>recall(key: str, agent_name: Optional[str] = None) -&gt; Optional[Any]</code></li> <li><code>search(query: str, agent_name: Optional[str] = None, limit: int = 10) -&gt; list[dict]</code></li> <li><code>forget(key: str, agent_name: Optional[str] = None) -&gt; None</code></li> <li><code>prune(older_than_days: int = 90, agent_name: Optional[str] = None) -&gt; int</code></li> <li><code>count(agent_name: Optional[str] = None) -&gt; int</code></li> </ul>"},{"location":"en/api/memory/#memoryrag","title":"MemoryRAG","text":"<p>Vector-based semantic memory search using ChromaDB for Retrieval-Augmented Generation (RAG).</p>"},{"location":"en/api/memory/#constructor_1","title":"Constructor","text":"<pre><code>from kagura.core.memory import MemoryRAG\n\nrag = MemoryRAG(\n    collection_name: str = \"kagura_memory\",\n    persist_dir: Optional[Path] = None\n)\n</code></pre> <p>Parameters:</p> <ul> <li><code>collection_name</code>: Name for the vector collection (default: <code>\"kagura_memory\"</code>)</li> <li><code>persist_dir</code>: Directory for persistent storage (default: <code>~/.kagura/vector_db</code>)</li> </ul> <p>Requires: <code>pip install chromadb</code></p> <p>Example:</p> <pre><code>from pathlib import Path\nfrom kagura.core.memory import MemoryRAG\n\n# Default location\nrag = MemoryRAG()\n\n# Custom location\nrag = MemoryRAG(\n    collection_name=\"my_agent_memory\",\n    persist_dir=Path.home() / \".myapp\" / \"vectors\"\n)\n</code></pre>"},{"location":"en/api/memory/#store","title":"store()","text":"<p>Store memory with automatic embedding.</p> <pre><code>rag.store(\n    content: str,\n    metadata: Optional[dict[str, Any]] = None,\n    agent_name: Optional[str] = None\n) -&gt; str\n</code></pre> <p>Parameters:</p> <ul> <li><code>content</code>: Content to store (will be automatically embedded)</li> <li><code>metadata</code>: Optional metadata dictionary</li> <li><code>agent_name</code>: Optional agent name for scoping</li> </ul> <p>Returns: Content hash (unique ID)</p> <p>Example:</p> <pre><code># Store facts\nrag.store(\"Python is a programming language created by Guido van Rossum\")\nrag.store(\"The Eiffel Tower is in Paris, France\")\n\n# With metadata\nrag.store(\n    \"User prefers dark mode\",\n    metadata={\"category\": \"preference\", \"user_id\": \"123\"},\n    agent_name=\"assistant\"\n)\n</code></pre>"},{"location":"en/api/memory/#recall_1","title":"recall()","text":"<p>Semantic search for memories using vector similarity.</p> <pre><code>rag.recall(\n    query: str,\n    top_k: int = 5,\n    agent_name: Optional[str] = None\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Parameters:</p> <ul> <li><code>query</code>: Search query (will be embedded automatically)</li> <li><code>top_k</code>: Number of results to return (sorted by similarity)</li> <li><code>agent_name</code>: Optional agent name filter</li> </ul> <p>Returns: List of memory dictionaries containing: - <code>content</code> (<code>str</code>): Original memory text - <code>distance</code> (<code>float</code>): Cosine distance (lower = more similar, range 0.0-2.0) - <code>metadata</code> (<code>dict</code>): Optional metadata</p> <p>Example:</p> <pre><code># Store knowledge\nrag.store(\"Python is a programming language\")\nrag.store(\"Java is a programming language\")\nrag.store(\"The Eiffel Tower is in Paris\")\n\n# Semantic search\nresults = rag.recall(\"What is Python?\", top_k=2)\n\nfor result in results:\n    print(f\"Content: {result['content']}\")\n    print(f\"Distance: {result['distance']:.3f}\")  # e.g., 0.342\n    print(f\"Metadata: {result.get('metadata')}\")\n</code></pre>"},{"location":"en/api/memory/#delete_all","title":"delete_all()","text":"<p>Delete all memories.</p> <pre><code>rag.delete_all(agent_name: Optional[str] = None) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>agent_name</code>: Optional agent name filter (deletes only that agent's memories)</li> </ul> <p>Example:</p> <pre><code># Delete all memories\nrag.delete_all()\n\n# Delete only specific agent's memories\nrag.delete_all(agent_name=\"assistant\")\n</code></pre>"},{"location":"en/api/memory/#count","title":"count()","text":"<p>Count stored memories.</p> <pre><code>rag.count(agent_name: Optional[str] = None) -&gt; int\n</code></pre> <p>Parameters:</p> <ul> <li><code>agent_name</code>: Optional agent name filter</li> </ul> <p>Returns: Number of memories</p> <p>Example:</p> <pre><code>total = rag.count()\nprint(f\"Total memories: {total}\")\n\nagent_memories = rag.count(agent_name=\"assistant\")\nprint(f\"Assistant memories: {agent_memories}\")\n</code></pre>"},{"location":"en/api/memory/#memorymanager-integration","title":"MemoryManager Integration","text":"<p>RAG is automatically enabled in MemoryManager when chromadb is available:</p> <pre><code>from kagura.core.memory import MemoryManager\n\n# Auto-detect (enables RAG if chromadb is installed)\nmemory = MemoryManager(agent_name=\"my_agent\")\n\n# Explicitly enable RAG\nmemory = MemoryManager(\n    agent_name=\"my_agent\",\n    enable_rag=True  # Requires chromadb\n)\n\n# Explicitly disable RAG\nmemory = MemoryManager(\n    agent_name=\"my_agent\",\n    enable_rag=False  # No RAG, even if chromadb is available\n)\n\n# Store semantically (works if RAG is enabled)\nif memory.rag:\n    memory.store_semantic(\"Python is great for AI development\")\n\n# Semantic recall\nresults = memory.recall_semantic(\"Tell me about Python\", top_k=3)\nfor result in results:\n    print(result['content'])\n</code></pre> <p>Note: When RAG is enabled (auto-detected or explicitly set to <code>True</code>), MemoryManager provides both working and persistent RAG capabilities for semantic retrieval.</p>"},{"location":"en/api/memory/#complete-rag-example","title":"Complete RAG Example","text":"<pre><code>from kagura.core.memory import MemoryRAG\n\n# Initialize\nrag = MemoryRAG(collection_name=\"knowledge_base\")\n\n# Store domain knowledge\nrag.store(\"Machine learning is a subset of artificial intelligence\")\nrag.store(\"Deep learning uses neural networks with multiple layers\")\nrag.store(\"Natural language processing deals with text and speech\")\nrag.store(\"Computer vision focuses on image and video analysis\")\n\n# Semantic search\nquery = \"What is deep learning?\"\nresults = rag.recall(query, top_k=2)\n\nprint(f\"Query: {query}\\n\")\nfor i, result in enumerate(results, 1):\n    print(f\"{i}. {result['content']}\")\n    print(f\"   Similarity: {1 - result['distance']/2:.2%}\\n\")\n\n# Output:\n# Query: What is deep learning?\n#\n# 1. Deep learning uses neural networks with multiple layers\n#    Similarity: 89%\n#\n# 2. Machine learning is a subset of artificial intelligence\n#    Similarity: 72%\n</code></pre>"},{"location":"en/api/memory/#rag-with-agent-integration","title":"RAG with Agent Integration","text":"<pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n@agent(enable_memory=True)\nasync def knowledge_agent(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Answer {{ query }} using semantic memory\"\"\"\n\n    # Store query in RAG (if RAG enabled in MemoryManager)\n    memory.add_message(\"user\", query)\n\n    # Semantic search over past conversations\n    if memory.rag:\n        relevant = memory.recall_semantic(query, top_k=3)\n        context = \"\\n\".join([r['content'] for r in relevant])\n        enriched_query = f\"Context: {context}\\n\\nQuery: {query}\"\n        # Use enriched_query for LLM call\n    else:\n        enriched_query = query\n\n    # Process with LLM...\n    response = f\"Processing: {enriched_query}\"\n    memory.add_message(\"assistant\", response)\n\n    return response\n</code></pre>"},{"location":"en/api/memory/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Meaningful Content: Store complete, self-contained information    <pre><code># Good\nrag.store(\"The capital of France is Paris\")\n\n# Less good (lacks context)\nrag.store(\"Paris\")\n</code></pre></p> </li> <li> <p>Use Metadata for Filtering:    <pre><code>rag.store(\"User prefers Python\", metadata={\"type\": \"preference\"})\nrag.store(\"Project deadline is March 1\", metadata={\"type\": \"deadline\"})\n</code></pre></p> </li> <li> <p>Agent Scoping:    <pre><code># Separate knowledge per agent\nrag.store(\"Translation context\", agent_name=\"translator\")\nrag.store(\"Code review context\", agent_name=\"reviewer\")\n\n# Query specific agent's knowledge\nresults = rag.recall(\"translate\", agent_name=\"translator\")\n</code></pre></p> </li> <li> <p>Semantic vs Keyword Search:    <pre><code># Semantic search - finds conceptually similar content\nrag.recall(\"programming languages\")  # Finds \"Python\", \"Java\", etc.\n\n# Keyword search would miss variations\nmemory.search_memory(\"programming language\")  # Exact match only\n</code></pre></p> </li> </ol>"},{"location":"en/api/memory/#agent-integration","title":"Agent Integration","text":"<p>Enable memory in agents using the <code>enable_memory</code> parameter:</p> <pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n@agent(enable_memory=True, max_messages=50)\nasync def my_agent(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Answer {{ query }} using memory\"\"\"\n\n    # Add to context\n    memory.add_message(\"user\", query)\n\n    # Remember facts\n    memory.remember(\"last_query\", query)\n\n    # Recall past information\n    past = memory.recall(\"user_name\")\n\n    response = f\"Processing {query}\"\n    memory.add_message(\"assistant\", response)\n\n    return response\n</code></pre>"},{"location":"en/api/memory/#parameters","title":"Parameters","text":"<ul> <li><code>enable_memory</code>: Enable memory management (default: <code>False</code>)</li> <li><code>persist_dir</code>: Custom directory for persistent storage</li> <li><code>max_messages</code>: Maximum messages in context (default: 100)</li> </ul>"},{"location":"en/api/memory/#examples","title":"Examples","text":""},{"location":"en/api/memory/#basic-usage","title":"Basic Usage","text":"<pre><code>from kagura.core.memory import MemoryManager\n\n# Create manager\nmemory = MemoryManager(agent_name=\"my_agent\")\n\n# Store and recall\nmemory.remember(\"api_key\", \"sk-...\")\napi_key = memory.recall(\"api_key\")\n\n# Conversation context\nmemory.add_message(\"user\", \"Hello\")\nmemory.add_message(\"assistant\", \"Hi there!\")\ncontext = memory.get_llm_context()\n\n# Search\nresults = memory.search_memory(\"api\")\n</code></pre>"},{"location":"en/api/memory/#session-persistence","title":"Session Persistence","text":"<pre><code># Save session\nmemory.add_message(\"user\", \"What is AI?\")\nmemory.add_message(\"assistant\", \"AI stands for...\")\nmemory.save_session(\"conversation_1\")\n\n# Later... restore session\nnew_memory = MemoryManager(agent_name=\"my_agent\")\nif new_memory.load_session(\"conversation_1\"):\n    messages = new_memory.get_context()\n    print(f\"Restored {len(messages)} messages\")\n</code></pre>"},{"location":"en/api/memory/#agent-with-memory","title":"Agent with Memory","text":"<pre><code>@agent(enable_memory=True, persist_dir=Path(\"./data\"))\nasync def assistant(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Personal assistant: {{ query }}\"\"\"\n\n    # Track conversation\n    memory.add_message(\"user\", query)\n\n    # Remember user preferences\n    if \"my name is\" in query.lower():\n        name = query.split(\"my name is\")[-1].strip()\n        memory.remember(\"user_name\", name)\n\n    # Use remembered information\n    user_name = memory.recall(\"user_name\") or \"there\"\n    response = f\"Hello {user_name}! How can I help?\"\n\n    memory.add_message(\"assistant\", response)\n    return response\n\n# Usage\nresult = await assistant(\"Hello, my name is Alice\")\n# \"Hello Alice! How can I help?\"\n\nresult = await assistant(\"What's the weather?\")\n# \"Hello Alice! How can I help?\" (remembers name)\n</code></pre>"},{"location":"en/api/memory/#see-also","title":"See Also","text":"<ul> <li>Memory Management Tutorial</li> <li>@agent Decorator API</li> <li>Code Execution API</li> </ul>"},{"location":"en/api/meta/","title":"Meta Agent API Reference","text":"<p>API reference for Kagura AI's Meta Agent - AI-powered agent code generator.</p>"},{"location":"en/api/meta/#overview","title":"Overview","text":"<p>The Meta Agent system allows you to generate complete Kagura agent code from natural language descriptions. It uses a multi-stage pipeline:</p> <ol> <li>Natural Language Parsing \u2192 Extract structured specification</li> <li>Code Generation \u2192 Generate Python code from templates</li> <li>Security Validation \u2192 Ensure generated code is safe</li> <li>File Creation \u2192 Save the agent to a file</li> </ol>"},{"location":"en/api/meta/#metaagent","title":"MetaAgent","text":"<p>Main class for AI-powered agent code generation.</p>"},{"location":"en/api/meta/#class-definition","title":"Class Definition","text":"<pre><code>from kagura.meta import MetaAgent\n\nclass MetaAgent:\n    \"\"\"AI-powered agent code generator\n\n    Generate Kagura agent code from natural language descriptions.\n\n    Args:\n        model: LLM model for spec parsing (default: \"gpt-4o-mini\")\n        template_dir: Custom template directory (optional)\n        validate: Whether to validate generated code (default: True)\n\n    Example:\n        &gt;&gt;&gt; meta = MetaAgent()\n        &gt;&gt;&gt; code = await meta.generate(\"Translate English to Japanese\")\n        &gt;&gt;&gt; print(code)  # Complete Python agent code\n    \"\"\"\n</code></pre>"},{"location":"en/api/meta/#methods","title":"Methods","text":""},{"location":"en/api/meta/#__init__modelgpt-4o-mini-template_dirnone-validatetrue","title":"<code>__init__(model=\"gpt-4o-mini\", template_dir=None, validate=True)</code>","text":"<p>Initialize MetaAgent.</p> <p>Parameters: - <code>model</code> (str): LLM model for parsing descriptions (default: \"gpt-4o-mini\") - <code>template_dir</code> (Path | None): Custom template directory (optional) - <code>validate</code> (bool): Whether to validate generated code (default: True)</p> <p>Example: <pre><code>meta = MetaAgent(model=\"gpt-4o-mini\", validate=True)\n</code></pre></p>"},{"location":"en/api/meta/#async-generatedescription-str-str","title":"<code>async generate(description: str) -&gt; str</code>","text":"<p>Generate agent code from natural language description.</p> <p>Parameters: - <code>description</code> (str): Natural language agent description</p> <p>Returns: - <code>str</code>: Generated Python code</p> <p>Raises: - <code>ValidationError</code>: If generated code is invalid (when validate=True)</p> <p>Example: <pre><code>meta = MetaAgent()\ncode = await meta.generate(\"Create a chatbot that remembers conversation history\")\nprint(code)  # Complete Python agent code with @agent decorator\n</code></pre></p>"},{"location":"en/api/meta/#async-generate_from_specspec-agentspec-str","title":"<code>async generate_from_spec(spec: AgentSpec) -&gt; str</code>","text":"<p>Generate agent code from AgentSpec.</p> <p>Parameters: - <code>spec</code> (AgentSpec): Agent specification</p> <p>Returns: - <code>str</code>: Generated Python code</p> <p>Raises: - <code>ValidationError</code>: If generated code is invalid</p> <p>Example: <pre><code>from kagura.meta.spec import AgentSpec\n\nspec = AgentSpec(\n    name=\"translator\",\n    description=\"Translate text\",\n    input_type=\"str\",\n    output_type=\"str\",\n    system_prompt=\"You are a professional translator.\"\n)\n\nmeta = MetaAgent()\ncode = await meta.generate_from_spec(spec)\n</code></pre></p>"},{"location":"en/api/meta/#async-generate_and_savedescription-str-output_path-path-tuplestr-path","title":"<code>async generate_and_save(description: str, output_path: Path) -&gt; tuple[str, Path]</code>","text":"<p>Generate agent code and save to file.</p> <p>Parameters: - <code>description</code> (str): Natural language agent description - <code>output_path</code> (Path): Output file path</p> <p>Returns: - <code>tuple[str, Path]</code>: (generated_code, output_path)</p> <p>Raises: - <code>ValidationError</code>: If generated code is invalid</p> <p>Example: <pre><code>from pathlib import Path\n\nmeta = MetaAgent()\ncode, path = await meta.generate_and_save(\n    \"Create a translator agent\",\n    Path(\"agents/translator.py\")\n)\nprint(f\"Saved to {path}\")\n</code></pre></p>"},{"location":"en/api/meta/#agentspec","title":"AgentSpec","text":"<p>Structured specification for an agent.</p>"},{"location":"en/api/meta/#class-definition_1","title":"Class Definition","text":"<pre><code>from kagura.meta.spec import AgentSpec\nfrom pydantic import BaseModel\n\nclass AgentSpec(BaseModel):\n    \"\"\"Agent specification parsed from natural language\n\n    Structured representation of agent requirements.\n\n    Fields:\n        name: Agent function name (snake_case)\n        description: What the agent does (1-2 sentences)\n        input_type: Parameter type (str, dict, list, etc.)\n        output_type: Return type (str, dict, list, etc.)\n        tools: List of required tools (optional)\n        has_memory: Whether agent needs conversation memory\n        system_prompt: Agent's system instructions\n        examples: Example inputs/outputs (optional)\n    \"\"\"\n</code></pre>"},{"location":"en/api/meta/#fields","title":"Fields","text":""},{"location":"en/api/meta/#name-str","title":"<code>name: str</code>","text":"<p>Agent function name in snake_case.</p> <p>Example: <pre><code>spec = AgentSpec(\n    name=\"translator\",\n    description=\"Translate text\",\n    system_prompt=\"You are a translator\"\n)\n</code></pre></p>"},{"location":"en/api/meta/#description-str","title":"<code>description: str</code>","text":"<p>What the agent does (1-2 sentences).</p> <p>Example: <pre><code>spec = AgentSpec(\n    name=\"summarizer\",\n    description=\"Summarize articles in 3 bullet points\",\n    system_prompt=\"You are a summarizer\"\n)\n</code></pre></p>"},{"location":"en/api/meta/#input_type-str-str","title":"<code>input_type: str = \"str\"</code>","text":"<p>Parameter type annotation.</p> <p>Default: <code>\"str\"</code></p> <p>Common types: <code>\"str\"</code>, <code>\"dict\"</code>, <code>\"list\"</code>, <code>\"int\"</code>, <code>\"float\"</code></p> <p>Example: <pre><code>spec = AgentSpec(\n    name=\"calculator\",\n    description=\"Calculate math\",\n    input_type=\"str\",\n    output_type=\"float\",\n    system_prompt=\"Calculate the result\"\n)\n</code></pre></p>"},{"location":"en/api/meta/#output_type-str-str","title":"<code>output_type: str = \"str\"</code>","text":"<p>Return type annotation.</p> <p>Default: <code>\"str\"</code></p>"},{"location":"en/api/meta/#tools-liststr","title":"<code>tools: list[str] = []</code>","text":"<p>List of required tools.</p> <p>Available tools: - <code>\"code_executor\"</code>: Execute Python code - <code>\"web_search\"</code>: Search the web - <code>\"memory\"</code>: Conversation memory - <code>\"file_ops\"</code>: File operations</p> <p>Default: <code>[]</code></p> <p>Example: <pre><code>spec = AgentSpec(\n    name=\"math_solver\",\n    description=\"Solve math problems\",\n    tools=[\"code_executor\"],\n    system_prompt=\"Solve math problems by executing Python code\"\n)\n</code></pre></p>"},{"location":"en/api/meta/#has_memory-bool-false","title":"<code>has_memory: bool = False</code>","text":"<p>Whether agent needs conversation memory.</p> <p>Default: <code>False</code></p> <p>Example: <pre><code>spec = AgentSpec(\n    name=\"chatbot\",\n    description=\"Conversational chatbot\",\n    has_memory=True,\n    system_prompt=\"You are a friendly chatbot\"\n)\n</code></pre></p>"},{"location":"en/api/meta/#system_prompt-str","title":"<code>system_prompt: str</code>","text":"<p>Agent's system instructions.</p> <p>Required field</p> <p>Example: <pre><code>spec = AgentSpec(\n    name=\"translator\",\n    description=\"Translate text\",\n    system_prompt=\"You are a professional translator. Translate text accurately while preserving meaning and tone.\"\n)\n</code></pre></p>"},{"location":"en/api/meta/#examples-listdictstr-str","title":"<code>examples: list[dict[str, str]] = []</code>","text":"<p>Example inputs/outputs (optional).</p> <p>Default: <code>[]</code></p> <p>Format: <code>[{\"input\": \"...\", \"output\": \"...\"}]</code></p> <p>Example: <pre><code>spec = AgentSpec(\n    name=\"translator\",\n    description=\"Translate text\",\n    system_prompt=\"You are a translator\",\n    examples=[\n        {\"input\": \"Hello\", \"output\": \"\u3053\u3093\u306b\u3061\u306f\"},\n        {\"input\": \"Thank you\", \"output\": \"\u3042\u308a\u304c\u3068\u3046\"}\n    ]\n)\n</code></pre></p>"},{"location":"en/api/meta/#nlspecparser","title":"NLSpecParser","text":"<p>Parse natural language descriptions into structured AgentSpec.</p>"},{"location":"en/api/meta/#class-definition_2","title":"Class Definition","text":"<pre><code>from kagura.meta.parser import NLSpecParser\n\nclass NLSpecParser:\n    \"\"\"Parse natural language agent descriptions into AgentSpec\n\n    Uses LLM to extract structured information from user descriptions.\n\n    Args:\n        model: LLM model to use for parsing (default: \"gpt-4o-mini\")\n\n    Example:\n        &gt;&gt;&gt; parser = NLSpecParser()\n        &gt;&gt;&gt; desc = \"Create an agent that translates English to Japanese\"\n        &gt;&gt;&gt; spec = await parser.parse(desc)\n        &gt;&gt;&gt; print(spec.name)  # \"translator\"\n    \"\"\"\n</code></pre>"},{"location":"en/api/meta/#methods_1","title":"Methods","text":""},{"location":"en/api/meta/#__init__modelgpt-4o-mini","title":"<code>__init__(model=\"gpt-4o-mini\")</code>","text":"<p>Initialize parser with LLM model.</p> <p>Parameters: - <code>model</code> (str): LLM model for parsing (default: \"gpt-4o-mini\")</p> <p>Example: <pre><code>parser = NLSpecParser(model=\"gpt-4o-mini\")\n</code></pre></p>"},{"location":"en/api/meta/#async-parsedescription-str-agentspec","title":"<code>async parse(description: str) -&gt; AgentSpec</code>","text":"<p>Parse natural language description into AgentSpec.</p> <p>Parameters: - <code>description</code> (str): Natural language agent description</p> <p>Returns: - <code>AgentSpec</code>: Structured specification</p> <p>Example: <pre><code>parser = NLSpecParser()\nspec = await parser.parse(\"Summarize articles in 3 bullet points\")\nprint(spec.name)  # \"article_summarizer\"\nprint(spec.output_type)  # \"str\"\n</code></pre></p>"},{"location":"en/api/meta/#detect_toolsdescription-str-liststr","title":"<code>detect_tools(description: str) -&gt; list[str]</code>","text":"<p>Detect required tools from description using pattern matching.</p> <p>Parameters: - <code>description</code> (str): Natural language description</p> <p>Returns: - <code>list[str]</code>: List of detected tool names</p> <p>Example: <pre><code>parser = NLSpecParser()\n\n# Code execution detection\ntools = parser.detect_tools(\"Execute Python code to solve math problems\")\nprint(tools)  # [\"code_executor\"]\n\n# Web search detection\ntools = parser.detect_tools(\"Search the web for information\")\nprint(tools)  # [\"web_search\"]\n\n# Memory detection\ntools = parser.detect_tools(\"Remember user preferences in conversation\")\nprint(tools)  # [\"memory\"]\n</code></pre></p> <p>Tool patterns: - code_executor: \"execute code\", \"run python\", \"calculate\" - web_search: \"search\", \"google\", \"find online\", \"web\" - memory: \"remember\", \"conversation\", \"history\" - file_ops: \"read file\", \"write file\"</p>"},{"location":"en/api/meta/#codegenerator","title":"CodeGenerator","text":"<p>Generate Python agent code from AgentSpec using Jinja2 templates.</p>"},{"location":"en/api/meta/#class-definition_3","title":"Class Definition","text":"<pre><code>from kagura.meta.generator import CodeGenerator\nfrom pathlib import Path\n\nclass CodeGenerator:\n    \"\"\"Generate agent Python code from AgentSpec\n\n    Uses Jinja2 templates to generate complete, runnable agent code.\n\n    Args:\n        template_dir: Directory containing Jinja2 templates\n                     (default: kagura/meta/templates/)\n\n    Example:\n        &gt;&gt;&gt; generator = CodeGenerator()\n        &gt;&gt;&gt; code = generator.generate(spec)\n        &gt;&gt;&gt; print(code)  # Complete Python code with @agent decorator\n    \"\"\"\n</code></pre>"},{"location":"en/api/meta/#methods_2","title":"Methods","text":""},{"location":"en/api/meta/#__init__template_dirnone","title":"<code>__init__(template_dir=None)</code>","text":"<p>Initialize with template directory.</p> <p>Parameters: - <code>template_dir</code> (Path | None): Directory containing Jinja2 templates (optional)</p> <p>Example: <pre><code>generator = CodeGenerator()\n</code></pre></p>"},{"location":"en/api/meta/#generatespec-agentspec-str","title":"<code>generate(spec: AgentSpec) -&gt; str</code>","text":"<p>Generate complete agent code.</p> <p>Parameters: - <code>spec</code> (AgentSpec): Agent specification</p> <p>Returns: - <code>str</code>: Python code as string</p> <p>Example: <pre><code>from kagura.meta.spec import AgentSpec\n\nspec = AgentSpec(\n    name=\"translator\",\n    description=\"Translate text\",\n    system_prompt=\"You are a translator\"\n)\n\ngenerator = CodeGenerator()\ncode = generator.generate(spec)\n\nassert \"@agent\" in code\nassert \"async def translator\" in code\n</code></pre></p>"},{"location":"en/api/meta/#savecode-str-output_path-path-none","title":"<code>save(code: str, output_path: Path) -&gt; None</code>","text":"<p>Save generated code to file.</p> <p>Parameters: - <code>code</code> (str): Generated Python code - <code>output_path</code> (Path): Output file path</p> <p>Example: <pre><code>from pathlib import Path\n\ngenerator = CodeGenerator()\ncode = generator.generate(spec)\ngenerator.save(code, Path(\"agents/my_agent.py\"))\n</code></pre></p>"},{"location":"en/api/meta/#codevalidator","title":"CodeValidator","text":"<p>Validate generated agent code for security and correctness.</p>"},{"location":"en/api/meta/#class-definition_4","title":"Class Definition","text":"<pre><code>from kagura.meta.validator import CodeValidator\n\nclass CodeValidator:\n    \"\"\"Validate generated agent code\n\n    Reuses security checks from kagura.core.executor.ASTValidator\n    to ensure generated code is safe and correct.\n\n    Args:\n        allowed_imports: Set of allowed import modules (optional)\n\n    Example:\n        &gt;&gt;&gt; validator = CodeValidator()\n        &gt;&gt;&gt; try:\n        ...     validator.validate(code)\n        ...     print(\"Code is valid\")\n        ... except ValidationError as e:\n        ...     print(f\"Validation failed: {e}\")\n    \"\"\"\n</code></pre>"},{"location":"en/api/meta/#methods_3","title":"Methods","text":""},{"location":"en/api/meta/#__init__allowed_importsnone","title":"<code>__init__(allowed_imports=None)</code>","text":"<p>Initialize validator.</p> <p>Parameters: - <code>allowed_imports</code> (set[str] | None): Set of allowed import modules (optional)</p> <p>Default allowed imports: - <code>kagura</code> - <code>kagura.core</code> - <code>kagura.core.executor</code> - <code>kagura.core.memory</code> - <code>pydantic</code> - <code>typing</code> - <code>datetime</code> - <code>pathlib</code> - <code>asyncio</code></p> <p>Example: <pre><code>validator = CodeValidator()\n</code></pre></p>"},{"location":"en/api/meta/#validatecode-str-bool","title":"<code>validate(code: str) -&gt; bool</code>","text":"<p>Validate agent code (raises ValidationError if invalid).</p> <p>Parameters: - <code>code</code> (str): Python code to validate</p> <p>Returns: - <code>bool</code>: True if valid</p> <p>Raises: - <code>ValidationError</code>: If code is invalid or insecure</p> <p>Checks performed: 1. \u2705 Syntax checking 2. \u2705 Security validation (disallowed imports, dangerous functions) 3. \u2705 @agent decorator verification</p> <p>Example: <pre><code>validator = CodeValidator()\n\n# Valid code\ncode = \"\"\"\nfrom kagura import agent\n\n@agent(name=\"test\")\nasync def test_agent(x: str) -&gt; str:\n    return x\n\"\"\"\nvalidator.validate(code)  # Returns True\n\n# Invalid code (missing decorator)\nbad_code = \"\"\"\nfrom kagura import agent\n\nasync def test_agent(x: str) -&gt; str:\n    return x\n\"\"\"\ntry:\n    validator.validate(bad_code)\nexcept ValidationError as e:\n    print(e)  # \"Missing @agent decorator\"\n</code></pre></p>"},{"location":"en/api/meta/#validationerror","title":"ValidationError","text":"<p>Exception raised when agent code validation fails.</p>"},{"location":"en/api/meta/#class-definition_5","title":"Class Definition","text":"<pre><code>from kagura.meta.validator import ValidationError\n\nclass ValidationError(Exception):\n    \"\"\"Agent validation failed\"\"\"\n</code></pre>"},{"location":"en/api/meta/#common-validation-errors","title":"Common Validation Errors","text":""},{"location":"en/api/meta/#missing-agent-decorator","title":"Missing @agent decorator","text":"<p>Error: <code>ValidationError: Missing @agent decorator</code></p> <p>Cause: Generated code doesn't include <code>@agent</code> decorator</p> <p>Solution: Report as bug</p>"},{"location":"en/api/meta/#disallowed-import","title":"Disallowed import","text":"<p>Error: <code>ValidationError: Disallowed import: subprocess</code></p> <p>Cause: Generated code includes dangerous imports</p> <p>Example: <pre><code>try:\n    validator.validate(code_with_subprocess)\nexcept ValidationError as e:\n    print(e)  # \"Disallowed import: subprocess\"\n</code></pre></p>"},{"location":"en/api/meta/#disallowed-name","title":"Disallowed name","text":"<p>Error: <code>ValidationError: Disallowed name: eval</code></p> <p>Cause: Generated code uses dangerous functions like <code>eval()</code>, <code>exec()</code></p> <p>Example: <pre><code>try:\n    validator.validate(code_with_eval)\nexcept ValidationError as e:\n    print(e)  # \"Disallowed name: eval\"\n</code></pre></p>"},{"location":"en/api/meta/#syntax-error","title":"Syntax error","text":"<p>Error: <code>ValidationError: Syntax error: ...</code></p> <p>Cause: Generated code has invalid Python syntax</p>"},{"location":"en/api/meta/#cli-commands","title":"CLI Commands","text":""},{"location":"en/api/meta/#kagura-build-agent","title":"kagura build agent","text":"<p>Generate agent code from natural language description.</p> <p>Usage: <pre><code>kagura build agent [OPTIONS]\n</code></pre></p> <p>Options: - <code>-d, --description TEXT</code>: Natural language agent description - <code>-o, --output PATH</code>: Output file path (default: <code>agents/&lt;name&gt;.py</code>) - <code>--model TEXT</code>: LLM model for code generation (default: <code>gpt-4o-mini</code>) - <code>--interactive / --no-interactive</code>: Interactive mode (default: <code>True</code>) - <code>--no-validate</code>: Skip code validation</p> <p>Interactive Mode (default): <pre><code>kagura build agent\n</code></pre></p> <p>Output: <pre><code>\ud83e\udd16 Kagura Agent Builder\nDescribe your agent in natural language and I'll generate the code.\n\nWhat should your agent do? Translate English to Japanese\n\n\ud83d\udd0d Parsing agent specification...\n\n\ud83d\udccb Agent Specification\nName: translator\nDescription: Translate English to Japanese\nInput: str\nOutput: str\nTools: None\nMemory: No\n\n\u2699\ufe0f  Generating agent code...\n\ud83d\udd12 Validating code security...\n\u2705 Code validated\n\n\u2705 Agent created: agents/translator.py\n</code></pre></p> <p>Non-Interactive Mode: <pre><code>kagura build agent \\\n  --description \"Translate English to Japanese\" \\\n  --output translator.py \\\n  --no-interactive\n</code></pre></p> <p>Examples: <pre><code># Interactive mode\nkagura build agent\n\n# Direct generation\nkagura build agent -d \"Summarize text in 3 bullet points\" -o summarizer.py\n\n# Use GPT-4\nkagura build agent -d \"Complex reasoning task\" --model gpt-4o\n\n# Skip validation (not recommended)\nkagura build agent -d \"Test agent\" --no-validate\n</code></pre></p>"},{"location":"en/api/meta/#complete-example","title":"Complete Example","text":"<p>Here's a complete example using the Meta Agent API:</p> <pre><code>import asyncio\nfrom pathlib import Path\nfrom kagura.meta import MetaAgent\nfrom kagura.meta.spec import AgentSpec\nfrom kagura.meta.validator import ValidationError\n\nasync def main():\n    # Method 1: Generate from natural language\n    meta = MetaAgent(model=\"gpt-4o-mini\", validate=True)\n\n    try:\n        code = await meta.generate(\"Create a chatbot that remembers conversation history\")\n        print(\"Generated code:\")\n        print(code)\n\n        # Save to file\n        output_path = Path(\"agents/chatbot.py\")\n        output_path.parent.mkdir(parents=True, exist_ok=True)\n        output_path.write_text(code)\n        print(f\"\\nSaved to {output_path}\")\n\n    except ValidationError as e:\n        print(f\"Validation failed: {e}\")\n\n    # Method 2: Generate from AgentSpec\n    spec = AgentSpec(\n        name=\"translator\",\n        description=\"Translate text between languages\",\n        input_type=\"str\",\n        output_type=\"str\",\n        system_prompt=\"\"\"You are a professional translator.\n        Translate text accurately while preserving meaning and tone.\"\"\",\n        examples=[\n            {\"input\": \"Hello\", \"output\": \"\u3053\u3093\u306b\u3061\u306f\"},\n            {\"input\": \"Thank you\", \"output\": \"\u3042\u308a\u304c\u3068\u3046\"}\n        ]\n    )\n\n    code = await meta.generate_from_spec(spec)\n    print(\"\\nGenerated from spec:\")\n    print(code)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/api/meta/#template-customization","title":"Template Customization","text":""},{"location":"en/api/meta/#default-templates","title":"Default Templates","text":"<p>Meta Agent includes three default templates:</p> <ol> <li>agent_base.py.j2: Basic agent</li> <li>agent_with_tools.py.j2: Agent with tools</li> <li>agent_with_memory.py.j2: Agent with memory</li> </ol>"},{"location":"en/api/meta/#custom-templates","title":"Custom Templates","text":"<p>You can provide custom templates:</p> <pre><code>from pathlib import Path\nfrom kagura.meta import MetaAgent\n\n# Custom template directory\ntemplate_dir = Path(\"my_templates\")\n\nmeta = MetaAgent(template_dir=template_dir)\ncode = await meta.generate(\"My agent description\")\n</code></pre> <p>Template variables: - <code>spec</code>: AgentSpec object - <code>timestamp</code>: Generation timestamp - <code>kagura_version</code>: Kagura version - <code>tool_descriptions</code>: Tool descriptions dict</p>"},{"location":"en/api/meta/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Always validate generated code (default: <code>validate=True</code>)</li> <li>Review generated code before running in production</li> <li>Use specific descriptions to avoid unexpected behavior</li> <li>Test generated agents thoroughly</li> <li>Keep Kagura up-to-date for latest security fixes</li> </ol>"},{"location":"en/api/meta/#see-also","title":"See Also","text":"<ul> <li>Meta Agent User Guide</li> <li>Agent API Reference</li> <li>CLI Reference</li> <li>Code Executor API</li> </ul>"},{"location":"en/api/observability/","title":"Observability API","text":"<p>Telemetry tracking and monitoring for agent execution.</p>"},{"location":"en/api/observability/#overview","title":"Overview","text":"<p>The <code>kagura.observability</code> module provides tools for monitoring agent behavior: - EventStore: SQLite-based telemetry storage - Dashboard: Rich TUI for visualization - CLI Commands: <code>kagura monitor</code> commands</p> <p>Telemetry is automatically tracked for all agent executions.</p>"},{"location":"en/api/observability/#class-eventstore","title":"Class: EventStore","text":"<p>Store and query telemetry events in SQLite database.</p> <pre><code>from kagura.observability import EventStore\n\nstore = EventStore()  # Uses ~/.kagura/telemetry.db\n</code></pre>"},{"location":"en/api/observability/#constructor","title":"Constructor","text":"<pre><code>def __init__(self, db_path: Optional[Path | str] = None) -&gt; None\n</code></pre> <p>Parameters: - db_path (<code>Optional[Path | str]</code>, default: <code>None</code>): Database path   - <code>None</code>: Uses <code>~/.kagura/telemetry.db</code>   - <code>\":memory:\"</code>: In-memory database (testing)   - <code>Path</code> or <code>str</code>: Custom file path</p> <p>Example: <pre><code># Default location\nstore = EventStore()\n\n# Custom location\nstore = EventStore(Path.home() / \"my_telemetry.db\")\n\n# In-memory (testing)\nstore = EventStore(\":memory:\")\n</code></pre></p>"},{"location":"en/api/observability/#save_execution","title":"save_execution()","text":"<p>Save execution record.</p> <pre><code>async def save_execution(self, execution: dict[str, Any]) -&gt; None\n</code></pre> <p>Parameters: - execution (<code>dict[str, Any]</code>): Execution data containing:   - <code>id</code> (<code>str</code>, required): Execution ID   - <code>agent_name</code> (<code>str</code>, required): Agent name   - <code>started_at</code> (<code>float</code>, required): Start timestamp   - <code>ended_at</code> (<code>float</code>, optional): End timestamp   - <code>duration</code> (<code>float</code>, optional): Duration in seconds   - <code>status</code> (<code>str</code>, optional): Status (<code>\"completed\"</code>, <code>\"failed\"</code>)   - <code>error</code> (<code>str</code>, optional): Error message if failed   - <code>kwargs</code> (<code>dict</code>, optional): Agent arguments   - <code>events</code> (<code>list</code>, optional): List of events   - <code>metrics</code> (<code>dict</code>, optional): Metrics dictionary</p> <p>Example: <pre><code>import time\n\nawait store.save_execution({\n    \"id\": \"exec_123\",\n    \"agent_name\": \"translator\",\n    \"started_at\": time.time(),\n    \"ended_at\": time.time() + 0.5,\n    \"duration\": 0.5,\n    \"status\": \"completed\",\n    \"metrics\": {\n        \"total_cost\": 0.0003,\n        \"total_tokens\": 85,\n        \"llm_calls\": 1\n    }\n})\n</code></pre></p>"},{"location":"en/api/observability/#get_execution","title":"get_execution()","text":"<p>Get execution by ID.</p> <pre><code>def get_execution(self, execution_id: str) -&gt; Optional[dict[str, Any]]\n</code></pre> <p>Parameters: - execution_id (<code>str</code>): Execution ID</p> <p>Returns: Execution dict or <code>None</code> if not found</p> <p>Example: <pre><code>execution = store.get_execution(\"exec_123\")\nif execution:\n    print(f\"Status: {execution['status']}\")\n    print(f\"Duration: {execution['duration']:.2f}s\")\n</code></pre></p>"},{"location":"en/api/observability/#get_executions","title":"get_executions()","text":"<p>Query execution records.</p> <pre><code>def get_executions(\n    self,\n    agent_name: Optional[str] = None,\n    status: Optional[str] = None,\n    since: Optional[float] = None,\n    limit: int = 100,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Parameters: - agent_name (<code>Optional[str]</code>): Filter by agent name - status (<code>Optional[str]</code>): Filter by status (<code>\"completed\"</code>, <code>\"failed\"</code>) - since (<code>Optional[float]</code>): Filter by start time (timestamp) - limit (<code>int</code>, default: <code>100</code>): Maximum number of records</p> <p>Returns: List of execution dictionaries (sorted by most recent first)</p> <p>Example: <pre><code>import time\n\n# Get all executions\nall_execs = store.get_executions(limit=1000)\n\n# Get translator executions\ntranslator_execs = store.get_executions(agent_name=\"translator\")\n\n# Get failed executions\nfailed = store.get_executions(status=\"failed\")\n\n# Get last 24 hours\nsince = time.time() - 86400\nrecent = store.get_executions(since=since)\n\n# Combined filters\nrecent_failed = store.get_executions(\n    agent_name=\"translator\",\n    status=\"failed\",\n    since=since,\n    limit=50\n)\n</code></pre></p>"},{"location":"en/api/observability/#get_summary_stats","title":"get_summary_stats()","text":"<p>Get summary statistics.</p> <pre><code>def get_summary_stats(\n    self, agent_name: Optional[str] = None, since: Optional[float] = None\n) -&gt; dict[str, Any]\n</code></pre> <p>Parameters: - agent_name (<code>Optional[str]</code>): Filter by agent name - since (<code>Optional[float]</code>): Filter by start time (timestamp)</p> <p>Returns: Dictionary containing: - <code>total_executions</code> (<code>int</code>): Total number of executions - <code>completed</code> (<code>int</code>): Number of completed executions - <code>failed</code> (<code>int</code>): Number of failed executions - <code>avg_duration</code> (<code>float</code>): Average duration in seconds</p> <p>Example: <pre><code># Overall stats\nstats = store.get_summary_stats()\nprint(f\"Total: {stats['total_executions']}\")\nprint(f\"Success rate: {stats['completed'] / stats['total_executions'] * 100:.1f}%\")\n\n# Agent-specific stats\ntranslator_stats = store.get_summary_stats(agent_name=\"translator\")\nprint(f\"Avg duration: {translator_stats['avg_duration']:.2f}s\")\n</code></pre></p>"},{"location":"en/api/observability/#delete_old_executions","title":"delete_old_executions()","text":"<p>Delete executions older than timestamp.</p> <pre><code>def delete_old_executions(self, older_than: float) -&gt; int\n</code></pre> <p>Parameters: - older_than (<code>float</code>): Timestamp threshold</p> <p>Returns: Number of deleted records</p> <p>Example: <pre><code>import time\n\n# Delete executions older than 30 days\nthirty_days_ago = time.time() - (30 * 86400)\ndeleted = store.delete_old_executions(older_than=thirty_days_ago)\nprint(f\"Deleted {deleted} old executions\")\n</code></pre></p>"},{"location":"en/api/observability/#clear_all","title":"clear_all()","text":"<p>Clear all execution records.</p> <pre><code>def clear_all(self) -&gt; None\n</code></pre> <p>Example: <pre><code># Use with caution!\nstore.clear_all()\n</code></pre></p>"},{"location":"en/api/observability/#class-dashboard","title":"Class: Dashboard","text":"<p>Rich TUI dashboard for visualizing telemetry data.</p> <pre><code>from kagura.observability import Dashboard\n\ndashboard = Dashboard(store)\n</code></pre>"},{"location":"en/api/observability/#constructor_1","title":"Constructor","text":"<pre><code>def __init__(self, store: EventStore) -&gt; None\n</code></pre> <p>Parameters: - store (<code>EventStore</code>): Event store to query data from</p> <p>Example: <pre><code>from kagura.observability import EventStore, Dashboard\n\nstore = EventStore()\ndashboard = Dashboard(store)\n</code></pre></p>"},{"location":"en/api/observability/#show_live","title":"show_live()","text":"<p>Show live monitoring dashboard (auto-refreshing).</p> <pre><code>def show_live(\n    self, agent_name: Optional[str] = None, refresh_rate: float = 1.0\n) -&gt; None\n</code></pre> <p>Parameters: - agent_name (<code>Optional[str]</code>): Filter by agent name - refresh_rate (<code>float</code>, default: <code>1.0</code>): Refresh interval in seconds</p> <p>Example: <pre><code># Monitor all agents (refresh every 1 second)\ndashboard.show_live()\n\n# Monitor specific agent\ndashboard.show_live(agent_name=\"translator\")\n\n# Custom refresh rate\ndashboard.show_live(refresh_rate=2.0)\n</code></pre></p> <p>Output: <pre><code>\ud83d\udcca Kagura Agent Monitor\nTotal: 42 | Completed: 40 | Failed: 2\n\n\u250c\u2500 Recent Activity \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Time     Agent         Status      Duration  Cost     \u2502\n\u2502 14:32:15 translator    \u2713 COMPLETED 0.52s    $0.0003  \u2502\n\u2502 14:31:58 chatbot       \u2713 COMPLETED 1.23s    $0.0012  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"en/api/observability/#show_list","title":"show_list()","text":"<p>Show execution list.</p> <pre><code>def show_list(\n    self,\n    agent_name: Optional[str] = None,\n    limit: int = 20,\n    status: Optional[str] = None,\n) -&gt; None\n</code></pre> <p>Parameters: - agent_name (<code>Optional[str]</code>): Filter by agent name - limit (<code>int</code>, default: <code>20</code>): Maximum number of executions - status (<code>Optional[str]</code>): Filter by status</p> <p>Example: <pre><code># Show last 20 executions\ndashboard.show_list()\n\n# Show translator executions\ndashboard.show_list(agent_name=\"translator\", limit=50)\n\n# Show failed executions\ndashboard.show_list(status=\"failed\")\n</code></pre></p>"},{"location":"en/api/observability/#show_stats","title":"show_stats()","text":"<p>Show statistics summary.</p> <pre><code>def show_stats(\n    self, agent_name: Optional[str] = None, since: Optional[float] = None\n) -&gt; None\n</code></pre> <p>Parameters: - agent_name (<code>Optional[str]</code>): Filter by agent name - since (<code>Optional[float]</code>): Filter by start time (timestamp)</p> <p>Example: <pre><code>import time\n\n# Overall statistics\ndashboard.show_stats()\n\n# Agent-specific stats\ndashboard.show_stats(agent_name=\"translator\")\n\n# Last 24 hours\nsince = time.time() - 86400\ndashboard.show_stats(since=since)\n</code></pre></p> <p>Output: <pre><code>\ud83d\udcca Summary Statistics\n\nTotal Executions: 42\n  \u2022 Completed: 40\n  \u2022 Failed: 2\nAvg Duration: 1.34s\nTotal Cost: $0.0512\nTotal Tokens: 12,450\nLLM Calls: 45\nTool Calls: 12\n\nSuccess Rate: 95.2%\n</code></pre></p>"},{"location":"en/api/observability/#show_trace","title":"show_trace()","text":"<p>Show detailed trace for specific execution.</p> <pre><code>def show_trace(self, execution_id: str) -&gt; None\n</code></pre> <p>Parameters: - execution_id (<code>str</code>): Execution ID</p> <p>Example: <pre><code>dashboard.show_trace(\"exec_abc123\")\n</code></pre></p> <p>Output: <pre><code>\ud83d\udccd Execution Trace: translator (exec_abc123)\n\nExecution Info\n\u251c\u2500\u2500 Started: 14:32:15\n\u251c\u2500\u2500 Status: \u2713 COMPLETED\n\u251c\u2500\u2500 Duration: 0.52s\n\nMetrics\n\u251c\u2500\u2500 total_cost: $0.0003\n\u251c\u2500\u2500 total_tokens: 85\n\u251c\u2500\u2500 llm_calls: 1\n\u2514\u2500\u2500 tool_calls: 0\n\nEvents Timeline (3 events)\n\u251c\u2500\u2500 [0.00s] LLM Call (gpt-4o-mini) - 85 tokens, $0.0003, 0.48s\n\u251c\u2500\u2500 [0.48s] Memory Op (store) - 0.02s\n\u2514\u2500\u2500 [0.50s] Completion\n</code></pre></p>"},{"location":"en/api/observability/#show_cost_summary","title":"show_cost_summary()","text":"<p>Show cost summary.</p> <pre><code>def show_cost_summary(\n    self, since: Optional[float] = None, group_by: str = \"agent\"\n) -&gt; None\n</code></pre> <p>Parameters: - since (<code>Optional[float]</code>): Filter by start time (timestamp) - group_by (<code>str</code>, default: <code>\"agent\"</code>): Group by <code>\"agent\"</code> or <code>\"date\"</code></p> <p>Example: <pre><code># Cost by agent\ndashboard.show_cost_summary(group_by=\"agent\")\n\n# Cost by date\ndashboard.show_cost_summary(group_by=\"date\")\n\n# Last 7 days\nimport time\nsince = time.time() - (7 * 86400)\ndashboard.show_cost_summary(since=since)\n</code></pre></p> <p>Output (by agent): <pre><code>\u250c\u2500 Cost by Agent \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Agent          Calls  Tokens    Cost     \u2502\n\u2502 translator     23     5,123     $0.0234  \u2502\n\u2502 chatbot        15     4,892     $0.0189  \u2502\n\u2502 researcher     4      2,435     $0.0089  \u2502\n\u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502 Total          42     12,450    $0.0512  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nEstimated monthly cost: $1.54\n</code></pre></p>"},{"location":"en/api/observability/#cli-commands","title":"CLI Commands","text":"<p>The <code>kagura monitor</code> command provides quick access to observability features.</p>"},{"location":"en/api/observability/#live-monitoring","title":"Live Monitoring","text":"<pre><code># Monitor all agents\nkagura monitor\n\n# Monitor specific agent\nkagura monitor --agent translator\n\n# Custom refresh rate\nkagura monitor --refresh 2.0\n\n# Custom database\nkagura monitor --db /path/to/telemetry.db\n</code></pre>"},{"location":"en/api/observability/#execution-list","title":"Execution List","text":"<pre><code># List recent executions\nkagura monitor list\n\n# Filter by agent\nkagura monitor list --agent translator\n\n# Filter by status\nkagura monitor list --status failed\n\n# Limit results\nkagura monitor list --limit 50\n</code></pre>"},{"location":"en/api/observability/#statistics","title":"Statistics","text":"<pre><code># Overall statistics\nkagura monitor stats\n\n# Agent-specific stats\nkagura monitor stats --agent translator\n</code></pre>"},{"location":"en/api/observability/#detailed-trace","title":"Detailed Trace","text":"<pre><code># Show trace for specific execution\nkagura monitor trace exec_abc123\n</code></pre>"},{"location":"en/api/observability/#cost-analysis","title":"Cost Analysis","text":"<pre><code># Cost by agent\nkagura monitor cost\n\n# Cost by date\nkagura monitor cost --group-by date\n</code></pre>"},{"location":"en/api/observability/#complete-example","title":"Complete Example","text":"<pre><code>import asyncio\nimport time\nfrom pathlib import Path\nfrom kagura import agent\nfrom kagura.observability import EventStore, Dashboard\n\n\n@agent(model=\"gpt-4o-mini\")\nasync def translator(text: str, target_lang: str) -&gt; str:\n    '''Translate \"{{ text }}\" to {{ target_lang }}'''\n    pass\n\n\nasync def main():\n    # Run agent multiple times\n    translations = [\n        (\"Hello\", \"French\"),\n        (\"Goodbye\", \"Japanese\"),\n        (\"Thank you\", \"Spanish\"),\n    ]\n\n    for text, lang in translations:\n        result = await translator(text, target_lang=lang)\n        print(f\"{text} \u2192 {lang}: {result}\")\n\n    # === Analyze Telemetry ===\n\n    # Initialize\n    store = EventStore()\n    dashboard = Dashboard(store)\n\n    # Get executions\n    executions = store.get_executions(agent_name=\"translator\", limit=10)\n    print(f\"\\n{len(executions)} executions found\")\n\n    # Show statistics\n    stats = store.get_summary_stats(agent_name=\"translator\")\n    print(f\"Avg duration: {stats['avg_duration']:.2f}s\")\n\n    # Show dashboard views\n    print(\"\\n\" + \"=\" * 50)\n    print(\"EXECUTION LIST\")\n    print(\"=\" * 50)\n    dashboard.show_list(agent_name=\"translator\")\n\n    print(\"\\n\" + \"=\" * 50)\n    print(\"STATISTICS\")\n    print(\"=\" * 50)\n    dashboard.show_stats(agent_name=\"translator\")\n\n    print(\"\\n\" + \"=\" * 50)\n    print(\"COST SUMMARY\")\n    print(\"=\" * 50)\n    dashboard.show_cost_summary()\n\n    # === Cleanup old data ===\n    thirty_days_ago = time.time() - (30 * 86400)\n    deleted = store.delete_old_executions(older_than=thirty_days_ago)\n    print(f\"\\nDeleted {deleted} old executions\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/api/observability/#best-practices","title":"Best Practices","text":""},{"location":"en/api/observability/#1-regular-monitoring","title":"1. Regular Monitoring","text":"<p>Check your agents regularly:</p> <pre><code># Daily health check\nkagura monitor stats\n\n# Weekly cost review\nkagura monitor cost\n</code></pre>"},{"location":"en/api/observability/#2-automated-alerts","title":"2. Automated Alerts","text":"<p>Create scripts to alert on issues:</p> <pre><code>def check_failure_rate(agent_name: str, threshold: float = 0.2) -&gt; None:\n    \"\"\"Alert if failure rate exceeds threshold.\"\"\"\n    store = EventStore()\n    stats = store.get_summary_stats(agent_name=agent_name)\n\n    if stats['total_executions'] == 0:\n        return\n\n    failure_rate = stats['failed'] / stats['total_executions']\n\n    if failure_rate &gt; threshold:\n        print(f\"\u26a0\ufe0f  ALERT: {agent_name} failure rate: {failure_rate:.1%}\")\n        # Send notification (email, Slack, etc.)\n</code></pre>"},{"location":"en/api/observability/#3-cost-tracking","title":"3. Cost Tracking","text":"<p>Monitor spending by project:</p> <pre><code>def get_project_cost(project_prefix: str) -&gt; float:\n    \"\"\"Get total cost for project.\"\"\"\n    store = EventStore()\n    executions = store.get_executions(limit=10000)\n\n    total_cost = 0.0\n    for exec in executions:\n        if exec['agent_name'].startswith(project_prefix):\n            total_cost += exec.get('metrics', {}).get('total_cost', 0.0)\n\n    return total_cost\n\n# Example\ncost = get_project_cost(\"project_a_\")\nprint(f\"Project A cost: ${cost:.2f}\")\n</code></pre>"},{"location":"en/api/observability/#4-performance-baselines","title":"4. Performance Baselines","text":"<p>Track performance trends:</p> <pre><code>def detect_performance_regression(\n    agent_name: str, threshold: float = 1.5\n) -&gt; bool:\n    \"\"\"Detect if agent has slowed down.\"\"\"\n    store = EventStore()\n\n    # Baseline (last 100 executions)\n    baseline = store.get_executions(agent_name=agent_name, limit=100)\n    baseline_avg = sum(e['duration'] for e in baseline) / len(baseline)\n\n    # Recent (last 10 executions)\n    recent = store.get_executions(agent_name=agent_name, limit=10)\n    recent_avg = sum(e['duration'] for e in recent) / len(recent)\n\n    return recent_avg &gt; baseline_avg * threshold\n</code></pre>"},{"location":"en/api/observability/#error-handling","title":"Error Handling","text":"<pre><code>from pathlib import Path\nfrom kagura.observability import EventStore\n\ntry:\n    # Access database\n    store = EventStore()\n    executions = store.get_executions()\nexcept Exception as e:\n    print(f\"Database error: {e}\")\n\ntry:\n    # Get specific execution\n    execution = store.get_execution(\"exec_123\")\n    if execution is None:\n        print(\"Execution not found\")\nexcept Exception as e:\n    print(f\"Query error: {e}\")\n</code></pre>"},{"location":"en/api/observability/#related","title":"Related","text":"<ul> <li>Tutorial: Observability - Step-by-step guide</li> <li>@agent Decorator - Core agent decorator</li> <li>Testing API - Agent testing</li> </ul>"},{"location":"en/api/observability/#see-also","title":"See Also","text":"<ul> <li>Quick Start - Getting started</li> <li>Tutorial: Agent Builder - Building agents</li> <li>Tutorial: Testing - Testing agents</li> </ul>"},{"location":"en/api/testing/","title":"Testing API","text":"<p>Framework for testing AI agents with assertions designed for non-deterministic LLM outputs.</p>"},{"location":"en/api/testing/#overview","title":"Overview","text":"<p>The <code>kagura.testing</code> module provides tools for testing AI agents: - AgentTestCase: Base class with assertion methods - LLMMock/LLMRecorder: Mock and record LLM calls - ToolMock: Mock tool executions - Timer: Measure execution time</p>"},{"location":"en/api/testing/#class-agenttestcase","title":"Class: AgentTestCase","text":"<p>Base class for testing Kagura agents.</p> <pre><code>from kagura.testing import AgentTestCase\nimport pytest\n\n\nclass TestMyAgent(AgentTestCase):\n    agent = my_agent  # Agent to test\n\n    @pytest.mark.asyncio\n    async def test_example(self):\n        result = await self.agent(\"test input\")\n        self.assert_not_empty(result)\n</code></pre>"},{"location":"en/api/testing/#constructor","title":"Constructor","text":"<pre><code>def __init__(self) -&gt; None\n</code></pre> <p>Initializes test case with empty telemetry tracking.</p>"},{"location":"en/api/testing/#content-assertions","title":"Content Assertions","text":""},{"location":"en/api/testing/#assert_contains","title":"assert_contains()","text":"<p>Assert text contains substring.</p> <pre><code>def assert_contains(self, text: str, substring: str) -&gt; None\n</code></pre> <p>Parameters: - text (<code>str</code>): Text to check - substring (<code>str</code>): Expected substring</p> <p>Raises: <code>AssertionError</code> if substring not found</p> <p>Example: <pre><code>result = await self.agent(\"Hello, Alice\")\nself.assert_contains(result, \"Alice\")\n</code></pre></p>"},{"location":"en/api/testing/#assert_contains_any","title":"assert_contains_any()","text":"<p>Assert text contains at least one of the options.</p> <pre><code>def assert_contains_any(self, text: str, options: list[str]) -&gt; None\n</code></pre> <p>Parameters: - text (<code>str</code>): Text to check - options (<code>list[str]</code>): List of possible substrings</p> <p>Raises: <code>AssertionError</code> if none of the options found</p> <p>Example: <pre><code>result = await self.agent(\"greet\")\nself.assert_contains_any(result, [\"Hello\", \"Hi\", \"Hey\"])\n</code></pre></p>"},{"location":"en/api/testing/#assert_not_contains","title":"assert_not_contains()","text":"<p>Assert text does not contain substring.</p> <pre><code>def assert_not_contains(self, text: str, substring: str) -&gt; None\n</code></pre> <p>Parameters: - text (<code>str</code>): Text to check - substring (<code>str</code>): Forbidden substring</p> <p>Raises: <code>AssertionError</code> if substring found</p> <p>Example: <pre><code>result = await self.agent(\"test\")\nself.assert_not_contains(result, \"error\")\n</code></pre></p>"},{"location":"en/api/testing/#assert_matches_pattern","title":"assert_matches_pattern()","text":"<p>Assert text matches regex pattern.</p> <pre><code>def assert_matches_pattern(self, text: str, pattern: str) -&gt; None\n</code></pre> <p>Parameters: - text (<code>str</code>): Text to check - pattern (<code>str</code>): Regex pattern</p> <p>Raises: <code>AssertionError</code> if pattern doesn't match</p> <p>Example: <pre><code>result = await self.agent(\"extract email\")\nself.assert_matches_pattern(result, r'\\w+@\\w+\\.\\w+')\n</code></pre></p>"},{"location":"en/api/testing/#assert_not_empty","title":"assert_not_empty()","text":"<p>Assert text is not empty.</p> <pre><code>def assert_not_empty(self, text: str) -&gt; None\n</code></pre> <p>Parameters: - text (<code>str</code>): Text to check</p> <p>Raises: <code>AssertionError</code> if text is empty or only whitespace</p> <p>Example: <pre><code>result = await self.agent(\"test\")\nself.assert_not_empty(result)\n</code></pre></p>"},{"location":"en/api/testing/#assert_language","title":"assert_language()","text":"<p>Assert text is in expected language.</p> <pre><code>def assert_language(self, text: str, expected_lang: str) -&gt; None\n</code></pre> <p>Parameters: - text (<code>str</code>): Text to check - expected_lang (<code>str</code>): Expected language code (e.g., <code>\"en\"</code>, <code>\"ja\"</code>, <code>\"fr\"</code>)</p> <p>Raises: - <code>AssertionError</code>: If language doesn't match - <code>ImportError</code>: If <code>langdetect</code> not installed</p> <p>Requires: <code>pip install langdetect</code></p> <p>Example: <pre><code>result = await self.agent(\"translate to French\")\nself.assert_language(result, \"fr\")\n</code></pre></p>"},{"location":"en/api/testing/#llm-behavior-assertions","title":"LLM Behavior Assertions","text":""},{"location":"en/api/testing/#assert_llm_calls","title":"assert_llm_calls()","text":"<p>Assert number and characteristics of LLM calls.</p> <pre><code>def assert_llm_calls(\n    self,\n    count: Optional[int] = None,\n    model: Optional[str] = None,\n) -&gt; None\n</code></pre> <p>Parameters: - count (<code>Optional[int]</code>): Expected number of LLM calls - model (<code>Optional[str]</code>): Expected model name</p> <p>Raises: <code>AssertionError</code> if LLM calls don't match expectations</p> <p>Example: <pre><code>with self.record_llm_calls():\n    result = await self.agent(\"test\")\n\n# Assert exactly 1 call\nself.assert_llm_calls(count=1)\n\n# Assert correct model\nself.assert_llm_calls(model=\"gpt-4o-mini\")\n\n# Assert both\nself.assert_llm_calls(count=1, model=\"gpt-4o-mini\")\n</code></pre></p>"},{"location":"en/api/testing/#assert_token_usage","title":"assert_token_usage()","text":"<p>Assert token usage is within bounds.</p> <pre><code>def assert_token_usage(\n    self,\n    max_tokens: Optional[int] = None,\n    min_tokens: Optional[int] = None,\n) -&gt; None\n</code></pre> <p>Parameters: - max_tokens (<code>Optional[int]</code>): Maximum allowed tokens - min_tokens (<code>Optional[int]</code>): Minimum expected tokens</p> <p>Raises: <code>AssertionError</code> if token usage out of bounds</p> <p>Example: <pre><code>with self.record_llm_calls():\n    result = await self.agent(\"test\")\n\n# Assert under budget\nself.assert_token_usage(max_tokens=500)\n\n# Assert meaningful response\nself.assert_token_usage(min_tokens=10)\n</code></pre></p>"},{"location":"en/api/testing/#assert_tool_calls","title":"assert_tool_calls()","text":"<p>Assert specific tools were called.</p> <pre><code>def assert_tool_calls(self, expected_tools: list[str]) -&gt; None\n</code></pre> <p>Parameters: - expected_tools (<code>list[str]</code>): List of expected tool names</p> <p>Raises: <code>AssertionError</code> if expected tools not called</p> <p>Example: <pre><code>result = await self.agent(\"search for Python\")\nself.assert_tool_calls([\"search_web\"])\n</code></pre></p>"},{"location":"en/api/testing/#performance-assertions","title":"Performance Assertions","text":""},{"location":"en/api/testing/#assert_duration","title":"assert_duration()","text":"<p>Assert execution duration is within limit.</p> <pre><code>def assert_duration(self, max_seconds: float) -&gt; None\n</code></pre> <p>Parameters: - max_seconds (<code>float</code>): Maximum allowed duration in seconds</p> <p>Raises: <code>AssertionError</code> if duration exceeds limit</p> <p>Example: <pre><code>with self.measure_time():\n    result = await self.agent(\"test\")\n\nself.assert_duration(5.0)  # Must complete within 5 seconds\n</code></pre></p>"},{"location":"en/api/testing/#assert_cost","title":"assert_cost()","text":"<p>Assert execution cost is within budget.</p> <pre><code>def assert_cost(self, max_cost: float) -&gt; None\n</code></pre> <p>Parameters: - max_cost (<code>float</code>): Maximum allowed cost in USD</p> <p>Raises: <code>AssertionError</code> if cost exceeds budget</p> <p>Example: <pre><code>with self.record_llm_calls():\n    result = await self.agent(\"test\")\n\nself.assert_cost(0.01)  # Must cost less than $0.01\n</code></pre></p>"},{"location":"en/api/testing/#structured-output-assertions","title":"Structured Output Assertions","text":""},{"location":"en/api/testing/#assert_valid_model","title":"assert_valid_model()","text":"<p>Assert result is valid instance of Pydantic model.</p> <pre><code>def assert_valid_model(self, result: Any, model_class: type) -&gt; None\n</code></pre> <p>Parameters: - result (<code>Any</code>): Result to check - model_class (<code>type</code>): Expected Pydantic model class</p> <p>Raises: <code>AssertionError</code> if result is not instance of model_class</p> <p>Example: <pre><code>from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\nresult = await self.agent(\"extract person\")\nself.assert_valid_model(result, Person)\n</code></pre></p>"},{"location":"en/api/testing/#assert_field_value","title":"assert_field_value()","text":"<p>Assert model field has expected value.</p> <pre><code>def assert_field_value(\n    self, result: Any, field: str, expected: Any\n) -&gt; None\n</code></pre> <p>Parameters: - result (<code>Any</code>): Pydantic model instance - field (<code>str</code>): Field name - expected (<code>Any</code>): Expected value</p> <p>Raises: <code>AssertionError</code> if field value doesn't match</p> <p>Example: <pre><code>person = await self.agent(\"extract person\")\nself.assert_field_value(person, \"name\", \"Alice\")\nself.assert_field_value(person, \"age\", 30)\n</code></pre></p>"},{"location":"en/api/testing/#context-managers","title":"Context Managers","text":""},{"location":"en/api/testing/#record_llm_calls","title":"record_llm_calls()","text":"<p>Context manager to record LLM calls.</p> <pre><code>def record_llm_calls(self) -&gt; LLMRecorder\n</code></pre> <p>Returns: <code>LLMRecorder</code> context manager</p> <p>Example: <pre><code>with self.record_llm_calls():\n    result = await self.agent(\"test\")\n\nself.assert_llm_calls(count=1)\n</code></pre></p>"},{"location":"en/api/testing/#mock_llm","title":"mock_llm()","text":"<p>Context manager to mock LLM responses.</p> <pre><code>def mock_llm(self, response: str) -&gt; LLMMock\n</code></pre> <p>Parameters: - response (<code>str</code>): Mock response to return</p> <p>Returns: <code>LLMMock</code> context manager</p> <p>Example: <pre><code>with self.mock_llm(\"Mocked response\"):\n    result = await self.agent(\"test\")\n\nassert result == \"Mocked response\"\n</code></pre></p>"},{"location":"en/api/testing/#mock_tool","title":"mock_tool()","text":"<p>Context manager to mock tool calls.</p> <pre><code>def mock_tool(self, tool_name: str, return_value: Any) -&gt; ToolMock\n</code></pre> <p>Parameters: - tool_name (<code>str</code>): Name of tool to mock - return_value (<code>Any</code>): Value to return</p> <p>Returns: <code>ToolMock</code> context manager</p> <p>Example: <pre><code>with self.mock_tool(\"search_web\", return_value=[\"result1\", \"result2\"]):\n    result = await self.agent(\"search query\")\n</code></pre></p>"},{"location":"en/api/testing/#measure_time","title":"measure_time()","text":"<p>Context manager to measure execution time.</p> <pre><code>def measure_time(self) -&gt; Timer\n</code></pre> <p>Returns: <code>Timer</code> context manager</p> <p>Example: <pre><code>with self.measure_time() as timer:\n    result = await self.agent(\"test\")\n\nprint(f\"Took {timer.duration:.2f}s\")\nself.assert_duration(5.0)\n</code></pre></p>"},{"location":"en/api/testing/#complete-example","title":"Complete Example","text":"<pre><code>import pytest\nfrom pydantic import BaseModel\nfrom kagura import agent\nfrom kagura.testing import AgentTestCase\n\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n\n@agent(model=\"gpt-4o-mini\")\nasync def person_extractor(text: str) -&gt; Person:\n    '''Extract person information from: {{ text }}'''\n    pass\n\n\nclass TestPersonExtractor(AgentTestCase):\n    agent = person_extractor\n\n    @pytest.mark.asyncio\n    async def test_extracts_person(self):\n        \"\"\"Test person extraction.\"\"\"\n        text = \"Alice is 30 years old and works as a software engineer\"\n        result = await self.agent(text)\n\n        # Structured output assertions\n        self.assert_valid_model(result, Person)\n        self.assert_field_value(result, \"name\", \"Alice\")\n        self.assert_field_value(result, \"age\", 30)\n        self.assert_field_value(result, \"occupation\", \"software engineer\")\n\n    @pytest.mark.asyncio\n    async def test_llm_behavior(self):\n        \"\"\"Test LLM call characteristics.\"\"\"\n        with self.record_llm_calls():\n            result = await self.agent(\"Test input\")\n\n        # LLM behavior assertions\n        self.assert_llm_calls(count=1, model=\"gpt-4o-mini\")\n        self.assert_token_usage(max_tokens=200)\n\n    @pytest.mark.asyncio\n    async def test_performance(self):\n        \"\"\"Test performance requirements.\"\"\"\n        with self.measure_time():\n            result = await self.agent(\"Test input\")\n\n        # Performance assertions\n        self.assert_duration(5.0)\n\n    @pytest.mark.asyncio\n    async def test_with_mock(self):\n        \"\"\"Test with mocked LLM response.\"\"\"\n        mock_person = Person(name=\"Mock\", age=25, occupation=\"tester\")\n\n        with self.mock_llm(mock_person.model_dump_json()):\n            result = await self.agent(\"Test input\")\n\n        self.assert_field_value(result, \"name\", \"Mock\")\n\n    @pytest.mark.asyncio\n    async def test_multiple_assertions(self):\n        \"\"\"Test with multiple assertion types.\"\"\"\n        text = \"Bob is 40 years old and is a doctor\"\n\n        # Execute\n        with self.record_llm_calls():\n            with self.measure_time():\n                result = await self.agent(text)\n\n        # Content assertions\n        self.assert_valid_model(result, Person)\n\n        # LLM behavior assertions\n        self.assert_llm_calls(count=1)\n        self.assert_token_usage(max_tokens=300)\n\n        # Performance assertions\n        self.assert_duration(5.0)\n</code></pre>"},{"location":"en/api/testing/#best-practices","title":"Best Practices","text":""},{"location":"en/api/testing/#1-test-patterns-not-exact-text","title":"1. Test Patterns, Not Exact Text","text":"<pre><code># Good - flexible\nself.assert_contains_any(result, [\"hello\", \"hi\", \"greetings\"])\n\n# Bad - brittle\nassert result == \"Hello, World!\"\n</code></pre>"},{"location":"en/api/testing/#2-use-mocks-for-fast-tests","title":"2. Use Mocks for Fast Tests","text":"<pre><code># Fast - mocked (use for unit tests)\nwith self.mock_llm(\"Mocked\"):\n    result = await self.agent(\"test\")\n\n# Slow - real LLM call (use for integration tests)\nresult = await self.agent(\"test\")\n</code></pre>"},{"location":"en/api/testing/#3-combine-assertions","title":"3. Combine Assertions","text":"<pre><code>@pytest.mark.asyncio\nasync def test_comprehensive(self):\n    with self.record_llm_calls():\n        with self.measure_time():\n            result = await self.agent(\"test\")\n\n    # Multiple assertions in one test\n    self.assert_not_empty(result)\n    self.assert_llm_calls(count=1)\n    self.assert_token_usage(max_tokens=500)\n    self.assert_duration(5.0)\n</code></pre>"},{"location":"en/api/testing/#4-parametrize-tests","title":"4. Parametrize Tests","text":"<pre><code>@pytest.mark.asyncio\n@pytest.mark.parametrize(\"text,expected_lang\", [\n    (\"Hello\", \"en\"),\n    (\"Bonjour\", \"fr\"),\n    (\"\u3053\u3093\u306b\u3061\u306f\", \"ja\"),\n])\nasync def test_languages(self, text, expected_lang):\n    result = await self.agent(text)\n    self.assert_language(result, expected_lang)\n</code></pre>"},{"location":"en/api/testing/#common-patterns","title":"Common Patterns","text":""},{"location":"en/api/testing/#pattern-1-golden-test","title":"Pattern 1: Golden Test","text":"<pre><code>@pytest.mark.asyncio\nasync def test_golden_output(self):\n    with self.mock_llm(\"Expected output\"):\n        result = await self.agent(\"test\")\n\n    with open(\"golden_output.txt\") as f:\n        expected = f.read()\n\n    assert result == expected\n</code></pre>"},{"location":"en/api/testing/#pattern-2-regression-test","title":"Pattern 2: Regression Test","text":"<pre><code>@pytest.mark.asyncio\nasync def test_no_regression(self):\n    with self.mock_llm(\"Previous version output\"):\n        result = await self.agent(\"test\")\n\n    self.assert_not_empty(result)\n</code></pre>"},{"location":"en/api/testing/#pattern-3-error-handling","title":"Pattern 3: Error Handling","text":"<pre><code>@pytest.mark.asyncio\nasync def test_handles_empty_response(self):\n    with self.mock_llm(\"\"):\n        result = await self.agent(\"test\")\n\n    # Agent should handle gracefully\n    # (implementation-dependent)\n</code></pre>"},{"location":"en/api/testing/#error-handling","title":"Error Handling","text":"<pre><code>from pydantic import ValidationError\nfrom litellm import APIError\n\n@pytest.mark.asyncio\nasync def test_validation_error(self):\n    \"\"\"Test validation error handling.\"\"\"\n    with pytest.raises(ValidationError):\n        result = await self.agent(\"invalid input\")\n\n@pytest.mark.asyncio\nasync def test_api_error(self):\n    \"\"\"Test API error handling.\"\"\"\n    with pytest.raises(APIError):\n        result = await self.agent(\"test\")\n</code></pre>"},{"location":"en/api/testing/#related","title":"Related","text":"<ul> <li>Tutorial: Testing - Step-by-step testing guide</li> <li>@agent Decorator - Core agent decorator</li> <li>Tutorial: Agent Builder - Building agents</li> </ul>"},{"location":"en/api/testing/#see-also","title":"See Also","text":"<ul> <li>Quick Start - Getting started</li> <li>Tutorial: Observability - Monitoring agents</li> </ul>"},{"location":"en/api/tools/","title":"Tools API Reference","text":""},{"location":"en/api/tools/#overview","title":"Overview","text":"<p>The Tools API provides decorators and utilities for creating non-LLM functions that can be called by agents and exposed via MCP.</p>"},{"location":"en/api/tools/#tool-decorator","title":"<code>@tool</code> Decorator","text":"<p>Convert a regular Python function into a registered tool.</p>"},{"location":"en/api/tools/#signature","title":"Signature","text":"<pre><code>@tool\ndef function_name(...) -&gt; ReturnType:\n    \"\"\"Function docstring\"\"\"\n    pass\n\n# Or with custom name\n@tool(name=\"custom_name\")\ndef function_name(...) -&gt; ReturnType:\n    \"\"\"Function docstring\"\"\"\n    pass\n</code></pre>"},{"location":"en/api/tools/#parameters","title":"Parameters","text":"<ul> <li>fn (<code>Callable[P, T] | None</code>): Function to decorate (optional, for use without parentheses)</li> <li>name (<code>str | None</code>): Custom tool name (defaults to function name)</li> </ul>"},{"location":"en/api/tools/#returns","title":"Returns","text":"<ul> <li>Callable[P, T]: Decorated function with type validation and registry integration</li> </ul>"},{"location":"en/api/tools/#behavior","title":"Behavior","text":"<ol> <li>Type Validation: Validates arguments against function signature at call time</li> <li>Registry Integration: Automatically registers tool in global <code>tool_registry</code></li> <li>Metadata Preservation: Preserves function name, docstring, and signature</li> <li>Error Handling: Raises <code>TypeError</code> for invalid arguments</li> </ol>"},{"location":"en/api/tools/#metadata-attributes","title":"Metadata Attributes","text":"<p>Decorated functions have the following metadata attributes:</p> <ul> <li><code>_is_tool</code> (<code>bool</code>): Always <code>True</code> for tool-decorated functions</li> <li><code>_tool_name</code> (<code>str</code>): Tool name (function name or custom name)</li> <li><code>_tool_signature</code> (<code>inspect.Signature</code>): Function signature</li> <li><code>_tool_docstring</code> (<code>str</code>): Function docstring</li> </ul>"},{"location":"en/api/tools/#examples","title":"Examples","text":""},{"location":"en/api/tools/#basic-tool","title":"Basic Tool","text":"<pre><code>from kagura import tool\n\n@tool\ndef add(a: float, b: float) -&gt; float:\n    \"\"\"Add two numbers\"\"\"\n    return a + b\n\nresult = add(5.0, 3.0)  # 8.0\n</code></pre>"},{"location":"en/api/tools/#tool-with-default-parameters","title":"Tool with Default Parameters","text":"<pre><code>@tool\ndef greet(name: str, greeting: str = \"Hello\") -&gt; str:\n    \"\"\"Greet someone\"\"\"\n    return f\"{greeting}, {name}!\"\n\ngreet(\"Alice\")           # \"Hello, Alice!\"\ngreet(\"Bob\", \"Hi\")       # \"Hi, Bob!\"\n</code></pre>"},{"location":"en/api/tools/#tool-with-custom-name","title":"Tool with Custom Name","text":"<pre><code>@tool(name=\"tax_calculator\")\ndef calc_tax(amount: float, rate: float = 0.1) -&gt; float:\n    \"\"\"Calculate tax amount\"\"\"\n    return amount * rate\n\n# Registered as \"tax_calculator\"\n</code></pre>"},{"location":"en/api/tools/#tool-with-complex-return-type","title":"Tool with Complex Return Type","text":"<pre><code>@tool\ndef get_user(user_id: int) -&gt; dict[str, Any]:\n    \"\"\"Get user data\"\"\"\n    return {\n        \"id\": user_id,\n        \"name\": \"Alice\",\n        \"active\": True\n    }\n</code></pre>"},{"location":"en/api/tools/#tool-with-error-handling","title":"Tool with Error Handling","text":"<pre><code>@tool\ndef divide(a: float, b: float) -&gt; float:\n    \"\"\"Divide two numbers\"\"\"\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n\nresult = divide(10.0, 2.0)  # 5.0\ndivide(10.0, 0.0)           # ValueError\n</code></pre>"},{"location":"en/api/tools/#error-handling","title":"Error Handling","text":"<pre><code>@tool\ndef strict_function(x: int, y: int) -&gt; int:\n    \"\"\"Requires exactly 2 arguments\"\"\"\n    return x + y\n\n# Valid\nstrict_function(1, 2)         # \u2705 3\nstrict_function(x=1, y=2)     # \u2705 3\n\n# Invalid - raises TypeError\nstrict_function(1)            # \u274c TypeError: invalid arguments\nstrict_function(1, 2, 3)      # \u274c TypeError: invalid arguments\n</code></pre>"},{"location":"en/api/tools/#tool-registry","title":"Tool Registry","text":""},{"location":"en/api/tools/#toolregistry-class","title":"<code>ToolRegistry</code> Class","text":"<p>Global registry for all Kagura tools.</p>"},{"location":"en/api/tools/#methods","title":"Methods","text":""},{"location":"en/api/tools/#registername-str-func-callable-any-none","title":"<code>register(name: str, func: Callable[..., Any]) -&gt; None</code>","text":"<p>Register a tool.</p> <p>Parameters: - <code>name</code> (<code>str</code>): Tool name (must be unique) - <code>func</code> (<code>Callable</code>): Tool function</p> <p>Raises: - <code>ValueError</code>: If tool name is already registered</p> <p>Example: <pre><code>from kagura.core.tool_registry import tool_registry\n\ndef my_tool():\n    return \"result\"\n\ntool_registry.register(\"my_tool\", my_tool)\n</code></pre></p>"},{"location":"en/api/tools/#getname-str-callable-any-none","title":"<code>get(name: str) -&gt; Callable[..., Any] | None</code>","text":"<p>Get tool by name.</p> <p>Parameters: - <code>name</code> (<code>str</code>): Tool name</p> <p>Returns: - Tool function, or <code>None</code> if not found</p> <p>Example: <pre><code>tool = tool_registry.get(\"my_tool\")\nif tool:\n    result = tool()\n</code></pre></p>"},{"location":"en/api/tools/#get_all-dictstr-callable-any","title":"<code>get_all() -&gt; dict[str, Callable[..., Any]]</code>","text":"<p>Get all registered tools.</p> <p>Returns: - Dictionary of <code>tool_name</code> \u2192 <code>tool_function</code></p> <p>Example: <pre><code>all_tools = tool_registry.get_all()\nfor name, func in all_tools.items():\n    print(f\"{name}: {func.__doc__}\")\n</code></pre></p>"},{"location":"en/api/tools/#list_names-liststr","title":"<code>list_names() -&gt; list[str]</code>","text":"<p>List all tool names.</p> <p>Returns: - List of tool names</p> <p>Example: <pre><code>names = tool_registry.list_names()\nprint(names)  # ['add', 'multiply', 'divide']\n</code></pre></p>"},{"location":"en/api/tools/#unregistername-str-none","title":"<code>unregister(name: str) -&gt; None</code>","text":"<p>Unregister a tool.</p> <p>Parameters: - <code>name</code> (<code>str</code>): Tool name</p> <p>Raises: - <code>KeyError</code>: If tool is not registered</p> <p>Example: <pre><code>tool_registry.unregister(\"my_tool\")\n</code></pre></p>"},{"location":"en/api/tools/#clear-none","title":"<code>clear() -&gt; None</code>","text":"<p>Clear all tools from registry.</p> <p>Example: <pre><code>tool_registry.clear()\nassert len(tool_registry.list_names()) == 0\n</code></pre></p>"},{"location":"en/api/tools/#auto_discovermodule_path-str-none","title":"<code>auto_discover(module_path: str) -&gt; None</code>","text":"<p>Auto-discover tools in a module.</p> <p>Scans a module for functions decorated with <code>@tool</code> and automatically registers them.</p> <p>Parameters: - <code>module_path</code> (<code>str</code>): Python module path (e.g., <code>\"my_package.tools\"</code>)</p> <p>Raises: - <code>ValueError</code>: If module is not found</p> <p>Example: <pre><code># my_package/tools.py\nfrom kagura import tool\n\n@tool\ndef tool1():\n    return 1\n\n@tool\ndef tool2():\n    return 2\n\n# main.py\nfrom kagura.core.tool_registry import tool_registry\n\ntool_registry.auto_discover(\"my_package.tools\")\nprint(tool_registry.list_names())  # ['tool1', 'tool2']\n</code></pre></p>"},{"location":"en/api/tools/#global-registry-instance","title":"Global Registry Instance","text":"<p>The global <code>tool_registry</code> instance is automatically created and available for import:</p> <pre><code>from kagura.core.tool_registry import tool_registry\n\n# Check if tool exists\nif \"my_tool\" in tool_registry.list_names():\n    tool = tool_registry.get(\"my_tool\")\n    result = tool()\n</code></pre>"},{"location":"en/api/tools/#type-validation","title":"Type Validation","text":"<p>Tools validate arguments using <code>inspect.signature</code> at call time.</p>"},{"location":"en/api/tools/#supported-features","title":"Supported Features","text":"<ol> <li> <p>Positional Arguments <pre><code>@tool\ndef func(a: int, b: int) -&gt; int:\n    return a + b\n\nfunc(1, 2)  # \u2705\n</code></pre></p> </li> <li> <p>Keyword Arguments <pre><code>func(a=1, b=2)  # \u2705\nfunc(1, b=2)    # \u2705\n</code></pre></p> </li> <li> <p>Default Parameters <pre><code>@tool\ndef func(a: int, b: int = 10) -&gt; int:\n    return a + b\n\nfunc(5)      # \u2705 15\nfunc(5, 20)  # \u2705 25\n</code></pre></p> </li> <li> <p>Variable Arguments <pre><code>@tool\ndef merge(*dicts: dict) -&gt; dict:\n    result = {}\n    for d in dicts:\n        result.update(d)\n    return result\n\nmerge({\"a\": 1}, {\"b\": 2})  # \u2705 {\"a\": 1, \"b\": 2}\n</code></pre></p> </li> </ol>"},{"location":"en/api/tools/#validation-errors","title":"Validation Errors","text":"<pre><code>@tool\ndef strict(x: int, y: int) -&gt; int:\n    return x + y\n\n# Missing argument\nstrict(1)  # \u274c TypeError: Tool 'strict' called with invalid arguments\n\n# Too many arguments\nstrict(1, 2, 3)  # \u274c TypeError: Tool 'strict' called with invalid arguments\n\n# Invalid keyword\nstrict(1, z=2)  # \u274c TypeError: Tool 'strict' called with invalid arguments\n</code></pre>"},{"location":"en/api/tools/#mcp-integration","title":"MCP Integration","text":"<p>Tools are automatically exposed via MCP when using <code>kagura mcp start</code>.</p>"},{"location":"en/api/tools/#example","title":"Example","text":"<pre><code># my_tools.py\nfrom kagura import tool\n\n@tool\ndef weather_lookup(city: str) -&gt; dict:\n    \"\"\"Get current weather for a city\"\"\"\n    return {\n        \"city\": city,\n        \"temperature\": 72,\n        \"condition\": \"sunny\"\n    }\n\n@tool\ndef currency_convert(amount: float, from_currency: str, to_currency: str) -&gt; float:\n    \"\"\"Convert currency\"\"\"\n    # Simplified example\n    rates = {\"USD\": 1.0, \"EUR\": 0.85, \"JPY\": 110.0}\n    return amount * rates[to_currency] / rates[from_currency]\n</code></pre> <p>Start MCP server: <pre><code>kagura mcp start\n</code></pre></p> <p>Tools are now available to Claude Desktop via MCP protocol.</p>"},{"location":"en/api/tools/#best-practices","title":"Best Practices","text":""},{"location":"en/api/tools/#1-clear-documentation","title":"1. Clear Documentation","text":"<pre><code>@tool\ndef calculate_discount(price: float, discount_percent: float) -&gt; float:\n    \"\"\"\n    Calculate discounted price.\n\n    Args:\n        price: Original price\n        discount_percent: Discount percentage (e.g., 15 for 15%)\n\n    Returns:\n        Final price after discount\n\n    Example:\n        &gt;&gt;&gt; calculate_discount(100.0, 15.0)\n        85.0\n    \"\"\"\n    return price * (1 - discount_percent / 100)\n</code></pre>"},{"location":"en/api/tools/#2-input-validation","title":"2. Input Validation","text":"<pre><code>@tool\ndef withdraw_money(account_id: str, amount: float) -&gt; dict:\n    \"\"\"Withdraw money from account\"\"\"\n    if amount &lt;= 0:\n        raise ValueError(\"Amount must be positive\")\n    if amount &gt; 10000:\n        raise ValueError(\"Exceeds daily limit\")\n\n    # Process withdrawal\n    return {\"success\": True, \"new_balance\": 5000 - amount}\n</code></pre>"},{"location":"en/api/tools/#3-type-hints","title":"3. Type Hints","text":"<p>Always use type hints for better documentation and validation:</p> <pre><code>@tool\ndef process_order(\n    order_id: str,\n    items: list[dict],\n    shipping_address: dict,\n    priority: bool = False\n) -&gt; dict:\n    \"\"\"Process customer order\"\"\"\n    return {\n        \"order_id\": order_id,\n        \"status\": \"processing\",\n        \"estimated_delivery\": \"2025-10-15\"\n    }\n</code></pre>"},{"location":"en/api/tools/#4-error-handling","title":"4. Error Handling","text":"<pre><code>@tool\ndef fetch_user_data(user_id: int) -&gt; dict:\n    \"\"\"Fetch user data from database\"\"\"\n    try:\n        user = database.get_user(user_id)\n        if not user:\n            raise ValueError(f\"User {user_id} not found\")\n        return user\n    except DatabaseError as e:\n        raise RuntimeError(f\"Database error: {e}\") from e\n</code></pre>"},{"location":"en/api/tools/#see-also","title":"See Also","text":"<ul> <li>Tools Tutorial</li> <li>Agent Decorator</li> <li>MCP Integration</li> </ul>"},{"location":"en/api/workflows/","title":"Workflows API Reference","text":""},{"location":"en/api/workflows/#overview","title":"Overview","text":"<p>The Workflows API provides decorators and utilities for creating multi-agent orchestrations that coordinate agents and tools to accomplish complex tasks.</p>"},{"location":"en/api/workflows/#workflow-decorator","title":"<code>@workflow</code> Decorator","text":"<p>Convert an async function into a registered workflow.</p>"},{"location":"en/api/workflows/#signature","title":"Signature","text":"<pre><code>@workflow\nasync def function_name(...) -&gt; ReturnType:\n    \"\"\"Function docstring\"\"\"\n    # Orchestration logic\n    pass\n\n# Or with custom name\n@workflow(name=\"custom_name\")\nasync def function_name(...) -&gt; ReturnType:\n    \"\"\"Function docstring\"\"\"\n    # Orchestration logic\n    pass\n</code></pre>"},{"location":"en/api/workflows/#parameters","title":"Parameters","text":"<ul> <li>fn (<code>Callable[P, Awaitable[T]] | None</code>): Function to decorate (optional, for use without parentheses)</li> <li>name (<code>str | None</code>): Custom workflow name (defaults to function name)</li> </ul>"},{"location":"en/api/workflows/#returns","title":"Returns","text":"<ul> <li>Callable[P, Awaitable[T]]: Decorated async function</li> </ul>"},{"location":"en/api/workflows/#behavior","title":"Behavior","text":"<ol> <li>Execution: Executes the function body (unlike @agent which calls LLM)</li> <li>Registry Integration: Automatically registers workflow in global <code>workflow_registry</code></li> <li>Metadata Preservation: Preserves function name, docstring, and signature</li> <li>Async Support: Fully supports async/await patterns</li> </ol>"},{"location":"en/api/workflows/#metadata-attributes","title":"Metadata Attributes","text":"<p>Decorated functions have the following metadata attributes:</p> <ul> <li><code>_is_workflow</code> (<code>bool</code>): Always <code>True</code> for workflow-decorated functions</li> <li><code>_workflow_name</code> (<code>str</code>): Workflow name (function name or custom name)</li> <li><code>_workflow_signature</code> (<code>inspect.Signature</code>): Function signature</li> <li><code>_workflow_docstring</code> (<code>str</code>): Function docstring</li> </ul>"},{"location":"en/api/workflows/#examples","title":"Examples","text":""},{"location":"en/api/workflows/#basic-workflow","title":"Basic Workflow","text":"<pre><code>from kagura import workflow, agent\n\n@agent\nasync def search(query: str) -&gt; str:\n    \"\"\"Search for {{ query }}\"\"\"\n    ...\n\n@agent\nasync def summarize(text: str) -&gt; str:\n    \"\"\"Summarize: {{ text }}\"\"\"\n    ...\n\n@workflow\nasync def research(topic: str) -&gt; dict:\n    \"\"\"Research workflow\"\"\"\n    results = await search(topic)\n    summary = await summarize(results)\n    return {\"results\": results, \"summary\": summary}\n\ndata = await research(\"AI safety\")\n</code></pre>"},{"location":"en/api/workflows/#workflow-with-custom-name","title":"Workflow with Custom Name","text":"<pre><code>@workflow(name=\"analysis_pipeline\")\nasync def analyze(data: str) -&gt; dict:\n    \"\"\"Data analysis pipeline\"\"\"\n    validated = await validate_agent(data)\n    processed = await process_agent(validated)\n    return {\"validated\": validated, \"processed\": processed}\n\n# Registered as \"analysis_pipeline\"\n</code></pre>"},{"location":"en/api/workflows/#sequential-execution","title":"Sequential Execution","text":"<pre><code>@workflow\nasync def content_pipeline(topic: str) -&gt; dict:\n    \"\"\"Create content through stages\"\"\"\n    research = await research_agent(topic)\n    draft = await writing_agent(research)\n    final = await editing_agent(draft)\n    return {\"research\": research, \"draft\": draft, \"final\": final}\n</code></pre>"},{"location":"en/api/workflows/#parallel-execution","title":"Parallel Execution","text":"<pre><code>import asyncio\n\n@workflow\nasync def multi_source(topic: str) -&gt; dict:\n    \"\"\"Gather from multiple sources\"\"\"\n    results = await asyncio.gather(\n        source_a_agent(topic),\n        source_b_agent(topic),\n        source_c_agent(topic)\n    )\n    a, b, c = results\n    combined = await synthesis_agent(f\"A: {a}\\nB: {b}\\nC: {c}\")\n    return {\"sources\": results, \"synthesis\": combined}\n</code></pre>"},{"location":"en/api/workflows/#conditional-logic","title":"Conditional Logic","text":"<pre><code>@workflow\nasync def adaptive(text: str) -&gt; dict:\n    \"\"\"Adapt processing based on content\"\"\"\n    category = await classifier_agent(text)\n\n    if category == \"technical\":\n        result = await technical_processor(text)\n    else:\n        result = await general_processor(text)\n\n    return {\"category\": category, \"result\": result}\n</code></pre>"},{"location":"en/api/workflows/#error-handling","title":"Error Handling","text":"<pre><code>@workflow\nasync def resilient(task: str) -&gt; dict:\n    \"\"\"Workflow with error handling\"\"\"\n    try:\n        result = await primary_agent(task)\n    except Exception:\n        result = await fallback_agent(task)\n\n    return {\"task\": task, \"result\": result}\n</code></pre>"},{"location":"en/api/workflows/#workflow-registry","title":"Workflow Registry","text":""},{"location":"en/api/workflows/#workflowregistry-class","title":"<code>WorkflowRegistry</code> Class","text":"<p>Global registry for all Kagura workflows.</p>"},{"location":"en/api/workflows/#methods","title":"Methods","text":""},{"location":"en/api/workflows/#registername-str-func-callable-any-none","title":"<code>register(name: str, func: Callable[..., Any]) -&gt; None</code>","text":"<p>Register a workflow.</p> <p>Parameters: - <code>name</code> (<code>str</code>): Workflow name (must be unique) - <code>func</code> (<code>Callable</code>): Workflow function</p> <p>Raises: - <code>ValueError</code>: If workflow name is already registered</p> <p>Example: <pre><code>from kagura.core.workflow_registry import workflow_registry\n\nasync def my_workflow():\n    return \"result\"\n\nworkflow_registry.register(\"my_workflow\", my_workflow)\n</code></pre></p>"},{"location":"en/api/workflows/#getname-str-callable-any-none","title":"<code>get(name: str) -&gt; Callable[..., Any] | None</code>","text":"<p>Get workflow by name.</p> <p>Parameters: - <code>name</code> (<code>str</code>): Workflow name</p> <p>Returns: - Workflow function, or <code>None</code> if not found</p> <p>Example: <pre><code>workflow = workflow_registry.get(\"my_workflow\")\nif workflow:\n    result = await workflow()\n</code></pre></p>"},{"location":"en/api/workflows/#get_all-dictstr-callable-any","title":"<code>get_all() -&gt; dict[str, Callable[..., Any]]</code>","text":"<p>Get all registered workflows.</p> <p>Returns: - Dictionary of <code>workflow_name</code> \u2192 <code>workflow_function</code></p> <p>Example: <pre><code>all_workflows = workflow_registry.get_all()\nfor name, func in all_workflows.items():\n    print(f\"{name}: {func.__doc__}\")\n</code></pre></p>"},{"location":"en/api/workflows/#list_names-liststr","title":"<code>list_names() -&gt; list[str]</code>","text":"<p>List all workflow names.</p> <p>Returns: - List of workflow names</p> <p>Example: <pre><code>names = workflow_registry.list_names()\nprint(names)  # ['research', 'analysis', 'content_pipeline']\n</code></pre></p>"},{"location":"en/api/workflows/#unregistername-str-none","title":"<code>unregister(name: str) -&gt; None</code>","text":"<p>Unregister a workflow.</p> <p>Parameters: - <code>name</code> (<code>str</code>): Workflow name</p> <p>Raises: - <code>KeyError</code>: If workflow is not registered</p> <p>Example: <pre><code>workflow_registry.unregister(\"my_workflow\")\n</code></pre></p>"},{"location":"en/api/workflows/#clear-none","title":"<code>clear() -&gt; None</code>","text":"<p>Clear all workflows from registry.</p> <p>Example: <pre><code>workflow_registry.clear()\nassert len(workflow_registry.list_names()) == 0\n</code></pre></p>"},{"location":"en/api/workflows/#auto_discovermodule_path-str-none","title":"<code>auto_discover(module_path: str) -&gt; None</code>","text":"<p>Auto-discover workflows in a module.</p> <p>Scans a module for functions decorated with <code>@workflow</code> and automatically registers them.</p> <p>Parameters: - <code>module_path</code> (<code>str</code>): Python module path (e.g., <code>\"my_package.workflows\"</code>)</p> <p>Raises: - <code>ValueError</code>: If module is not found</p> <p>Example: <pre><code># my_package/workflows.py\nfrom kagura import workflow\n\n@workflow\nasync def workflow1():\n    return 1\n\n@workflow\nasync def workflow2():\n    return 2\n\n# main.py\nfrom kagura.core.workflow_registry import workflow_registry\n\nworkflow_registry.auto_discover(\"my_package.workflows\")\nprint(workflow_registry.list_names())  # ['workflow1', 'workflow2']\n</code></pre></p>"},{"location":"en/api/workflows/#global-registry-instance","title":"Global Registry Instance","text":"<p>The global <code>workflow_registry</code> instance is automatically created and available for import:</p> <pre><code>from kagura.core.workflow_registry import workflow_registry\n\n# Check if workflow exists\nif \"my_workflow\" in workflow_registry.list_names():\n    workflow = workflow_registry.get(\"my_workflow\")\n    result = await workflow()\n</code></pre>"},{"location":"en/api/workflows/#common-patterns","title":"Common Patterns","text":""},{"location":"en/api/workflows/#chaining-agents","title":"Chaining Agents","text":"<pre><code>@workflow\nasync def chain(input_data: str) -&gt; str:\n    \"\"\"Chain multiple agents\"\"\"\n    step1 = await agent1(input_data)\n    step2 = await agent2(step1)\n    step3 = await agent3(step2)\n    return step3\n</code></pre>"},{"location":"en/api/workflows/#fan-outfan-in","title":"Fan-Out/Fan-In","text":"<pre><code>@workflow\nasync def fan_out_fan_in(input_data: str) -&gt; str:\n    \"\"\"Process in parallel, then combine\"\"\"\n    # Fan-out: Process in parallel\n    results = await asyncio.gather(\n        processor1(input_data),\n        processor2(input_data),\n        processor3(input_data)\n    )\n\n    # Fan-in: Combine results\n    combined = await combiner_agent(results)\n    return combined\n</code></pre>"},{"location":"en/api/workflows/#loop-processing","title":"Loop Processing","text":"<pre><code>@workflow\nasync def batch_process(items: list) -&gt; list:\n    \"\"\"Process multiple items\"\"\"\n    results = []\n    for item in items:\n        result = await processing_agent(item)\n        results.append(result)\n    return results\n</code></pre>"},{"location":"en/api/workflows/#conditional-branching","title":"Conditional Branching","text":"<pre><code>@workflow\nasync def route_by_type(data: str) -&gt; dict:\n    \"\"\"Route based on data type\"\"\"\n    data_type = await type_detector(data)\n\n    if data_type == \"A\":\n        result = await handler_a(data)\n    elif data_type == \"B\":\n        result = await handler_b(data)\n    else:\n        result = await default_handler(data)\n\n    return {\"type\": data_type, \"result\": result}\n</code></pre>"},{"location":"en/api/workflows/#retry-logic","title":"Retry Logic","text":"<pre><code>@workflow\nasync def with_retry(task: str) -&gt; dict:\n    \"\"\"Retry on failure\"\"\"\n    max_attempts = 3\n\n    for attempt in range(max_attempts):\n        try:\n            result = await unreliable_agent(task)\n            return {\"task\": task, \"result\": result, \"attempts\": attempt + 1}\n        except Exception as e:\n            if attempt == max_attempts - 1:\n                raise\n            await asyncio.sleep(2 ** attempt)\n\n    raise RuntimeError(\"Should not reach here\")\n</code></pre>"},{"location":"en/api/workflows/#integration","title":"Integration","text":""},{"location":"en/api/workflows/#with-agents","title":"With Agents","text":"<pre><code>from kagura import workflow, agent\n\n@agent\nasync def my_agent(query: str) -&gt; str:\n    \"\"\"Process {{ query }}\"\"\"\n    ...\n\n@workflow\nasync def my_workflow(input_data: str) -&gt; dict:\n    \"\"\"Use agents in workflow\"\"\"\n    result1 = await my_agent(input_data)\n    result2 = await my_agent(result1)\n    return {\"result1\": result1, \"result2\": result2}\n</code></pre>"},{"location":"en/api/workflows/#with-tools","title":"With Tools","text":"<pre><code>from kagura import workflow, tool, agent\n\n@tool\ndef calculate(x: float, y: float) -&gt; float:\n    \"\"\"Calculate something\"\"\"\n    return x * y\n\n@agent\nasync def analyzer(result: float) -&gt; str:\n    \"\"\"Analyze {{ result }}\"\"\"\n    ...\n\n@workflow\nasync def hybrid(x: float, y: float) -&gt; dict:\n    \"\"\"Combine tools and agents\"\"\"\n    # Use tool\n    calculation = calculate(x, y)\n\n    # Use agent\n    analysis = await analyzer(calculation)\n\n    return {\"calculation\": calculation, \"analysis\": analysis}\n</code></pre>"},{"location":"en/api/workflows/#with-mcp","title":"With MCP","text":"<p>Workflows are automatically exposed via MCP:</p> <pre><code>@workflow\nasync def mcp_workflow(query: str) -&gt; dict:\n    \"\"\"This workflow is available via MCP\"\"\"\n    result = await process_agent(query)\n    return {\"query\": query, \"result\": result}\n\n# Automatically available in MCP\n# Run: kagura mcp start\n</code></pre>"},{"location":"en/api/workflows/#best-practices","title":"Best Practices","text":""},{"location":"en/api/workflows/#1-clear-documentation","title":"1. Clear Documentation","text":"<pre><code>@workflow\nasync def documented_workflow(input_data: str) -&gt; dict:\n    \"\"\"\n    Process data through multiple stages.\n\n    Args:\n        input_data: Raw input to process\n\n    Returns:\n        Dictionary with processed results\n\n    Workflow Stages:\n        1. Validation\n        2. Processing\n        3. Analysis\n        4. Reporting\n    \"\"\"\n    validated = await validation_agent(input_data)\n    processed = await processing_agent(validated)\n    analyzed = await analysis_agent(processed)\n    report = await reporting_agent(analyzed)\n\n    return {\n        \"validated\": validated,\n        \"processed\": processed,\n        \"analyzed\": analyzed,\n        \"report\": report\n    }\n</code></pre>"},{"location":"en/api/workflows/#2-error-handling","title":"2. Error Handling","text":"<pre><code>@workflow\nasync def safe_workflow(task: str) -&gt; dict:\n    \"\"\"Workflow with comprehensive error handling\"\"\"\n    try:\n        result = await risky_agent(task)\n    except ValueError as e:\n        # Handle specific error\n        result = await fallback_agent(task)\n    except Exception as e:\n        # Handle any other error\n        raise RuntimeError(f\"Workflow failed: {e}\") from e\n\n    return {\"task\": task, \"result\": result}\n</code></pre>"},{"location":"en/api/workflows/#3-modular-design","title":"3. Modular Design","text":"<pre><code># Reusable sub-workflows\n@workflow\nasync def data_prep(raw: str) -&gt; dict:\n    \"\"\"Reusable data preparation\"\"\"\n    cleaned = await clean_agent(raw)\n    normalized = await normalize_agent(cleaned)\n    return {\"cleaned\": cleaned, \"normalized\": normalized}\n\n@workflow\nasync def main_workflow(input_data: str) -&gt; dict:\n    \"\"\"Main workflow using sub-workflows\"\"\"\n    prepared = await data_prep(input_data)\n    analysis = await analysis_agent(prepared[\"normalized\"])\n    return {\"prepared\": prepared, \"analysis\": analysis}\n</code></pre>"},{"location":"en/api/workflows/#4-type-hints","title":"4. Type Hints","text":"<pre><code>@workflow\nasync def typed_workflow(\n    data: list[str],\n    options: dict[str, Any]\n) -&gt; dict[str, list[str]]:\n    \"\"\"Workflow with clear type hints\"\"\"\n    results = []\n    for item in data:\n        result = await process_agent(item, options)\n        results.append(result)\n\n    return {\"processed\": results}\n</code></pre>"},{"location":"en/api/workflows/#advanced-workflow-features","title":"Advanced Workflow Features","text":"<p>Kagura provides advanced workflow capabilities for complex multi-agent orchestration.</p>"},{"location":"en/api/workflows/#workflow-context-sharing","title":"Workflow Context Sharing","text":"<p>Share state across workflow steps using context dictionary:</p> <pre><code>@workflow\nasync def context_workflow(input_data: str, workflow_context: dict) -&gt; dict:\n    \"\"\"Workflow with shared context\"\"\"\n\n    # Initialize context\n    workflow_context[\"step_count\"] = 0\n    workflow_context[\"accumulated_data\"] = []\n\n    # Step 1\n    workflow_context[\"step_count\"] += 1\n    result1 = await agent1(input_data)\n    workflow_context[\"accumulated_data\"].append(result1)\n\n    # Step 2 - uses context from step 1\n    workflow_context[\"step_count\"] += 1\n    result2 = await agent2(result1, previous_data=workflow_context[\"accumulated_data\"])\n\n    return {\n        \"final_result\": result2,\n        \"steps_executed\": workflow_context[\"step_count\"]\n    }\n\n# Execute with context\ncontext = {}\nresult = await context_workflow(\"input\", workflow_context=context)\nprint(f\"Executed {context['step_count']} steps\")\n</code></pre>"},{"location":"en/api/workflows/#conditional-branching_1","title":"Conditional Branching","text":"<p>Implement conditional logic in workflows:</p> <pre><code>@workflow\nasync def conditional_workflow(query: str) -&gt; dict:\n    \"\"\"Workflow with conditional branches\"\"\"\n\n    # Classify query\n    classification = await classifier_agent(query)\n\n    # Branch based on classification\n    if classification == \"technical\":\n        result = await technical_agent(query)\n    elif classification == \"business\":\n        result = await business_agent(query)\n    else:\n        result = await general_agent(query)\n\n    return {\"classification\": classification, \"result\": result}\n</code></pre>"},{"location":"en/api/workflows/#parallel-execution_1","title":"Parallel Execution","text":"<p>Execute multiple agents in parallel:</p> <pre><code>import asyncio\n\n@workflow\nasync def parallel_workflow(input_data: str) -&gt; dict:\n    \"\"\"Workflow with parallel agent execution\"\"\"\n\n    # Execute agents in parallel\n    results = await asyncio.gather(\n        agent1(input_data),\n        agent2(input_data),\n        agent3(input_data)\n    )\n\n    # Combine results\n    combined = await synthesis_agent(results)\n\n    return {\"individual\": results, \"combined\": combined}\n</code></pre>"},{"location":"en/api/workflows/#retry-logic_1","title":"Retry Logic","text":"<p>Implement automatic retry for failed steps:</p> <pre><code>@workflow\nasync def retry_workflow(data: str, max_retries: int = 3) -&gt; dict:\n    \"\"\"Workflow with retry logic\"\"\"\n\n    for attempt in range(max_retries):\n        try:\n            result = await unreliable_agent(data)\n            return {\"success\": True, \"result\": result, \"attempts\": attempt + 1}\n        except Exception as e:\n            if attempt == max_retries - 1:\n                # Final attempt failed\n                return {\"success\": False, \"error\": str(e), \"attempts\": attempt + 1}\n            # Wait before retry\n            await asyncio.sleep(2 ** attempt)  # Exponential backoff\n\n    return {\"success\": False, \"error\": \"Max retries exceeded\"}\n</code></pre>"},{"location":"en/api/workflows/#dynamic-agent-selection","title":"Dynamic Agent Selection","text":"<p>Select agents dynamically based on runtime conditions:</p> <pre><code>@workflow\nasync def dynamic_workflow(query: str, agent_pool: dict) -&gt; dict:\n    \"\"\"Workflow with dynamic agent selection\"\"\"\n\n    # Analyze query to determine best agent\n    analysis = await analyzer_agent(query)\n\n    # Select agent from pool\n    selected_agent_name = analysis[\"recommended_agent\"]\n    selected_agent = agent_pool.get(selected_agent_name)\n\n    if not selected_agent:\n        raise ValueError(f\"Agent {selected_agent_name} not found\")\n\n    # Execute selected agent\n    result = await selected_agent(query)\n\n    return {\n        \"selected_agent\": selected_agent_name,\n        \"result\": result\n    }\n\n# Usage\nagents = {\n    \"translator\": translator_agent,\n    \"summarizer\": summarizer_agent,\n    \"analyzer\": analyzer_agent\n}\n\nresult = await dynamic_workflow(\"Translate to French\", agent_pool=agents)\n</code></pre>"},{"location":"en/api/workflows/#workflow-monitoring","title":"Workflow Monitoring","text":"<p>Track workflow execution with telemetry:</p> <pre><code>import time\n\n@workflow\nasync def monitored_workflow(data: str) -&gt; dict:\n    \"\"\"Workflow with execution monitoring\"\"\"\n\n    start_time = time.time()\n    steps_executed = []\n\n    try:\n        # Step 1\n        step_start = time.time()\n        result1 = await agent1(data)\n        steps_executed.append({\n            \"step\": \"agent1\",\n            \"duration\": time.time() - step_start,\n            \"success\": True\n        })\n\n        # Step 2\n        step_start = time.time()\n        result2 = await agent2(result1)\n        steps_executed.append({\n            \"step\": \"agent2\",\n            \"duration\": time.time() - step_start,\n            \"success\": True\n        })\n\n        return {\n            \"result\": result2,\n            \"metadata\": {\n                \"total_duration\": time.time() - start_time,\n                \"steps\": steps_executed\n            }\n        }\n\n    except Exception as e:\n        steps_executed.append({\n            \"step\": \"error\",\n            \"error\": str(e),\n            \"success\": False\n        })\n        raise\n</code></pre>"},{"location":"en/api/workflows/#workflow-composition","title":"Workflow Composition","text":"<p>Compose workflows from sub-workflows:</p> <pre><code>@workflow\nasync def data_processing_workflow(data: str) -&gt; dict:\n    \"\"\"Sub-workflow for data processing\"\"\"\n    cleaned = await clean_agent(data)\n    normalized = await normalize_agent(cleaned)\n    return {\"cleaned\": cleaned, \"normalized\": normalized}\n\n\n@workflow\nasync def analysis_workflow(data: dict) -&gt; dict:\n    \"\"\"Sub-workflow for analysis\"\"\"\n    insights = await analysis_agent(data[\"normalized\"])\n    summary = await summary_agent(insights)\n    return {\"insights\": insights, \"summary\": summary}\n\n\n@workflow\nasync def master_workflow(raw_data: str) -&gt; dict:\n    \"\"\"Master workflow composing sub-workflows\"\"\"\n\n    # Execute sub-workflows in sequence\n    processed = await data_processing_workflow(raw_data)\n    analyzed = await analysis_workflow(processed)\n\n    # Combine results\n    return {\n        \"processing\": processed,\n        \"analysis\": analyzed,\n        \"pipeline\": \"master_workflow\"\n    }\n</code></pre>"},{"location":"en/api/workflows/#complete-advanced-example","title":"Complete Advanced Example","text":"<pre><code>import asyncio\nimport time\nfrom kagura import agent, workflow\n\n\n@agent\nasync def classifier(text: str) -&gt; str:\n    '''Classify {{ text }} as: technical, business, or general'''\n    pass\n\n\n@agent\nasync def technical_expert(query: str) -&gt; str:\n    '''Technical answer: {{ query }}'''\n    pass\n\n\n@agent\nasync def business_expert(query: str) -&gt; str:\n    '''Business answer: {{ query }}'''\n    pass\n\n\n@agent\nasync def summarizer(text: str) -&gt; str:\n    '''Summarize: {{ text }}'''\n    pass\n\n\n@workflow\nasync def intelligent_workflow(\n    query: str,\n    workflow_context: dict,\n    max_retries: int = 3\n) -&gt; dict:\n    \"\"\"Advanced workflow with multiple features\"\"\"\n\n    start_time = time.time()\n    workflow_context[\"steps\"] = []\n\n    # Step 1: Classification\n    classification = await classifier(query)\n    workflow_context[\"steps\"].append({\"step\": \"classification\", \"result\": classification})\n\n    # Step 2: Conditional routing with retry\n    for attempt in range(max_retries):\n        try:\n            if classification == \"technical\":\n                response = await technical_expert(query)\n            elif classification == \"business\":\n                response = await business_expert(query)\n            else:\n                # Parallel execution for general queries\n                responses = await asyncio.gather(\n                    technical_expert(query),\n                    business_expert(query)\n                )\n                response = \" | \".join(responses)\n\n            workflow_context[\"steps\"].append({\"step\": \"response\", \"attempt\": attempt + 1})\n            break\n\n        except Exception as e:\n            if attempt == max_retries - 1:\n                workflow_context[\"steps\"].append({\"step\": \"error\", \"error\": str(e)})\n                raise\n            await asyncio.sleep(1)\n\n    # Step 3: Summarization\n    summary = await summarizer(response)\n    workflow_context[\"steps\"].append({\"step\": \"summary\"})\n\n    # Return comprehensive result\n    return {\n        \"classification\": classification,\n        \"response\": response,\n        \"summary\": summary,\n        \"metadata\": {\n            \"duration\": time.time() - start_time,\n            \"steps_executed\": len(workflow_context[\"steps\"])\n        }\n    }\n\n\n# Execute\nasync def main():\n    context = {}\n    result = await intelligent_workflow(\n        \"Explain machine learning\",\n        workflow_context=context\n    )\n\n    print(f\"Classification: {result['classification']}\")\n    print(f\"Summary: {result['summary']}\")\n    print(f\"Steps executed: {result['metadata']['steps_executed']}\")\n\n\nasyncio.run(main())\n</code></pre>"},{"location":"en/api/workflows/#best-practices-for-advanced-workflows","title":"Best Practices for Advanced Workflows","text":"<ol> <li>Use Context Judiciously: Only share state that's truly needed across steps</li> <li>Handle Errors Gracefully: Implement proper error handling and recovery</li> <li>Monitor Performance: Track execution time and identify bottlenecks</li> <li>Keep It Modular: Break complex workflows into reusable sub-workflows</li> <li>Document Branching Logic: Make conditional logic clear and well-documented</li> </ol>"},{"location":"en/api/workflows/#see-also","title":"See Also","text":"<ul> <li>Workflows Tutorial</li> <li>Agent Decorator</li> <li>Tool Decorator</li> <li>MCP Integration</li> <li>RFC-001: Advanced Workflow System</li> </ul>"},{"location":"en/configuration/environment-variables/","title":"Environment Variables","text":"<p>Kagura AI uses environment variables for configuration, including API keys, default settings, and feature toggles. This guide documents all available environment variables and how to use them.</p>"},{"location":"en/configuration/environment-variables/#quick-start","title":"Quick Start","text":"<ol> <li> <p>Copy the example file:    <pre><code>cp .env.example .env\n</code></pre></p> </li> <li> <p>Add your API keys:    <pre><code># At least one LLM provider is required\nOPENAI_API_KEY=sk-...\n</code></pre></p> </li> <li> <p>Load environment variables (optional):    <pre><code># Kagura automatically loads .env files\n# Or use python-dotenv:\npython -m dotenv run kagura chat\n</code></pre></p> </li> </ol>"},{"location":"en/configuration/environment-variables/#required-variables","title":"Required Variables","text":"<p>At least one LLM provider API key is required for Kagura to work:</p> Variable Provider Get API Key Models <code>OPENAI_API_KEY</code> OpenAI platform.openai.com gpt-4o, gpt-5-mini, gpt-4-turbo, gpt-3.5-turbo <code>ANTHROPIC_API_KEY</code> Anthropic console.anthropic.com claude-3-5-sonnet, claude-3-opus, claude-3-haiku <code>GOOGLE_API_KEY</code> Google AI aistudio.google.com gemini-1.5-pro, gemini-1.5-flash, gemini-pro"},{"location":"en/configuration/environment-variables/#example","title":"Example","text":"<pre><code># Option 1: OpenAI (most common)\nOPENAI_API_KEY=sk-proj-...\n\n# Option 2: Anthropic\nANTHROPIC_API_KEY=sk-ant-...\n\n# Option 3: Google AI (for multimodal features)\nGOOGLE_API_KEY=AIza...\n\n# Or use multiple providers\nOPENAI_API_KEY=sk-proj-...\nANTHROPIC_API_KEY=sk-ant-...\n</code></pre>"},{"location":"en/configuration/environment-variables/#optional-variables","title":"Optional Variables","text":""},{"location":"en/configuration/environment-variables/#web-search","title":"Web Search","text":"Variable Service Get API Key Purpose <code>BRAVE_SEARCH_API_KEY</code> Brave Search brave.com/search/api Web search capabilities <p>Example: <pre><code>BRAVE_SEARCH_API_KEY=BSA...\n</code></pre></p> <p>Note: This API key is required for web search functionality.</p>"},{"location":"en/configuration/environment-variables/#default-settings","title":"Default Settings","text":"Variable Default Description <code>DEFAULT_MODEL</code> <code>gpt-5-mini</code> Default LLM model to use <code>DEFAULT_TEMPERATURE</code> <code>0.7</code> Default temperature (0.0-2.0) <p>Example: <pre><code># Use GPT-4o by default\nDEFAULT_MODEL=gpt-4o\n\n# Make responses more creative\nDEFAULT_TEMPERATURE=1.0\n</code></pre></p>"},{"location":"en/configuration/environment-variables/#programmatic-access","title":"Programmatic Access","text":"<p>Kagura provides a centralized API for accessing environment variables:</p> <pre><code>from kagura.config.env import (\n    get_openai_api_key,\n    get_anthropic_api_key,\n    get_google_api_key,\n    get_brave_search_api_key,\n    get_default_model,\n    get_default_temperature,\n)\n\n# Get API keys (returns None if not set)\nopenai_key = get_openai_api_key()\nbrave_key = get_brave_search_api_key()\n\n# Get defaults (returns default value if not set)\nmodel = get_default_model()  # \"gpt-5-mini\"\ntemperature = get_default_temperature()  # 0.7\n</code></pre>"},{"location":"en/configuration/environment-variables/#utility-functions","title":"Utility Functions","text":"<pre><code>from kagura.config.env import list_env_vars, check_required_env_vars\n\n# List all environment variables (API keys are masked)\nenv_vars = list_env_vars()\nprint(env_vars)\n# {\n#   'OPENAI_API_KEY': '***',\n#   'ANTHROPIC_API_KEY': None,\n#   'GOOGLE_API_KEY': '***',\n#   'BRAVE_SEARCH_API_KEY': '***',\n#   'DEFAULT_MODEL': 'gpt-5-mini',\n#   'DEFAULT_TEMPERATURE': '0.7'\n# }\n\n# Check for missing required variables\nmissing = check_required_env_vars()\nif missing:\n    print(f\"Missing: {', '.join(missing)}\")\n</code></pre>"},{"location":"en/configuration/environment-variables/#backward-compatibility","title":"Backward Compatibility","text":"<p>Kagura AI v3.0 uses <code>BRAVE_SEARCH_API_KEY</code> for web search (previously <code>BRAVE_API_KEY</code> in older versions).</p>"},{"location":"en/configuration/environment-variables/#additional-providers","title":"Additional Providers","text":"<p>Kagura uses LiteLLM which supports 100+ LLM providers. You can add keys for any supported provider:</p>"},{"location":"en/configuration/environment-variables/#azure-openai","title":"Azure OpenAI","text":"<pre><code>AZURE_API_KEY=...\nAZURE_API_BASE=https://your-resource.openai.azure.com/\nAZURE_API_VERSION=2024-02-15-preview\n</code></pre>"},{"location":"en/configuration/environment-variables/#aws-bedrock","title":"AWS Bedrock","text":"<pre><code>AWS_ACCESS_KEY_ID=...\nAWS_SECRET_ACCESS_KEY=...\nAWS_REGION_NAME=us-east-1\n</code></pre>"},{"location":"en/configuration/environment-variables/#other-providers","title":"Other Providers","text":"<ul> <li>Cohere: <code>COHERE_API_KEY</code></li> <li>Hugging Face: <code>HUGGINGFACE_API_KEY</code></li> <li>Together AI: <code>TOGETHERAI_API_KEY</code></li> <li>Replicate: <code>REPLICATE_API_KEY</code></li> </ul> <p>See LiteLLM Providers for full list.</p>"},{"location":"en/configuration/environment-variables/#security-best-practices","title":"Security Best Practices","text":""},{"location":"en/configuration/environment-variables/#1-never-commit-api-keys","title":"1. Never Commit API Keys","text":"<pre><code># \u2705 Good: Use .env (already in .gitignore)\necho \"OPENAI_API_KEY=sk-...\" &gt; .env\n\n# \u274c Bad: Never commit keys to Git\ngit add .env  # Don't do this!\n</code></pre>"},{"location":"en/configuration/environment-variables/#2-use-environment-specific-files","title":"2. Use Environment-Specific Files","text":"<pre><code>.env              # Local development (gitignored)\n.env.production   # Production (never committed)\n.env.example      # Template (safe to commit)\n</code></pre>"},{"location":"en/configuration/environment-variables/#3-rotate-keys-regularly","title":"3. Rotate Keys Regularly","text":"<ul> <li>Rotate API keys every 90 days</li> <li>Use separate keys for development/production</li> <li>Revoke keys immediately if compromised</li> </ul>"},{"location":"en/configuration/environment-variables/#4-limit-key-permissions","title":"4. Limit Key Permissions","text":"<ul> <li>Use read-only keys when possible</li> <li>Set spending limits on API keys</li> <li>Use service-specific keys (not admin keys)</li> </ul>"},{"location":"en/configuration/environment-variables/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/configuration/environment-variables/#no-api-key-found","title":"\"No API key found\"","text":"<p>Error: <pre><code>ValueError: Google API key not found.\nSet GOOGLE_API_KEY environment variable or pass api_key parameter.\n</code></pre></p> <p>Solution: <pre><code># Check if variable is set\necho $GOOGLE_API_KEY\n\n# Set the variable\nexport GOOGLE_API_KEY=AIza...\n\n# Or add to .env\necho \"GOOGLE_API_KEY=AIza...\" &gt;&gt; .env\n</code></pre></p>"},{"location":"en/configuration/environment-variables/#invalid-temperature","title":"\"Invalid temperature\"","text":"<p>Error: <pre><code>UserWarning: Invalid DEFAULT_TEMPERATURE value: abc. Using default: 0.7\n</code></pre></p> <p>Solution: <pre><code># Temperature must be a number between 0.0 and 2.0\nDEFAULT_TEMPERATURE=0.7  # \u2705 Valid\nDEFAULT_TEMPERATURE=abc  # \u274c Invalid\n</code></pre></p>"},{"location":"en/configuration/environment-variables/#environment-not-loading","title":"Environment not loading","text":"<p>Problem: Changes to <code>.env</code> not taking effect</p> <p>Solutions: <pre><code># 1. Restart your shell/terminal\n\n# 2. Explicitly load .env\npython -m dotenv run kagura chat\n\n# 3. Check .env file location\npwd  # Should be in project root\n\n# 4. Verify .env syntax\ncat .env  # Check for typos, missing =, etc.\n</code></pre></p>"},{"location":"en/configuration/environment-variables/#related-documentation","title":"Related Documentation","text":"<ul> <li>Quick Start Guide</li> <li>Agent Configuration</li> <li>LiteLLM Providers</li> <li>API Reference</li> </ul>"},{"location":"en/configuration/environment-variables/#reference-all-variables","title":"Reference: All Variables","text":""},{"location":"en/configuration/environment-variables/#llm-providers-required","title":"LLM Providers (Required)","text":"<ul> <li><code>OPENAI_API_KEY</code> - OpenAI API key</li> <li><code>ANTHROPIC_API_KEY</code> - Anthropic API key</li> <li><code>GOOGLE_API_KEY</code> - Google AI API key</li> </ul>"},{"location":"en/configuration/environment-variables/#features-optional","title":"Features (Optional)","text":"<ul> <li><code>BRAVE_SEARCH_API_KEY</code> - Brave Search API key</li> </ul>"},{"location":"en/configuration/environment-variables/#defaults-optional","title":"Defaults (Optional)","text":"<ul> <li><code>DEFAULT_MODEL</code> - Default LLM model (default: <code>gpt-5-mini</code>)</li> <li><code>DEFAULT_TEMPERATURE</code> - Default temperature (default: <code>0.7</code>)</li> </ul> <p>Last updated: 2025-10-19 Version: v3.0</p>"},{"location":"en/guides/claude-code-mcp-setup/","title":"Claude Code MCP Setup","text":"<p>Use all Kagura features from Claude Code with a single configuration.</p>"},{"location":"en/guides/claude-code-mcp-setup/#quick-setup","title":"Quick Setup","text":""},{"location":"en/guides/claude-code-mcp-setup/#1-find-your-mcp-configuration-file","title":"1. Find your MCP configuration file","text":"<p>Location (varies by installation): - <code>~/.config/claude-code/mcp.json</code> (Linux/macOS) - <code>~/Library/Application Support/Claude/mcp.json</code> (macOS alternative) - Check Claude Code documentation for exact path</p>"},{"location":"en/guides/claude-code-mcp-setup/#2-add-kagura-to-mcp-config","title":"2. Add Kagura to MCP config","text":"<p>Edit your MCP config file:</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura-ai\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"]\n    }\n  }\n}\n</code></pre>"},{"location":"en/guides/claude-code-mcp-setup/#3-restart-claude-code","title":"3. Restart Claude Code","text":"<p>Restart Claude Code to load the new MCP server.</p>"},{"location":"en/guides/claude-code-mcp-setup/#4-verify","title":"4. Verify","text":"<p>In Claude Code, you should now have access to all Kagura tools:</p> <pre><code>User: List available Kagura tools\nClaude: [Lists all 15+ built-in tools]\n</code></pre>"},{"location":"en/guides/claude-code-mcp-setup/#available-tools","title":"Available Tools","text":""},{"location":"en/guides/claude-code-mcp-setup/#memory-operations","title":"Memory Operations","text":"<ul> <li><code>kagura_tool_memory_store</code> - Store information</li> <li><code>kagura_tool_memory_recall</code> - Recall stored information</li> <li><code>kagura_tool_memory_search</code> - Semantic search in memory</li> <li><code>kagura_tool_memory_list</code> - List all stored memories (debugging)</li> </ul>"},{"location":"en/guides/claude-code-mcp-setup/#web-operations","title":"Web Operations","text":"<ul> <li><code>kagura_tool_web_search</code> - Search the web</li> <li><code>kagura_tool_web_scrape</code> - Scrape web pages</li> </ul>"},{"location":"en/guides/claude-code-mcp-setup/#filedirectory-operations","title":"File/Directory Operations","text":"<ul> <li><code>kagura_tool_file_read</code> - Read file contents</li> <li><code>kagura_tool_file_write</code> - Write to files</li> <li><code>kagura_tool_dir_list</code> - List directory contents</li> <li><code>kagura_tool_shell_exec</code> - Execute shell commands safely</li> </ul>"},{"location":"en/guides/claude-code-mcp-setup/#observability","title":"Observability","text":"<ul> <li><code>kagura_tool_telemetry_stats</code> - Get execution statistics</li> <li><code>kagura_tool_telemetry_cost</code> - Analyze costs</li> </ul>"},{"location":"en/guides/claude-code-mcp-setup/#meta-agent","title":"Meta Agent","text":"<ul> <li><code>kagura_tool_meta_create_agent</code> - Generate new agents</li> </ul>"},{"location":"en/guides/claude-code-mcp-setup/#multimodal-requires-web-extra","title":"Multimodal (requires <code>web</code> extra)","text":"<ul> <li><code>kagura_tool_multimodal_index</code> - Index multimedia files</li> <li><code>kagura_tool_multimodal_search</code> - Search indexed content</li> </ul>"},{"location":"en/guides/claude-code-mcp-setup/#usage-examples","title":"Usage Examples","text":""},{"location":"en/guides/claude-code-mcp-setup/#example-1-memory","title":"Example 1: Memory","text":"<pre><code>User: Remember that my favorite programming language is Python\nClaude: [Uses kagura_tool_memory_store]\n       \u2713 Stored information\n\nUser: What's my favorite language?\nClaude: [Uses kagura_tool_memory_recall]\n       Your favorite programming language is Python\n</code></pre>"},{"location":"en/guides/claude-code-mcp-setup/#example-2-web-search-file","title":"Example 2: Web Search + File","text":"<pre><code>User: Search for latest Python news and save to news.txt\nClaude: [Uses kagura_tool_web_search]\n       [Uses kagura_tool_file_write]\n       \u2713 Saved to news.txt\n</code></pre>"},{"location":"en/guides/claude-code-mcp-setup/#example-3-code-generation","title":"Example 3: Code Generation","text":"<pre><code>User: Create a translator agent\nClaude: [Uses kagura_tool_meta_create_agent]\n       Generated agent code...\n</code></pre>"},{"location":"en/guides/claude-code-mcp-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/claude-code-mcp-setup/#tools-not-appearing","title":"Tools not appearing","text":"<ol> <li>Check MCP config syntax is valid JSON</li> <li>Verify <code>kagura</code> command is in PATH</li> <li>Restart Claude Code completely</li> <li>Check Claude Code logs for errors</li> </ol>"},{"location":"en/guides/claude-code-mcp-setup/#requires-x-extra-errors","title":"\"requires X extra\" errors","text":"<p>Install required extras:</p> <pre><code># All features\npip install kagura-ai[full]\n\n# Specific features\npip install kagura-ai[ai]     # Memory, Routing\npip install kagura-ai[web]    # Web, Multimodal\n</code></pre>"},{"location":"en/guides/claude-code-mcp-setup/#permission-errors","title":"Permission errors","text":"<p>Ensure <code>kagura</code> command is executable:</p> <pre><code>which kagura\nchmod +x $(which kagura)\n</code></pre>"},{"location":"en/guides/claude-code-mcp-setup/#advanced","title":"Advanced","text":""},{"location":"en/guides/claude-code-mcp-setup/#custom-tools","title":"Custom Tools","text":"<p>You can also expose your own @tool definitions:</p> <pre><code># my_tools.py\nfrom kagura import tool\n\n@tool\ndef custom_calculator(x: float, y: float) -&gt; float:\n    '''Add two numbers'''\n    return x + y\n</code></pre> <p>Just import before starting MCP:</p> <pre><code>python -c \"import my_tools; import kagura.mcp.builtin\" &amp;&amp; kagura mcp serve\n</code></pre> <p>Or create a wrapper script.</p>"},{"location":"en/guides/cli-performance/","title":"CLI Performance","text":"<p>Kagura CLI uses lazy loading to ensure fast startup times.</p>"},{"location":"en/guides/cli-performance/#startup-performance","title":"Startup Performance","text":"<p>Before optimization: <code>kagura --help</code> took 8.8 seconds</p> <p>After optimization: <code>kagura --help</code> takes 0.1 seconds (98.9% faster!)</p>"},{"location":"en/guides/cli-performance/#how-it-works","title":"How It Works","text":""},{"location":"en/guides/cli-performance/#lazy-loading","title":"Lazy Loading","text":"<p>Subcommands are imported only when invoked:</p> <pre><code># Before (slow)\nfrom .mcp import mcp          # Always imported - 393ms!\nfrom .monitor import monitor  # Always imported\n\n# After (fast)\n@click.group(cls=LazyGroup, lazy_subcommands={\n    \"mcp\": (\"kagura.cli.mcp\", \"mcp\", \"MCP commands\"),     # Import on demand\n    \"monitor\": (\"kagura.cli.monitor\", \"monitor\", \"Monitor telemetry\"),\n})\n</code></pre> <p>Benefits: - <code>kagura --help</code>: No heavy modules loaded - <code>kagura chat</code>: Only chat module loaded - <code>kagura mcp start</code>: Only MCP module loaded</p>"},{"location":"en/guides/cli-performance/#module-level-lazy-imports","title":"Module-level Lazy Imports","text":"<p>The main <code>kagura</code> package also uses lazy imports via <code>__getattr__</code>:</p> <pre><code># kagura/__init__.py\n\ndef __getattr__(name: str):\n    \"\"\"Lazy import attributes on demand\"\"\"\n    if name == \"agent\":\n        from .core.decorators import agent\n        return agent\n    # ...\n</code></pre> <p>Benefits: - CLI startup doesn't load decorators, memory, etc. - User code loads only what it needs</p>"},{"location":"en/guides/cli-performance/#performance-metrics","title":"Performance Metrics","text":"Command Before After Improvement <code>kagura --help</code> 8.8s 0.1s 98.9% faster <code>kagura version</code> 8.8s 0.1s 98.9% faster <code>kagura chat</code> 8.8s 0.5s 94.3% faster <code>kagura mcp start</code> 8.8s 1.0s 88.6% faster"},{"location":"en/guides/cli-performance/#adding-new-commands","title":"Adding New Commands","text":"<p>When adding a new CLI command, use lazy loading to maintain performance:</p> <pre><code># src/kagura/cli/main.py\n\n@click.group(cls=LazyGroup, lazy_subcommands={\n    # Add your command here\n    \"mycommand\": (\"kagura.cli.mycommand\", \"mycommand\", \"My command description\"),\n})\ndef cli():\n    pass\n</code></pre> <p>Guidelines: 1. Always add new commands to <code>lazy_subcommands</code> 2. Provide a short description (third tuple element) 3. Avoid top-level imports in <code>main.py</code></p>"},{"location":"en/guides/cli-performance/#benchmarking","title":"Benchmarking","text":""},{"location":"en/guides/cli-performance/#measure-startup-time","title":"Measure Startup Time","text":"<pre><code># Overall time\ntime kagura --help\n\n# Import time only\npython -c \"\nimport time\nstart = time.time()\nfrom kagura.cli.main import cli\nprint(f'Import: {(time.time()-start)*1000:.0f}ms')\n\"\n</code></pre>"},{"location":"en/guides/cli-performance/#profile-imports","title":"Profile Imports","text":"<pre><code># Detailed import profiling\npython -X importtime -c \"from kagura.cli.main import cli\" 2&gt;&amp;1 | tail -50\n</code></pre>"},{"location":"en/guides/cli-performance/#expected-results","title":"Expected Results","text":"<ul> <li>CLI import: &lt; 50ms</li> <li><code>kagura --help</code>: &lt; 200ms</li> <li>No heavy modules (mcp, observability) loaded on <code>--help</code></li> </ul>"},{"location":"en/guides/cli-performance/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/cli-performance/#q-my-command-is-slow-to-start","title":"Q: My command is slow to start","text":"<p>A: Check if you're importing heavy modules at the top level:</p> <pre><code># Bad - imports immediately\nfrom heavy_module import something\n\n@click.command()\ndef mycommand():\n    pass\n\n# Good - imports on execution\n@click.command()\ndef mycommand():\n    from heavy_module import something  # Import here\n    pass\n</code></pre>"},{"location":"en/guides/cli-performance/#q-how-do-i-know-if-a-module-is-heavy","title":"Q: How do I know if a module is heavy?","text":"<p>A: Use <code>python -X importtime</code>:</p> <pre><code>python -X importtime -c \"import my_module\" 2&gt;&amp;1 | tail -20\n</code></pre> <p>Look for cumulative times &gt; 100ms.</p>"},{"location":"en/guides/cli-performance/#q-can-i-disable-lazy-loading","title":"Q: Can I disable lazy loading?","text":"<p>A: Not recommended, but you can import modules explicitly in <code>main.py</code>:</p> <pre><code># Not recommended - slow startup\nfrom .mcp import mcp\nfrom .monitor import monitor\n# ...\n\ncli.add_command(mcp)\ncli.add_command(monitor)\n</code></pre>"},{"location":"en/guides/cli-performance/#best-practices","title":"Best Practices","text":"<ol> <li>Always use lazy loading for CLI commands</li> <li>Import heavy modules inside functions, not at module level</li> <li>Test startup time in CI (see <code>tests/cli/test_lazy_loading.py</code>)</li> <li>Profile regularly to catch regressions</li> </ol>"},{"location":"en/guides/cli-performance/#future-improvements","title":"Future Improvements","text":"<ul> <li>Pre-compiled bytecode (<code>.pyc</code>) optimization</li> <li>Startup profiling in CI</li> <li>Dynamic help text loading</li> </ul>"},{"location":"en/guides/context-compression/","title":"Context Compression Guide","text":"<p>RFC-024 Phase 1: Token Management</p> <p>Since: v2.5.0</p>"},{"location":"en/guides/context-compression/#overview","title":"Overview","text":"<p>Context compression enables efficient long-form conversations by managing token usage and preventing context window overflow.</p> <p>Phase 1 (current) provides: - \u2705 Accurate token counting for all major LLM models - \u2705 Real-time context usage monitoring - \u2705 Compression recommendations</p> <p>Future phases will add: - \ud83d\udccb Phase 2: Message trimming (Week 2) - \ud83d\udccb Phase 3: LLM-based summarization (Week 3-4) - \ud83d\udccb Phase 4: Automatic compression (Week 5)</p>"},{"location":"en/guides/context-compression/#installation","title":"Installation","text":"<pre><code># Install with AI features (includes context compression)\npip install kagura-ai[ai]\n\n# Or install all features\npip install kagura-ai[all]\n</code></pre> <p>Dependencies: - <code>tiktoken&gt;=0.7.0</code> - OpenAI's token counting library</p>"},{"location":"en/guides/context-compression/#quick-start","title":"Quick Start","text":""},{"location":"en/guides/context-compression/#basic-token-counting","title":"Basic Token Counting","text":"<pre><code>from kagura.core.compression import TokenCounter\n\n# Create counter\ncounter = TokenCounter(model=\"gpt-4o-mini\")\n\n# Count tokens in text\ntext = \"Hello, world!\"\ntokens = counter.count_tokens(text)\nprint(f\"Tokens: {tokens}\")  # Tokens: 4\n\n# Count tokens in messages\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Hello!\"},\n    {\"role\": \"assistant\", \"content\": \"Hi there!\"}\n]\n\ntotal_tokens = counter.count_tokens_messages(messages)\nprint(f\"Total tokens: {total_tokens}\")  # Includes message overhead\n</code></pre>"},{"location":"en/guides/context-compression/#context-usage-monitoring","title":"Context Usage Monitoring","text":"<pre><code>from kagura.core.compression import TokenCounter, ContextMonitor\n\n# Create counter and monitor\ncounter = TokenCounter(model=\"gpt-4o-mini\")\nmonitor = ContextMonitor(counter, max_tokens=10000)\n\n# Check usage\nmessages = [...]  # Your conversation history\nusage = monitor.check_usage(messages, system_prompt=\"Be helpful.\")\n\n# Display usage\nprint(f\"Usage: {usage.usage_ratio:.1%}\")  # e.g., 45.3%\nprint(f\"Tokens: {usage.total_tokens:,} / {usage.max_tokens:,}\")\n\nif usage.should_compress:\n    print(\"\u26a0\ufe0f Context is getting full!\")\n    print(\"Consider compressing (Phase 2+)\")\n</code></pre>"},{"location":"en/guides/context-compression/#advanced-usage","title":"Advanced Usage","text":""},{"location":"en/guides/context-compression/#auto-detect-model-limits","title":"Auto-Detect Model Limits","text":"<pre><code># Automatically detect max tokens from model\ncounter = TokenCounter(model=\"claude-3-5-sonnet\")\nmonitor = ContextMonitor(counter, max_tokens=None)\n\nprint(f\"Max tokens: {monitor.max_tokens:,}\")\n# For Claude 3.5 Sonnet: 196,000 (200k - 4k reserved)\n</code></pre>"},{"location":"en/guides/context-compression/#custom-compression-threshold","title":"Custom Compression Threshold","text":"<pre><code># Trigger compression at 70% instead of default 80%\nshould_compress = counter.should_compress(\n    current_tokens=usage.total_tokens,\n    max_tokens=usage.max_tokens,\n    threshold=0.7  # 70%\n)\n\nif should_compress:\n    print(\"Time to compress!\")\n</code></pre>"},{"location":"en/guides/context-compression/#estimate-context-size","title":"Estimate Context Size","text":"<pre><code># Estimate how much context a conversation will use\nestimate = counter.estimate_context_size(\n    messages=messages,\n    system_prompt=\"You are helpful.\",\n    max_tokens=1000  # Reserve for completion\n)\n\nprint(f\"Prompt: {estimate['prompt_tokens']:,} tokens\")\nprint(f\"Completion: {estimate['completion_tokens']:,} tokens\")\nprint(f\"Total: {estimate['total_tokens']:,} tokens\")\n</code></pre>"},{"location":"en/guides/context-compression/#model-support","title":"Model Support","text":""},{"location":"en/guides/context-compression/#supported-models","title":"Supported Models","text":"<p>All major LLM providers are supported:</p> <pre><code># OpenAI\ncounter_openai = TokenCounter(model=\"gpt-4o-mini\")\n\n# Anthropic Claude\ncounter_claude = TokenCounter(model=\"claude-3-5-sonnet\")\n\n# Google Gemini\ncounter_gemini = TokenCounter(model=\"gemini-1.5-pro\")\n</code></pre>"},{"location":"en/guides/context-compression/#model-limits","title":"Model Limits","text":"<p>Get token limits for any model:</p> <pre><code>limits = counter.get_model_limits(\"gpt-4o-mini\")\nprint(f\"Context window: {limits['context_window']:,}\")  # 128,000\nprint(f\"Max completion: {limits['max_completion']:,}\")  # 16,384\n</code></pre> <p>Available Limits:</p> Model Context Window Max Completion gpt-4o-mini 128,000 16,384 gpt-4o 128,000 16,384 claude-3-5-sonnet 200,000 8,192 gemini-1.5-pro 2,000,000 8,192 <p>For unknown models, defaults to 8,000 / 2,000.</p>"},{"location":"en/guides/context-compression/#best-practices","title":"Best Practices","text":""},{"location":"en/guides/context-compression/#1-monitor-usage-regularly","title":"1. Monitor Usage Regularly","text":"<pre><code># Check usage after each turn\nusage = monitor.check_usage(messages)\n\nif usage.usage_ratio &gt; 0.7:\n    print(f\"\u26a0\ufe0f Warning: {usage.usage_ratio:.0%} full\")\n\nif usage.should_compress:\n    print(\"\ud83d\udea8 Compression recommended\")\n    # In Phase 2+: await compress(messages)\n</code></pre>"},{"location":"en/guides/context-compression/#2-reserve-space-for-completion","title":"2. Reserve Space for Completion","text":"<p>When creating a monitor, ensure you reserve enough tokens for model responses:</p> <pre><code># Good: Auto-detect reserves 4000 tokens\nmonitor = ContextMonitor(counter, max_tokens=None)\n\n# Custom: Reserve explicit amount\nmodel_limit = 128_000\nreserved_for_completion = 8_000\nmonitor = ContextMonitor(counter, max_tokens=model_limit - reserved_for_completion)\n</code></pre>"},{"location":"en/guides/context-compression/#3-choose-appropriate-model","title":"3. Choose Appropriate Model","text":"<p>For long conversations, prefer models with larger context windows:</p> <pre><code># Small context (16k) - frequent compression needed\ncounter_small = TokenCounter(model=\"gpt-3.5-turbo\")\n\n# Large context (128k) - less compression needed\ncounter_large = TokenCounter(model=\"gpt-4o-mini\")\n\n# Huge context (2M) - minimal compression needed\ncounter_huge = TokenCounter(model=\"gemini-1.5-pro\")\n</code></pre>"},{"location":"en/guides/context-compression/#examples","title":"Examples","text":""},{"location":"en/guides/context-compression/#example-1-track-conversation-growth","title":"Example 1: Track Conversation Growth","text":"<pre><code>from kagura.core.compression import TokenCounter, ContextMonitor\n\ncounter = TokenCounter(model=\"gpt-4o-mini\")\nmonitor = ContextMonitor(counter, max_tokens=50000)\n\nmessages = [{\"role\": \"system\", \"content\": \"You are helpful.\"}]\n\nfor turn in range(100):\n    # Add user message\n    messages.append({\"role\": \"user\", \"content\": f\"Question {turn}\"})\n\n    # Check usage before responding\n    usage = monitor.check_usage(messages)\n    print(f\"Turn {turn}: {usage.usage_ratio:.1%} full\")\n\n    if usage.should_compress:\n        print(f\"\u26a0\ufe0f Compression needed at turn {turn}\")\n        break\n\n    # Add assistant response\n    messages.append({\"role\": \"assistant\", \"content\": f\"Answer {turn}\"})\n</code></pre>"},{"location":"en/guides/context-compression/#example-2-multi-model-comparison","title":"Example 2: Multi-Model Comparison","text":"<pre><code>models = [\"gpt-4o-mini\", \"claude-3-5-sonnet\", \"gemini-1.5-pro\"]\n\ntext = \"The quick brown fox jumps over the lazy dog.\"\n\nfor model in models:\n    counter = TokenCounter(model=model)\n    tokens = counter.count_tokens(text)\n    limits = counter.get_model_limits(model)\n\n    print(f\"{model}:\")\n    print(f\"  Tokens: {tokens}\")\n    print(f\"  Context window: {limits['context_window']:,}\")\n</code></pre> <p>Output: <pre><code>gpt-4o-mini:\n  Tokens: 10\n  Context window: 128,000\n\nclaude-3-5-sonnet:\n  Tokens: 10\n  Context window: 200,000\n\ngemini-1.5-pro:\n  Tokens: 10\n  Context window: 2,000,000\n</code></pre></p>"},{"location":"en/guides/context-compression/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/context-compression/#q-token-count-seems-inaccurate","title":"Q: Token count seems inaccurate","text":"<p>A: Different models use different tokenizers. TokenCounter uses <code>tiktoken</code> which is optimized for OpenAI models. For Claude and Gemini, it uses <code>cl100k_base</code> as an approximation (\u00b110% accuracy).</p>"},{"location":"en/guides/context-compression/#q-what-if-i-exceed-context-window","title":"Q: What if I exceed context window?","text":"<p>A: Phase 1 only monitors usage. Phases 2-4 will provide automatic compression: - Phase 2: Message trimming - Phase 3: LLM-based summarization - Phase 4: Automatic compression</p>"},{"location":"en/guides/context-compression/#q-how-accurate-is-token-counting","title":"Q: How accurate is token counting?","text":"<p>A: Very accurate for OpenAI models (\u00b11%). For other models: \u00b15-10%.</p>"},{"location":"en/guides/context-compression/#q-can-i-use-this-with-streaming","title":"Q: Can I use this with streaming?","text":"<p>A: Yes! Count tokens before and after streaming to track usage.</p>"},{"location":"en/guides/context-compression/#next-steps","title":"Next Steps","text":"<p>Phase 1 (current) provides monitoring only.</p> <p>Coming soon: - Phase 2 (Week 2): Message trimming with 4 strategies - Phase 3 (Week 3-4): Context summarization - Phase 4 (Week 5): Automatic compression integrated with <code>@agent</code> decorator</p> <p>Stay tuned for updates!</p>"},{"location":"en/guides/context-compression/#see-also","title":"See Also","text":"<ul> <li>Compression API Reference - Detailed API documentation</li> <li>RFC-024 - Full specification</li> <li>Memory Management - Memory system (integrates in Phase 4)</li> </ul> <p>Phase 1 implementation provides the foundation for efficient long-form conversations!</p>"},{"location":"en/guides/meta-agent/","title":"Meta Agent: AI-Powered Agent Code Generator","text":""},{"location":"en/guides/meta-agent/#overview","title":"Overview","text":"<p>The Meta Agent is an AI-powered code generator that creates Kagura agents from natural language descriptions. Simply describe what you want your agent to do, and Meta Agent will generate complete, production-ready Python code.</p>"},{"location":"en/guides/meta-agent/#quick-start","title":"Quick Start","text":""},{"location":"en/guides/meta-agent/#interactive-mode","title":"Interactive Mode","text":"<pre><code>kagura build agent\n</code></pre> <p>You'll be prompted to describe your agent:</p> <pre><code>\ud83e\udd16 Kagura Agent Builder\nDescribe your agent in natural language and I'll generate the code.\n\nWhat should your agent do? Translate English to Japanese\n\n\ud83d\udd0d Parsing agent specification...\n\n\ud83d\udccb Agent Specification\nName: translator\nDescription: Translate English to Japanese\nInput: str\nOutput: str\nTools: None\nMemory: No\n\n\u2699\ufe0f  Generating agent code...\n\ud83d\udd12 Validating code security...\n\u2705 Code validated\n\n\u2705 Agent created: agents/translator.py\n</code></pre>"},{"location":"en/guides/meta-agent/#non-interactive-mode","title":"Non-Interactive Mode","text":"<pre><code>kagura build agent \\\n  --description \"Translate English to Japanese\" \\\n  --output translator.py \\\n  --no-interactive\n</code></pre>"},{"location":"en/guides/meta-agent/#generated-code-example","title":"Generated Code Example","text":"<p>For the description \"Translate English to Japanese\", Meta Agent generates:</p> <pre><code>\"\"\"Translate English to Japanese\n\nAuto-generated by Kagura Meta Agent\nCreated: 2025-10-13 12:00:00\nKagura Version: 2.5.0\n\"\"\"\n\nfrom kagura import agent\n\n\n@agent(\n    model=\"gpt-4o-mini\",\n    temperature=0.7,\n)\nasync def translator(input_data: str) -&gt; str:\n    \"\"\"Translate English to Japanese\n\n    Args:\n        input_data: str - Input data\n\n    Returns:\n        str - Generated result\n    \"\"\"\n    # System prompt for this agent\n    system_prompt = \"\"\"You are a professional translator. Translate text from English to Japanese.\"\"\"\n\n    # Template variable for LLM (will be rendered at runtime)\n    return f\"{system_prompt}\\n\\nInput: {input_data}\"\n</code></pre>"},{"location":"en/guides/meta-agent/#advanced-features","title":"Advanced Features","text":""},{"location":"en/guides/meta-agent/#agent-with-tools","title":"Agent with Tools","text":"<p>If your description mentions code execution, web search, or other tools, Meta Agent will automatically include them:</p> <pre><code>kagura build agent -d \"Execute Python code to solve math problems\" --no-interactive\n</code></pre> <p>Generated code will include:</p> <pre><code>from kagura import agent\nfrom kagura.core.executor import CodeExecutor\n\n@agent(\n    model=\"gpt-4o-mini\",\n    temperature=0.7,\n    tools=[CodeExecutor()],\n)\nasync def math_solver(input_data: str) -&gt; str:\n    \"\"\"Solve math problems using Python\"\"\"\n    # ...\n</code></pre>"},{"location":"en/guides/meta-agent/#agent-with-memory","title":"Agent with Memory","text":"<p>For conversational agents:</p> <pre><code>kagura build agent -d \"Chatbot that remembers conversation history\" --no-interactive\n</code></pre> <p>Generated code will include:</p> <pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n@agent(\n    model=\"gpt-4o-mini\",\n    temperature=0.7,\n    enable_memory=True,\n    max_messages=100,\n)\nasync def chatbot(input_data: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Conversational chatbot with memory\"\"\"\n    memory.add_message(\"user\", str(input_data))\n    # ...\n</code></pre>"},{"location":"en/guides/meta-agent/#cli-options","title":"CLI Options","text":""},{"location":"en/guides/meta-agent/#kagura-build-agent","title":"<code>kagura build agent</code>","text":"<p>Options:</p> <ul> <li><code>-d, --description TEXT</code>: Natural language agent description</li> <li><code>-o, --output PATH</code>: Output file path (default: <code>agents/&lt;name&gt;.py</code>)</li> <li><code>--model TEXT</code>: LLM model for code generation (default: <code>gpt-4o-mini</code>)</li> <li><code>--interactive / --no-interactive</code>: Interactive mode (default: <code>True</code>)</li> <li><code>--no-validate</code>: Skip code validation</li> </ul>"},{"location":"en/guides/meta-agent/#examples","title":"Examples","text":"<pre><code># Interactive mode (default)\nkagura build agent\n\n# Direct generation\nkagura build agent -d \"Summarize text in 3 bullet points\" -o summarizer.py\n\n# Use GPT-4\nkagura build agent -d \"Complex reasoning task\" --model gpt-4o\n\n# Skip validation (not recommended)\nkagura build agent -d \"Test agent\" --no-validate\n</code></pre>"},{"location":"en/guides/meta-agent/#how-it-works","title":"How It Works","text":"<p>Meta Agent uses a multi-stage pipeline:</p> <ol> <li>Natural Language Parsing: Uses LLM to extract structured specification from your description</li> <li>Code Generation: Uses Jinja2 templates to generate clean Python code</li> <li>Security Validation: AST analysis ensures generated code is safe</li> <li>File Creation: Saves the generated agent to a file</li> </ol>"},{"location":"en/guides/meta-agent/#architecture","title":"Architecture","text":"<pre><code>Natural Language \u2192 NLSpecParser \u2192 AgentSpec \u2192 CodeGenerator \u2192 Python Code\n                                                    \u2193\n                                              CodeValidator (Security)\n</code></pre>"},{"location":"en/guides/meta-agent/#security","title":"Security","text":"<p>All generated code is validated for security:</p> <ul> <li>\u2705 Syntax checking</li> <li>\u2705 Forbidden import detection (subprocess, eval, etc.)</li> <li>\u2705 Dangerous function call detection</li> <li>\u2705 Required @agent decorator verification</li> </ul> <p>Dangerous code will be rejected before saving.</p>"},{"location":"en/guides/meta-agent/#best-practices","title":"Best Practices","text":""},{"location":"en/guides/meta-agent/#writing-good-descriptions","title":"Writing Good Descriptions","text":"<p>Good descriptions are specific:</p> <p>\u2705 \"Translate English to Japanese\" \u2705 \"Summarize articles in 3 bullet points\" \u2705 \"Execute Python code to solve math problems\"</p> <p>Avoid vague descriptions:</p> <p>\u274c \"Do something with text\" \u274c \"Help me\" \u274c \"Agent\"</p>"},{"location":"en/guides/meta-agent/#tool-detection","title":"Tool Detection","text":"<p>Meta Agent automatically detects when tools are needed:</p> <ul> <li>Code Execution: \"execute code\", \"run python\", \"calculate\"</li> <li>Web Search: \"search web\", \"google\", \"find online\"</li> <li>Memory: \"remember\", \"conversation history\", \"recall\"</li> <li>File Operations: \"read file\", \"write file\"</li> </ul> <p>Be explicit if you need specific tools.</p>"},{"location":"en/guides/meta-agent/#programmatic-usage","title":"Programmatic Usage","text":"<p>You can also use Meta Agent from Python:</p> <pre><code>from kagura.meta import MetaAgent\n\n# Initialize\nmeta = MetaAgent(model=\"gpt-4o-mini\")\n\n# Generate from description\ncode = await meta.generate(\"Translate English to Japanese\")\nprint(code)\n\n# Generate from spec\nfrom kagura.meta.spec import AgentSpec\n\nspec = AgentSpec(\n    name=\"translator\",\n    description=\"Translate text\",\n    input_type=\"str\",\n    output_type=\"str\",\n    system_prompt=\"You are a professional translator.\"\n)\n\ncode = await meta.generate_from_spec(spec)\n</code></pre>"},{"location":"en/guides/meta-agent/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/meta-agent/#validation-failed-missing-agent-decorator","title":"\"Validation failed: Missing @agent decorator\"","text":"<p>The generated code doesn't include the <code>@agent</code> decorator. This is a bug - please report it.</p>"},{"location":"en/guides/meta-agent/#validation-failed-disallowed-import-subprocess","title":"\"Validation failed: Disallowed import: subprocess\"","text":"<p>The LLM generated code with dangerous imports. Try a more specific description or use <code>--no-validate</code> (not recommended).</p>"},{"location":"en/guides/meta-agent/#generated-code-doesnt-work","title":"Generated code doesn't work","text":"<p>The generated code is a starting point. You may need to:</p> <ol> <li>Adjust the system prompt</li> <li>Add more specific logic</li> <li>Test and iterate</li> </ol>"},{"location":"en/guides/meta-agent/#examples_1","title":"Examples","text":"<p>See <code>examples/meta_agent/</code> for complete examples:</p> <ul> <li><code>translator.py</code>: Simple translation agent</li> <li><code>code_solver.py</code>: Agent with code execution</li> <li><code>chatbot.py</code>: Agent with memory</li> </ul>"},{"location":"en/guides/meta-agent/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Agent Builder for more complex configurations</li> <li>Explore Testing Framework for testing generated agents</li> <li>Read the Meta Agent API Reference</li> </ul>"},{"location":"en/guides/oauth2-authentication/","title":"OAuth2 Authentication Guide","text":"<p>Learn how to use OAuth2 authentication with Kagura AI to access Google models (like Gemini) without managing API keys.</p> <p>\ud83d\udccc Important Note</p> <p>For most users, using API Keys is recommended as it's simpler and faster to set up: - Gemini: Get API key from Google AI Studio \u2192 Set <code>GOOGLE_API_KEY</code> - Claude: Get API key from Anthropic Console \u2192 Set <code>ANTHROPIC_API_KEY</code> - OpenAI: Get API key from OpenAI Platform \u2192 Set <code>OPENAI_API_KEY</code></p> <p>OAuth2 is an advanced feature for specific use cases like: - Multi-user applications where each user authenticates with their own Google account - Production environments requiring strict access controls - Applications that need per-user quota management</p> <p>Currently, only Google/Gemini supports OAuth2. Claude and OpenAI use API keys only.</p>"},{"location":"en/guides/oauth2-authentication/#overview","title":"Overview","text":"<p>Kagura AI supports OAuth2 authentication for Google services only, allowing you to:</p> <ul> <li>No API Key Management: Use Google models without storing API keys</li> <li>Secure Authentication: OAuth2 tokens are encrypted locally (Fernet/AES-128)</li> <li>Automatic Token Refresh: Tokens are automatically refreshed when expired</li> <li>Simple CLI Commands: Easy login/logout/status management</li> </ul>"},{"location":"en/guides/oauth2-authentication/#prerequisites","title":"Prerequisites","text":"<ol> <li>Google Cloud Project with Generative Language API enabled</li> <li>OAuth 2.0 Client ID (Desktop application type)</li> <li>Kagura AI with OAuth support installed:</li> </ol> <pre><code>pip install kagura-ai[auth]\n</code></pre>"},{"location":"en/guides/oauth2-authentication/#setup-guide","title":"Setup Guide","text":""},{"location":"en/guides/oauth2-authentication/#step-1-create-oauth-20-client-id","title":"Step 1: Create OAuth 2.0 Client ID","text":"<ol> <li>Go to Google Cloud Console - Credentials</li> <li>Click \"Create Credentials\" \u2192 \"OAuth client ID\"</li> <li>Select \"Desktop app\" as the application type</li> <li>Name it (e.g., \"Kagura AI Desktop\")</li> <li>Click \"Create\"</li> <li>Download the JSON file</li> </ol>"},{"location":"en/guides/oauth2-authentication/#step-2-save-client-secrets","title":"Step 2: Save Client Secrets","text":"<p>Save the downloaded JSON file as <code>~/.kagura/client_secrets.json</code>:</p> <pre><code>mkdir -p ~/.kagura\nmv ~/Downloads/client_secret_*.json ~/.kagura/client_secrets.json\nchmod 600 ~/.kagura/client_secrets.json\n</code></pre> <p>Important: Keep this file secure! It contains your OAuth client credentials.</p>"},{"location":"en/guides/oauth2-authentication/#step-3-login","title":"Step 3: Login","text":"<p>Run the <code>kagura auth login</code> command:</p> <pre><code>kagura auth login --provider google\n</code></pre> <p>This will: 1. Open your browser for Google OAuth2 authentication 2. Ask you to authorize Kagura AI to access Google Generative Language API 3. Save encrypted credentials to <code>~/.kagura/credentials.json.enc</code></p> <p>Output: <pre><code>\u2713 Authentication successful!\n\u2713 Credentials saved to: /home/user/.kagura/credentials.json.enc\n</code></pre></p>"},{"location":"en/guides/oauth2-authentication/#step-4-verify-authentication","title":"Step 4: Verify Authentication","text":"<p>Check your authentication status:</p> <pre><code>kagura auth status --provider google\n</code></pre> <p>Output: <pre><code>\u2713 Authenticated with google\nToken expires: 2025-10-13 15:30:00 UTC\n</code></pre></p>"},{"location":"en/guides/oauth2-authentication/#using-oauth2-in-your-code","title":"Using OAuth2 in Your Code","text":""},{"location":"en/guides/oauth2-authentication/#basic-usage-with-llmconfig","title":"Basic Usage with LLMConfig","text":"<pre><code>from kagura.core.llm import LLMConfig, call_llm\n\n# Configure OAuth2 authentication\nconfig = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\"\n)\n\n# Call LLM (OAuth2 token retrieved automatically)\nresponse = await call_llm(\"What is the capital of France?\", config)\nprint(response)  # \"The capital of France is Paris.\"\n</code></pre>"},{"location":"en/guides/oauth2-authentication/#using-with-agent-decorator","title":"Using with @agent Decorator","text":"<pre><code>from kagura import agent\nfrom kagura.core.llm import LLMConfig\n\n# Create OAuth2 config\ngemini_config = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\",\n    temperature=0.7\n)\n\n@agent(\n    name=\"translator\",\n    template=\"Translate '{{ text }}' to {{ language }}\",\n    llm_config=gemini_config\n)\ndef translate(text: str, language: str) -&gt; str:\n    pass\n\n# Use the agent\nresult = translate(\"Hello\", \"Japanese\")\nprint(result)  # \"\u3053\u3093\u306b\u3061\u306f\"\n</code></pre>"},{"location":"en/guides/oauth2-authentication/#switching-between-api-key-and-oauth2","title":"Switching Between API Key and OAuth2","text":"<p>You can use both authentication methods in the same project:</p> <pre><code>from kagura.core.llm import LLMConfig\n\n# OpenAI with API key (uses OPENAI_API_KEY env var)\nopenai_config = LLMConfig(\n    model=\"gpt-4o-mini\",\n    auth_type=\"api_key\"  # default\n)\n\n# Gemini with OAuth2\ngemini_config = LLMConfig(\n    model=\"gemini/gemini-1.5-flash\",\n    auth_type=\"oauth2\",\n    oauth_provider=\"google\"\n)\n</code></pre>"},{"location":"en/guides/oauth2-authentication/#cli-commands","title":"CLI Commands","text":""},{"location":"en/guides/oauth2-authentication/#login","title":"Login","text":"<p>Authenticate with Google OAuth2:</p> <pre><code>kagura auth login --provider google\n</code></pre> <p>Options: - <code>--provider</code>: OAuth2 provider (default: <code>google</code>)</p>"},{"location":"en/guides/oauth2-authentication/#logout","title":"Logout","text":"<p>Remove stored credentials:</p> <pre><code>kagura auth logout --provider google\n</code></pre> <p>Output: <pre><code>\u2713 Logged out from google\n</code></pre></p>"},{"location":"en/guides/oauth2-authentication/#status","title":"Status","text":"<p>Check authentication status:</p> <pre><code>kagura auth status --provider google\n</code></pre> <p>Possible outputs:</p> <p>Authenticated: <pre><code>\u2713 Authenticated with google\nToken expires: 2025-10-13 15:30:00 UTC\n</code></pre></p> <p>Not Authenticated: <pre><code>\u2717 Not authenticated with google\nRun: kagura auth login --provider google\n</code></pre></p>"},{"location":"en/guides/oauth2-authentication/#security","title":"Security","text":""},{"location":"en/guides/oauth2-authentication/#credential-storage","title":"Credential Storage","text":"<p>OAuth2 credentials are stored securely:</p> <ul> <li>Location: <code>~/.kagura/credentials.json.enc</code></li> <li>Encryption: Fernet (AES-128 in CBC mode)</li> <li>Key Storage: <code>~/.kagura/.key</code> (with 0600 permissions)</li> <li>File Permissions: Both files have 0600 (owner read/write only)</li> </ul>"},{"location":"en/guides/oauth2-authentication/#token-refresh","title":"Token Refresh","text":"<p>Access tokens are automatically refreshed:</p> <ol> <li>Automatic: Tokens are checked before each API call</li> <li>Transparent: Refresh happens automatically when expired</li> <li>Secure: Refresh tokens are encrypted and stored locally</li> </ol>"},{"location":"en/guides/oauth2-authentication/#best-practices","title":"Best Practices","text":"<ol> <li>Never commit <code>~/.kagura/</code> directory to version control</li> <li>Keep <code>client_secrets.json</code> secure - it's like a password</li> <li>Don't share your <code>credentials.json.enc</code> file</li> <li>Logout when you're done on shared machines</li> <li>Regenerate OAuth client ID if credentials are compromised</li> </ol>"},{"location":"en/guides/oauth2-authentication/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/oauth2-authentication/#client-secrets-file-not-found","title":"\"Client secrets file not found\"","text":"<p>Error: <pre><code>FileNotFoundError: Client secrets file not found: /home/user/.kagura/client_secrets.json\n</code></pre></p> <p>Solution: 1. Download OAuth 2.0 Client ID JSON from Google Cloud Console 2. Save it as <code>~/.kagura/client_secrets.json</code></p>"},{"location":"en/guides/oauth2-authentication/#not-authenticated-with-google","title":"\"Not authenticated with google\"","text":"<p>Error: <pre><code>NotAuthenticatedError: Not authenticated with google. Please run: kagura auth login --provider google\n</code></pre></p> <p>Solution: Run <code>kagura auth login --provider google</code> to authenticate.</p>"},{"location":"en/guides/oauth2-authentication/#token-refresh-failed","title":"\"Token refresh failed\"","text":"<p>Error: <pre><code>TokenRefreshError: Failed to refresh token for google\n</code></pre></p> <p>Solution: 1. Logout: <code>kagura auth logout --provider google</code> 2. Login again: <code>kagura auth login --provider google</code></p>"},{"location":"en/guides/oauth2-authentication/#invalid-credentials","title":"\"Invalid credentials\"","text":"<p>Error: <pre><code>InvalidCredentialsError: Failed to decrypt credentials\n</code></pre></p> <p>Possible causes: - Corrupted credentials file - Encryption key was regenerated</p> <p>Solution: 1. Remove credentials: <code>rm ~/.kagura/credentials.json.enc</code> 2. Login again: <code>kagura auth login --provider google</code></p>"},{"location":"en/guides/oauth2-authentication/#environment-variables","title":"Environment Variables","text":"<p>OAuth2 authentication does NOT use environment variables. All authentication is handled through the OAuth2 flow and stored encrypted credentials.</p> <p>If you prefer to use API keys instead:</p> <pre><code># For Gemini (using API key)\nexport GOOGLE_API_KEY=\"your-api-key\"\n\n# Then use api_key auth type (default)\nconfig = LLMConfig(model=\"gemini/gemini-1.5-flash\")\n</code></pre>"},{"location":"en/guides/oauth2-authentication/#comparison-oauth2-vs-api-key","title":"Comparison: OAuth2 vs API Key","text":"Feature OAuth2 API Key Supported LLMs Google/Gemini only All LLMs (OpenAI, Claude, Gemini) Setup Complexity Complex (Google Cloud Console setup required) Simple (just get API key) Security OAuth2 tokens (short-lived, auto-refresh) Long-lived API keys Use Case Multi-user apps, production with strict access control Personal development, prototyping, CI/CD Recommended For Advanced users with specific needs Most users (recommended) Expiration Auto-refresh Manual rotation Revocation Can revoke from Google Console Delete/regenerate key"},{"location":"en/guides/oauth2-authentication/#when-to-use-api-key-recommended","title":"When to Use API Key (Recommended)","text":"<p>\u2705 Use API Key if: - You're doing personal development or prototyping - You want quick and simple setup - You're using Claude or OpenAI (OAuth2 not supported) - You're running in CI/CD pipelines - You're building single-user applications</p> <p>How to get API Keys: - Gemini: Google AI Studio (fastest way!) - Claude: Anthropic Console - OpenAI: OpenAI Platform</p>"},{"location":"en/guides/oauth2-authentication/#when-to-use-oauth2-advanced","title":"When to Use OAuth2 (Advanced)","text":"<p>\u26a0\ufe0f Use OAuth2 only if: - You're building a multi-user application - Each user needs their own Google account authentication - You need strict per-user quota management - You have specific security requirements - You're comfortable with Google Cloud Console setup</p> <p>Note: OAuth2 is only available for Google/Gemini.</p>"},{"location":"en/guides/oauth2-authentication/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"en/guides/oauth2-authentication/#custom-client-secrets-path","title":"Custom Client Secrets Path","text":"<p>If you want to store <code>client_secrets.json</code> in a custom location:</p> <pre><code>from kagura.auth import OAuth2Manager, AuthConfig\nfrom pathlib import Path\n\n# Custom config\nconfig = AuthConfig(\n    provider=\"google\",\n    client_secrets_path=Path(\"/custom/path/client_secrets.json\")\n)\n\n# Use custom config\nauth = OAuth2Manager(config=config)\nauth.login()\n</code></pre>"},{"location":"en/guides/oauth2-authentication/#custom-scopes","title":"Custom Scopes","text":"<p>The default scopes are: - <code>https://www.googleapis.com/auth/generative-language</code> - <code>openid</code></p> <p>To use custom scopes:</p> <pre><code>from kagura.auth import OAuth2Manager, AuthConfig\n\nconfig = AuthConfig(\n    provider=\"google\",\n    scopes=[\n        \"https://www.googleapis.com/auth/generative-language\",\n        \"openid\",\n        \"https://www.googleapis.com/auth/userinfo.email\"\n    ]\n)\n\nauth = OAuth2Manager(config=config)\n</code></pre>"},{"location":"en/guides/oauth2-authentication/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Agent Routing</li> <li>Explore Memory Management</li> <li>Try MCP Integration</li> </ul>"},{"location":"en/guides/oauth2-authentication/#related-documentation","title":"Related Documentation","text":"<ul> <li>API Reference: OAuth2Manager</li> <li>Installation Guide</li> <li>Quickstart Tutorial</li> </ul>"},{"location":"en/guides/performance-caching/","title":"Performance: LLM Response Caching","text":"<p>Reduce response times by 70% and API costs by 60% through intelligent LLM response caching.</p>"},{"location":"en/guides/performance-caching/#overview","title":"Overview","text":"<p>Kagura AI automatically caches LLM responses to:</p> <ul> <li>Reduce response times: 70%+ faster for cached queries</li> <li>Lower API costs: 60%+ cost reduction through cache reuse</li> <li>Improve scalability: Handle more concurrent users</li> <li>Better UX: Instant responses for repeated queries</li> </ul>"},{"location":"en/guides/performance-caching/#how-it-works","title":"How It Works","text":"<pre><code>from kagura import agent, LLMConfig\n\n# Caching is enabled by default\nconfig = LLMConfig(model=\"gpt-4o-mini\", enable_cache=True)\n\n@agent(config=config)\nasync def translator(text: str, target_lang: str) -&gt; str:\n    \"\"\"Translate {{ text }} to {{ target_lang }}\"\"\"\n    pass\n\n# First call: Cache miss (~2s)\nresult1 = await translator(\"Hello\", \"Japanese\")\n\n# Second call: Cache hit (~0ms) \u26a1\nresult2 = await translator(\"Hello\", \"Japanese\")  # Instant!\n</code></pre>"},{"location":"en/guides/performance-caching/#quick-start","title":"Quick Start","text":""},{"location":"en/guides/performance-caching/#default-behavior","title":"Default Behavior","text":"<p>Caching is enabled by default with sensible defaults:</p> <pre><code>from kagura import LLMConfig\n\n# These are equivalent:\nconfig1 = LLMConfig(model=\"gpt-4o-mini\")\nconfig2 = LLMConfig(\n    model=\"gpt-4o-mini\",\n    enable_cache=True,      # Enabled by default\n    cache_ttl=3600,         # 1 hour TTL\n    cache_backend=\"memory\"  # In-memory cache\n)\n</code></pre>"},{"location":"en/guides/performance-caching/#disabling-cache","title":"Disabling Cache","text":"<p>For non-deterministic or time-sensitive queries:</p> <pre><code>config = LLMConfig(\n    model=\"gpt-4o-mini\",\n    enable_cache=False  # Disable caching\n)\n\n@agent(config=config)\nasync def breaking_news() -&gt; str:\n    \"\"\"Get latest breaking news\"\"\"\n    pass\n</code></pre>"},{"location":"en/guides/performance-caching/#configuration","title":"Configuration","text":""},{"location":"en/guides/performance-caching/#cache-ttl-time-to-live","title":"Cache TTL (Time-To-Live)","text":"<p>Control how long responses are cached:</p> <pre><code># Short TTL for frequently changing data\nconfig_short = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_ttl=300  # 5 minutes\n)\n\n# Long TTL for stable data\nconfig_long = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_ttl=86400  # 24 hours\n)\n\n# No expiration (cache indefinitely)\nconfig_infinite = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_ttl=0  # Never expires (use with caution!)\n)\n</code></pre>"},{"location":"en/guides/performance-caching/#cache-backend","title":"Cache Backend","text":"<p>Choose between in-memory and Redis backends:</p> <pre><code># In-memory cache (default, fast, single-process)\nconfig_memory = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_backend=\"memory\"\n)\n\n# Redis cache (shared across processes, persistent)\n# Note: Redis backend will be available in Phase 1 Day 3\nconfig_redis = LLMConfig(\n    model=\"gpt-4o-mini\",\n    cache_backend=\"redis\"  # Coming soon!\n)\n</code></pre>"},{"location":"en/guides/performance-caching/#cache-management","title":"Cache Management","text":""},{"location":"en/guides/performance-caching/#inspecting-cache","title":"Inspecting Cache","text":"<p>Get cache statistics:</p> <pre><code>from kagura.core.llm import get_llm_cache\n\ncache = get_llm_cache()\nstats = cache.stats()\n\nprint(f\"Cache size: {stats['size']}/{stats['max_size']}\")\nprint(f\"Hit rate: {stats['hit_rate']:.1%}\")\nprint(f\"Hits: {stats['hits']}, Misses: {stats['misses']}\")\n</code></pre> <p>Example output: <pre><code>Cache size: 243/1000\nHit rate: 87.3%\nHits: 1247, Misses: 182\n</code></pre></p>"},{"location":"en/guides/performance-caching/#cache-invalidation","title":"Cache Invalidation","text":"<p>Clear cache when data changes:</p> <pre><code>cache = get_llm_cache()\n\n# Clear all cache entries\nawait cache.invalidate()\n\n# Clear specific pattern\nawait cache.invalidate(\"translate\")  # Clears all translation caches\n</code></pre>"},{"location":"en/guides/performance-caching/#custom-cache-instance","title":"Custom Cache Instance","text":"<p>Use a custom cache configuration:</p> <pre><code>from kagura.core.cache import LLMCache\nfrom kagura.core.llm import set_llm_cache\n\n# Create custom cache\ncustom_cache = LLMCache(\n    max_size=5000,      # Store up to 5000 entries\n    default_ttl=7200    # 2 hour default TTL\n)\n\nset_llm_cache(custom_cache)\n</code></pre>"},{"location":"en/guides/performance-caching/#best-practices","title":"Best Practices","text":""},{"location":"en/guides/performance-caching/#1-enable-caching-for-stable-queries","title":"1. Enable Caching for Stable Queries","text":"<p>\u2705 Good use cases: - Translation services - Text summarization - Code generation (same prompt) - General knowledge queries</p> <pre><code>@agent(config=LLMConfig(enable_cache=True))\nasync def translator(text: str) -&gt; str:\n    \"\"\"Translate {{ text }} to English\"\"\"\n    pass\n</code></pre> <p>\u274c Bad use cases: - Real-time data (news, weather, stock prices) - User-specific personalized responses - Queries with timestamps</p> <pre><code>@agent(config=LLMConfig(enable_cache=False))\nasync def weather_now() -&gt; str:\n    \"\"\"Get current weather\"\"\"\n    pass\n</code></pre>"},{"location":"en/guides/performance-caching/#2-adjust-ttl-based-on-data-stability","title":"2. Adjust TTL Based on Data Stability","text":"<pre><code># Fast-changing data: Short TTL\nnews_config = LLMConfig(cache_ttl=300)  # 5 min\n\n# Stable data: Long TTL\ndocs_config = LLMConfig(cache_ttl=86400)  # 24 hours\n\n# Never changes: Very long TTL\nconst_config = LLMConfig(cache_ttl=604800)  # 1 week\n</code></pre>"},{"location":"en/guides/performance-caching/#3-tool-functions-disable-caching","title":"3. Tool Functions Disable Caching","text":"<p>Caching is automatically disabled when using tool functions:</p> <pre><code>@agent(config=LLMConfig(enable_cache=True))\nasync def research(query: str) -&gt; str:\n    \"\"\"Research {{ query }}\"\"\"\n    pass\n\n# Caching enabled (no tools)\nresult1 = await research(\"AI trends\")\n\n# Caching disabled (tools provided)\nresult2 = await research(\n    \"AI trends\",\n    tools=[web_search, calculator]  # Tools disable cache\n)\n</code></pre> <p>Reason: Tool functions may have side effects or return different results each time.</p>"},{"location":"en/guides/performance-caching/#4-monitor-cache-performance","title":"4. Monitor Cache Performance","text":"<p>Track hit rate to optimize:</p> <pre><code>import asyncio\nfrom kagura.core.llm import get_llm_cache\n\nasync def monitor_cache():\n    while True:\n        cache = get_llm_cache()\n        stats = cache.stats()\n\n        hit_rate = stats['hit_rate']\n        if hit_rate &lt; 0.5:\n            print(f\"\u26a0\ufe0f Low hit rate: {hit_rate:.1%}\")\n            print(\"Consider: Longer TTL or fewer unique queries\")\n\n        await asyncio.sleep(60)  # Check every minute\n</code></pre> <p>Target hit rate: 70-90% for most applications</p>"},{"location":"en/guides/performance-caching/#performance-benchmarks","title":"Performance Benchmarks","text":""},{"location":"en/guides/performance-caching/#response-time-reduction","title":"Response Time Reduction","text":"Scenario Without Cache With Cache (Hit) Improvement Simple query 1.5s ~0ms 99.9% faster \u26a1 Complex query 3.2s ~0ms 99.9% faster \u26a1 Translation 1.8s ~0ms 99.9% faster \u26a1"},{"location":"en/guides/performance-caching/#cost-reduction","title":"Cost Reduction","text":"<p>Assuming 1000 requests/day with 85% cache hit rate:</p> Model Without Cache With Cache Savings gpt-4o-mini $2.00/day $0.30/day 85% cheaper \ud83d\udcb0 gpt-4o $30.00/day $4.50/day 85% cheaper \ud83d\udcb0 claude-3-5-sonnet $15.00/day $2.25/day 85% cheaper \ud83d\udcb0"},{"location":"en/guides/performance-caching/#advanced-topics","title":"Advanced Topics","text":""},{"location":"en/guides/performance-caching/#cache-key-generation","title":"Cache Key Generation","text":"<p>Cache keys include: - Prompt text - Model name - All LLM parameters (temperature, max_tokens, etc.)</p> <pre><code># Same cache key (identical parameters)\nconfig = LLMConfig(model=\"gpt-4o-mini\", temperature=0.7)\nresult1 = await call_llm(\"Hello\", config)\nresult2 = await call_llm(\"Hello\", config)  # Cache hit \u2705\n\n# Different cache key (different temperature)\nconfig2 = LLMConfig(model=\"gpt-4o-mini\", temperature=0.9)\nresult3 = await call_llm(\"Hello\", config2)  # Cache miss \u274c\n</code></pre>"},{"location":"en/guides/performance-caching/#cache-eviction","title":"Cache Eviction","text":"<p>When cache reaches <code>max_size</code>, the oldest entries are evicted (LRU):</p> <pre><code>cache = LLMCache(max_size=1000)\n\n# After 1000 unique queries:\n# - Query 1001: Evicts oldest entry\n# - Query 1002: Evicts next oldest entry\n</code></pre> <p>Tip: Increase <code>max_size</code> if you have many unique queries.</p>"},{"location":"en/guides/performance-caching/#memory-usage","title":"Memory Usage","text":"<p>Approximate memory usage per cached entry:</p> <ul> <li>Simple response (100 chars): ~500 bytes</li> <li>Complex response (2000 chars): ~8 KB</li> <li>1000 entries: ~5-8 MB</li> </ul> <pre><code># Low memory: Small cache\nlow_mem_cache = LLMCache(max_size=100)\n\n# High memory: Large cache\nhigh_mem_cache = LLMCache(max_size=10000)\n</code></pre>"},{"location":"en/guides/performance-caching/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/performance-caching/#cache-not-working","title":"Cache Not Working","text":"<p>Symptom: All queries are cache misses</p> <p>Possible causes: 1. Caching disabled: <code>enable_cache=False</code> 2. Tool functions provided (auto-disables cache) 3. Different parameters on each call</p> <p>Solution: <pre><code># Check cache is enabled\nconfig = LLMConfig(enable_cache=True)\n\n# Verify no tools\nresult = await call_llm(prompt, config, tool_functions=None)\n\n# Check stats\ncache = get_llm_cache()\nprint(cache.stats())\n</code></pre></p>"},{"location":"en/guides/performance-caching/#low-hit-rate","title":"Low Hit Rate","text":"<p>Symptom: Hit rate &lt; 50%</p> <p>Possible causes: 1. Too many unique queries 2. TTL too short (entries expiring) 3. Dynamic prompts (timestamps, user IDs in prompt)</p> <p>Solution: <pre><code># Increase TTL\nconfig = LLMConfig(cache_ttl=7200)  # 2 hours\n\n# Remove dynamic parts from prompt\n# \u274c Bad: Includes timestamp\nprompt = f\"Translate 'hello' at {datetime.now()}\"\n\n# \u2705 Good: Static prompt\nprompt = \"Translate 'hello' to French\"\n</code></pre></p>"},{"location":"en/guides/performance-caching/#memory-issues","title":"Memory Issues","text":"<p>Symptom: High memory usage</p> <p>Solution: <pre><code># Reduce cache size\ncache = LLMCache(max_size=500)  # Smaller cache\nset_llm_cache(cache)\n\n# Or invalidate periodically\nawait cache.invalidate()  # Clear all entries\n</code></pre></p>"},{"location":"en/guides/performance-caching/#next-steps","title":"Next Steps","text":"<ul> <li>API Reference: cache.py</li> <li>API Reference: llm.py</li> <li>Performance Optimization Guide (coming soon)</li> </ul> <p>Need help? Open an issue</p>"},{"location":"en/guides/web-integration/","title":"Web Integration Guide","text":"<p>This guide explains how to use Kagura AI's web search and scraping capabilities to access real-time information from the internet.</p>"},{"location":"en/guides/web-integration/#overview","title":"Overview","text":"<p>Web integration allows you to: - Search the web for current information - Scrape content from websites - Combine local knowledge (RAG) with web data - Get up-to-date answers beyond LLM training cutoff</p>"},{"location":"en/guides/web-integration/#prerequisites","title":"Prerequisites","text":""},{"location":"en/guides/web-integration/#installation","title":"Installation","text":"<p>Install Kagura AI with web support:</p> <pre><code>pip install kagura-ai[web]\n</code></pre> <p>This installs: - <code>httpx</code> - Async HTTP client - <code>beautifulsoup4</code> - HTML parsing - <code>lxml</code> - Fast XML/HTML parser - <code>brave-search-python-client</code> - Brave Search API</p>"},{"location":"en/guides/web-integration/#api-key-setup-required","title":"API Key Setup (Required)","text":"<p>For Brave Search:</p> <pre><code>export BRAVE_SEARCH_API_KEY=\"your-brave-api-key\"\n</code></pre> <p>Get a free API key from Brave Search API (2000 queries/month free).</p> <p>Note: Web search requires a valid BRAVE_SEARCH_API_KEY.</p>"},{"location":"en/guides/web-integration/#quick-start","title":"Quick Start","text":""},{"location":"en/guides/web-integration/#basic-usage","title":"Basic Usage","text":"<p>Start chat with web search enabled:</p> <pre><code>kagura chat --enable-web\n</code></pre> <p>The AI will automatically search the web when needed:</p> <pre><code>$ kagura chat --enable-web\n\n[You] &gt; What are the latest AI news today?\n\n\ud83c\udf10 Searching the web for: latest AI news\n\u2713 Web search completed\n\ud83d\udcac Generating response...\n\n[AI]\nHere are today's top AI news:\n\n1. **OpenAI releases GPT-5 Preview** - OpenAI announced a preview of\n   GPT-5 with improved reasoning capabilities...\n\n2. **Google's Gemini 2.0 launched** - Google released Gemini 2.0 with\n   native multimodal support...\n\n3. **AI regulation update** - EU Parliament approved new AI safety\n   regulations affecting...\n\n[Sources: TechCrunch, The Verge, MIT Technology Review]\n</code></pre>"},{"location":"en/guides/web-integration/#web-search","title":"Web Search","text":""},{"location":"en/guides/web-integration/#automatic-search-detection","title":"Automatic Search Detection","text":"<p>The AI decides when to search the web:</p> <pre><code>from kagura import agent\n\n@agent(\n    model=\"gpt-4o-mini\",\n    enable_web=True  # Enable automatic web search\n)\nasync def research_assistant(question: str) -&gt; str:\n    \"\"\"Answer the user's question.\n\n    Question: {{ question }}\n\n    If you need current information, use web search.\n    \"\"\"\n    pass\n\n# The agent will automatically search when needed\nresponse = await research_assistant(\"What's the weather in Tokyo?\")\n</code></pre>"},{"location":"en/guides/web-integration/#manual-web-search","title":"Manual Web Search","text":"<p>Use the <code>web_search</code> function directly:</p> <pre><code>from kagura.web import web_search\n\n# Search the web\nresults_text = await web_search(\"Python async best practices 2025\")\nprint(results_text)\n</code></pre> <p>Output format:</p> <pre><code>Search results for: Python async best practices 2025\n\n1. Best Practices for Async Python in 2025\n   https://realpython.com/async-python-2025\n   Comprehensive guide to async/await patterns, asyncio best practices...\n\n2. Asyncio Performance Tips - 2025 Edition\n   https://python.org/asyncio-tips\n   Learn how to optimize asyncio applications for production...\n</code></pre>"},{"location":"en/guides/web-integration/#brave-search-engine","title":"Brave Search Engine","text":"<p>Kagura uses Brave Search for web queries:</p> <pre><code>from kagura.web.search import BraveSearch\n\nsearch = BraveSearch(api_key=\"your-key\")\nresults = await search.search(\"query\", max_results=10)\n\nfor result in results:\n    print(f\"{result.title}: {result.url}\")\n</code></pre>"},{"location":"en/guides/web-integration/#search-api","title":"Search API","text":"<pre><code>from kagura.web.search import SearchResult\n\n# Search returns list of SearchResult objects\nresults: list[SearchResult] = await search.search(\"query\")\n\nfor result in results:\n    print(f\"Title: {result.title}\")\n    print(f\"URL: {result.url}\")\n    print(f\"Snippet: {result.snippet}\")\n    print(f\"Source: {result.source}\")  # \"brave\"\n    print()\n</code></pre>"},{"location":"en/guides/web-integration/#web-scraping","title":"Web Scraping","text":""},{"location":"en/guides/web-integration/#basic-scraping","title":"Basic Scraping","text":"<p>Fetch and parse webpage content:</p> <pre><code>from kagura.web.scraper import WebScraper\n\nscraper = WebScraper()\n\n# Fetch HTML\nhtml = await scraper.fetch(\"https://example.com\")\n\n# Extract text content\ntext = await scraper.fetch_text(\"https://example.com\")\nprint(text)  # Clean, readable text\n\n# Scrape with CSS selectors\ntitles = await scraper.scrape(\n    \"https://news.ycombinator.com\",\n    selector=\"span.titleline &gt; a\"\n)\nfor title in titles:\n    print(title)\n</code></pre>"},{"location":"en/guides/web-integration/#robotstxt-compliance","title":"robots.txt Compliance","text":"<p>Kagura respects robots.txt by default:</p> <pre><code>scraper = WebScraper(\n    respect_robots_txt=True,  # Default: True\n    user_agent=\"KaguraAI/2.5.0\",\n    rate_limit_delay=1.0  # Delay between requests (seconds)\n)\n</code></pre> <p>If a site disallows scraping:</p> <pre><code>try:\n    html = await scraper.fetch(\"https://example.com/private\")\nexcept ValueError as e:\n    print(f\"Blocked by robots.txt: {e}\")\n</code></pre>"},{"location":"en/guides/web-integration/#rate-limiting","title":"Rate Limiting","text":"<p>Automatic rate limiting prevents overwhelming servers:</p> <pre><code>from kagura.web.scraper import WebScraper\n\nscraper = WebScraper(rate_limit_delay=2.0)  # 2 seconds between requests\n\n# These will be rate-limited automatically\nawait scraper.fetch(\"https://example.com/page1\")\nawait scraper.fetch(\"https://example.com/page2\")  # Waits 2 seconds\nawait scraper.fetch(\"https://example.com/page3\")  # Waits 2 seconds\n</code></pre>"},{"location":"en/guides/web-integration/#advanced-scraping","title":"Advanced Scraping","text":"<pre><code>from kagura.web.scraper import WebScraper\n\nscraper = WebScraper(\n    user_agent=\"MyBot/1.0 (+https://mysite.com/bot)\",\n    respect_robots_txt=True,\n    rate_limit_delay=1.5\n)\n\n# Custom timeout\nhtml = await scraper.fetch(\"https://slow-site.com\", timeout=60.0)\n\n# Parse specific elements\narticles = await scraper.scrape(\n    \"https://blog.com\",\n    selector=\"article.post\"\n)\n</code></pre>"},{"location":"en/guides/web-integration/#agent-integration","title":"Agent Integration","text":""},{"location":"en/guides/web-integration/#web-enabled-agent","title":"Web-Enabled Agent","text":"<p>Create an agent that can search the web:</p> <pre><code>from kagura import agent\nfrom kagura.web import web_search\n\nasync def search_tool(query: str) -&gt; str:\n    \"\"\"Search the web for information.\"\"\"\n    return await web_search(query)\n\n@agent(\n    model=\"gpt-4o-mini\",\n    tools=[search_tool]\n)\nasync def research_agent(topic: str) -&gt; str:\n    \"\"\"Research {{ topic }} using web search.\n\n    Use search_tool(query) to search the web.\n    \"\"\"\n    pass\n\n# The agent will use the tool when needed\nreport = await research_agent(\"AI safety regulations 2025\")\n</code></pre>"},{"location":"en/guides/web-integration/#custom-web-tools","title":"Custom Web Tools","text":"<p>Create specialized web tools:</p> <pre><code>from kagura import agent\nfrom kagura.web.scraper import WebScraper\n\nasync def fetch_news(topic: str) -&gt; str:\n    \"\"\"Fetch latest news about a topic.\"\"\"\n    scraper = WebScraper()\n\n    # Scrape news site\n    headlines = await scraper.scrape(\n        f\"https://news-site.com/search?q={topic}\",\n        selector=\"h2.headline\"\n    )\n\n    return \"\\n\".join(headlines[:5])\n\n@agent(tools=[fetch_news])\nasync def news_assistant(query: str) -&gt; str:\n    \"\"\"Answer questions about current news.\n\n    Query: {{ query }}\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/guides/web-integration/#configuration","title":"Configuration","text":""},{"location":"en/guides/web-integration/#environment-variables","title":"Environment Variables","text":"<pre><code># Brave Search (optional)\nexport BRAVE_SEARCH_API_KEY=\"your-key\"\n\n# User agent (optional)\nexport USER_AGENT=\"MyBot/1.0\"\n\n# Rate limiting (optional)\nexport WEB_RATE_LIMIT=1.5\n</code></pre>"},{"location":"en/guides/web-integration/#programmatic-configuration","title":"Programmatic Configuration","text":"<pre><code>from kagura.web.search import BraveSearch\nfrom kagura.web.scraper import WebScraper\nimport os\n\n# Configure search (requires API key)\nsearch = BraveSearch(api_key=os.getenv(\"BRAVE_SEARCH_API_KEY\"))\n\n# Configure scraper\nscraper = WebScraper(\n    user_agent=os.getenv(\"USER_AGENT\", \"KaguraAI/2.5.0\"),\n    respect_robots_txt=True,\n    rate_limit_delay=float(os.getenv(\"WEB_RATE_LIMIT\", \"1.0\"))\n)\n</code></pre>"},{"location":"en/guides/web-integration/#best-practices","title":"Best Practices","text":""},{"location":"en/guides/web-integration/#1-respect-robotstxt","title":"1. Respect robots.txt","text":"<p>Always check robots.txt before scraping:</p> <pre><code>scraper = WebScraper(respect_robots_txt=True)  # Default\n</code></pre>"},{"location":"en/guides/web-integration/#2-use-appropriate-user-agent","title":"2. Use Appropriate User Agent","text":"<p>Identify your bot:</p> <pre><code>scraper = WebScraper(\n    user_agent=\"MyBot/1.0 (+https://mysite.com/bot-info)\"\n)\n</code></pre>"},{"location":"en/guides/web-integration/#3-rate-limiting","title":"3. Rate Limiting","text":"<p>Be a good citizen:</p> <pre><code>scraper = WebScraper(rate_limit_delay=1.0)  # Minimum 1 second\n</code></pre>"},{"location":"en/guides/web-integration/#4-handle-errors","title":"4. Handle Errors","text":"<pre><code>from httpx import HTTPError\n\ntry:\n    content = await scraper.fetch_text(url)\nexcept HTTPError as e:\n    print(f\"HTTP error: {e}\")\nexcept ValueError as e:\n    print(f\"Blocked by robots.txt: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"en/guides/web-integration/#5-cache-results","title":"5. Cache Results","text":"<p>Avoid repeated requests:</p> <pre><code>from functools import lru_cache\n\n@lru_cache(maxsize=100)\nasync def cached_search(query: str) -&gt; str:\n    return await web_search(query)\n</code></pre>"},{"location":"en/guides/web-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/guides/web-integration/#importerror-httpx-not-installed","title":"\"ImportError: httpx not installed\"","text":"<p>Install web dependencies:</p> <pre><code>pip install kagura-ai[web]\n</code></pre>"},{"location":"en/guides/web-integration/#rate-limit-exceeded","title":"\"Rate limit exceeded\"","text":"<p>Increase delay between requests:</p> <pre><code>scraper = WebScraper(rate_limit_delay=2.0)\n</code></pre> <p>Or wait before retrying:</p> <pre><code>import asyncio\n\ntry:\n    results = await search.search(query)\nexcept Exception as e:\n    print(f\"Rate limited, waiting...\")\n    await asyncio.sleep(60)\n    results = await search.search(query)\n</code></pre>"},{"location":"en/guides/web-integration/#robotstxt-disallows-fetching","title":"\"robots.txt disallows fetching\"","text":"<p>Either:</p> <ol> <li>Respect the site's wishes (recommended)</li> <li>Disable robots.txt check (not recommended):</li> </ol> <pre><code>scraper = WebScraper(respect_robots_txt=False)\n</code></pre>"},{"location":"en/guides/web-integration/#connection-timeout","title":"Connection Timeout","text":"<p>Increase timeout:</p> <pre><code>html = await scraper.fetch(url, timeout=60.0)  # 60 seconds\n</code></pre>"},{"location":"en/guides/web-integration/#examples","title":"Examples","text":""},{"location":"en/guides/web-integration/#example-1-news-aggregator","title":"Example 1: News Aggregator","text":"<pre><code>from kagura import agent\nfrom kagura.web import web_search\n\n@agent(model=\"gpt-4o-mini\")\nasync def news_bot(topic: str) -&gt; str:\n    \"\"\"Fetch and summarize news about {{ topic }}.\n\n    Use web_search() to find latest news.\n    \"\"\"\n    pass\n\n# Usage\nsummary = await news_bot(\"AI breakthroughs\")\n</code></pre>"},{"location":"en/guides/web-integration/#example-2-documentation-fetcher","title":"Example 2: Documentation Fetcher","text":"<pre><code>from kagura.web.scraper import WebScraper\n\nasync def fetch_api_docs(library: str) -&gt; str:\n    \"\"\"Fetch API documentation for a library.\"\"\"\n    scraper = WebScraper()\n\n    # Fetch official docs\n    docs_url = f\"https://{library}.readthedocs.io/\"\n    text = await scraper.fetch_text(docs_url)\n\n    return text[:5000]  # First 5000 chars\n\n# Usage\ndocs = await fetch_api_docs(\"httpx\")\n</code></pre>"},{"location":"en/guides/web-integration/#example-3-competitor-analysis","title":"Example 3: Competitor Analysis","text":"<pre><code>from kagura import agent\nfrom kagura.web import web_search\nfrom kagura.web.scraper import WebScraper\n\nasync def analyze_competitor(competitor_url: str) -&gt; dict:\n    \"\"\"Analyze competitor website.\"\"\"\n    scraper = WebScraper()\n\n    # Fetch homepage\n    text = await scraper.fetch_text(competitor_url)\n\n    # Extract features\n    features = await scraper.scrape(\n        competitor_url,\n        selector=\"div.feature h3\"\n    )\n\n    return {\n        \"content\": text[:2000],\n        \"features\": features\n    }\n\n@agent\nasync def market_analyst(company_name: str) -&gt; str:\n    \"\"\"Analyze {{ company_name }} and competitors.\"\"\"\n    pass\n</code></pre>"},{"location":"en/guides/web-integration/#performance-tips","title":"Performance Tips","text":""},{"location":"en/guides/web-integration/#1-parallel-requests","title":"1. Parallel Requests","text":"<p>Use asyncio.gather for parallel fetching:</p> <pre><code>import asyncio\n\nurls = [\"https://site1.com\", \"https://site2.com\", \"https://site3.com\"]\n\n# Fetch in parallel\nresults = await asyncio.gather(\n    *[scraper.fetch_text(url) for url in urls]\n)\n</code></pre>"},{"location":"en/guides/web-integration/#2-connection-pooling","title":"2. Connection Pooling","text":"<p>httpx automatically pools connections:</p> <pre><code># Reuse scraper instance\nscraper = WebScraper()\n\nfor url in urls:\n    await scraper.fetch(url)  # Reuses connections\n</code></pre>"},{"location":"en/guides/web-integration/#3-timeout-management","title":"3. Timeout Management","text":"<p>Set appropriate timeouts:</p> <pre><code># Fast timeout for quick checks\nawait scraper.fetch(url, timeout=5.0)\n\n# Longer timeout for heavy pages\nawait scraper.fetch(url, timeout=30.0)\n</code></pre>"},{"location":"en/guides/web-integration/#next-steps","title":"Next Steps","text":"<ul> <li>Multimodal RAG Guide - Add local file indexing</li> <li>Full-Featured Mode - Combine all features</li> <li>API Reference - Detailed API documentation</li> </ul>"},{"location":"en/guides/web-integration/#resources","title":"Resources","text":"<ul> <li>Brave Search API</li> <li>httpx Documentation</li> <li>BeautifulSoup Documentation</li> <li>robots.txt Specification</li> </ul>"},{"location":"en/tutorials/01-basic-agent/","title":"Tutorial 1: Creating Your First Agent","text":"<p>Learn how to create a basic AI agent using the <code>@agent</code> decorator.</p>"},{"location":"en/tutorials/01-basic-agent/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed (<code>pip install kagura-ai</code>)</li> <li>OpenAI API key (or other LLM provider)</li> </ul>"},{"location":"en/tutorials/01-basic-agent/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand the <code>@agent</code> decorator - Create a simple conversational agent - Run and test your agent - Understand how prompts work</p>"},{"location":"en/tutorials/01-basic-agent/#step-1-set-up-your-environment","title":"Step 1: Set Up Your Environment","text":"<p>First, set your API key:</p> <pre><code>export OPENAI_API_KEY=\"your-key-here\"\n</code></pre> <p>Create a new file called <code>hello_agent.py</code>:</p> <pre><code>touch hello_agent.py\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#step-2-import-kagura","title":"Step 2: Import Kagura","text":"<p>Open <code>hello_agent.py</code> and add the import:</p> <pre><code>import asyncio\nfrom kagura import agent\n</code></pre> <p>Explanation: - <code>asyncio</code>: Python's built-in library for async operations - <code>agent</code>: The core decorator from Kagura AI</p>"},{"location":"en/tutorials/01-basic-agent/#step-3-define-your-first-agent","title":"Step 3: Define Your First Agent","text":"<p>Add this agent definition:</p> <pre><code>@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n</code></pre> <p>Let's break this down:</p> <ol> <li><code>@agent</code> - The decorator that converts the function into an AI agent</li> <li><code>async def hello</code> - An async function (required for all agents)</li> <li><code>(name: str)</code> - Function parameter with type hint</li> <li><code>-&gt; str</code> - Return type annotation (tells parser to expect a string)</li> <li><code>'''Say hello to {{ name }}'''</code> - The prompt template using Jinja2 syntax</li> <li><code>pass</code> - Function body (ignored, as decorator replaces it)</li> </ol>"},{"location":"en/tutorials/01-basic-agent/#step-4-create-a-main-function","title":"Step 4: Create a Main Function","text":"<p>Add code to run the agent:</p> <pre><code>async def main():\n    # Call the agent\n    result = await hello(\"World\")\n    print(result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#step-5-run-your-agent","title":"Step 5: Run Your Agent","text":"<p>Execute the script:</p> <pre><code>python hello_agent.py\n</code></pre> <p>Expected output: <pre><code>Hello, World! How can I assist you today?\n</code></pre></p> <p>\ud83c\udf89 Congratulations! You've created your first AI agent.</p>"},{"location":"en/tutorials/01-basic-agent/#complete-code","title":"Complete Code","text":"<p>Here's the full <code>hello_agent.py</code>:</p> <pre><code>import asyncio\nfrom kagura import agent\n\n\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\n\nasync def main():\n    result = await hello(\"World\")\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#understanding-what-happened","title":"Understanding What Happened","text":"<p>Let's trace the execution:</p> <ol> <li>You call: <code>await hello(\"World\")</code></li> <li>Decorator extracts: Parameter <code>name = \"World\"</code></li> <li>Template renders: <code>\"Say hello to World\"</code></li> <li>LLM is called: With the rendered prompt</li> <li>Response is parsed: As a string (because <code>-&gt; str</code>)</li> <li>Result returned: <code>\"Hello, World! How can I assist you today?\"</code></li> </ol>"},{"location":"en/tutorials/01-basic-agent/#experiment-different-names","title":"Experiment: Different Names","text":"<p>Try calling with different names:</p> <pre><code>async def main():\n    print(await hello(\"Alice\"))\n    print(await hello(\"Bob\"))\n    print(await hello(\"\u795e\u697d\"))  # Japanese name\n</code></pre> <p>Output: <pre><code>Hello, Alice! How can I help you?\nHello, Bob! Nice to meet you!\n\u3053\u3093\u306b\u3061\u306f\u3001\u795e\u697d\u3055\u3093\uff01\u304a\u624b\u4f1d\u3044\u3067\u304d\u308b\u3053\u3068\u306f\u3042\u308a\u307e\u3059\u304b\uff1f\n</code></pre></p> <p>Notice how the LLM adapts its response based on the input!</p>"},{"location":"en/tutorials/01-basic-agent/#experiment-multiple-parameters","title":"Experiment: Multiple Parameters","text":"<p>Let's create an agent with multiple parameters:</p> <pre><code>@agent\nasync def greet(name: str, time_of_day: str = \"morning\") -&gt; str:\n    '''Good {{ time_of_day }}, {{ name }}! How are you doing?'''\n    pass\n\n\nasync def main():\n    print(await greet(\"Alice\"))\n    print(await greet(\"Bob\", \"evening\"))\n</code></pre> <p>Output: <pre><code>Good morning, Alice! How are you doing?\nI hope you're doing well!\n\nGood evening, Bob! How are you doing?\nI hope you had a great day!\n</code></pre></p>"},{"location":"en/tutorials/01-basic-agent/#experiment-different-prompts","title":"Experiment: Different Prompts","text":"<p>The prompt greatly affects the response. Try these variations:</p>"},{"location":"en/tutorials/01-basic-agent/#formal-greeting","title":"Formal Greeting","text":"<pre><code>@agent\nasync def formal_greet(name: str) -&gt; str:\n    '''Provide a formal business greeting to {{ name }}, a potential client.'''\n    pass\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#casual-greeting","title":"Casual Greeting","text":"<pre><code>@agent\nasync def casual_greet(name: str) -&gt; str:\n    '''Give a super casual, friendly greeting to {{ name }}, your best friend.'''\n    pass\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#poetic-greeting","title":"Poetic Greeting","text":"<pre><code>@agent\nasync def poetic_greet(name: str) -&gt; str:\n    '''Write a short, poetic greeting to {{ name }} (2-3 lines).'''\n    pass\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"en/tutorials/01-basic-agent/#1-the-agent-decorator","title":"1. The @agent Decorator","text":"<p>Converts a function into an AI agent: - Extracts function signature - Uses docstring as prompt template - Calls LLM automatically - Parses response based on return type</p>"},{"location":"en/tutorials/01-basic-agent/#2-asyncawait","title":"2. Async/Await","text":"<p>All agents are async functions: <pre><code>result = await hello(\"World\")  # \u2713 Correct\nresult = hello(\"World\")        # \u2717 Wrong - missing await\n</code></pre></p>"},{"location":"en/tutorials/01-basic-agent/#3-type-hints","title":"3. Type Hints","text":"<p>Type hints tell the parser how to handle the response: <pre><code>async def hello(name: str) -&gt; str:  # Returns string\n    pass\n</code></pre></p>"},{"location":"en/tutorials/01-basic-agent/#4-prompt-templates","title":"4. Prompt Templates","text":"<p>Docstrings use Jinja2 syntax for dynamic prompts: <pre><code>'''Say hello to {{ name }}'''  # {{ }} injects variables\n</code></pre></p>"},{"location":"en/tutorials/01-basic-agent/#common-mistakes","title":"Common Mistakes","text":""},{"location":"en/tutorials/01-basic-agent/#1-forgetting-asyncawait","title":"1. Forgetting <code>async</code>/<code>await</code>","text":"<pre><code># Wrong\n@agent\ndef hello(name: str) -&gt; str:  # Missing 'async'\n    pass\n\nresult = hello(\"World\")  # Missing 'await'\n\n# Correct\n@agent\nasync def hello(name: str) -&gt; str:\n    pass\n\nresult = await hello(\"World\")\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#2-missing-return-type","title":"2. Missing Return Type","text":"<pre><code># Less good\n@agent\nasync def hello(name: str):  # No return type\n    pass\n\n# Better\n@agent\nasync def hello(name: str) -&gt; str:  # Explicit return type\n    pass\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#3-empty-docstring","title":"3. Empty Docstring","text":"<pre><code># Won't work well\n@agent\nasync def hello(name: str) -&gt; str:\n    pass  # No docstring = no prompt!\n\n# Correct\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n</code></pre>"},{"location":"en/tutorials/01-basic-agent/#next-steps","title":"Next Steps","text":"<p>Now that you understand basic agents, you can:</p> <ol> <li>Learn about templates - Tutorial 2: Template Engine</li> <li>Explore type parsing - Tutorial 3: Type-Based Parsing</li> <li>Try Interactive Chat - Run <code>kagura chat</code> to experiment</li> </ol>"},{"location":"en/tutorials/01-basic-agent/#practice-exercises","title":"Practice Exercises","text":""},{"location":"en/tutorials/01-basic-agent/#exercise-1-sentiment-analysis","title":"Exercise 1: Sentiment Analysis","text":"<p>Create an agent that analyzes sentiment:</p> <pre><code>@agent\nasync def analyze_sentiment(text: str) -&gt; str:\n    '''Analyze the sentiment (positive/negative/neutral) of: {{ text }}'''\n    pass\n</code></pre> <p>Test it: <pre><code>print(await analyze_sentiment(\"I love this product!\"))\nprint(await analyze_sentiment(\"This is terrible.\"))\nprint(await analyze_sentiment(\"It's okay.\"))\n</code></pre></p>"},{"location":"en/tutorials/01-basic-agent/#exercise-2-language-translation","title":"Exercise 2: Language Translation","text":"<p>Create a translation agent:</p> <pre><code>@agent\nasync def translate(text: str, target_language: str) -&gt; str:\n    '''Translate to {{ target_language }}: {{ text }}'''\n    pass\n</code></pre> <p>Test it: <pre><code>print(await translate(\"Hello, world!\", \"Japanese\"))\nprint(await translate(\"Hello, world!\", \"French\"))\n</code></pre></p>"},{"location":"en/tutorials/01-basic-agent/#exercise-3-question-answering","title":"Exercise 3: Question Answering","text":"<p>Create a Q&amp;A agent:</p> <pre><code>@agent\nasync def answer_question(question: str) -&gt; str:\n    '''Answer this question concisely: {{ question }}'''\n    pass\n</code></pre> <p>Test it: <pre><code>print(await answer_question(\"What is Python?\"))\nprint(await answer_question(\"How do I install Kagura AI?\"))\n</code></pre></p>"},{"location":"en/tutorials/01-basic-agent/#summary","title":"Summary","text":"<p>You learned: - \u2713 How to use the <code>@agent</code> decorator - \u2713 How to create async agent functions - \u2713 How to use type hints for return types - \u2713 How to write prompt templates with Jinja2 - \u2713 How to call and test agents</p> <p>Continue to Tutorial 2: Template Engine to learn more advanced prompting techniques!</p>"},{"location":"en/tutorials/02-templates/","title":"Tutorial 02: Template Engine","text":"<p>Learn how to use Jinja2 templates in your AI agents to create dynamic prompts.</p>"},{"location":"en/tutorials/02-templates/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How to use Jinja2 template syntax in agent docstrings</li> <li>Template variables and expressions</li> <li>Advanced template features (loops, conditionals)</li> <li>Best practices for prompt engineering</li> </ul>"},{"location":"en/tutorials/02-templates/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Tutorial 01: Your First Agent</li> <li>Basic understanding of Python f-strings</li> </ul>"},{"location":"en/tutorials/02-templates/#template-basics","title":"Template Basics","text":"<p>Kagura uses Jinja2 template syntax in agent docstrings. Templates are rendered before being sent to the LLM.</p>"},{"location":"en/tutorials/02-templates/#simple-variables","title":"Simple Variables","text":"<pre><code>from kagura import agent\n\n@agent\nasync def greet(name: str) -&gt; str:\n    \"\"\"Say hello to {{ name }}\"\"\"\n    pass\n\n# Template renders to: \"Say hello to Alice\"\nresult = await greet(\"Alice\")\n</code></pre> <p>Key Points: - Use <code>{{ variable }}</code> to insert values - Variable names must match function parameters - Values are automatically escaped</p>"},{"location":"en/tutorials/02-templates/#multiple-variables","title":"Multiple Variables","text":"<pre><code>@agent\nasync def introduce(name: str, age: int, occupation: str) -&gt; str:\n    \"\"\"\n    Introduce yourself as {{ name }}, a {{ age }}-year-old {{ occupation }}.\n    Be friendly and professional.\n    \"\"\"\n    pass\n\nresult = await introduce(\"Bob\", 30, \"engineer\")\n# Template renders to: \"Introduce yourself as Bob, a 30-year-old engineer...\"\n</code></pre>"},{"location":"en/tutorials/02-templates/#template-expressions","title":"Template Expressions","text":"<p>Jinja2 supports Python-like expressions:</p> <pre><code>@agent\nasync def analyze(score: int) -&gt; str:\n    \"\"\"\n    The score is {{ score }}.\n    {% if score &gt;= 80 %}\n    This is excellent performance!\n    {% elif score &gt;= 60 %}\n    This is good performance.\n    {% else %}\n    This needs improvement.\n    {% endif %}\n    \"\"\"\n    pass\n</code></pre> <p>Expressions You Can Use: - Arithmetic: <code>{{ price * 1.1 }}</code> - Comparison: <code>{% if age &gt; 18 %}</code> - String methods: <code>{{ name.upper() }}</code> - List access: <code>{{ items[0] }}</code></p>"},{"location":"en/tutorials/02-templates/#loops","title":"Loops","text":"<p>Process lists and dictionaries in templates:</p> <pre><code>from typing import List\n\n@agent\nasync def summarize_items(items: List[str]) -&gt; str:\n    \"\"\"\n    Summarize the following items:\n    {% for item in items %}\n    - {{ item }}\n    {% endfor %}\n\n    Provide a brief overview.\n    \"\"\"\n    pass\n\nresult = await summarize_items([\"apples\", \"oranges\", \"bananas\"])\n</code></pre> <p>Loop Features: - <code>{% for item in list %}</code>: Iterate over lists - <code>{{ loop.index }}</code>: Current iteration (1-based) - <code>{{ loop.first }}</code>: True on first iteration - <code>{{ loop.last }}</code>: True on last iteration</p>"},{"location":"en/tutorials/02-templates/#filters","title":"Filters","text":"<p>Transform values with filters:</p> <pre><code>@agent\nasync def format_text(text: str) -&gt; str:\n    \"\"\"\n    Original: {{ text }}\n    Uppercase: {{ text | upper }}\n    Capitalized: {{ text | capitalize }}\n    First 50 chars: {{ text[:50] }}\n    \"\"\"\n    pass\n</code></pre> <p>Common Filters: - <code>upper</code>, <code>lower</code>, <code>capitalize</code>: Text transformation - <code>length</code>: Get length of string/list - <code>default(value)</code>: Default value if undefined - <code>join(separator)</code>: Join list items</p>"},{"location":"en/tutorials/02-templates/#complex-data-structures","title":"Complex Data Structures","text":"<p>Work with dictionaries and objects:</p> <pre><code>from pydantic import BaseModel\nfrom typing import Dict\n\nclass User(BaseModel):\n    name: str\n    email: str\n    age: int\n\n@agent\nasync def analyze_user(user: User) -&gt; str:\n    \"\"\"\n    Analyze user profile:\n    - Name: {{ user.name }}\n    - Email: {{ user.email }}\n    - Age: {{ user.age }}\n\n    Provide insights about this user.\n    \"\"\"\n    pass\n\nuser = User(name=\"Alice\", email=\"alice@example.com\", age=25)\nresult = await analyze_user(user)\n</code></pre> <p>Accessing Data: - Dictionary: <code>{{ data['key'] }}</code> or <code>{{ data.key }}</code> - Object attributes: <code>{{ obj.attribute }}</code> - Nested: <code>{{ user.address.city }}</code></p>"},{"location":"en/tutorials/02-templates/#multiline-templates","title":"Multiline Templates","text":"<p>For complex prompts, use multiline docstrings:</p> <pre><code>@agent\nasync def write_email(\n    recipient: str,\n    subject: str,\n    points: List[str],\n    tone: str = \"professional\"\n) -&gt; str:\n    \"\"\"\n    Write an email with the following specifications:\n\n    To: {{ recipient }}\n    Subject: {{ subject }}\n    Tone: {{ tone }}\n\n    Key points to cover:\n    {% for point in points %}\n    {{ loop.index }}. {{ point }}\n    {% endfor %}\n\n    Make it {{ tone }} and concise.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/02-templates/#1-clear-instructions","title":"1. Clear Instructions","text":"<pre><code># \u2705 Good: Clear instructions\n@agent\nasync def translate(text: str, target_lang: str) -&gt; str:\n    \"\"\"\n    Translate the following text to {{ target_lang }}:\n    {{ text }}\n\n    Return only the translated text, no explanations.\n    \"\"\"\n    pass\n\n# \u274c Bad: Vague instructions\n@agent\nasync def translate(text: str, target_lang: str) -&gt; str:\n    \"\"\"{{ text }} {{ target_lang }}\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#2-structure-your-prompts","title":"2. Structure Your Prompts","text":"<pre><code>@agent\nasync def analyze(data: str) -&gt; str:\n    \"\"\"\n    ## Task\n    Analyze the following data.\n\n    ## Data\n    {{ data }}\n\n    ## Requirements\n    - Identify key trends\n    - Provide insights\n    - Be concise\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#3-use-conditionals-wisely","title":"3. Use Conditionals Wisely","text":"<pre><code>@agent\nasync def respond(message: str, context: str = None) -&gt; str:\n    \"\"\"\n    {% if context %}\n    Context: {{ context }}\n    {% endif %}\n\n    User message: {{ message }}\n\n    Respond appropriately{{ \" based on the context\" if context else \"\" }}.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#4-validate-input","title":"4. Validate Input","text":"<pre><code>@agent\nasync def process(items: List[str]) -&gt; str:\n    \"\"\"\n    {% if items %}\n    Process these items:\n    {% for item in items %}\n    - {{ item }}\n    {% endfor %}\n    {% else %}\n    No items to process.\n    {% endif %}\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#common-patterns","title":"Common Patterns","text":""},{"location":"en/tutorials/02-templates/#chain-of-thought","title":"Chain of Thought","text":"<pre><code>@agent\nasync def solve_math(problem: str) -&gt; str:\n    \"\"\"\n    Solve this math problem: {{ problem }}\n\n    Think step by step:\n    1. First, identify the operation\n    2. Then, calculate the result\n    3. Finally, verify your answer\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#few-shot-learning","title":"Few-Shot Learning","text":"<pre><code>@agent\nasync def classify(text: str) -&gt; str:\n    \"\"\"\n    Classify the sentiment of the text.\n\n    Examples:\n    Text: \"I love this!\" \u2192 Sentiment: positive\n    Text: \"This is terrible\" \u2192 Sentiment: negative\n    Text: \"It's okay\" \u2192 Sentiment: neutral\n\n    Text: {{ text }} \u2192 Sentiment: ?\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#role-based-prompts","title":"Role-Based Prompts","text":"<pre><code>@agent\nasync def code_review(code: str, language: str) -&gt; str:\n    \"\"\"\n    You are an expert {{ language }} developer.\n    Review this code and provide suggestions:\n\n    ```{{ language }}\n    {{ code }}\n    ```\n\n    Focus on:\n    - Code quality\n    - Best practices\n    - Potential bugs\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/02-templates/#template-syntax-errors","title":"Template Syntax Errors","text":"<pre><code># \u274c Wrong: Missing closing tag\n\"\"\"\n{% for item in items %}\n{{ item }}\n\"\"\"\n\n# \u2705 Correct: Proper closing\n\"\"\"\n{% for item in items %}\n{{ item }}\n{% endfor %}\n\"\"\"\n</code></pre>"},{"location":"en/tutorials/02-templates/#variable-not-found","title":"Variable Not Found","text":"<pre><code># \u274c Wrong: Variable doesn't match parameter\n@agent\nasync def greet(name: str) -&gt; str:\n    \"\"\"Hello {{ username }}\"\"\"  # username doesn't exist\n    pass\n\n# \u2705 Correct: Variable matches parameter\n@agent\nasync def greet(name: str) -&gt; str:\n    \"\"\"Hello {{ name }}\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#escaping-special-characters","title":"Escaping Special Characters","text":"<pre><code># If you need literal {{ or }}\n@agent\nasync def explain() -&gt; str:\n    \"\"\"\n    In Jinja2, use {% raw %}{{ variable }}{% endraw %} for templates.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#practice-exercises","title":"Practice Exercises","text":""},{"location":"en/tutorials/02-templates/#exercise-1-user-profile-generator","title":"Exercise 1: User Profile Generator","text":"<p>Create an agent that generates user profiles:</p> <pre><code>from typing import List\n\n@agent\nasync def create_profile(\n    name: str,\n    skills: List[str],\n    experience_years: int\n) -&gt; str:\n    \"\"\"\n    # TODO: Write template that:\n    # - Introduces the person\n    # - Lists their skills\n    # - Mentions experience level\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#exercise-2-conditional-email-writer","title":"Exercise 2: Conditional Email Writer","text":"<p>Create an agent with conditional formatting:</p> <pre><code>@agent\nasync def write_email(\n    recipient: str,\n    is_urgent: bool,\n    has_attachments: bool\n) -&gt; str:\n    \"\"\"\n    # TODO: Write template that:\n    # - Adds [URGENT] to subject if urgent\n    # - Mentions attachments if present\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#exercise-3-data-analyzer","title":"Exercise 3: Data Analyzer","text":"<p>Create an agent that analyzes data with loops:</p> <pre><code>from typing import Dict\n\n@agent\nasync def analyze_metrics(metrics: Dict[str, float]) -&gt; str:\n    \"\"\"\n    # TODO: Write template that:\n    # - Iterates over metrics\n    # - Highlights values &gt; 80\n    # - Provides summary\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/02-templates/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial 03: Type-Based Parsing - Learn how to parse structured responses</li> <li>API Reference: Templates - Complete template documentation</li> </ul>"},{"location":"en/tutorials/02-templates/#additional-resources","title":"Additional Resources","text":"<ul> <li>Jinja2 Documentation</li> <li>Prompt Engineering Guide</li> </ul>"},{"location":"en/tutorials/03-type-parsing/","title":"Tutorial 03: Type-Based Parsing","text":"<p>Learn how to use Python type hints to automatically parse LLM responses into structured data.</p>"},{"location":"en/tutorials/03-type-parsing/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How type-based parsing works in Kagura</li> <li>Using Pydantic models for complex structures</li> <li>Handling lists, dicts, and nested objects</li> <li>Error handling and validation</li> </ul>"},{"location":"en/tutorials/03-type-parsing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Tutorial 01: Basic Agent</li> <li>Basic understanding of Python type hints</li> <li>Familiarity with Pydantic (helpful but not required)</li> </ul>"},{"location":"en/tutorials/03-type-parsing/#why-type-based-parsing","title":"Why Type-Based Parsing?","text":"<p>LLMs return unstructured text, but your application needs structured data. Kagura automatically converts LLM responses to Python types based on your return type annotation.</p> <pre><code># Without parsing: raw string\nasync def get_age(name: str) -&gt; str:\n    \"\"\"What is {{ name }}'s age?\"\"\"\n    pass\n\nresult = await get_age(\"Alice\")\n# result = \"Alice is 25 years old.\"  \u2190 Hard to use in code\n\n# With parsing: structured data\nasync def get_age(name: str) -&gt; int:\n    \"\"\"What is {{ name }}'s age? Return only the number.\"\"\"\n    pass\n\nresult = await get_age(\"Alice\")\n# result = 25  \u2190 Easy to use!\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#basic-types","title":"Basic Types","text":""},{"location":"en/tutorials/03-type-parsing/#strings","title":"Strings","text":"<pre><code>from kagura import agent\n\n@agent\nasync def summarize(text: str) -&gt; str:\n    \"\"\"Summarize this in one sentence: {{ text }}\"\"\"\n    pass\n\nresult = await summarize(\"Long article...\")\n# result: str = \"Article summary.\"\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#numbers","title":"Numbers","text":"<pre><code>@agent\nasync def count_words(text: str) -&gt; int:\n    \"\"\"Count the words in: {{ text }}. Return only the number.\"\"\"\n    pass\n\nresult = await count_words(\"Hello world\")\n# result: int = 2\n\n@agent\nasync def calculate_average(numbers: list[int]) -&gt; float:\n    \"\"\"Calculate the average of {{ numbers }}. Return only the number.\"\"\"\n    pass\n\nresult = await calculate_average([1, 2, 3, 4, 5])\n# result: float = 3.0\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#booleans","title":"Booleans","text":"<pre><code>@agent\nasync def is_positive(text: str) -&gt; bool:\n    \"\"\"Is this text positive in sentiment? {{ text }}\n    Return only 'true' or 'false'.\"\"\"\n    pass\n\nresult = await is_positive(\"I love this!\")\n# result: bool = True\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#collections","title":"Collections","text":""},{"location":"en/tutorials/03-type-parsing/#lists","title":"Lists","text":"<pre><code>from typing import List\n\n@agent\nasync def extract_keywords(text: str) -&gt; List[str]:\n    \"\"\"Extract keywords from: {{ text }}\n    Return as JSON array.\"\"\"\n    pass\n\nresult = await extract_keywords(\"Python is great for AI\")\n# result: List[str] = [\"Python\", \"AI\", \"programming\"]\n</code></pre> <p>Supported List Types: - <code>List[str]</code>: List of strings - <code>List[int]</code>: List of integers - <code>List[float]</code>: List of floats - <code>List[YourModel]</code>: List of Pydantic models</p>"},{"location":"en/tutorials/03-type-parsing/#dictionaries","title":"Dictionaries","text":"<pre><code>from typing import Dict\n\n@agent\nasync def extract_metadata(text: str) -&gt; Dict[str, str]:\n    \"\"\"Extract metadata from: {{ text }}\n    Return as JSON object.\"\"\"\n    pass\n\nresult = await extract_metadata(\"Title: Hello\\nAuthor: Alice\")\n# result: Dict[str, str] = {\"title\": \"Hello\", \"author\": \"Alice\"}\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#pydantic-models","title":"Pydantic Models","text":"<p>For complex structures, use Pydantic models:</p> <pre><code>from pydantic import BaseModel, Field\nfrom typing import List\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    email: str\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    \"\"\"Extract person information from: {{ text }}\n    Return as JSON object with fields: name, age, email.\"\"\"\n    pass\n\nresult = await extract_person(\"Alice (25) - alice@example.com\")\n# result: Person = Person(name=\"Alice\", age=25, email=\"alice@example.com\")\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#model-validation","title":"Model Validation","text":"<p>Pydantic automatically validates the data:</p> <pre><code>from pydantic import BaseModel, EmailStr, validator\n\nclass User(BaseModel):\n    name: str\n    email: EmailStr  # Validates email format\n    age: int\n\n    @validator('age')\n    def age_must_be_positive(cls, v):\n        if v &lt; 0:\n            raise ValueError('age must be positive')\n        return v\n\n@agent\nasync def extract_user(text: str) -&gt; User:\n    \"\"\"Extract user info from: {{ text }}\n    Return as JSON: {name, email, age}\"\"\"\n    pass\n\n# Valid input\nresult = await extract_user(\"Bob, bob@example.com, 30\")\n# result: User(name=\"Bob\", email=\"bob@example.com\", age=30)\n\n# Invalid input (bad email)\n# Will raise ValidationError\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#field-descriptions","title":"Field Descriptions","text":"<p>Help the LLM understand fields:</p> <pre><code>class Article(BaseModel):\n    title: str = Field(description=\"The article title\")\n    summary: str = Field(description=\"Brief summary, max 100 words\")\n    tags: List[str] = Field(description=\"Relevant tags, 3-5 items\")\n    published: bool = Field(description=\"Whether article is published\")\n\n@agent\nasync def analyze_article(content: str) -&gt; Article:\n    \"\"\"Analyze this article: {{ content }}\n    Return as JSON with: title, summary, tags, published.\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#nested-structures","title":"Nested Structures","text":""},{"location":"en/tutorials/03-type-parsing/#nested-models","title":"Nested Models","text":"<pre><code>class Address(BaseModel):\n    street: str\n    city: str\n    country: str\n\nclass Company(BaseModel):\n    name: str\n    address: Address\n    employees: int\n\n@agent\nasync def extract_company(text: str) -&gt; Company:\n    \"\"\"Extract company information from: {{ text }}\n    Return as JSON with nested address object.\"\"\"\n    pass\n\nresult = await extract_company(\"Acme Corp, 123 Main St, NYC, USA, 500 employees\")\n# result: Company(\n#     name=\"Acme Corp\",\n#     address=Address(street=\"123 Main St\", city=\"NYC\", country=\"USA\"),\n#     employees=500\n# )\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#lists-of-models","title":"Lists of Models","text":"<pre><code>class Task(BaseModel):\n    title: str\n    priority: str\n    estimated_hours: int\n\n@agent\nasync def extract_tasks(text: str) -&gt; List[Task]:\n    \"\"\"Extract tasks from: {{ text }}\n    Return as JSON array of objects.\"\"\"\n    pass\n\nresult = await extract_tasks(\"\"\"\n    1. Fix bug - High priority - 3 hours\n    2. Write docs - Low priority - 5 hours\n\"\"\")\n# result: List[Task] = [\n#     Task(title=\"Fix bug\", priority=\"High\", estimated_hours=3),\n#     Task(title=\"Write docs\", priority=\"Low\", estimated_hours=5)\n# ]\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"en/tutorials/03-type-parsing/#optional-fields","title":"Optional Fields","text":"<pre><code>from typing import Optional\n\nclass Product(BaseModel):\n    name: str\n    price: float\n    discount: Optional[float] = None\n    description: Optional[str] = None\n\n@agent\nasync def extract_product(text: str) -&gt; Product:\n    \"\"\"Extract product info from: {{ text }}\n    Return as JSON. discount and description are optional.\"\"\"\n    pass\n\nresult = await extract_product(\"Laptop $999\")\n# result: Product(name=\"Laptop\", price=999.0, discount=None, description=None)\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#union-types","title":"Union Types","text":"<pre><code>from typing import Union\n\n@agent\nasync def parse_value(text: str) -&gt; Union[int, str]:\n    \"\"\"Parse the value from: {{ text }}\n    Return as number if numeric, otherwise as string.\"\"\"\n    pass\n\nresult1 = await parse_value(\"42\")        # returns int: 42\nresult2 = await parse_value(\"hello\")     # returns str: \"hello\"\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#enums","title":"Enums","text":"<pre><code>from enum import Enum\n\nclass Priority(str, Enum):\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n\nclass Issue(BaseModel):\n    title: str\n    priority: Priority\n\n@agent\nasync def extract_issue(text: str) -&gt; Issue:\n    \"\"\"Extract issue from: {{ text }}\n    Priority must be: low, medium, or high.\"\"\"\n    pass\n\nresult = await extract_issue(\"Fix login bug - high priority\")\n# result: Issue(title=\"Fix login bug\", priority=Priority.HIGH)\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/03-type-parsing/#1-clear-return-format-instructions","title":"1. Clear Return Format Instructions","text":"<pre><code># \u2705 Good: Explicit format\n@agent\nasync def extract_data(text: str) -&gt; Person:\n    \"\"\"Extract person from: {{ text }}\n    Return as JSON: {\"name\": str, \"age\": int, \"email\": str}\"\"\"\n    pass\n\n# \u274c Bad: Unclear format\n@agent\nasync def extract_data(text: str) -&gt; Person:\n    \"\"\"Get person from: {{ text }}\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#2-use-field-descriptions","title":"2. Use Field Descriptions","text":"<pre><code># \u2705 Good: Descriptive fields\nclass Report(BaseModel):\n    summary: str = Field(description=\"Executive summary, 2-3 sentences\")\n    findings: List[str] = Field(description=\"Key findings, bullet points\")\n    score: int = Field(description=\"Overall score 0-100\")\n\n# \u274c Bad: No descriptions\nclass Report(BaseModel):\n    summary: str\n    findings: List[str]\n    score: int\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#3-validate-constraints","title":"3. Validate Constraints","text":"<pre><code>from pydantic import validator, Field\n\nclass Temperature(BaseModel):\n    celsius: float = Field(ge=-273.15, description=\"Temperature in Celsius\")\n\n    @validator('celsius')\n    def validate_temp(cls, v):\n        if v &lt; -273.15:\n            raise ValueError('Temperature below absolute zero')\n        return v\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#4-handle-errors-gracefully","title":"4. Handle Errors Gracefully","text":"<pre><code>from pydantic import ValidationError\n\n@agent\nasync def extract_safe(text: str) -&gt; Optional[Person]:\n    \"\"\"Extract person from: {{ text }}\n    Return as JSON or null if not found.\"\"\"\n    pass\n\ntry:\n    result = await extract_safe(\"No person here\")\nexcept ValidationError as e:\n    print(f\"Validation failed: {e}\")\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#error-handling","title":"Error Handling","text":""},{"location":"en/tutorials/03-type-parsing/#validation-errors","title":"Validation Errors","text":"<pre><code>from pydantic import ValidationError\n\n@agent\nasync def parse_age(text: str) -&gt; int:\n    \"\"\"Extract age from: {{ text }}. Return only the number.\"\"\"\n    pass\n\ntry:\n    result = await parse_age(\"Alice is twenty-five\")\n    # LLM returns \"twenty-five\" instead of 25\nexcept ValidationError as e:\n    print(f\"Failed to parse: {e}\")\n    # Handle error: retry, use default, etc.\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#missing-fields","title":"Missing Fields","text":"<pre><code>class Contact(BaseModel):\n    name: str\n    email: str\n    phone: str  # Required\n\n@agent\nasync def extract_contact(text: str) -&gt; Contact:\n    \"\"\"Extract contact from: {{ text }}\n    Return JSON with: name, email, phone.\"\"\"\n    pass\n\n# If LLM omits phone, ValidationError is raised\ntry:\n    result = await extract_contact(\"John, john@example.com\")\nexcept ValidationError as e:\n    print(\"Missing required field:\", e)\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#type-mismatches","title":"Type Mismatches","text":"<pre><code>@agent\nasync def get_count(text: str) -&gt; int:\n    \"\"\"Count items in: {{ text }}. Return only the number.\"\"\"\n    pass\n\n# If LLM returns \"five\" instead of 5\ntry:\n    result = await get_count(\"five items\")\nexcept ValidationError:\n    # Retry with more explicit instructions\n    @agent\n    async def get_count_strict(text: str) -&gt; int:\n        \"\"\"Count items in: {{ text }}.\n        Return ONLY a numeric digit, no words.\"\"\"\n        pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#common-patterns","title":"Common Patterns","text":""},{"location":"en/tutorials/03-type-parsing/#progressive-extraction","title":"Progressive Extraction","text":"<pre><code># Step 1: Extract basic info\n@agent\nasync def extract_basic(text: str) -&gt; Dict[str, str]:\n    \"\"\"Extract key-value pairs from: {{ text }}\"\"\"\n    pass\n\n# Step 2: Parse into model\nbasic = await extract_basic(text)\nperson = Person(**basic)\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#fallback-values","title":"Fallback Values","text":"<pre><code>class Config(BaseModel):\n    timeout: int = 30  # Default value\n    retries: int = 3\n    debug: bool = False\n\n@agent\nasync def parse_config(text: str) -&gt; Config:\n    \"\"\"Parse config from: {{ text }}\n    Use defaults for missing values.\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#multi-step-validation","title":"Multi-Step Validation","text":"<pre><code>class ValidatedData(BaseModel):\n    data: str\n\n    @validator('data')\n    def clean_data(cls, v):\n        # Clean and validate\n        return v.strip().lower()\n\n@agent\nasync def extract_and_validate(text: str) -&gt; ValidatedData:\n    \"\"\"Extract data from: {{ text }}\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#practice-exercises","title":"Practice Exercises","text":""},{"location":"en/tutorials/03-type-parsing/#exercise-1-contact-extractor","title":"Exercise 1: Contact Extractor","text":"<p>Create a model for contact information:</p> <pre><code>class Contact(BaseModel):\n    # TODO: Add fields for name, email, phone, company\n    pass\n\n@agent\nasync def extract_contact(text: str) -&gt; Contact:\n    \"\"\"# TODO: Write prompt to extract contact info\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#exercise-2-product-list-parser","title":"Exercise 2: Product List Parser","text":"<p>Parse a list of products:</p> <pre><code>class Product(BaseModel):\n    # TODO: Add fields for name, price, stock\n    pass\n\n@agent\nasync def parse_products(text: str) -&gt; List[Product]:\n    \"\"\"# TODO: Write prompt to parse product list\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#exercise-3-nested-organization","title":"Exercise 3: Nested Organization","text":"<p>Create a nested structure:</p> <pre><code>class Employee(BaseModel):\n    # TODO: name, role, salary\n    pass\n\nclass Department(BaseModel):\n    # TODO: name, employees list, budget\n    pass\n\n@agent\nasync def parse_org(text: str) -&gt; Department:\n    \"\"\"# TODO: Write prompt to parse organization\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/03-type-parsing/#llm-returns-wrong-format","title":"LLM Returns Wrong Format","text":"<pre><code># Problem: LLM returns \"The age is 25\" instead of just \"25\"\n\n# Solution: Be more explicit\n@agent\nasync def get_age(name: str) -&gt; int:\n    \"\"\"What is {{ name }}'s age?\n    IMPORTANT: Return ONLY the numeric age, nothing else.\n    Example: 25\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#validation-fails-repeatedly","title":"Validation Fails Repeatedly","text":"<pre><code># Problem: LLM returns data that fails validation\n\n# Solution: Relax constraints or provide examples\nclass Person(BaseModel):\n    age: int = Field(ge=0, le=150, description=\"Age between 0-150\")\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    \"\"\"Extract person from: {{ text }}\n    Return JSON: {\"name\": \"string\", \"age\": number between 0-150}\n    Example: {\"name\": \"Alice\", \"age\": 25}\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/03-type-parsing/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial 04: Code Execution - Execute Python code with AI</li> <li>API Reference: Type Parsing - Complete parsing documentation</li> <li>Pydantic Documentation - Learn more about Pydantic</li> </ul>"},{"location":"en/tutorials/03-type-parsing/#additional-resources","title":"Additional Resources","text":"<ul> <li>Type Hints Cheat Sheet</li> <li>Pydantic Field Types</li> </ul>"},{"location":"en/tutorials/04-code-execution/","title":"Tutorial 04: Code Execution","text":"<p>Learn how to safely execute Python code generated by AI agents.</p>"},{"location":"en/tutorials/04-code-execution/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How to use the <code>execute_code</code> agent</li> <li>Security constraints and sandboxing</li> <li>Working with execution results</li> <li>Building code-generating workflows</li> <li>Best practices for code execution</li> </ul>"},{"location":"en/tutorials/04-code-execution/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Tutorial 01: Basic Agent</li> <li>Understanding of Python basics</li> <li>Familiarity with security concepts (helpful)</li> </ul>"},{"location":"en/tutorials/04-code-execution/#why-code-execution","title":"Why Code Execution?","text":"<p>Sometimes the best way to solve a problem is to write and execute code. Kagura provides a safe way to let AI agents generate and run Python code:</p> <pre><code>from kagura.agents import execute_code\n\nresult = await execute_code(\"Calculate the factorial of 10\")\n\nif result[\"success\"]:\n    print(result[\"result\"])  # 3628800\n    print(result[\"code\"])    # Shows the generated code\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#basic-usage","title":"Basic Usage","text":""},{"location":"en/tutorials/04-code-execution/#simple-calculations","title":"Simple Calculations","text":"<pre><code>from kagura.agents import execute_code\n\n# Mathematical operations\nresult = await execute_code(\"What is 2^10?\")\nprint(result[\"result\"])  # 1024\n\n# Data processing\nresult = await execute_code(\"Sum the numbers from 1 to 100\")\nprint(result[\"result\"])  # 5050\n\n# String operations\nresult = await execute_code(\"Reverse the string 'hello'\")\nprint(result[\"result\"])  # \"olleh\"\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#understanding-the-result","title":"Understanding the Result","text":"<p>The <code>execute_code</code> function returns a dictionary:</p> <pre><code>result = {\n    \"success\": True,         # Whether execution succeeded\n    \"result\": 3628800,       # The value of the `result` variable\n    \"code\": \"...\",          # The generated Python code\n    \"error\": None           # Error message if failed\n}\n</code></pre> <p>Important: The executed code must set a variable named <code>result</code>:</p> <pre><code># \u2705 Good: Sets result variable\nresult = await execute_code(\"Calculate 5 * 5\")\n# Generated code: result = 5 * 5\n\n# \u274c Bad: Doesn't set result\nresult = await execute_code(\"Print hello world\")\n# No result variable \u2192 result[\"result\"] is None\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#data-processing","title":"Data Processing","text":""},{"location":"en/tutorials/04-code-execution/#working-with-lists","title":"Working with Lists","text":"<pre><code># Filter data\nresult = await execute_code(\"\"\"\nFind all even numbers in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\"\"\")\nprint(result[\"result\"])  # [2, 4, 6, 8, 10]\n\n# Transform data\nresult = await execute_code(\"\"\"\nSquare each number in [1, 2, 3, 4, 5]\n\"\"\")\nprint(result[\"result\"])  # [1, 4, 9, 16, 25]\n\n# Aggregate data\nresult = await execute_code(\"\"\"\nCalculate the average of [10, 20, 30, 40, 50]\n\"\"\")\nprint(result[\"result\"])  # 30.0\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#working-with-dictionaries","title":"Working with Dictionaries","text":"<pre><code># Extract data\nresult = await execute_code(\"\"\"\nFrom this data: {'name': 'Alice', 'age': 25, 'city': 'NYC'}\nExtract the age\n\"\"\")\nprint(result[\"result\"])  # 25\n\n# Transform data\nresult = await execute_code(\"\"\"\nConvert this data to uppercase keys:\n{'name': 'Alice', 'role': 'engineer'}\n\"\"\")\nprint(result[\"result\"])  # {'NAME': 'Alice', 'ROLE': 'engineer'}\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#json-processing","title":"JSON Processing","text":"<pre><code>import json\n\n# Parse and analyze JSON\njson_data = json.dumps({\n    \"users\": [\n        {\"name\": \"Alice\", \"score\": 95},\n        {\"name\": \"Bob\", \"score\": 87},\n        {\"name\": \"Charlie\", \"score\": 92}\n    ]\n})\n\nresult = await execute_code(f\"\"\"\nParse this JSON and find the average score:\n{json_data}\n\"\"\")\nprint(result[\"result\"])  # 91.33...\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#advanced-features","title":"Advanced Features","text":""},{"location":"en/tutorials/04-code-execution/#multi-step-calculations","title":"Multi-Step Calculations","text":"<pre><code>result = await execute_code(\"\"\"\n1. Create a list of numbers from 1 to 20\n2. Filter only prime numbers\n3. Calculate their sum\n\"\"\")\n\nprint(result[\"code\"])    # See the generated algorithm\nprint(result[\"result\"])  # Sum of primes\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#custom-algorithms","title":"Custom Algorithms","text":"<pre><code>result = await execute_code(\"\"\"\nImplement the Fibonacci sequence up to the 10th number\n\"\"\")\n\nprint(result[\"result\"])  # [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#data-analysis","title":"Data Analysis","text":"<pre><code>result = await execute_code(\"\"\"\nGiven these test scores: [78, 92, 85, 88, 95, 72, 90]\nCalculate:\n- Mean\n- Median\n- Mode (if exists)\nReturn as a dictionary\n\"\"\")\n\nprint(result[\"result\"])\n# {'mean': 85.71, 'median': 88, 'mode': None}\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#security","title":"Security","text":"<p>Kagura executes code in a sandboxed environment with strict security constraints.</p>"},{"location":"en/tutorials/04-code-execution/#allowed-modules","title":"Allowed Modules","text":"<pre><code># \u2705 Allowed: Safe standard library modules\nresult = await execute_code(\"\"\"\nimport math\nresult = math.sqrt(16)\n\"\"\")\n# Success: 4.0\n\nresult = await execute_code(\"\"\"\nimport json\nresult = json.dumps({'key': 'value'})\n\"\"\")\n# Success: '{\"key\": \"value\"}'\n\nresult = await execute_code(\"\"\"\nfrom datetime import datetime\nresult = datetime.now().year\n\"\"\")\n# Success: 2025\n</code></pre> <p>Allowed modules: - <code>math</code>, <code>random</code>, <code>statistics</code> - <code>json</code>, <code>re</code>, <code>string</code> - <code>datetime</code>, <code>collections</code>, <code>itertools</code> - <code>functools</code>, <code>operator</code>, <code>copy</code></p>"},{"location":"en/tutorials/04-code-execution/#forbidden-operations","title":"Forbidden Operations","text":"<pre><code># \u274c File system access\nresult = await execute_code(\"Read file config.txt\")\n# Error: Forbidden import: os\n\n# \u274c Network access\nresult = await execute_code(\"Fetch data from https://api.example.com\")\n# Error: Forbidden import: requests\n\n# \u274c System commands\nresult = await execute_code(\"Run shell command ls\")\n# Error: Forbidden import: subprocess\n\n# \u274c Code execution\nresult = await execute_code(\"Execute eval('1+1')\")\n# Error: Forbidden operation: eval\n</code></pre> <p>Forbidden modules/operations: - File I/O: <code>os</code>, <code>sys</code>, <code>io</code>, <code>pathlib</code>, <code>open()</code> - Network: <code>socket</code>, <code>urllib</code>, <code>requests</code> - Execution: <code>eval</code>, <code>exec</code>, <code>compile</code>, <code>__import__</code> - System: <code>subprocess</code>, <code>multiprocessing</code></p>"},{"location":"en/tutorials/04-code-execution/#timeout-protection","title":"Timeout Protection","text":"<pre><code>from kagura.core.executor import CodeExecutor\n\n# Default timeout: 5 seconds\nexecutor = CodeExecutor()\n\n# Custom timeout\nexecutor = CodeExecutor(timeout=10.0)\n\nresult = await executor.execute(\"\"\"\nimport time\ntime.sleep(15)  # Will timeout after 10 seconds\nresult = \"done\"\n\"\"\")\n\nprint(result.success)  # False\nprint(result.error)    # \"Execution timeout\"\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#custom-codeexecutor","title":"Custom CodeExecutor","text":"<p>For advanced use cases, use <code>CodeExecutor</code> directly:</p> <pre><code>from kagura.core.executor import CodeExecutor\n\n# Create executor with custom settings\nexecutor = CodeExecutor(\n    timeout=10.0,           # 10 second timeout\n    max_output_size=1000    # Limit output size\n)\n\n# Execute code\nresult = await executor.execute(\"\"\"\nresult = sum(range(1, 1001))\n\"\"\")\n\nprint(result.success)    # True\nprint(result.result)     # 500500\nprint(result.code)       # Generated code\nprint(result.error)      # None\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#execution-result-object","title":"Execution Result Object","text":"<pre><code>from kagura.core.executor import ExecutionResult\n\nresult = await executor.execute(\"result = 42\")\n\n# Result attributes\nprint(result.success)    # bool: True/False\nprint(result.result)     # Any: The result value\nprint(result.code)       # str: Executed code\nprint(result.error)      # Optional[str]: Error message\nprint(result.stdout)     # str: Standard output\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#building-code-workflows","title":"Building Code Workflows","text":""},{"location":"en/tutorials/04-code-execution/#plan-code-execute-pattern","title":"Plan-Code-Execute Pattern","text":"<pre><code>from kagura import agent\nfrom kagura.agents import execute_code\n\n@agent\nasync def plan_solution(problem: str) -&gt; str:\n    \"\"\"\n    Analyze this problem and describe the algorithm:\n    {{ problem }}\n\n    Provide step-by-step approach.\n    \"\"\"\n    pass\n\nasync def solve_with_code(problem: str):\n    # Step 1: Plan\n    plan = await plan_solution(problem)\n    print(f\"Plan: {plan}\")\n\n    # Step 2: Execute\n    result = await execute_code(problem)\n\n    # Step 3: Verify\n    if result[\"success\"]:\n        print(f\"Result: {result['result']}\")\n        print(f\"Code:\\n{result['code']}\")\n    else:\n        print(f\"Error: {result['error']}\")\n\n# Use it\nawait solve_with_code(\"Find all prime numbers between 1 and 50\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#iterative-refinement","title":"Iterative Refinement","text":"<pre><code>async def solve_with_retry(problem: str, max_retries: int = 3):\n    for attempt in range(max_retries):\n        result = await execute_code(problem)\n\n        if result[\"success\"]:\n            return result[\"result\"]\n\n        # If failed, try with more specific instructions\n        problem = f\"{problem}\\n\\nPrevious error: {result['error']}\\nPlease fix and try again.\"\n\n    raise Exception(f\"Failed after {max_retries} attempts\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#code-review-agent","title":"Code Review Agent","text":"<pre><code>@agent\nasync def review_code(code: str) -&gt; str:\n    \"\"\"\n    Review this Python code for:\n    - Correctness\n    - Efficiency\n    - Best practices\n\n    Code:\n    ```python\n    {{ code }}\n    ```\n    \"\"\"\n    pass\n\nasync def code_and_review(problem: str):\n    # Generate code\n    result = await execute_code(problem)\n\n    if result[\"success\"]:\n        # Review the code\n        review = await review_code(result[\"code\"])\n        print(f\"Review: {review}\")\n\n        return result[\"result\"]\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/04-code-execution/#1-clear-specifications","title":"1. Clear Specifications","text":"<pre><code># \u2705 Good: Clear requirements\nresult = await execute_code(\"\"\"\nCalculate the factorial of 10.\nStore the result in a variable named 'result'.\n\"\"\")\n\n# \u274c Bad: Vague request\nresult = await execute_code(\"Do factorial stuff\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#2-handle-errors","title":"2. Handle Errors","text":"<pre><code># \u2705 Good: Error handling\nresult = await execute_code(problem)\n\nif result[\"success\"]:\n    process_result(result[\"result\"])\nelse:\n    logger.error(f\"Code execution failed: {result['error']}\")\n    fallback_solution()\n\n# \u274c Bad: No error handling\nresult = await execute_code(problem)\nprocess_result(result[\"result\"])  # May fail!\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#3-validate-results","title":"3. Validate Results","text":"<pre><code># \u2705 Good: Validate output\nresult = await execute_code(\"Calculate sum of [1,2,3]\")\n\nif result[\"success\"]:\n    value = result[\"result\"]\n    if isinstance(value, (int, float)) and value &gt; 0:\n        use_result(value)\n    else:\n        raise ValueError(f\"Unexpected result: {value}\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#4-provide-context","title":"4. Provide Context","text":"<pre><code># \u2705 Good: Context and examples\nresult = await execute_code(f\"\"\"\nGiven this data: {json.dumps(data)}\nExtract all items where status is 'active'\nReturn as a list\n\nExample output: [item1, item2, ...]\n\"\"\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#5-use-appropriate-timeout","title":"5. Use Appropriate Timeout","text":"<pre><code># \u2705 Good: Adjust timeout based on task\nexecutor = CodeExecutor(timeout=1.0)   # Quick tasks\nresult = await executor.execute(\"result = 2 + 2\")\n\nexecutor = CodeExecutor(timeout=30.0)  # Complex tasks\nresult = await executor.execute(\"Analyze large dataset...\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#common-patterns","title":"Common Patterns","text":""},{"location":"en/tutorials/04-code-execution/#data-transformation-pipeline","title":"Data Transformation Pipeline","text":"<pre><code>async def transform_data(data: list, operations: list[str]):\n    \"\"\"Apply multiple transformations to data\"\"\"\n    current_data = data\n\n    for operation in operations:\n        result = await execute_code(f\"\"\"\nApply this operation to the data: {operation}\nData: {current_data}\n\"\"\")\n        if result[\"success\"]:\n            current_data = result[\"result\"]\n        else:\n            raise Exception(f\"Failed: {result['error']}\")\n\n    return current_data\n\n# Use it\ndata = [1, 2, 3, 4, 5]\noperations = [\n    \"Multiply each by 2\",\n    \"Filter numbers &gt; 5\",\n    \"Sum all numbers\"\n]\nresult = await transform_data(data, operations)\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#calculator-agent","title":"Calculator Agent","text":"<pre><code>@agent\nasync def calculate(expression: str) -&gt; float:\n    \"\"\"A calculator agent that evaluates expressions\"\"\"\n    result = await execute_code(f\"Calculate: {expression}\")\n\n    if result[\"success\"]:\n        return result[\"result\"]\n    else:\n        raise ValueError(f\"Calculation failed: {result['error']}\")\n\n# Use it\nanswer = await calculate(\"(5 + 3) * 2 - 10\")\nprint(answer)  # 6.0\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#data-analysis-agent","title":"Data Analysis Agent","text":"<pre><code>async def analyze_dataset(data: list[dict], query: str):\n    \"\"\"Analyze structured data with natural language\"\"\"\n    data_str = json.dumps(data)\n\n    result = await execute_code(f\"\"\"\nDataset: {data_str}\nQuery: {query}\n\nAnalyze the dataset and answer the query.\n\"\"\")\n\n    return result[\"result\"] if result[\"success\"] else None\n\n# Use it\nsales_data = [\n    {\"product\": \"A\", \"revenue\": 1000},\n    {\"product\": \"B\", \"revenue\": 1500},\n    {\"product\": \"C\", \"revenue\": 800}\n]\n\nresult = await analyze_dataset(\n    sales_data,\n    \"What is the total revenue?\"\n)\nprint(result)  # 3300\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#practice-exercises","title":"Practice Exercises","text":""},{"location":"en/tutorials/04-code-execution/#exercise-1-prime-number-finder","title":"Exercise 1: Prime Number Finder","text":"<pre><code># TODO: Create a function that finds prime numbers\nasync def find_primes(n: int):\n    \"\"\"Find all prime numbers up to n\"\"\"\n    result = await execute_code(f\"\"\"\n    Find all prime numbers up to {n}\n    Return as a list\n    \"\"\")\n    return result[\"result\"] if result[\"success\"] else []\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#exercise-2-data-aggregator","title":"Exercise 2: Data Aggregator","text":"<pre><code># TODO: Create a function that aggregates data\nasync def aggregate_sales(sales: list[dict]) -&gt; dict:\n    \"\"\"Calculate total, average, min, max from sales data\"\"\"\n    # Use execute_code to analyze the sales list\n    pass\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#exercise-3-text-analyzer","title":"Exercise 3: Text Analyzer","text":"<pre><code># TODO: Create a function that analyzes text\nasync def analyze_text(text: str) -&gt; dict:\n    \"\"\"\n    Analyze text and return:\n    - word_count\n    - unique_words\n    - most_common_word\n    - average_word_length\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/04-code-execution/#result-is-none","title":"Result is None","text":"<pre><code># Problem: result[\"result\"] is None\n\n# Cause: Code doesn't set 'result' variable\nresult = await execute_code(\"print(42)\")  # Only prints\n\n# Solution: Ask for explicit result\nresult = await execute_code(\"Calculate 42 and store in result variable\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#timeout-errors","title":"Timeout Errors","text":"<pre><code># Problem: Execution timeout\n\n# Cause: Complex operation or infinite loop\nresult = await execute_code(\"Calculate factorial of 100000\")\n\n# Solution: Increase timeout or simplify\nexecutor = CodeExecutor(timeout=30.0)\nresult = await executor.execute(\"Calculate factorial of 100\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#security-errors","title":"Security Errors","text":"<pre><code># Problem: Forbidden import error\n\n# Cause: Trying to use restricted module\nresult = await execute_code(\"Read file data.txt\")\n\n# Solution: Use allowed modules or provide data\nresult = await execute_code(f\"Process this data: {data}\")\n</code></pre>"},{"location":"en/tutorials/04-code-execution/#next-steps","title":"Next Steps","text":"<ul> <li>Interactive Chat: Try <code>kagura chat</code> for hands-on experimentation</li> <li>API Reference: Code Execution - Complete executor documentation</li> <li>Examples: Code Generator - Full example</li> </ul>"},{"location":"en/tutorials/04-code-execution/#additional-resources","title":"Additional Resources","text":"<ul> <li>Python Security Best Practices</li> <li>AST Module Documentation</li> </ul>"},{"location":"en/tutorials/06-mcp-integration/","title":"MCP Integration","text":""},{"location":"en/tutorials/06-mcp-integration/#overview","title":"Overview","text":"<p>Kagura AI supports MCP (Model Context Protocol), enabling your agents to be used as tools in Claude Desktop, Claude Code, Cline, and other MCP-compatible applications.</p> <p>With MCP integration, you can: - Expose Kagura agents as MCP tools - Use agents from Claude Desktop/Code directly - Share agents across MCP-compatible applications - Build agent ecosystems with standard protocols</p>"},{"location":"en/tutorials/06-mcp-integration/#what-is-mcp","title":"What is MCP?","text":"<p>Model Context Protocol (MCP) is an open protocol developed by Anthropic that standardizes how AI applications connect to external tools and data sources.</p>"},{"location":"en/tutorials/06-mcp-integration/#installation","title":"Installation","text":"<p>Install Kagura AI with MCP support:</p> <pre><code>pip install kagura-ai[mcp]\n</code></pre> <p>Or with uv:</p> <pre><code>uv add \"kagura-ai[mcp]\"\n</code></pre> <p>This installs additional dependencies: - <code>mcp&gt;=1.0.0</code> - MCP SDK - <code>jsonschema&gt;=4.20.0</code> - Schema validation</p>"},{"location":"en/tutorials/06-mcp-integration/#quick-start","title":"Quick Start","text":""},{"location":"en/tutorials/06-mcp-integration/#1-create-an-agent","title":"1. Create an Agent","text":"<p>Create a simple agent in <code>my_agents.py</code>:</p> <pre><code>from kagura import agent\n\n@agent\nasync def analyze_code(code: str, language: str = \"python\") -&gt; str:\n    \"\"\"\n    Analyze code quality and suggest improvements.\n\n    code: Source code to analyze\n    language: Programming language (default: python)\n    \"\"\"\n    pass\n</code></pre> <p>That's it! The agent is automatically registered and ready to use via MCP.</p>"},{"location":"en/tutorials/06-mcp-integration/#2-start-mcp-server","title":"2. Start MCP Server","text":"<p>Start the Kagura MCP server:</p> <pre><code>kagura mcp serve\n</code></pre> <p>This starts a stdio-based MCP server that listens for requests.</p>"},{"location":"en/tutorials/06-mcp-integration/#3-configure-claude-desktop","title":"3. Configure Claude Desktop","text":"<p>Add Kagura to your Claude Desktop configuration:</p> <p>macOS: <code>~/Library/Application Support/Claude/claude_desktop_config.json</code> Windows: <code>%APPDATA%\\Claude\\claude_desktop_config.json</code> Linux: <code>~/.config/Claude/claude_desktop_config.json</code></p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n</code></pre> <p>Note: Replace <code>OPENAI_API_KEY</code> with your actual API key, or use <code>ANTHROPIC_API_KEY</code> if using Claude models.</p>"},{"location":"en/tutorials/06-mcp-integration/#4-restart-claude-desktop","title":"4. Restart Claude Desktop","text":"<ol> <li>Quit Claude Desktop completely</li> <li>Restart Claude Desktop</li> <li>Your Kagura agents are now available as tools!</li> </ol>"},{"location":"en/tutorials/06-mcp-integration/#5-use-your-agent-in-claude-desktop","title":"5. Use Your Agent in Claude Desktop","text":"<p>In Claude Desktop, simply ask:</p> <pre><code>Can you analyze this Python code for me?\n\ndef calculate(x):\n    return x * 2 + 3\n</code></pre> <p>Claude will automatically use your <code>analyze_code</code> agent via MCP.</p>"},{"location":"en/tutorials/06-mcp-integration/#configuration-options","title":"Configuration Options","text":""},{"location":"en/tutorials/06-mcp-integration/#custom-server-name","title":"Custom Server Name","text":"<pre><code>kagura mcp serve --name my-custom-server\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#environment-variables","title":"Environment Variables","text":"<p>Set API keys and other environment variables in the configuration:</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"${OPENAI_API_KEY}\",\n        \"MODEL\": \"gpt-4o-mini\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#multiple-agent-files","title":"Multiple Agent Files","text":"<p>If you have agents in multiple files, import them before starting the server:</p> <pre><code># startup.py\nimport my_agents\nimport more_agents\n\n# Agents are automatically registered on import\n</code></pre> <p>Then configure Claude Desktop to run your startup script:</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"python\",\n      \"args\": [\"-c\", \"import startup; from kagura.cli.main import cli; cli(['mcp', 'serve'])\"]\n    }\n  }\n}\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#managing-agents","title":"Managing Agents","text":""},{"location":"en/tutorials/06-mcp-integration/#list-registered-agents","title":"List Registered Agents","text":"<p>See all agents available via MCP:</p> <pre><code>kagura mcp list\n</code></pre> <p>Output: <pre><code>Registered agents (1):\n\n  \u2022 analyze_code\n    Analyze code quality and suggest improvements\n</code></pre></p>"},{"location":"en/tutorials/06-mcp-integration/#agent-naming-convention","title":"Agent Naming Convention","text":"<p>MCP tool names are prefixed with <code>kagura_</code>: - Agent function: <code>analyze_code</code> - MCP tool name: <code>kagura_analyze_code</code></p> <p>This prevents naming conflicts with other MCP tools.</p>"},{"location":"en/tutorials/06-mcp-integration/#advanced-usage","title":"Advanced Usage","text":""},{"location":"en/tutorials/06-mcp-integration/#multiple-agents","title":"Multiple Agents","text":"<p>Create multiple specialized agents:</p> <pre><code>from kagura import agent\n\n@agent\nasync def review_code(code: str) -&gt; str:\n    \"\"\"Review code and provide feedback\"\"\"\n    pass\n\n@agent\nasync def generate_tests(code: str, framework: str = \"pytest\") -&gt; str:\n    \"\"\"Generate unit tests for the code\"\"\"\n    pass\n\n@agent\nasync def explain_code(code: str, audience: str = \"beginner\") -&gt; str:\n    \"\"\"Explain code for different audiences\"\"\"\n    pass\n</code></pre> <p>All three agents are automatically available in Claude Desktop.</p>"},{"location":"en/tutorials/06-mcp-integration/#complex-input-types","title":"Complex Input Types","text":"<p>Use Pydantic models for structured inputs:</p> <pre><code>from kagura import agent\nfrom pydantic import BaseModel\n\nclass CodeReviewRequest(BaseModel):\n    code: str\n    language: str\n    focus_areas: list[str]\n\n@agent\nasync def detailed_review(request: CodeReviewRequest) -&gt; dict:\n    \"\"\"Perform detailed code review\"\"\"\n    return {\n        \"score\": 8.5,\n        \"issues\": [...],\n        \"suggestions\": [...]\n    }\n</code></pre> <p>The Pydantic model is automatically converted to JSON Schema for MCP.</p>"},{"location":"en/tutorials/06-mcp-integration/#error-handling","title":"Error Handling","text":"<p>Agents should handle errors gracefully:</p> <pre><code>@agent\nasync def safe_analysis(code: str) -&gt; str:\n    \"\"\"Analyze code with error handling\"\"\"\n    try:\n        # Analysis logic\n        return \"Analysis complete\"\n    except Exception as e:\n        return f\"Error during analysis: {str(e)}\"\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#integration-with-other-mcp-clients","title":"Integration with Other MCP Clients","text":"<p>Kagura MCP works with any MCP-compatible client:</p>"},{"location":"en/tutorials/06-mcp-integration/#claude-code-vs-code-extension","title":"Claude Code (VS Code Extension)","text":"<p>Add to <code>.vscode/settings.json</code>:</p> <pre><code>{\n  \"mcp.servers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"]\n    }\n  }\n}\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#cline-vs-code-extension","title":"Cline (VS Code Extension)","text":"<p>Similar configuration in Cline settings.</p>"},{"location":"en/tutorials/06-mcp-integration/#custom-mcp-clients","title":"Custom MCP Clients","text":"<p>Use the MCP Python SDK to connect:</p> <pre><code>from mcp import ClientSession\nimport asyncio\n\nasync def test_kagura_mcp():\n    async with ClientSession() as session:\n        # Connect to Kagura MCP server\n        await session.initialize()\n\n        # List tools\n        tools = await session.list_tools()\n        print(f\"Available tools: {[t.name for t in tools]}\")\n\n        # Call agent\n        result = await session.call_tool(\n            \"kagura_analyze_code\",\n            {\"code\": \"def hello(): print('hi')\"}\n        )\n        print(result)\n\nasyncio.run(test_kagura_mcp())\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#debugging","title":"Debugging","text":""},{"location":"en/tutorials/06-mcp-integration/#enable-verbose-logging","title":"Enable Verbose Logging","text":"<pre><code>kagura -v mcp serve\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#check-agent-registration","title":"Check Agent Registration","text":"<pre><code>kagura mcp list\n</code></pre> <p>If your agent doesn't appear: 1. Ensure the file is imported 2. Check the <code>@agent</code> decorator is applied 3. Verify no import errors</p>"},{"location":"en/tutorials/06-mcp-integration/#test-without-claude-desktop","title":"Test Without Claude Desktop","text":"<p>Use <code>mcp</code> CLI tool to test directly:</p> <pre><code># Install MCP CLI\nnpm install -g @modelcontextprotocol/cli\n\n# Test Kagura MCP server\nmcp call kagura_analyze_code '{\"code\": \"def test(): pass\"}'\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/06-mcp-integration/#1-clear-descriptions","title":"1. Clear Descriptions","text":"<p>Write clear docstrings - they become tool descriptions in Claude:</p> <pre><code>@agent\nasync def analyze_code(code: str, language: str = \"python\") -&gt; str:\n    \"\"\"\n    Analyze code quality and suggest improvements.\n\n    This agent examines code structure, identifies potential issues,\n    and provides actionable suggestions for improvement.\n\n    code: Source code to analyze\n    language: Programming language (python, javascript, etc.)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#2-type-hints","title":"2. Type Hints","text":"<p>Use type hints for automatic schema generation:</p> <pre><code>@agent\nasync def process_data(\n    data: list[dict[str, Any]],\n    max_items: int = 100,\n    include_metadata: bool = False\n) -&gt; dict[str, Any]:\n    \"\"\"Process data with options\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#3-default-values","title":"3. Default Values","text":"<p>Provide sensible defaults for optional parameters:</p> <pre><code>@agent\nasync def translate(\n    text: str,\n    target_language: str = \"English\",\n    tone: str = \"neutral\"\n) -&gt; str:\n    \"\"\"Translate text\"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#4-structured-output","title":"4. Structured Output","text":"<p>Return structured data when appropriate:</p> <pre><code>@agent\nasync def analyze_sentiment(text: str) -&gt; dict:\n    \"\"\"\n    Analyze sentiment of text\n\n    Returns:\n        {\n            \"sentiment\": \"positive\" | \"negative\" | \"neutral\",\n            \"confidence\": float,\n            \"keywords\": list[str]\n        }\n    \"\"\"\n    pass\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/06-mcp-integration/#agent-not-appearing-in-claude-desktop","title":"Agent Not Appearing in Claude Desktop","text":"<ol> <li>Check configuration file location</li> <li>macOS: <code>~/Library/Application Support/Claude/claude_desktop_config.json</code></li> <li>Windows: <code>%APPDATA%\\Claude\\claude_desktop_config.json</code></li> <li> <p>Linux: <code>~/.config/Claude/claude_desktop_config.json</code></p> </li> <li> <p>Verify JSON syntax <pre><code># Test JSON validity\ncat ~/Library/Application\\ Support/Claude/claude_desktop_config.json | python -m json.tool\n</code></pre></p> </li> <li> <p>Check server logs <pre><code>kagura -v mcp serve 2&gt; mcp_server.log\n</code></pre></p> </li> <li> <p>Restart Claude Desktop completely</p> </li> <li>Quit application</li> <li>Restart</li> <li>Check MCP indicator in status bar</li> </ol>"},{"location":"en/tutorials/06-mcp-integration/#authentication-errors","title":"Authentication Errors","text":"<p>Make sure API keys are set:</p> <pre><code>{\n  \"mcpServers\": {\n    \"kagura\": {\n      \"command\": \"kagura\",\n      \"args\": [\"mcp\", \"serve\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"sk-...\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#permission-errors","title":"Permission Errors","text":"<p>On Unix systems, ensure <code>kagura</code> is executable:</p> <pre><code>which kagura\nchmod +x $(which kagura)\n</code></pre>"},{"location":"en/tutorials/06-mcp-integration/#next-steps","title":"Next Steps","text":"<ul> <li> <p>API Reference - MCP API documentation</p> </li> <li> <p>MCP Specification - Learn more about MCP</p> </li> </ul>"},{"location":"en/tutorials/06-mcp-integration/#example-projects","title":"Example Projects","text":"<p>See <code>examples/mcp_integration/</code> for complete examples: - Code analysis agent - Multi-agent workflow - Custom tool integration</p>"},{"location":"en/tutorials/08-memory-management/","title":"Memory Management Tutorial","text":"<p>Learn how to build agents with memory capabilities using Kagura AI's memory management system.</p>"},{"location":"en/tutorials/08-memory-management/#introduction","title":"Introduction","text":"<p>Kagura AI provides a three-tier memory system:</p> <ol> <li>Working Memory: Temporary data during execution</li> <li>Context Memory: Conversation history</li> <li>Persistent Memory: Long-term storage</li> </ol> <p>All three are accessed through the unified <code>MemoryManager</code> interface.</p>"},{"location":"en/tutorials/08-memory-management/#quick-start","title":"Quick Start","text":""},{"location":"en/tutorials/08-memory-management/#basic-memory-usage","title":"Basic Memory Usage","text":"<pre><code>from kagura.core.memory import MemoryManager\n\n# Create memory manager\nmemory = MemoryManager(agent_name=\"my_assistant\")\n\n# Store and recall persistent data\nmemory.remember(\"user_name\", \"Alice\")\nname = memory.recall(\"user_name\")  # \"Alice\"\n\n# Track conversation\nmemory.add_message(\"user\", \"Hello!\")\nmemory.add_message(\"assistant\", \"Hi there!\")\n\n# Get conversation context\ncontext = memory.get_llm_context()\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#agent-with-memory","title":"Agent with Memory","text":"<pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n@agent(enable_memory=True)\nasync def greeter(name: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Greet {{ name }} personally\"\"\"\n\n    # Remember this person\n    memory.remember(f\"greeted_{name}\", True)\n\n    # Check if we've met before\n    met_before = memory.recall(f\"greeted_{name}\")\n\n    if met_before:\n        return f\"Welcome back, {name}!\"\n    else:\n        return f\"Nice to meet you, {name}!\"\n\n# First time\nresult = await greeter(\"Alice\")  # \"Nice to meet you, Alice!\"\n\n# Second time\nresult = await greeter(\"Alice\")  # \"Welcome back, Alice!\"\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#working-memory","title":"Working Memory","text":"<p>Temporary storage that's cleared after execution.</p>"},{"location":"en/tutorials/08-memory-management/#use-cases","title":"Use Cases","text":"<ul> <li>Tracking loop iterations</li> <li>Storing intermediate results</li> <li>Temporary configuration</li> </ul>"},{"location":"en/tutorials/08-memory-management/#example","title":"Example","text":"<pre><code>from kagura.core.memory import MemoryManager\n\nmemory = MemoryManager()\n\n# Store temporary data\nmemory.set_temp(\"retry_count\", 0)\nmemory.set_temp(\"current_task\", \"data_processing\")\n\n# Retrieve\ncount = memory.get_temp(\"retry_count\")  # 0\ntask = memory.get_temp(\"current_task\")  # \"data_processing\"\n\n# Check existence\nif memory.has_temp(\"retry_count\"):\n    count = memory.get_temp(\"retry_count\")\n    memory.set_temp(\"retry_count\", count + 1)\n\n# Delete\nmemory.delete_temp(\"current_task\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#context-memory","title":"Context Memory","text":"<p>Manages conversation history with automatic pruning.</p>"},{"location":"en/tutorials/08-memory-management/#message-roles","title":"Message Roles","text":"<ul> <li><code>\"user\"</code>: User messages</li> <li><code>\"assistant\"</code>: Agent responses</li> <li><code>\"system\"</code>: System prompts</li> </ul>"},{"location":"en/tutorials/08-memory-management/#basic-usage","title":"Basic Usage","text":"<pre><code>memory = MemoryManager(max_messages=100)\n\n# Add messages\nmemory.add_message(\"user\", \"What is AI?\")\nmemory.add_message(\"assistant\", \"AI stands for Artificial Intelligence...\")\n\n# Get all messages\nmessages = memory.get_context()\n\n# Get last N messages\nrecent = memory.get_context(last_n=5)\n\n# Get last user message\nlast_user = memory.get_last_message(role=\"user\")\nprint(last_user.content)  # \"What is AI?\"\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#llm-integration","title":"LLM Integration","text":"<pre><code># Get context for LLM API\nllm_messages = memory.get_llm_context()\n\n# Format: [{\"role\": \"user\", \"content\": \"...\"}, ...]\nfor msg in llm_messages:\n    print(f\"{msg['role']}: {msg['content']}\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#auto-pruning","title":"Auto-Pruning","text":"<p>Context memory automatically prunes old messages when exceeding the limit:</p> <pre><code>memory = MemoryManager(max_messages=3)\n\nmemory.add_message(\"user\", \"Message 1\")\nmemory.add_message(\"assistant\", \"Message 2\")\nmemory.add_message(\"user\", \"Message 3\")\n# 3 messages stored\n\nmemory.add_message(\"assistant\", \"Message 4\")\n# Only last 3 kept: Message 2, 3, 4\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#metadata","title":"Metadata","text":"<p>Attach metadata to messages:</p> <pre><code>memory.add_message(\n    \"assistant\",\n    \"The answer is 42\",\n    metadata={\n        \"confidence\": 0.95,\n        \"source\": \"knowledge_base\",\n        \"timestamp\": \"2025-01-01T00:00:00Z\"\n    }\n)\n\nmessages = memory.get_context()\nprint(messages[0].metadata[\"confidence\"])  # 0.95\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#persistent-memory","title":"Persistent Memory","text":"<p>Long-term storage using SQLite.</p>"},{"location":"en/tutorials/08-memory-management/#basic-operations","title":"Basic Operations","text":"<pre><code>from pathlib import Path\n\nmemory = MemoryManager(\n    agent_name=\"my_agent\",\n    persist_dir=Path(\"./data\")\n)\n\n# Store\nmemory.remember(\"api_key\", \"sk-...\")\nmemory.remember(\"user_prefs\", {\"theme\": \"dark\", \"lang\": \"en\"})\n\n# Recall\napi_key = memory.recall(\"api_key\")\nprefs = memory.recall(\"user_prefs\")\n\n# Delete\nmemory.forget(\"api_key\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#search","title":"Search","text":"<p>Search using SQL LIKE patterns:</p> <pre><code># Store multiple items\nmemory.remember(\"user_name\", \"Alice\")\nmemory.remember(\"user_email\", \"alice@example.com\")\nmemory.remember(\"user_age\", 25)\nmemory.remember(\"product_name\", \"Widget\")\n\n# Search for user-related items\nresults = memory.search_memory(\"user\")\n# Returns: user_name, user_email, user_age\n\nfor item in results:\n    print(f\"{item['key']}: {item['value']}\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#agent-scoping","title":"Agent Scoping","text":"<p>Memories can be scoped to specific agents:</p> <pre><code># Agent 1\nmemory1 = MemoryManager(agent_name=\"agent1\")\nmemory1.remember(\"config\", {\"mode\": \"fast\"})\n\n# Agent 2\nmemory2 = MemoryManager(agent_name=\"agent2\")\nmemory2.remember(\"config\", {\"mode\": \"accurate\"})\n\n# Each agent has separate memories\nconfig1 = memory1.recall(\"config\")  # {\"mode\": \"fast\"}\nconfig2 = memory2.recall(\"config\")  # {\"mode\": \"accurate\"}\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#maintenance","title":"Maintenance","text":"<pre><code># Prune old memories (older than 30 days)\ndeleted = memory.prune_old(older_than_days=30)\nprint(f\"Deleted {deleted} old memories\")\n\n# Count memories\ncount = memory.persistent.count(agent_name=\"my_agent\")\nprint(f\"{count} memories stored\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#session-management","title":"Session Management","text":"<p>Save and restore complete agent state.</p>"},{"location":"en/tutorials/08-memory-management/#saving-sessions","title":"Saving Sessions","text":"<pre><code>memory = MemoryManager(agent_name=\"assistant\")\n\n# Have a conversation\nmemory.add_message(\"user\", \"What is machine learning?\")\nmemory.add_message(\"assistant\", \"Machine learning is...\")\n\n# Store temporary data\nmemory.set_temp(\"conversation_step\", 5)\n\n# Save everything\nmemory.save_session(\"ml_discussion\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#loading-sessions","title":"Loading Sessions","text":"<pre><code># Later... create new memory manager\nnew_memory = MemoryManager(agent_name=\"assistant\")\n\n# Restore session\nif new_memory.load_session(\"ml_discussion\"):\n    print(\"Session restored!\")\n\n    # Context is restored\n    messages = new_memory.get_context()\n    print(f\"Restored {len(messages)} messages\")\n\n    # Session ID is restored\n    session_id = new_memory.get_session_id()\nelse:\n    print(\"Session not found\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#agent-integration","title":"Agent Integration","text":""},{"location":"en/tutorials/08-memory-management/#enable-memory","title":"Enable Memory","text":"<p>Use <code>enable_memory=True</code> in the <code>@agent</code> decorator:</p> <pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n@agent(enable_memory=True)\nasync def chatbot(message: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Chat: {{ message }}\"\"\"\n\n    # Memory is automatically injected\n    memory.add_message(\"user\", message)\n\n    # Use memory for personalization\n    user_name = memory.recall(\"user_name\")\n    if user_name:\n        response = f\"Hello {user_name}! You said: {message}\"\n    else:\n        response = f\"Hello! You said: {message}\"\n\n    memory.add_message(\"assistant\", response)\n    return response\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#custom-configuration","title":"Custom Configuration","text":"<pre><code>from pathlib import Path\n\n@agent(\n    enable_memory=True,\n    persist_dir=Path(\"./agent_data\"),\n    max_messages=50\n)\nasync def my_agent(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Process: {{ query }}\"\"\"\n    # Custom persist directory and message limit\n    pass\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#practical-examples","title":"Practical Examples","text":""},{"location":"en/tutorials/08-memory-management/#personal-assistant","title":"Personal Assistant","text":"<pre><code>@agent(enable_memory=True)\nasync def personal_assistant(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Answer: {{ query }}\"\"\"\n\n    memory.add_message(\"user\", query)\n\n    # Learn user preferences\n    if \"my favorite color is\" in query.lower():\n        color = query.split(\"my favorite color is\")[-1].strip()\n        memory.remember(\"favorite_color\", color)\n\n    if \"my name is\" in query.lower():\n        name = query.split(\"my name is\")[-1].strip()\n        memory.remember(\"user_name\", name)\n\n    # Use learned information\n    name = memory.recall(\"user_name\") or \"there\"\n    fav_color = memory.recall(\"favorite_color\") or \"unknown\"\n\n    response = f\"Hi {name}! Your favorite color is {fav_color}.\"\n    memory.add_message(\"assistant\", response)\n\n    return response\n\n# Usage\nawait personal_assistant(\"Hi, my name is Alice\")\nawait personal_assistant(\"my favorite color is blue\")\nawait personal_assistant(\"what's my name?\")\n# \"Hi Alice! Your favorite color is blue.\"\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#multi-turn-conversation","title":"Multi-Turn Conversation","text":"<pre><code>@agent(enable_memory=True, max_messages=20)\nasync def conversational_agent(query: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Continue conversation: {{ query }}\n\n    Previous context:\n    {% for msg in context %}\n    {{ msg.role }}: {{ msg.content }}\n    {% endfor %}\n    \"\"\"\n\n    # Get recent context for prompt\n    context = memory.get_context(last_n=5)\n\n    # Add current message\n    memory.add_message(\"user\", query)\n\n    # Response would come from LLM\n    response = \"...\"  # LLM processes with full context\n\n    memory.add_message(\"assistant\", response)\n    return response\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#task-tracker","title":"Task Tracker","text":"<pre><code>@agent(enable_memory=True)\nasync def task_tracker(command: str, memory: MemoryManager) -&gt; str:\n    \"\"\"Manage tasks: {{ command }}\"\"\"\n\n    if command.startswith(\"add\"):\n        task = command[4:].strip()\n        tasks = memory.recall(\"tasks\") or []\n        tasks.append(task)\n        memory.remember(\"tasks\", tasks)\n        return f\"Added task: {task}\"\n\n    elif command == \"list\":\n        tasks = memory.recall(\"tasks\") or []\n        if not tasks:\n            return \"No tasks\"\n        return \"Tasks:\\n\" + \"\\n\".join(f\"- {t}\" for t in tasks)\n\n    elif command.startswith(\"done\"):\n        task = command[5:].strip()\n        tasks = memory.recall(\"tasks\") or []\n        if task in tasks:\n            tasks.remove(task)\n            memory.remember(\"tasks\", tasks)\n            return f\"Completed: {task}\"\n        return \"Task not found\"\n\n    return \"Unknown command\"\n\n# Usage\nawait task_tracker(\"add Write documentation\")\nawait task_tracker(\"add Review code\")\nawait task_tracker(\"list\")\n# \"Tasks:\\n- Write documentation\\n- Review code\"\nawait task_tracker(\"done Write documentation\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/08-memory-management/#1-use-appropriate-memory-types","title":"1. Use Appropriate Memory Types","text":"<ul> <li>Working Memory: Temporary state, loop counters, intermediate results</li> <li>Context Memory: Conversation history, user interactions</li> <li>Persistent Memory: User preferences, learned facts, configuration</li> </ul>"},{"location":"en/tutorials/08-memory-management/#2-set-reasonable-limits","title":"2. Set Reasonable Limits","text":"<pre><code># For chat applications\nmemory = MemoryManager(max_messages=50)  # Keep last 50 messages\n\n# For long-running agents\nmemory = MemoryManager(max_messages=200)  # More context\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#3-clean-up-old-data","title":"3. Clean Up Old Data","text":"<pre><code># Periodically prune old memories\nif datetime.now().day == 1:  # First day of month\n    deleted = memory.prune_old(older_than_days=90)\n    print(f\"Pruned {deleted} old memories\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#4-use-agent-scoping","title":"4. Use Agent Scoping","text":"<pre><code># Separate memories for different agents\ntranslator = MemoryManager(agent_name=\"translator\")\nsummarizer = MemoryManager(agent_name=\"summarizer\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#5-add-metadata","title":"5. Add Metadata","text":"<pre><code>memory.remember(\n    \"api_key\",\n    \"sk-...\",\n    metadata={\n        \"created\": \"2025-01-01\",\n        \"expires\": \"2026-01-01\",\n        \"environment\": \"production\"\n    }\n)\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/08-memory-management/#memory-not-persisting","title":"Memory Not Persisting","text":"<p>Ensure <code>persist_dir</code> exists:</p> <pre><code>from pathlib import Path\n\npersist_dir = Path(\"./data\")\npersist_dir.mkdir(exist_ok=True)\n\nmemory = MemoryManager(persist_dir=persist_dir)\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#context-too-large","title":"Context Too Large","text":"<p>Reduce <code>max_messages</code>:</p> <pre><code>memory = MemoryManager(max_messages=20)\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#agent-specific-memories","title":"Agent-Specific Memories","text":"<p>Always use <code>agent_name</code>:</p> <pre><code>memory = MemoryManager(agent_name=\"my_unique_agent\")\n</code></pre>"},{"location":"en/tutorials/08-memory-management/#next-steps","title":"Next Steps","text":"<ul> <li>Memory Management API Reference</li> <li>Code Execution Tutorial</li> <li>Shell Integration Tutorial</li> </ul>"},{"location":"en/tutorials/09-agent-routing/","title":"Agent Routing Tutorial","text":"<p>Learn how to use agent routing to automatically select the best agent for user requests.</p>"},{"location":"en/tutorials/09-agent-routing/#what-is-agent-routing","title":"What is Agent Routing?","text":"<p>Agent routing automatically selects the most appropriate agent based on user input, eliminating the need to manually choose which agent to call.</p> <p>Benefits: - \ud83c\udfaf Automatic agent selection - \ud83d\ude80 Simplified user experience - \ud83d\udd04 Easy to add new agents - \ud83c\udf10 Multilingual support</p>"},{"location":"en/tutorials/09-agent-routing/#quick-start","title":"Quick Start","text":""},{"location":"en/tutorials/09-agent-routing/#step-1-install-kagura-ai","title":"Step 1: Install Kagura AI","text":"<pre><code>pip install kagura-ai\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#step-2-define-agents","title":"Step 2: Define Agents","text":"<pre><code>from kagura import agent\n\n@agent\nasync def code_reviewer(code: str) -&gt; str:\n    '''Review code quality and suggest improvements.\n    Code: {{ code }}'''\n    pass\n\n@agent\nasync def translator(text: str, target_lang: str = \"en\") -&gt; str:\n    '''Translate text to target language.\n    Text: {{ text }}\n    Target: {{ target_lang }}'''\n    pass\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#step-3-create-router","title":"Step 3: Create Router","text":"<pre><code>from kagura.routing import AgentRouter\n\nrouter = AgentRouter()\n\n# Register agents with intent keywords\nrouter.register(\n    code_reviewer,\n    intents=[\"review\", \"check\", \"analyze\"],\n    description=\"Reviews code for quality and bugs\"\n)\n\nrouter.register(\n    translator,\n    intents=[\"translate\", \"\u7ffb\u8a33\", \"translation\"],\n    description=\"Translates text between languages\"\n)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#step-4-use-automatic-routing","title":"Step 4: Use Automatic Routing","text":"<pre><code># The router automatically selects the right agent!\nresult = await router.route(\"Please review this code\")\n# \u2192 code_reviewer is selected\n\nresult = await router.route(\"Translate 'Hello' to Japanese\")\n# \u2192 translator is selected\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#basic-usage","title":"Basic Usage","text":""},{"location":"en/tutorials/09-agent-routing/#registering-agents","title":"Registering Agents","text":"<p>Agents are registered with intent keywords that help the router identify them:</p> <pre><code>from kagura import agent\nfrom kagura.routing import AgentRouter\n\n@agent\nasync def python_expert(question: str) -&gt; str:\n    '''Python programming expert: {{ question }}'''\n    pass\n\nrouter = AgentRouter()\n\nrouter.register(\n    python_expert,\n    intents=[\n        \"python\",      # Programming language\n        \"decorator\",   # Python-specific concepts\n        \"asyncio\",\n        \"pip\"\n    ],\n    description=\"Answers Python programming questions\"\n)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#routing-requests","title":"Routing Requests","text":"<pre><code># These will all route to python_expert\nawait router.route(\"How do I use Python decorators?\")\nawait router.route(\"Explain asyncio in Python\")\nawait router.route(\"What's the best way to use pip?\")\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#confidence-threshold","title":"Confidence Threshold","text":"<p>The router calculates a confidence score for each agent. You can control the minimum required confidence:</p> <pre><code>router = AgentRouter(confidence_threshold=0.5)\n</code></pre> <p>How Confidence Works:</p> <pre><code># Agent has intents: [\"review\", \"check\", \"analyze\"]\nuser_input = \"review and check code\"\n\n# Scoring:\n# - \"review\" \u2713 matched\n# - \"check\"  \u2713 matched\n# - \"analyze\" \u2717 not matched\n# Score = 2/3 = 0.67 \u2192 Above threshold (0.5) \u2192 Agent selected\n</code></pre> <p>Lower threshold = more lenient matching Higher threshold = stricter matching</p> <pre><code># Lenient (more matches)\nrouter = AgentRouter(confidence_threshold=0.3)\n\n# Strict (fewer matches, higher accuracy)\nrouter = AgentRouter(confidence_threshold=0.7)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#fallback-agent","title":"Fallback Agent","text":"<p>Always provide a fallback agent for requests that don't match any registered agent:</p> <pre><code>@agent\nasync def general_assistant(query: str) -&gt; str:\n    '''General purpose assistant: {{ query }}'''\n    pass\n\nrouter = AgentRouter(\n    fallback_agent=general_assistant,\n    confidence_threshold=0.4\n)\n\n# If no agent matches or confidence is low, fallback is used\nresult = await router.route(\"What's the weather today?\")\n# \u2192 general_assistant (fallback) handles this\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#multilingual-support","title":"Multilingual Support","text":"<p>Add intent keywords in multiple languages:</p> <pre><code>router.register(\n    translator,\n    intents=[\n        # English\n        \"translate\", \"translation\",\n        # Japanese\n        \"\u7ffb\u8a33\", \"\u8a33\u3057\u3066\",\n        # Spanish\n        \"traducir\", \"traducci\u00f3n\",\n        # Korean\n        \"\ubc88\uc5ed\"\n    ],\n    description=\"Multilingual translator\"\n)\n\n# Works with any language\nawait router.route(\"\u3053\u306e\u6587\u7ae0\u3092\u7ffb\u8a33\u3057\u3066\")  # Japanese\nawait router.route(\"Traducir este texto\")  # Spanish\nawait router.route(\"\uc774\uac83\uc744 \ubc88\uc5ed\ud574\uc8fc\uc138\uc694\")  # Korean\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#checking-matched-agents","title":"Checking Matched Agents","text":"<p>See which agents match and their confidence scores:</p> <pre><code>matches = router.get_matched_agents(\"review my code\", top_k=3)\n\nfor agent, score in matches:\n    print(f\"{agent.__name__}: {score:.2f}\")\n\n# Output:\n# code_reviewer: 0.67\n# quality_checker: 0.33\n# general_assistant: 0.00\n</code></pre> <p>This is useful for: - Debugging routing issues - Tuning confidence thresholds - Understanding why an agent was selected</p>"},{"location":"en/tutorials/09-agent-routing/#semantic-routing-advanced","title":"Semantic Routing (Advanced)","text":"<p>Semantic routing uses embedding-based similarity matching for more intelligent routing. Instead of keyword matching, it understands the meaning of user queries.</p>"},{"location":"en/tutorials/09-agent-routing/#installation","title":"Installation","text":"<pre><code>pip install kagura-ai[ai]\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from kagura import agent\nfrom kagura.routing import AgentRouter\n\n@agent\nasync def code_reviewer(code: str) -&gt; str:\n    '''Review code: {{ code }}'''\n    pass\n\n@agent\nasync def translator(text: str, lang: str = \"en\") -&gt; str:\n    '''Translate: {{ text }} to {{ lang }}'''\n    pass\n\n# Create semantic router\nrouter = AgentRouter(strategy=\"semantic\")\n\n# Register with sample queries (not keywords!)\nrouter.register(\n    code_reviewer,\n    samples=[\n        \"Can you review this code?\",\n        \"Check my implementation\",\n        \"Look at this function\",\n        \"\u3053\u306e\u30b3\u30fc\u30c9\u3092\u30ec\u30d3\u30e5\u30fc\u3057\u3066\"  # Japanese\n    ]\n)\n\nrouter.register(\n    translator,\n    samples=[\n        \"Translate this text\",\n        \"Convert to Japanese\",\n        \"What does this mean in French?\",\n        \"\u7ffb\u8a33\u3057\u3066\"  # Japanese\n    ]\n)\n\n# Semantic matching understands meaning!\nawait router.route(\"Could you look at my Python script?\")\n# \u2192 code_reviewer (understands \"look at\" \u2248 \"review\")\n\nawait router.route(\"\u82f1\u8a9e\u3067\u4f55\u3066\u8a00\u3046\uff1f\")\n# \u2192 translator (understands Japanese intent)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#benefits-of-semantic-routing","title":"Benefits of Semantic Routing","text":"<p>\u2705 Understands synonyms: \"check\", \"review\", \"analyze\" all match \u2705 Cross-language: Matches meaning across languages \u2705 Context-aware: Understands similar phrases \u2705 No keyword tuning: Just provide natural examples</p>"},{"location":"en/tutorials/09-agent-routing/#intent-vs-semantic-comparison","title":"Intent vs Semantic Comparison","text":"Feature Intent (Keyword) Semantic (Embedding) Speed \u26a1 Very fast (&lt;1ms) \ud83d\udc22 Slower (~50-200ms) Cost \ud83d\udcb0 Free \ud83d\udcb5 API calls required Accuracy \u2713 Good for exact keywords \u2713\u2713 Better for natural language Setup Simple keywords Sample queries needed Offline \u2705 Yes \u274c No (needs API) <p>When to use Intent: - High-volume routing - Offline applications - Clear keyword patterns - Cost-sensitive applications</p> <p>When to use Semantic: - Natural language queries - Multilingual support - Complex intent understanding - User-facing chatbots</p>"},{"location":"en/tutorials/09-agent-routing/#configuration","title":"Configuration","text":"<pre><code># OpenAI encoder (default)\nrouter = AgentRouter(\n    strategy=\"semantic\",\n    encoder=\"openai\"\n)\n\n# Cohere encoder\nrouter = AgentRouter(\n    strategy=\"semantic\",\n    encoder=\"cohere\"\n)\n\n# With fallback and threshold\nrouter = AgentRouter(\n    strategy=\"semantic\",\n    fallback_agent=general_assistant,\n    confidence_threshold=0.7,\n    encoder=\"openai\"\n)\n</code></pre> <p>Environment Variables:</p> <pre><code># For OpenAI\nexport OPENAI_API_KEY=\"sk-...\"\n\n# For Cohere\nexport COHERE_API_KEY=\"...\"\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#practical-examples","title":"Practical Examples","text":""},{"location":"en/tutorials/09-agent-routing/#example-1-customer-support-bot","title":"Example 1: Customer Support Bot","text":"<pre><code>from kagura import agent\nfrom kagura.routing import AgentRouter\n\n# Define specialized agents\n@agent\nasync def billing_agent(query: str) -&gt; str:\n    '''Handle billing inquiries: {{ query }}'''\n    pass\n\n@agent\nasync def technical_agent(query: str) -&gt; str:\n    '''Handle technical issues: {{ query }}'''\n    pass\n\n@agent\nasync def general_agent(query: str) -&gt; str:\n    '''General customer support: {{ query }}'''\n    pass\n\n# Create router\nrouter = AgentRouter(\n    fallback_agent=general_agent,\n    confidence_threshold=0.4\n)\n\n# Register agents\nrouter.register(\n    billing_agent,\n    intents=[\"billing\", \"payment\", \"invoice\", \"charge\", \"subscription\"],\n    description=\"Handles billing and payment questions\"\n)\n\nrouter.register(\n    technical_agent,\n    intents=[\"technical\", \"bug\", \"error\", \"crash\", \"not working\"],\n    description=\"Handles technical support issues\"\n)\n\n# Use in chat loop\nasync def customer_support_chat():\n    print(\"Customer Support Bot (type 'exit' to quit)\")\n\n    while True:\n        query = input(\"\\nCustomer: \")\n        if query.lower() == \"exit\":\n            break\n\n        response = await router.route(query)\n        print(f\"Support: {response}\")\n\n# Run\nawait customer_support_chat()\n\n# Example conversation:\n# Customer: I was charged twice for my subscription\n# Support: [billing_agent handles this]\n#\n# Customer: The app keeps crashing on startup\n# Support: [technical_agent handles this]\n#\n# Customer: What are your business hours?\n# Support: [general_agent handles this]\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#example-2-development-assistant","title":"Example 2: Development Assistant","text":"<pre><code>@agent\nasync def code_generator(description: str) -&gt; str:\n    '''Generate code from description: {{ description }}'''\n    pass\n\n@agent\nasync def code_reviewer(code: str) -&gt; str:\n    '''Review code quality: {{ code }}'''\n    pass\n\n@agent\nasync def bug_finder(code: str) -&gt; str:\n    '''Find bugs in code: {{ code }}'''\n    pass\n\n@agent\nasync def documenter(code: str) -&gt; str:\n    '''Generate documentation: {{ code }}'''\n    pass\n\nrouter = AgentRouter(confidence_threshold=0.3)\n\nrouter.register(code_generator, intents=[\"generate\", \"create\", \"write\"])\nrouter.register(code_reviewer, intents=[\"review\", \"check\", \"assess\"])\nrouter.register(bug_finder, intents=[\"bug\", \"error\", \"issue\", \"debug\"])\nrouter.register(documenter, intents=[\"document\", \"docs\", \"comment\"])\n\n# Automatic task routing\nawait router.route(\"Generate a function to sort a list\")\n# \u2192 code_generator\n\nawait router.route(\"Check this code for issues\")\n# \u2192 code_reviewer\n\nawait router.route(\"Find bugs in this code\")\n# \u2192 bug_finder\n\nawait router.route(\"Add documentation to this function\")\n# \u2192 documenter\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#example-3-educational-platform","title":"Example 3: Educational Platform","text":"<pre><code>@agent\nasync def math_tutor(question: str) -&gt; str:\n    '''Math tutor: {{ question }}'''\n    pass\n\n@agent\nasync def physics_tutor(question: str) -&gt; str:\n    '''Physics tutor: {{ question }}'''\n    pass\n\n@agent\nasync def chemistry_tutor(question: str) -&gt; str:\n    '''Chemistry tutor: {{ question }}'''\n    pass\n\n@agent\nasync def general_tutor(question: str) -&gt; str:\n    '''General education tutor: {{ question }}'''\n    pass\n\nrouter = AgentRouter(\n    fallback_agent=general_tutor,\n    confidence_threshold=0.4\n)\n\nrouter.register(\n    math_tutor,\n    intents=[\"math\", \"algebra\", \"calculus\", \"geometry\", \"trigonometry\"],\n    description=\"Mathematics tutor\"\n)\n\nrouter.register(\n    physics_tutor,\n    intents=[\"physics\", \"mechanics\", \"thermodynamics\", \"electricity\"],\n    description=\"Physics tutor\"\n)\n\nrouter.register(\n    chemistry_tutor,\n    intents=[\"chemistry\", \"molecule\", \"reaction\", \"element\"],\n    description=\"Chemistry tutor\"\n)\n\n# Smart subject routing\nawait router.route(\"How do I solve quadratic equations?\")\n# \u2192 math_tutor\n\nawait router.route(\"Explain Newton's laws of motion\")\n# \u2192 physics_tutor\n\nawait router.route(\"What is a covalent bond?\")\n# \u2192 chemistry_tutor\n\nawait router.route(\"How do I study effectively?\")\n# \u2192 general_tutor (fallback)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#managing-agents","title":"Managing Agents","text":""},{"location":"en/tutorials/09-agent-routing/#list-registered-agents","title":"List Registered Agents","text":"<pre><code>agents = router.list_agents()\nprint(f\"Registered agents: {', '.join(agents)}\")\n# Registered agents: code_reviewer, translator, data_analyzer\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#get-agent-information","title":"Get Agent Information","text":"<pre><code>info = router.get_agent_info(\"code_reviewer\")\nprint(f\"Description: {info['description']}\")\nprint(f\"Intents: {info['intents']}\")\n\n# Output:\n# Description: Reviews code for quality and bugs\n# Intents: ['review', 'check', 'analyze']\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#error-handling","title":"Error Handling","text":""},{"location":"en/tutorials/09-agent-routing/#no-agent-found","title":"No Agent Found","text":"<pre><code>from kagura.routing import NoAgentFoundError\n\ntry:\n    result = await router.route(\"Unknown request\")\nexcept NoAgentFoundError as e:\n    print(f\"No agent found for: {e.user_input}\")\n    # Handle the error gracefully\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#with-fallback-recommended","title":"With Fallback (Recommended)","text":"<pre><code>@agent\nasync def fallback(query: str) -&gt; str:\n    '''Fallback handler: {{ query }}'''\n    pass\n\nrouter = AgentRouter(fallback_agent=fallback)\n\n# No exception raised - fallback is used automatically\nresult = await router.route(\"Any request\")\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/09-agent-routing/#1-use-specific-intent-keywords","title":"1. Use Specific Intent Keywords","text":"<pre><code># \u2705 Good: Specific, distinctive keywords\nrouter.register(\n    code_reviewer,\n    intents=[\"review\", \"code quality\", \"static analysis\"]\n)\n\n# \u274c Bad: Generic, overlapping keywords\nrouter.register(\n    code_reviewer,\n    intents=[\"help\", \"check\", \"look\"]\n)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#2-provide-agent-descriptions","title":"2. Provide Agent Descriptions","text":"<pre><code># \u2705 Good: Clear description\nrouter.register(\n    translator,\n    intents=[\"translate\"],\n    description=\"Translates text between 50+ languages\"\n)\n\n# \u274c Bad: No description\nrouter.register(translator, intents=[\"translate\"])\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#3-test-edge-cases","title":"3. Test Edge Cases","text":"<pre><code># Test ambiguous inputs\ntest_cases = [\n    \"review and translate\",  # Matches multiple agents\n    \"\",  # Empty input\n    \"xyz123\",  # Random input\n    \"\u3053\u3093\u306b\u3061\u306f\",  # Unicode\n]\n\nfor test in test_cases:\n    try:\n        matches = router.get_matched_agents(test)\n        print(f\"{test}: {len(matches)} matches\")\n    except Exception as e:\n        print(f\"{test}: Error - {e}\")\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#4-monitor-confidence-scores","title":"4. Monitor Confidence Scores","text":"<pre><code># Log routing decisions\nmatches = router.get_matched_agents(user_input, top_k=1)\nif matches:\n    agent, score = matches[0]\n    print(f\"Selected: {agent.__name__} (confidence: {score:.2f})\")\n\n    if score &lt; 0.5:\n        print(\"Warning: Low confidence routing\")\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#5-always-use-fallback","title":"5. Always Use Fallback","text":"<pre><code># \u2705 Good: Always have a fallback\nrouter = AgentRouter(fallback_agent=general_agent)\n\n# \u274c Bad: No fallback (exceptions for unmatched inputs)\nrouter = AgentRouter()\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/09-agent-routing/#agent-not-being-selected","title":"Agent Not Being Selected","text":"<p>Problem: Expected agent is not selected</p> <p>Solution: Check intent keywords and scoring</p> <pre><code># Debug: Check matched agents\nmatches = router.get_matched_agents(user_input, top_k=5)\nfor agent, score in matches:\n    print(f\"{agent.__name__}: {score:.2f}\")\n\n# If score is too low, add more intent keywords\nrouter.register(\n    my_agent,\n    intents=[\"original\", \"keywords\", \"plus\", \"more\", \"variants\"]\n)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#fallback-always-used","title":"Fallback Always Used","text":"<p>Problem: Fallback agent is always selected</p> <p>Solution: Lower confidence threshold or add more intent keywords</p> <pre><code># Option 1: Lower threshold\nrouter = AgentRouter(\n    fallback_agent=fallback,\n    confidence_threshold=0.2  # More lenient\n)\n\n# Option 2: Add more intents\nrouter.register(\n    my_agent,\n    intents=[\"many\", \"different\", \"keyword\", \"variations\"]\n)\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#multiple-agents-match","title":"Multiple Agents Match","text":"<p>Problem: Multiple agents have similar scores</p> <p>Solution: Make intents more specific</p> <pre><code># Before: Generic intents\nrouter.register(agent1, intents=[\"check\", \"analyze\"])\nrouter.register(agent2, intents=[\"check\", \"review\"])\n\n# After: Specific intents\nrouter.register(agent1, intents=[\"performance check\", \"load analysis\"])\nrouter.register(agent2, intents=[\"code review\", \"quality review\"])\n</code></pre>"},{"location":"en/tutorials/09-agent-routing/#next-steps","title":"Next Steps","text":"<ul> <li>Phase 2: Semantic routing with embedding-based matching</li> <li>Phase 3: Agent chaining and conditional routing</li> <li>Integration: Use with Chat REPL for conversational AI</li> </ul>"},{"location":"en/tutorials/09-agent-routing/#see-also","title":"See Also","text":"<ul> <li>Agent Routing API Reference</li> <li>Agent Decorator Guide</li> <li>RFC-016: Agent Routing System</li> </ul>"},{"location":"en/tutorials/11-tools/","title":"Tools Tutorial","text":"<p>The @tool decorator allows you to convert regular Python functions into tools that can be used by AI agents or exposed via MCP.</p>"},{"location":"en/tutorials/11-tools/#what-are-tools","title":"What are Tools?","text":"<p>Tools are non-LLM functions that provide deterministic, reliable functionality to your agents:</p> <ul> <li>Calculations: Math, tax, conversions</li> <li>Data Access: Database queries, API calls</li> <li>File Operations: Read, write, process files</li> <li>System Operations: Execute commands, manage resources</li> </ul> <p>Unlike <code>@agent</code> (which calls an LLM), <code>@tool</code> functions execute pure Python code.</p>"},{"location":"en/tutorials/11-tools/#quick-start","title":"Quick Start","text":""},{"location":"en/tutorials/11-tools/#basic-tool","title":"Basic Tool","text":"<pre><code>from kagura import tool\n\n@tool\ndef calculate_tax(amount: float, rate: float = 0.1) -&gt; float:\n    \"\"\"Calculate tax amount\"\"\"\n    return amount * rate\n\n# Call directly\ntax = calculate_tax(100.0, 0.15)  # 15.0\n</code></pre>"},{"location":"en/tutorials/11-tools/#using-tools-with-agents","title":"Using Tools with Agents","text":"<pre><code>from kagura import agent, tool\n\n@tool\ndef get_exchange_rate(from_currency: str, to_currency: str) -&gt; float:\n    \"\"\"Get currency exchange rate (simplified)\"\"\"\n    rates = {\n        (\"USD\", \"EUR\"): 0.85,\n        (\"EUR\", \"USD\"): 1.18,\n        (\"USD\", \"JPY\"): 110.0,\n    }\n    return rates.get((from_currency, to_currency), 1.0)\n\n@agent\nasync def currency_assistant(query: str) -&gt; str:\n    \"\"\"\n    Help with currency conversions.\n\n    Available tools:\n    - get_exchange_rate(from_currency, to_currency): Get exchange rate\n\n    Query: {{ query }}\n    \"\"\"\n    pass\n\n# Use\nresult = await currency_assistant(\"Convert 100 USD to EUR\")\n# AI will suggest using get_exchange_rate(\"USD\", \"EUR\") = 0.85\n# Then calculate: 100 * 0.85 = 85 EUR\n</code></pre>"},{"location":"en/tutorials/11-tools/#tool-features","title":"Tool Features","text":""},{"location":"en/tutorials/11-tools/#1-type-validation","title":"1. Type Validation","text":"<p>Tools automatically validate argument types:</p> <pre><code>@tool\ndef divide(a: float, b: float) -&gt; float:\n    \"\"\"Divide two numbers\"\"\"\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return a / b\n\n# Valid\nresult = divide(10.0, 2.0)  # 5.0\n\n# Invalid - raises TypeError\ndivide(10.0)  # Missing argument\ndivide(10.0, 2.0, 3.0)  # Too many arguments\n</code></pre>"},{"location":"en/tutorials/11-tools/#2-default-parameters","title":"2. Default Parameters","text":"<pre><code>@tool\ndef greet(name: str, greeting: str = \"Hello\") -&gt; str:\n    \"\"\"Greet someone\"\"\"\n    return f\"{greeting}, {name}!\"\n\ngreet(\"Alice\")  # \"Hello, Alice!\"\ngreet(\"Bob\", \"Hi\")  # \"Hi, Bob!\"\ngreet(name=\"Charlie\", greeting=\"Hey\")  # \"Hey, Charlie!\"\n</code></pre>"},{"location":"en/tutorials/11-tools/#3-custom-names","title":"3. Custom Names","text":"<pre><code>@tool(name=\"tax_calculator\")\ndef calc_tax(amount: float) -&gt; float:\n    \"\"\"Calculate 10% tax\"\"\"\n    return amount * 0.1\n\n# Registered as \"tax_calculator\" instead of \"calc_tax\"\n</code></pre>"},{"location":"en/tutorials/11-tools/#4-documentation","title":"4. Documentation","text":"<p>Docstrings are preserved for MCP integration:</p> <pre><code>@tool\ndef search_database(query: str, limit: int = 10) -&gt; list:\n    \"\"\"\n    Search database for records matching query.\n\n    Args:\n        query: Search query string\n        limit: Maximum number of results\n\n    Returns:\n        List of matching records\n    \"\"\"\n    # Implementation here\n    return []\n</code></pre>"},{"location":"en/tutorials/11-tools/#tool-registry","title":"Tool Registry","text":"<p>All tools are automatically registered in the global <code>tool_registry</code>:</p> <pre><code>from kagura.core.tool_registry import tool_registry\n\n# List all tools\nprint(tool_registry.list_names())\n# ['calculate_tax', 'get_exchange_rate', 'divide', ...]\n\n# Get a specific tool\ntax_tool = tool_registry.get(\"calculate_tax\")\nresult = tax_tool(100.0, 0.15)  # 15.0\n\n# Get all tools\nall_tools = tool_registry.get_all()\nfor name, func in all_tools.items():\n    print(f\"{name}: {func.__doc__}\")\n</code></pre>"},{"location":"en/tutorials/11-tools/#examples","title":"Examples","text":""},{"location":"en/tutorials/11-tools/#example-1-calculator-tools","title":"Example 1: Calculator Tools","text":"<pre><code>from kagura import tool\n\n@tool\ndef add(a: float, b: float) -&gt; float:\n    \"\"\"Add two numbers\"\"\"\n    return a + b\n\n@tool\ndef subtract(a: float, b: float) -&gt; float:\n    \"\"\"Subtract b from a\"\"\"\n    return a - b\n\n@tool\ndef multiply(a: float, b: float) -&gt; float:\n    \"\"\"Multiply two numbers\"\"\"\n    return a * b\n\n@tool\ndef divide(a: float, b: float) -&gt; float:\n    \"\"\"Divide a by b\"\"\"\n    if b == 0:\n        raise ValueError(\"Division by zero\")\n    return a / b\n\n# Use directly\nprint(add(5, 3))       # 8.0\nprint(multiply(4, 7))  # 28.0\n</code></pre>"},{"location":"en/tutorials/11-tools/#example-2-string-processing-tools","title":"Example 2: String Processing Tools","text":"<pre><code>@tool\ndef count_words(text: str) -&gt; int:\n    \"\"\"Count words in text\"\"\"\n    return len(text.split())\n\n@tool\ndef to_uppercase(text: str) -&gt; str:\n    \"\"\"Convert text to uppercase\"\"\"\n    return text.upper()\n\n@tool\ndef extract_emails(text: str) -&gt; list[str]:\n    \"\"\"Extract email addresses from text\"\"\"\n    import re\n    pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n    return re.findall(pattern, text)\n\n# Use\ntext = \"Contact: alice@example.com or bob@test.org\"\nemails = extract_emails(text)\nprint(emails)  # ['alice@example.com', 'bob@test.org']\n</code></pre>"},{"location":"en/tutorials/11-tools/#example-3-data-processing-tools","title":"Example 3: Data Processing Tools","text":"<pre><code>@tool\ndef filter_dict(data: dict, keys: list[str]) -&gt; dict:\n    \"\"\"Filter dictionary to only include specified keys\"\"\"\n    return {k: v for k, v in data.items() if k in keys}\n\n@tool\ndef merge_dicts(*dicts: dict) -&gt; dict:\n    \"\"\"Merge multiple dictionaries\"\"\"\n    result = {}\n    for d in dicts:\n        result.update(d)\n    return result\n\n@tool\ndef get_nested_value(data: dict, path: str, default=None):\n    \"\"\"Get value from nested dictionary using dot notation\"\"\"\n    keys = path.split('.')\n    value = data\n    for key in keys:\n        if isinstance(value, dict):\n            value = value.get(key, default)\n        else:\n            return default\n    return value\n\n# Use\ndata = {\"user\": {\"name\": \"Alice\", \"age\": 30, \"email\": \"alice@example.com\"}}\nname = get_nested_value(data, \"user.name\")  # \"Alice\"\n</code></pre>"},{"location":"en/tutorials/11-tools/#example-4-file-tools","title":"Example 4: File Tools","text":"<pre><code>import json\nfrom pathlib import Path\n\n@tool\ndef read_json_file(filepath: str) -&gt; dict:\n    \"\"\"Read and parse JSON file\"\"\"\n    with open(filepath) as f:\n        return json.load(f)\n\n@tool\ndef write_json_file(filepath: str, data: dict) -&gt; None:\n    \"\"\"Write data to JSON file\"\"\"\n    with open(filepath, 'w') as f:\n        json.dump(data, f, indent=2)\n\n@tool\ndef list_files(directory: str, extension: str = \"*\") -&gt; list[str]:\n    \"\"\"List files in directory with optional extension filter\"\"\"\n    path = Path(directory)\n    if extension == \"*\":\n        return [str(f) for f in path.iterdir() if f.is_file()]\n    return [str(f) for f in path.glob(f\"*.{extension}\")]\n\n# Use\nfiles = list_files(\".\", \"py\")  # All .py files in current directory\n</code></pre>"},{"location":"en/tutorials/11-tools/#integration-with-mcp","title":"Integration with MCP","text":"<p>Tools can be exposed via MCP for use in Claude Desktop:</p> <pre><code>from kagura import tool\n\n@tool\ndef weather_lookup(city: str) -&gt; dict:\n    \"\"\"Get current weather for a city\"\"\"\n    # Implementation\n    return {\n        \"city\": city,\n        \"temperature\": 72,\n        \"condition\": \"sunny\"\n    }\n\n# Automatically available in MCP\n# Run: kagura mcp start\n# Claude Desktop can now call weather_lookup\n</code></pre>"},{"location":"en/tutorials/11-tools/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/11-tools/#1-clear-documentation","title":"1. Clear Documentation","text":"<pre><code>@tool\ndef calculate_discount(price: float, discount_percent: float) -&gt; float:\n    \"\"\"\n    Calculate discounted price.\n\n    Args:\n        price: Original price\n        discount_percent: Discount percentage (e.g., 15 for 15%)\n\n    Returns:\n        Final price after discount\n\n    Example:\n        &gt;&gt;&gt; calculate_discount(100.0, 15.0)\n        85.0\n    \"\"\"\n    return price * (1 - discount_percent / 100)\n</code></pre>"},{"location":"en/tutorials/11-tools/#2-input-validation","title":"2. Input Validation","text":"<pre><code>@tool\ndef withdraw_money(account_id: str, amount: float) -&gt; dict:\n    \"\"\"Withdraw money from account\"\"\"\n    if amount &lt;= 0:\n        raise ValueError(\"Amount must be positive\")\n    if amount &gt; 10000:\n        raise ValueError(\"Exceeds daily limit\")\n\n    # Process withdrawal\n    return {\"success\": True, \"new_balance\": 5000 - amount}\n</code></pre>"},{"location":"en/tutorials/11-tools/#3-error-handling","title":"3. Error Handling","text":"<pre><code>@tool\ndef fetch_user_data(user_id: int) -&gt; dict:\n    \"\"\"Fetch user data from database\"\"\"\n    try:\n        # Database query\n        user = database.get_user(user_id)\n        if not user:\n            raise ValueError(f\"User {user_id} not found\")\n        return user\n    except DatabaseError as e:\n        raise RuntimeError(f\"Database error: {e}\") from e\n</code></pre>"},{"location":"en/tutorials/11-tools/#4-type-hints","title":"4. Type Hints","text":"<p>Always use type hints for better documentation and validation:</p> <pre><code>@tool\ndef process_order(\n    order_id: str,\n    items: list[dict],\n    shipping_address: dict,\n    priority: bool = False\n) -&gt; dict:\n    \"\"\"Process customer order\"\"\"\n    # Implementation\n    return {\n        \"order_id\": order_id,\n        \"status\": \"processing\",\n        \"estimated_delivery\": \"2025-10-15\"\n    }\n</code></pre>"},{"location":"en/tutorials/11-tools/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/11-tools/#tool-not-found-in-registry","title":"Tool not found in registry","text":"<pre><code>from kagura.core.tool_registry import tool_registry\n\n# Check if tool is registered\nif \"my_tool\" not in tool_registry.list_names():\n    print(\"Tool not found!\")\n    print(\"Available tools:\", tool_registry.list_names())\n</code></pre>"},{"location":"en/tutorials/11-tools/#type-validation-errors","title":"Type validation errors","text":"<pre><code>@tool\ndef strict_function(x: int) -&gt; int:\n    return x * 2\n\n# This will raise TypeError\nstrict_function(\"not an int\")  # Error!\nstrict_function(5, 10)  # Too many arguments!\n</code></pre>"},{"location":"en/tutorials/11-tools/#tool-name-conflicts","title":"Tool name conflicts","text":"<pre><code># This will raise ValueError\n@tool\ndef duplicate():\n    pass\n\n@tool\ndef duplicate():  # Error: already registered!\n    pass\n\n# Solution: Use custom names\n@tool(name=\"duplicate_v2\")\ndef duplicate():\n    pass\n</code></pre>"},{"location":"en/tutorials/11-tools/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Agent Routing</li> <li>Explore MCP Integration</li> <li>Try Chat REPL</li> </ul>"},{"location":"en/tutorials/11-tools/#further-reading","title":"Further Reading","text":"<ul> <li>Tools API Reference</li> <li>Tool Registry API</li> <li>MCP Tools Integration</li> </ul>"},{"location":"en/tutorials/12-workflows/","title":"Workflows Tutorial","text":"<p>The @workflow decorator allows you to create multi-agent orchestrations that coordinate multiple agents and tools to accomplish complex tasks.</p>"},{"location":"en/tutorials/12-workflows/#what-are-workflows","title":"What are Workflows?","text":"<p>Workflows are multi-agent orchestrations that combine agents and tools in a coordinated sequence:</p> <ul> <li>Coordination: Call multiple agents in sequence or parallel</li> <li>Data Flow: Pass results between agents</li> <li>Complex Tasks: Break down large problems into steps</li> <li>Reusability: Package multi-step processes</li> </ul> <p>Unlike <code>@agent</code> (which calls an LLM) and <code>@tool</code> (which executes pure Python), <code>@workflow</code> executes the function body to orchestrate agent calls.</p>"},{"location":"en/tutorials/12-workflows/#quick-start","title":"Quick Start","text":""},{"location":"en/tutorials/12-workflows/#basic-workflow","title":"Basic Workflow","text":"<pre><code>from kagura import workflow, agent\n\n@agent\nasync def search_agent(query: str) -&gt; str:\n    \"\"\"Search for information about {{ query }}\"\"\"\n    ...\n\n@agent\nasync def summarize_agent(text: str) -&gt; str:\n    \"\"\"Summarize: {{ text }}\"\"\"\n    ...\n\n@workflow\nasync def research_workflow(topic: str) -&gt; dict:\n    \"\"\"Research a topic using multiple agents\"\"\"\n    # Step 1: Search for information\n    search_results = await search_agent(topic)\n\n    # Step 2: Summarize findings\n    summary = await summarize_agent(search_results)\n\n    return {\n        \"topic\": topic,\n        \"findings\": search_results,\n        \"summary\": summary\n    }\n\n# Use\nresult = await research_workflow(\"AI safety\")\n</code></pre>"},{"location":"en/tutorials/12-workflows/#workflow-features","title":"Workflow Features","text":""},{"location":"en/tutorials/12-workflows/#1-sequential-execution","title":"1. Sequential Execution","text":"<p>Execute agents in a specific order:</p> <pre><code>@workflow\nasync def content_pipeline(topic: str) -&gt; dict:\n    \"\"\"Create content through multiple stages\"\"\"\n    # Research phase\n    research = await research_agent(topic)\n\n    # Writing phase\n    draft = await writing_agent(research)\n\n    # Editing phase\n    final = await editing_agent(draft)\n\n    return {\n        \"topic\": topic,\n        \"draft\": draft,\n        \"final\": final\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#2-parallel-execution","title":"2. Parallel Execution","text":"<p>Run agents concurrently using <code>asyncio.gather</code>:</p> <pre><code>import asyncio\n\n@workflow\nasync def multi_source_research(topic: str) -&gt; dict:\n    \"\"\"Research from multiple sources in parallel\"\"\"\n    # Execute in parallel\n    results = await asyncio.gather(\n        academic_search_agent(topic),\n        news_search_agent(topic),\n        social_media_agent(topic)\n    )\n\n    academic, news, social = results\n\n    # Combine results\n    combined = await synthesis_agent(\n        f\"Academic: {academic}\\nNews: {news}\\nSocial: {social}\"\n    )\n\n    return {\n        \"academic\": academic,\n        \"news\": news,\n        \"social\": social,\n        \"synthesis\": combined\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#3-conditional-logic","title":"3. Conditional Logic","text":"<p>Use branching logic based on results:</p> <pre><code>@workflow\nasync def smart_analysis(text: str) -&gt; dict:\n    \"\"\"Analyze text with conditional processing\"\"\"\n    # Classify content type\n    content_type = await classifier_agent(text)\n\n    # Different processing based on type\n    if content_type == \"technical\":\n        analysis = await technical_analyzer(text)\n    elif content_type == \"creative\":\n        analysis = await creative_analyzer(text)\n    else:\n        analysis = await general_analyzer(text)\n\n    return {\n        \"type\": content_type,\n        \"analysis\": analysis\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#4-error-handling","title":"4. Error Handling","text":"<p>Handle failures gracefully:</p> <pre><code>@workflow\nasync def robust_workflow(query: str) -&gt; dict:\n    \"\"\"Workflow with error handling\"\"\"\n    try:\n        primary_result = await primary_agent(query)\n    except Exception as e:\n        # Fallback to secondary agent\n        primary_result = await fallback_agent(query)\n\n    # Validate result\n    if not primary_result:\n        raise ValueError(\"No results found\")\n\n    return {\n        \"query\": query,\n        \"result\": primary_result\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#workflow-registry","title":"Workflow Registry","text":"<p>All workflows are automatically registered in the global <code>workflow_registry</code>:</p> <pre><code>from kagura.core.workflow_registry import workflow_registry\n\n# List all workflows\nprint(workflow_registry.list_names())\n# ['research_workflow', 'content_pipeline', ...]\n\n# Get a specific workflow\nworkflow = workflow_registry.get(\"research_workflow\")\nresult = await workflow(\"AI safety\")\n\n# Get all workflows\nall_workflows = workflow_registry.get_all()\nfor name, func in all_workflows.items():\n    print(f\"{name}: {func.__doc__}\")\n</code></pre>"},{"location":"en/tutorials/12-workflows/#examples","title":"Examples","text":""},{"location":"en/tutorials/12-workflows/#example-1-document-processing-workflow","title":"Example 1: Document Processing Workflow","text":"<pre><code>@workflow\nasync def process_document(file_path: str) -&gt; dict:\n    \"\"\"Complete document processing pipeline\"\"\"\n    # Extract text\n    text = await extract_text_tool(file_path)\n\n    # Analyze sentiment\n    sentiment = await sentiment_agent(text)\n\n    # Extract key points\n    key_points = await extraction_agent(text)\n\n    # Generate summary\n    summary = await summarization_agent(text)\n\n    # Categorize\n    category = await categorization_agent(text)\n\n    return {\n        \"file\": file_path,\n        \"sentiment\": sentiment,\n        \"key_points\": key_points,\n        \"summary\": summary,\n        \"category\": category\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#example-2-customer-support-workflow","title":"Example 2: Customer Support Workflow","text":"<pre><code>@workflow\nasync def customer_support_workflow(ticket: dict) -&gt; dict:\n    \"\"\"Handle customer support ticket\"\"\"\n    # Classify urgency\n    urgency = await urgency_classifier(ticket[\"description\"])\n\n    # Route based on urgency\n    if urgency == \"high\":\n        # Immediate escalation\n        response = await senior_support_agent(ticket)\n    else:\n        # Standard processing\n        response = await support_agent(ticket)\n\n    # Generate follow-up\n    follow_up = await follow_up_agent(response)\n\n    return {\n        \"ticket_id\": ticket[\"id\"],\n        \"urgency\": urgency,\n        \"response\": response,\n        \"follow_up\": follow_up\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#example-3-data-analysis-workflow","title":"Example 3: Data Analysis Workflow","text":"<pre><code>@workflow\nasync def data_analysis_workflow(dataset: str) -&gt; dict:\n    \"\"\"Analyze dataset with multiple techniques\"\"\"\n    # Load and validate data\n    data = await data_loader_tool(dataset)\n\n    # Statistical analysis\n    stats = await statistical_agent(data)\n\n    # Pattern detection\n    patterns = await pattern_detection_agent(data)\n\n    # Visualization\n    viz = await visualization_agent(data, patterns)\n\n    # Report generation\n    report = await report_agent(\n        f\"Stats: {stats}\\nPatterns: {patterns}\"\n    )\n\n    return {\n        \"dataset\": dataset,\n        \"statistics\": stats,\n        \"patterns\": patterns,\n        \"visualization\": viz,\n        \"report\": report\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#example-4-content-creation-workflow","title":"Example 4: Content Creation Workflow","text":"<pre><code>@workflow\nasync def content_creation_workflow(\n    topic: str,\n    target_audience: str\n) -&gt; dict:\n    \"\"\"Create content tailored to audience\"\"\"\n    # Research topic\n    research = await research_agent(f\"{topic} for {target_audience}\")\n\n    # Generate outline\n    outline = await outline_agent(research)\n\n    # Write content sections in parallel\n    sections = await asyncio.gather(\n        intro_writer_agent(outline[0]),\n        body_writer_agent(outline[1]),\n        conclusion_writer_agent(outline[2])\n    )\n\n    # Combine sections\n    full_content = \"\\n\\n\".join(sections)\n\n    # Edit for audience\n    edited = await editor_agent(\n        f\"Edit for {target_audience}: {full_content}\"\n    )\n\n    # SEO optimization\n    seo_optimized = await seo_agent(edited, topic)\n\n    return {\n        \"topic\": topic,\n        \"audience\": target_audience,\n        \"research\": research,\n        \"outline\": outline,\n        \"content\": seo_optimized\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#integration-with-agents-and-tools","title":"Integration with Agents and Tools","text":""},{"location":"en/tutorials/12-workflows/#combining-agents-and-tools","title":"Combining Agents and Tools","text":"<pre><code>from kagura import workflow, agent, tool\n\n@tool\ndef calculate_metrics(data: list) -&gt; dict:\n    \"\"\"Calculate statistical metrics\"\"\"\n    return {\n        \"mean\": sum(data) / len(data),\n        \"max\": max(data),\n        \"min\": min(data)\n    }\n\n@agent\nasync def insights_agent(metrics: dict) -&gt; str:\n    \"\"\"Generate insights from {{ metrics }}\"\"\"\n    ...\n\n@workflow\nasync def analytics_workflow(data: list) -&gt; dict:\n    \"\"\"Analyze data and generate insights\"\"\"\n    # Use tool for calculations\n    metrics = calculate_metrics(data)\n\n    # Use agent for insights\n    insights = await insights_agent(metrics)\n\n    return {\n        \"metrics\": metrics,\n        \"insights\": insights\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/12-workflows/#1-clear-workflow-structure","title":"1. Clear Workflow Structure","text":"<pre><code>@workflow\nasync def well_structured_workflow(input_data: str) -&gt; dict:\n    \"\"\"\n    Process data through multiple stages.\n\n    Stages:\n    1. Validation\n    2. Processing\n    3. Analysis\n    4. Reporting\n    \"\"\"\n    # Stage 1: Validation\n    validated = await validation_agent(input_data)\n\n    # Stage 2: Processing\n    processed = await processing_agent(validated)\n\n    # Stage 3: Analysis\n    analyzed = await analysis_agent(processed)\n\n    # Stage 4: Reporting\n    report = await reporting_agent(analyzed)\n\n    return {\n        \"validated\": validated,\n        \"processed\": processed,\n        \"analyzed\": analyzed,\n        \"report\": report\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#2-error-recovery","title":"2. Error Recovery","text":"<pre><code>@workflow\nasync def resilient_workflow(task: str) -&gt; dict:\n    \"\"\"Workflow with retry logic\"\"\"\n    max_retries = 3\n\n    for attempt in range(max_retries):\n        try:\n            result = await unreliable_agent(task)\n            break\n        except Exception as e:\n            if attempt == max_retries - 1:\n                # Final fallback\n                result = await fallback_agent(task)\n            else:\n                # Retry with backoff\n                await asyncio.sleep(2 ** attempt)\n\n    return {\"task\": task, \"result\": result}\n</code></pre>"},{"location":"en/tutorials/12-workflows/#3-progress-tracking","title":"3. Progress Tracking","text":"<pre><code>@workflow\nasync def tracked_workflow(items: list) -&gt; dict:\n    \"\"\"Track progress through workflow\"\"\"\n    results = []\n    total = len(items)\n\n    for i, item in enumerate(items, 1):\n        print(f\"Processing {i}/{total}: {item}\")\n        result = await processing_agent(item)\n        results.append(result)\n\n    return {\n        \"total\": total,\n        \"processed\": len(results),\n        \"results\": results\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#4-modular-design","title":"4. Modular Design","text":"<pre><code># Define reusable sub-workflows\n@workflow\nasync def data_prep_workflow(raw_data: str) -&gt; dict:\n    \"\"\"Reusable data preparation\"\"\"\n    cleaned = await cleaning_agent(raw_data)\n    normalized = await normalization_agent(cleaned)\n    return {\"cleaned\": cleaned, \"normalized\": normalized}\n\n@workflow\nasync def main_workflow(input_data: str) -&gt; dict:\n    \"\"\"Main workflow using sub-workflows\"\"\"\n    # Reuse data prep\n    prepared = await data_prep_workflow(input_data)\n\n    # Continue with analysis\n    analysis = await analysis_agent(prepared[\"normalized\"])\n\n    return {\n        \"prepared\": prepared,\n        \"analysis\": analysis\n    }\n</code></pre>"},{"location":"en/tutorials/12-workflows/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/12-workflows/#workflow-not-found-in-registry","title":"Workflow not found in registry","text":"<pre><code>from kagura.core.workflow_registry import workflow_registry\n\n# Check if workflow is registered\nif \"my_workflow\" not in workflow_registry.list_names():\n    print(\"Workflow not found!\")\n    print(\"Available workflows:\", workflow_registry.list_names())\n</code></pre>"},{"location":"en/tutorials/12-workflows/#workflow-name-conflicts","title":"Workflow name conflicts","text":"<pre><code># This will raise ValueError\n@workflow\ndef duplicate():\n    pass\n\n@workflow\ndef duplicate():  # Error: already registered!\n    pass\n\n# Solution: Use custom names\n@workflow(name=\"duplicate_v2\")\nasync def duplicate():\n    pass\n</code></pre>"},{"location":"en/tutorials/12-workflows/#asyncawait-issues","title":"Async/await issues","text":"<pre><code># \u274c Wrong: Forgot await\n@workflow\nasync def broken_workflow(query: str) -&gt; str:\n    result = search_agent(query)  # Missing await!\n    return result\n\n# \u2705 Correct: Always await agent calls\n@workflow\nasync def correct_workflow(query: str) -&gt; str:\n    result = await search_agent(query)\n    return result\n</code></pre>"},{"location":"en/tutorials/12-workflows/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about MCP Integration</li> <li>Explore Agent Routing</li> <li>Try Chat REPL</li> </ul>"},{"location":"en/tutorials/12-workflows/#further-reading","title":"Further Reading","text":"<ul> <li>Workflows API Reference</li> <li>Workflow Registry API</li> <li>MCP Workflows Integration</li> </ul>"},{"location":"en/tutorials/13-agent-builder/","title":"Tutorial 13: Agent Builder","text":"<p>Learn how to use the AgentBuilder fluent API to create complex agents with integrated features.</p>"},{"location":"en/tutorials/13-agent-builder/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed (<code>pip install kagura-ai</code>)</li> <li>Completion of Tutorial 1: Basic Agent</li> <li>OpenAI API key (or other LLM provider)</li> </ul>"},{"location":"en/tutorials/13-agent-builder/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand the AgentBuilder fluent API pattern - Build agents with memory, tools, and hooks - Configure LLM generation parameters - Create reusable agent configurations</p>"},{"location":"en/tutorials/13-agent-builder/#what-is-agentbuilder","title":"What is AgentBuilder?","text":"<p><code>AgentBuilder</code> is a fluent API that simplifies creating complex agents with multiple features. Instead of manually wiring together memory, tools, hooks, and routing, you can use method chaining to build agents declaratively.</p>"},{"location":"en/tutorials/13-agent-builder/#before-agentbuilder","title":"Before AgentBuilder","text":"<pre><code>from kagura import agent\nfrom kagura.core.memory import MemoryManager\n\n# Manually configure everything\nmemory = MemoryManager(agent_name=\"my_agent\", enable_rag=True)\n\n@agent(model=\"gpt-4o-mini\", temperature=0.7)\nasync def my_agent(prompt: str) -&gt; str:\n    '''Process: {{ prompt }}'''\n    pass\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#with-agentbuilder","title":"With AgentBuilder","text":"<pre><code>from kagura import AgentBuilder\n\n# Declarative configuration\nagent = (\n    AgentBuilder(\"my_agent\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(type=\"rag\", enable_rag=True)\n    .with_context(temperature=0.7)\n    .build()\n)\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#step-1-basic-agent-creation","title":"Step 1: Basic Agent Creation","text":"<p>Create a file called <code>builder_demo.py</code>:</p> <pre><code>import asyncio\nfrom kagura import AgentBuilder\n\n\nasync def main():\n    # Create a basic agent with AgentBuilder\n    agent = (\n        AgentBuilder(\"greeter\")\n        .with_model(\"gpt-4o-mini\")\n        .build()\n    )\n\n    result = await agent(\"Say hello!\")\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Run it:</p> <pre><code>python builder_demo.py\n</code></pre> <p>Explanation: 1. <code>AgentBuilder(\"greeter\")</code> - Initialize builder with agent name 2. <code>.with_model(\"gpt-4o-mini\")</code> - Set the LLM model 3. <code>.build()</code> - Build the final agent</p>"},{"location":"en/tutorials/13-agent-builder/#step-2-adding-memory","title":"Step 2: Adding Memory","text":"<p>Let's add memory so the agent can remember conversation history:</p> <pre><code>agent = (\n    AgentBuilder(\"assistant\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(\n        type=\"working\",\n        max_messages=50,\n        enable_rag=False\n    )\n    .build()\n)\n\n# Agent can now access conversation history\nresult = await agent(\"My name is Alice\")\nprint(result)  # \"Nice to meet you, Alice!\"\n\nresult = await agent(\"What's my name?\")\nprint(result)  # \"Your name is Alice.\"\n</code></pre> <p>Memory Types: - <code>\"working\"</code> - In-memory storage (fast, temporary) - <code>\"context\"</code> - Conversation context (for LLM context window) - <code>\"persistent\"</code> - SQLite storage (survives restarts) - <code>\"rag\"</code> - Vector-based semantic search (requires ChromaDB)</p>"},{"location":"en/tutorials/13-agent-builder/#step-3-rag-semantic-memory","title":"Step 3: RAG (Semantic Memory)","text":"<p>For semantic search over conversation history:</p> <pre><code>agent = (\n    AgentBuilder(\"smart_assistant\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(\n        type=\"rag\",\n        enable_rag=True,\n        max_messages=100\n    )\n    .build()\n)\n\n# Store various facts\nawait agent(\"Python is a programming language created by Guido van Rossum\")\nawait agent(\"I love hiking in the mountains\")\nawait agent(\"My favorite food is sushi\")\n\n# Semantic search finds relevant context\nresult = await agent(\"Tell me about programming\")\n# Agent recalls: \"Python is a programming language...\"\n\nresult = await agent(\"What do I like to eat?\")\n# Agent recalls: \"My favorite food is sushi\"\n</code></pre> <p>Note: RAG requires ChromaDB installation: <pre><code>pip install chromadb\n</code></pre></p>"},{"location":"en/tutorials/13-agent-builder/#step-4-adding-tools","title":"Step 4: Adding Tools","text":"<p>Tools extend agents with external capabilities:</p> <pre><code>def search_web(query: str) -&gt; str:\n    \"\"\"Search the web for information.\"\"\"\n    # Simulate web search\n    return f\"Search results for: {query}\"\n\n\ndef calculate(expression: str) -&gt; float:\n    \"\"\"Evaluate a mathematical expression.\"\"\"\n    return eval(expression)  # Note: Use safely in production!\n\n\nagent = (\n    AgentBuilder(\"researcher\")\n    .with_model(\"gpt-4o-mini\")\n    .with_tools([search_web, calculate])\n    .build()\n)\n\n# Agent can now use tools\nresult = await agent(\"What is 15 * 23?\")\n# Agent calls calculate(\"15 * 23\") and returns: \"345\"\n\nresult = await agent(\"Search for Python tutorials\")\n# Agent calls search_web(\"Python tutorials\")\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#step-5-pre-and-post-hooks","title":"Step 5: Pre and Post Hooks","text":"<p>Hooks let you inject logic before and after agent execution:</p> <pre><code>def log_input(*args, **kwargs):\n    \"\"\"Log agent input.\"\"\"\n    print(f\"[PRE] Input: {args}, {kwargs}\")\n\n\ndef log_output(result):\n    \"\"\"Log agent output.\"\"\"\n    print(f\"[POST] Output: {result}\")\n\n\nagent = (\n    AgentBuilder(\"monitored_agent\")\n    .with_model(\"gpt-4o-mini\")\n    .with_hooks(\n        pre=[log_input],\n        post=[log_output]\n    )\n    .build()\n)\n\nresult = await agent(\"Hello!\")\n# Console output:\n# [PRE] Input: ('Hello!',), {}\n# [POST] Output: Hi there! How can I help you?\n</code></pre> <p>Use Cases for Hooks: - Logging and monitoring - Input validation - Output sanitization - Rate limiting - Caching</p>"},{"location":"en/tutorials/13-agent-builder/#step-6-llm-generation-parameters","title":"Step 6: LLM Generation Parameters","text":"<p>Control how the LLM generates responses:</p> <pre><code># More deterministic (factual tasks)\nfactual_agent = (\n    AgentBuilder(\"fact_checker\")\n    .with_model(\"gpt-4o-mini\")\n    .with_context(\n        temperature=0.2,\n        max_tokens=500\n    )\n    .build()\n)\n\n# More creative (story generation)\ncreative_agent = (\n    AgentBuilder(\"storyteller\")\n    .with_model(\"gpt-4o-mini\")\n    .with_context(\n        temperature=1.5,\n        max_tokens=1000,\n        top_p=0.9\n    )\n    .build()\n)\n</code></pre> <p>Common Parameters: - <code>temperature</code> (0.0-2.0): Randomness (lower = more deterministic) - <code>max_tokens</code>: Maximum response length - <code>top_p</code> (0.0-1.0): Nucleus sampling threshold - <code>frequency_penalty</code>: Discourage repetition - <code>presence_penalty</code>: Encourage new topics</p>"},{"location":"en/tutorials/13-agent-builder/#complete-example-multi-feature-agent","title":"Complete Example: Multi-Feature Agent","text":"<p>Here's an agent with all features combined:</p> <pre><code>import asyncio\nfrom pathlib import Path\nfrom kagura import AgentBuilder\n\n\ndef web_search(query: str) -&gt; str:\n    \"\"\"Search the web.\"\"\"\n    return f\"Results for: {query}\"\n\n\ndef log_execution(result):\n    \"\"\"Log each execution.\"\"\"\n    print(f\"[LOG] Agent returned: {result}\")\n\n\nasync def main():\n    # Build a powerful multi-feature agent\n    agent = (\n        AgentBuilder(\"advanced_assistant\")\n        .with_model(\"gpt-4o-mini\")\n        .with_memory(\n            type=\"persistent\",\n            persist_dir=Path.home() / \".kagura\" / \"agents\",\n            max_messages=100,\n            enable_rag=True\n        )\n        .with_tools([web_search])\n        .with_hooks(\n            post=[log_execution]\n        )\n        .with_context(\n            temperature=0.7,\n            max_tokens=800\n        )\n        .build()\n    )\n\n    # Test the agent\n    result = await agent(\"Search for Python tutorials\")\n    print(f\"Response: {result}\")\n\n    result = await agent(\"What did I just ask you?\")\n    print(f\"Response: {result}\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#agent-configuration-object","title":"Agent Configuration Object","text":"<p>You can also work with configuration separately:</p> <pre><code>from kagura import AgentBuilder\nfrom kagura.builder import AgentConfiguration, MemoryConfig\n\n# Create configuration\nconfig = AgentConfiguration(\n    name=\"my_agent\",\n    model=\"gpt-4o-mini\"\n)\n\n# Build agent from config\nbuilder = AgentBuilder(config.name)\nbuilder._config = config\nagent = builder.build()\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/13-agent-builder/#1-descriptive-agent-names","title":"1. Descriptive Agent Names","text":"<pre><code># Good\nAgentBuilder(\"customer_support_chatbot\")\nAgentBuilder(\"data_analysis_assistant\")\n\n# Less clear\nAgentBuilder(\"agent1\")\nAgentBuilder(\"my_agent\")\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#2-choose-appropriate-memory-type","title":"2. Choose Appropriate Memory Type","text":"<pre><code># Short conversations - working memory\nAgentBuilder(\"quick_qa\").with_memory(type=\"working\")\n\n# Long-term knowledge - RAG\nAgentBuilder(\"knowledge_base\").with_memory(type=\"rag\", enable_rag=True)\n\n# Persistent storage - persistent memory\nAgentBuilder(\"assistant\").with_memory(\n    type=\"persistent\",\n    persist_dir=Path.home() / \".kagura\"\n)\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#3-model-selection","title":"3. Model Selection","text":"<pre><code># Fast, cheap tasks\n.with_model(\"gpt-4o-mini\")\n\n# Complex reasoning\n.with_model(\"gpt-4o\")\n.with_model(\"claude-3-5-sonnet-20241022\")\n\n# Local models\n.with_model(\"ollama/llama3.2\")\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#4-method-chaining-formatting","title":"4. Method Chaining Formatting","text":"<pre><code># Good - readable\nagent = (\n    AgentBuilder(\"name\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(type=\"rag\")\n    .with_tools([tool1, tool2])\n    .build()\n)\n\n# Less readable\nagent = AgentBuilder(\"name\").with_model(\"gpt-4o-mini\").with_memory(type=\"rag\").with_tools([tool1, tool2]).build()\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#common-patterns","title":"Common Patterns","text":""},{"location":"en/tutorials/13-agent-builder/#pattern-1-chatbot-with-memory","title":"Pattern 1: Chatbot with Memory","text":"<pre><code>chatbot = (\n    AgentBuilder(\"chatbot\")\n    .with_model(\"gpt-4o-mini\")\n    .with_memory(type=\"context\", max_messages=20)\n    .with_context(temperature=0.8)\n    .build()\n)\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#pattern-2-researcher-with-tools","title":"Pattern 2: Researcher with Tools","text":"<pre><code>researcher = (\n    AgentBuilder(\"researcher\")\n    .with_model(\"gpt-4o\")\n    .with_tools([web_search, summarize, extract_facts])\n    .with_context(temperature=0.3)\n    .build()\n)\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#pattern-3-monitored-agent","title":"Pattern 3: Monitored Agent","text":"<pre><code>monitored = (\n    AgentBuilder(\"monitored\")\n    .with_model(\"gpt-4o-mini\")\n    .with_hooks(\n        pre=[validate_input, rate_limit],\n        post=[log_output, cache_result]\n    )\n    .build()\n)\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#common-mistakes","title":"Common Mistakes","text":""},{"location":"en/tutorials/13-agent-builder/#1-forgetting-build","title":"1. Forgetting <code>.build()</code>","text":"<pre><code># Wrong - returns AgentBuilder, not an agent\nagent = AgentBuilder(\"name\").with_model(\"gpt-4o-mini\")\n\n# Correct\nagent = AgentBuilder(\"name\").with_model(\"gpt-4o-mini\").build()\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#2-enabling-rag-without-chromadb","title":"2. Enabling RAG Without ChromaDB","text":"<pre><code># This will fail if chromadb is not installed\nagent = (\n    AgentBuilder(\"agent\")\n    .with_memory(enable_rag=True)\n    .build()\n)\n\n# Install first:\n# pip install chromadb\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#3-incompatible-memory-and-rag","title":"3. Incompatible Memory and RAG","text":"<pre><code># RAG should use \"rag\" or \"persistent\" memory type\nagent = (\n    AgentBuilder(\"agent\")\n    .with_memory(type=\"working\", enable_rag=True)  # Conflict!\n    .build()\n)\n\n# Better\nagent = (\n    AgentBuilder(\"agent\")\n    .with_memory(type=\"rag\", enable_rag=True)\n    .build()\n)\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#practice-exercises","title":"Practice Exercises","text":""},{"location":"en/tutorials/13-agent-builder/#exercise-1-build-a-knowledge-assistant","title":"Exercise 1: Build a Knowledge Assistant","text":"<p>Create an agent that: - Uses GPT-4o-mini - Has RAG-enabled memory - Logs all interactions</p> <pre><code># Your code here\nknowledge_assistant = (\n    AgentBuilder(\"knowledge_assistant\")\n    # Add configurations\n    .build()\n)\n\n# Test it\nawait knowledge_assistant(\"Python is a programming language\")\nawait knowledge_assistant(\"What did I tell you about Python?\")\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#exercise-2-tool-equipped-researcher","title":"Exercise 2: Tool-Equipped Researcher","text":"<p>Create an agent with: - GPT-4o model - Web search and calculator tools - Low temperature (0.2) for accuracy</p> <pre><code># Your code here\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#exercise-3-multi-agent-system","title":"Exercise 3: Multi-Agent System","text":"<p>Build two agents with different configurations and have them work together:</p> <pre><code># Analyst (factual)\nanalyst = AgentBuilder(\"analyst\")...\n\n# Storyteller (creative)\nstoryteller = AgentBuilder(\"storyteller\")...\n\n# Workflow\nfacts = await analyst(\"Analyze: quantum computing\")\nstory = await storyteller(f\"Write a story about: {facts}\")\n</code></pre>"},{"location":"en/tutorials/13-agent-builder/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"en/tutorials/13-agent-builder/#1-fluent-api-pattern","title":"1. Fluent API Pattern","text":"<p>Method chaining for readable configuration: <pre><code>builder.method1().method2().method3()\n</code></pre></p>"},{"location":"en/tutorials/13-agent-builder/#2-declarative-agent-configuration","title":"2. Declarative Agent Configuration","text":"<p>Specify what you want, not how to build it: <pre><code>AgentBuilder(\"name\").with_feature().build()\n</code></pre></p>"},{"location":"en/tutorials/13-agent-builder/#3-feature-integration","title":"3. Feature Integration","text":"<p>Combine memory, tools, and hooks seamlessly: <pre><code>.with_memory().with_tools().with_hooks()\n</code></pre></p>"},{"location":"en/tutorials/13-agent-builder/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial 14: Agent Testing - Learn to test your agents</li> <li>Tutorial 15: Observability - Monitor agent performance</li> <li>API Reference: Builder - Complete API documentation</li> </ul>"},{"location":"en/tutorials/13-agent-builder/#summary","title":"Summary","text":"<p>You learned: - \u2713 How to use AgentBuilder's fluent API - \u2713 How to add memory (working, persistent, RAG) - \u2713 How to integrate tools and hooks - \u2713 How to configure LLM generation parameters - \u2713 Best practices for agent configuration</p> <p>Continue to Tutorial 14: Agent Testing to learn how to test your agents!</p>"},{"location":"en/tutorials/13-multimodal-rag/","title":"Tutorial 13: Multimodal RAG - Search Images, Audio, Videos &amp; PDFs","text":"<p>Learn how to create AI agents that can search and understand multimodal content (images, audio, video, PDFs) from your directories using Retrieval-Augmented Generation (RAG).</p>"},{"location":"en/tutorials/13-multimodal-rag/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed with web support: <code>pip install kagura-ai[web]</code></li> <li>Google API key (for Gemini API)</li> <li>ChromaDB installed (included with multimodal extra)</li> </ul>"},{"location":"en/tutorials/13-multimodal-rag/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand what Multimodal RAG is and why it's useful - Set up a directory for multimodal content indexing - Create agents that can search across text, images, audio, videos, and PDFs - Build a documentation assistant that understands diagrams and screenshots</p>"},{"location":"en/tutorials/13-multimodal-rag/#what-is-multimodal-rag","title":"What is Multimodal RAG?","text":"<p>RAG (Retrieval-Augmented Generation) enhances AI agents by giving them access to external knowledge. Multimodal RAG extends this to work with:</p> <ul> <li>Images (PNG, JPG, GIF, WEBP)</li> <li>Audio (MP3, WAV, M4A)</li> <li>Video (MP4, MOV, AVI)</li> <li>PDFs (documents with text and images)</li> <li>Text files (MD, TXT, Python code, etc.)</li> </ul> <p>Instead of just searching text, your agent can: - Find relevant diagrams and screenshots - Transcribe and search audio recordings - Extract information from video content - Process PDF documentation</p>"},{"location":"en/tutorials/13-multimodal-rag/#step-1-set-up-your-environment","title":"Step 1: Set Up Your Environment","text":"<p>Set your Google API key (required for processing multimodal content):</p> <pre><code>export GOOGLE_API_KEY=\"your-gemini-api-key\"\n</code></pre> <p>Install Kagura AI with web support (includes multimodal features):</p> <pre><code>pip install kagura-ai[web]\n</code></pre> <p>This installs: - <code>google-generativeai</code> - For Gemini API (multimodal processing) - <code>chromadb</code> - Vector database for semantic search (included in <code>ai</code> extra) - <code>pillow</code> - Image processing</p>"},{"location":"en/tutorials/13-multimodal-rag/#step-2-prepare-your-content-directory","title":"Step 2: Prepare Your Content Directory","text":"<p>Create a project directory with mixed content:</p> <pre><code>mkdir my_project\ncd my_project\n\n# Create some documentation\necho \"# Authentication\\nOur app uses OAuth 2.0\" &gt; auth.md\n\n# Create a docs folder\nmkdir docs\necho \"User guide content here\" &gt; docs/guide.txt\n\n# Add some images (diagrams, screenshots, etc.)\nmkdir images\n# Add your actual images here\n</code></pre> <p>Your directory structure: <pre><code>my_project/\n\u251c\u2500\u2500 auth.md           # Text documentation\n\u251c\u2500\u2500 docs/\n\u2502   \u2514\u2500\u2500 guide.txt     # More docs\n\u2514\u2500\u2500 images/\n    \u251c\u2500\u2500 diagram.png   # Architecture diagram\n    \u2514\u2500\u2500 screenshot.jpg # UI screenshot\n</code></pre></p>"},{"location":"en/tutorials/13-multimodal-rag/#step-3-create-your-first-rag-agent","title":"Step 3: Create Your First RAG Agent","text":"<p>Create <code>rag_agent.py</code>:</p> <pre><code>import asyncio\nfrom pathlib import Path\nfrom kagura import agent\n\n\n@agent(\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./my_project\")\n)\nasync def docs_assistant(query: str, rag) -&gt; str:\n    '''Answer the question: {{ query }}\n\n    Use rag.query(query) to search documentation.\n    Include relevant details from the search results.'''\n    pass\n\n\nasync def main():\n    # First call: Builds index (may take a moment)\n    result = await docs_assistant(\"How does authentication work?\")\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Let's break this down:</p> <ol> <li><code>enable_multimodal_rag=True</code> - Enables RAG functionality</li> <li><code>rag_directory=Path(\"./my_project\")</code> - Directory to index</li> <li><code>rag</code> parameter - Auto-injected MultimodalRAG instance</li> <li><code>rag.query(query)</code> - Search for relevant content</li> </ol>"},{"location":"en/tutorials/13-multimodal-rag/#step-4-run-your-rag-agent","title":"Step 4: Run Your RAG Agent","text":"<p>Execute the script:</p> <pre><code>python rag_agent.py\n</code></pre> <p>First run: <pre><code>Building index from /path/to/my_project\nIndex built: 5 files (3 text, 2 multimodal)\nOur app uses OAuth 2.0 for authentication...\n</code></pre></p> <p>Subsequent runs: Much faster (uses cached index)</p> <p>\ud83c\udf89 Your agent can now search across all your documentation!</p>"},{"location":"en/tutorials/13-multimodal-rag/#how-it-works-behind-the-scenes","title":"How It Works: Behind the Scenes","text":""},{"location":"en/tutorials/13-multimodal-rag/#index-building","title":"Index Building","text":"<p>When you first call the agent:</p> <ol> <li>Directory Scanning: Recursively scans <code>my_project/</code></li> <li>File Type Detection: Identifies text, images, audio, video, PDFs</li> <li>Content Processing:</li> <li>Text files: Read directly</li> <li>Images: Analyzed with Gemini Vision API (describes content)</li> <li>Audio: Transcribed to text</li> <li>Video: Frames extracted and analyzed</li> <li>PDFs: Text and images extracted</li> <li>Vector Indexing: Stores in ChromaDB for semantic search</li> <li>Caching: Results cached for faster subsequent access</li> </ol>"},{"location":"en/tutorials/13-multimodal-rag/#query-time","title":"Query Time","text":"<p>When you search:</p> <ol> <li>Semantic Search: Finds relevant content using vector similarity</li> <li>Context Injection: Results available to the agent</li> <li>LLM Response: Agent synthesizes answer using search results</li> </ol>"},{"location":"en/tutorials/13-multimodal-rag/#step-5-advanced-usage-manual-search","title":"Step 5: Advanced Usage - Manual Search","text":"<p>You can manually control the search and response:</p> <pre><code>@agent(\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./my_project\")\n)\nasync def smart_assistant(query: str, rag) -&gt; str:\n    '''You are a helpful documentation assistant.\n\n    First, search for relevant information using: rag.query(\"{{ query }}\", n_results=3)\n    Then answer based on the search results: {{ query }}\n\n    If no relevant results found, say \"I couldn't find information about that.\"'''\n    pass\n</code></pre> <p>How this works: - The prompt tells the LLM to use <code>rag.query()</code> - The LLM calls it during generation (via tool calling) - Results are incorporated into the response</p>"},{"location":"en/tutorials/13-multimodal-rag/#step-6-building-the-index-explicitly","title":"Step 6: Building the Index Explicitly","text":"<p>For large directories, build the index ahead of time:</p> <pre><code>from pathlib import Path\nfrom kagura.core.memory import MultimodalRAG\nimport asyncio\n\n\nasync def build_index():\n    # Initialize RAG\n    rag = MultimodalRAG(\n        directory=Path(\"./my_project\"),\n        collection_name=\"my_docs\"\n    )\n\n    # Build index\n    stats = await rag.build_index(max_concurrent=3)\n\n    print(f\"Indexed {stats['total_files']} files\")\n    print(f\"  - Text: {stats['text_files']}\")\n    print(f\"  - Multimodal: {stats['multimodal_files']}\")\n    print(f\"  - Failed: {stats['failed_files']}\")\n    print(f\"Cache hit rate: {stats['cache_hit_rate']:.2%}\")\n\n\nasyncio.run(build_index())\n</code></pre> <p>Output: <pre><code>Building index from ./my_project\nIndexed 15 files\n  - Text: 10\n  - Multimodal: 5\n  - Failed: 0\nCache hit rate: 0.00%\n</code></pre></p>"},{"location":"en/tutorials/13-multimodal-rag/#step-7-search-by-file-type","title":"Step 7: Search by File Type","text":"<p>Filter results by content type:</p> <pre><code>from kagura.loaders.file_types import FileType\n\n# Search only images\nresults = rag.query(\"architecture diagram\", file_type=FileType.IMAGE)\n\n# Search only text\nresults = rag.query(\"authentication\", file_type=FileType.TEXT)\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#step-8-incremental-updates","title":"Step 8: Incremental Updates","text":"<p>Update the index when files change:</p> <pre><code># Add new files to my_project/\n# Then update incrementally (faster than full rebuild)\nstats = await rag.incremental_update()\nprint(f\"Updated {stats['total_files']} new/modified files\")\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#configuration-options","title":"Configuration Options","text":""},{"location":"en/tutorials/13-multimodal-rag/#rag-parameters","title":"RAG Parameters","text":"<pre><code>@agent(\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./docs\"),        # Required\n    rag_cache_size_mb=100,                # Cache size (default: 100MB)\n    persist_dir=Path(\"./.kagura\")         # ChromaDB storage location\n)\nasync def my_agent(query: str, rag) -&gt; str:\n    pass\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#multimodalrag-options","title":"MultimodalRAG Options","text":"<pre><code>from kagura.core.memory import MultimodalRAG\n\nrag = MultimodalRAG(\n    directory=Path(\"./project\"),\n    collection_name=\"my_docs\",         # ChromaDB collection name\n    persist_dir=Path(\"./.kagura\"),     # Storage directory\n    cache_size_mb=100,                 # File cache size\n    respect_gitignore=True,            # Honor .gitignore/.kaguraignore\n)\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#step-9-gitignore-support","title":"Step 9: Gitignore Support","text":"<p>Create <code>.kaguraignore</code> to exclude files:</p> <pre><code># .kaguraignore\nnode_modules/\n*.log\n.env\n__pycache__/\n</code></pre> <p>Files matching these patterns are automatically excluded from indexing.</p>"},{"location":"en/tutorials/13-multimodal-rag/#complete-example-documentation-assistant","title":"Complete Example: Documentation Assistant","text":"<p>Here's a full example with proper error handling:</p> <pre><code>import asyncio\nfrom pathlib import Path\nfrom kagura import agent\nfrom kagura.core.memory import MultimodalRAG\n\n\n@agent(\n    model=\"gpt-4o-mini\",\n    temperature=0.7,\n    enable_multimodal_rag=True,\n    rag_directory=Path(\"./my_project\")\n)\nasync def docs_bot(query: str, rag: MultimodalRAG) -&gt; str:\n    '''You are a documentation assistant.\n\n    Search relevant documentation: rag.query(\"{{ query }}\", n_results=5)\n    Answer based on results: {{ query }}\n\n    If you can't find relevant info, say so clearly.'''\n    pass\n\n\nasync def main():\n    print(\"Documentation Assistant\")\n    print(\"=\" * 40)\n\n    # Build index first (optional, but recommended)\n    print(\"Building knowledge base...\")\n\n    queries = [\n        \"How does authentication work?\",\n        \"Show me the architecture diagram\",\n        \"What's in the user guide?\",\n    ]\n\n    for query in queries:\n        print(f\"\\nQ: {query}\")\n        result = await docs_bot(query)\n        print(f\"A: {result}\\n\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#use-cases","title":"Use Cases","text":""},{"location":"en/tutorials/13-multimodal-rag/#1-technical-documentation","title":"1. Technical Documentation","text":"<pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./docs\"))\nasync def tech_support(question: str, rag) -&gt; str:\n    '''Answer technical questions using docs, diagrams, and screenshots.\n    Question: {{ question }}'''\n    pass\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#2-meeting-notes-search","title":"2. Meeting Notes Search","text":"<pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./meetings\"))\nasync def meeting_search(topic: str, rag) -&gt; str:\n    '''Search meeting recordings and notes for: {{ topic }}\n    Include timestamps and speakers.'''\n    pass\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#3-design-system-assistant","title":"3. Design System Assistant","text":"<pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./design_system\"))\nasync def design_helper(component: str, rag) -&gt; str:\n    '''Find design specs and screenshots for: {{ component }}'''\n    pass\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#performance-tips","title":"Performance Tips","text":""},{"location":"en/tutorials/13-multimodal-rag/#1-cache-sizing","title":"1. Cache Sizing","text":"<pre><code># For large projects\nrag_cache_size_mb=500  # 500MB cache\n\n# For small projects\nrag_cache_size_mb=50   # 50MB cache\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#2-concurrency-control","title":"2. Concurrency Control","text":"<pre><code># Build index with controlled concurrency\nawait rag.build_index(max_concurrent=5)  # Process 5 files at once\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#3-incremental-updates","title":"3. Incremental Updates","text":"<pre><code># Instead of full rebuild\nawait rag.build_index(force_rebuild=True)  # Slow\n\n# Use incremental update\nawait rag.incremental_update()             # Fast\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/13-multimodal-rag/#issue-google-api-key-not-found","title":"Issue: \"Google API key not found\"","text":"<p>Solution: Set the environment variable: <pre><code>export GOOGLE_API_KEY=\"your-key\"\n</code></pre></p>"},{"location":"en/tutorials/13-multimodal-rag/#issue-importerror-no-module-named-chromadb","title":"Issue: \"ImportError: No module named 'chromadb'\"","text":"<p>Solution: Install with web support (includes multimodal): <pre><code>pip install kagura-ai[web]\n</code></pre></p>"},{"location":"en/tutorials/13-multimodal-rag/#issue-index-build-is-slow","title":"Issue: Index build is slow","text":"<p>Solutions: 1. Reduce concurrency: <code>max_concurrent=2</code> 2. Exclude large files with <code>.kaguraignore</code> 3. Use smaller cache: <code>rag_cache_size_mb=50</code></p>"},{"location":"en/tutorials/13-multimodal-rag/#issue-out-of-memory","title":"Issue: Out of memory","text":"<p>Solutions: 1. Reduce cache size: <code>rag_cache_size_mb=50</code> 2. Process in batches with <code>incremental_update()</code> 3. Exclude large video files</p>"},{"location":"en/tutorials/13-multimodal-rag/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"en/tutorials/13-multimodal-rag/#1-multimodal-rag","title":"1. Multimodal RAG","text":"<p>Search and understand multiple content types: - Text, images, audio, video, PDFs - Automatic processing with Gemini API - Semantic vector search with ChromaDB</p>"},{"location":"en/tutorials/13-multimodal-rag/#2-agent-integration","title":"2. @agent Integration","text":"<pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./docs\"))\nasync def my_agent(query: str, rag: MultimodalRAG) -&gt; str:\n    pass\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#3-directory-scanning","title":"3. Directory Scanning","text":"<ul> <li>Recursive scanning with <code>.gitignore</code> support</li> <li>Automatic file type detection</li> <li>Parallel processing for speed</li> </ul>"},{"location":"en/tutorials/13-multimodal-rag/#4-caching-performance","title":"4. Caching &amp; Performance","text":"<ul> <li>File content caching (configurable size)</li> <li>Incremental updates (only new/modified files)</li> <li>Vector index persistence (no re-indexing on restart)</li> </ul>"},{"location":"en/tutorials/13-multimodal-rag/#next-steps","title":"Next Steps","text":"<p>Now that you understand Multimodal RAG:</p> <ol> <li>Combine with Memory - Use <code>enable_memory=True</code> for conversational RAG</li> <li>Add Tools - Combine RAG with custom tools for enhanced capabilities</li> <li>Deploy - Use RAG agents in production applications</li> </ol>"},{"location":"en/tutorials/13-multimodal-rag/#practice-exercises","title":"Practice Exercises","text":""},{"location":"en/tutorials/13-multimodal-rag/#exercise-1-image-search-agent","title":"Exercise 1: Image Search Agent","text":"<p>Create an agent that searches only images:</p> <pre><code>from kagura.loaders.file_types import FileType\n\n@agent(enable_multimodal_rag=True, rag_directory=Path(\"./images\"))\nasync def image_search(query: str, rag) -&gt; str:\n    '''Find images matching: {{ query }}\n    Use: rag.query(query, file_type=FileType.IMAGE)'''\n    pass\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#exercise-2-code-documentation","title":"Exercise 2: Code Documentation","text":"<p>Index a codebase and answer questions:</p> <pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./src\"))\nasync def code_qa(question: str, rag) -&gt; str:\n    '''Answer questions about the codebase: {{ question }}'''\n    pass\n\n# Test\nprint(await code_qa(\"How does the authentication module work?\"))\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#exercise-3-meeting-minutes-bot","title":"Exercise 3: Meeting Minutes Bot","text":"<p>Search meeting recordings and notes:</p> <pre><code>@agent(enable_multimodal_rag=True, rag_directory=Path(\"./meetings\"))\nasync def meeting_bot(topic: str, rag) -&gt; str:\n    '''Summarize discussions about: {{ topic }}\n    Include meeting dates and key decisions.'''\n    pass\n</code></pre>"},{"location":"en/tutorials/13-multimodal-rag/#summary","title":"Summary","text":"<p>You learned: - \u2713 What Multimodal RAG is and its benefits - \u2713 How to set up content directories for indexing - \u2713 How to create RAG-enabled agents with <code>@agent</code> - \u2713 How to search across text, images, audio, video, PDFs - \u2713 Performance optimization and troubleshooting</p> <p>Continue exploring with Tutorial 14: Advanced Memory Management!</p>"},{"location":"en/tutorials/14-testing/","title":"Tutorial 14: Agent Testing","text":"<p>Learn how to test AI agents using Kagura's testing framework, designed to handle the non-deterministic nature of LLM outputs.</p>"},{"location":"en/tutorials/14-testing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed (<code>pip install kagura-ai</code>)</li> <li>pytest installed (<code>pip install pytest</code>)</li> <li>Completion of Tutorial 1: Basic Agent</li> </ul>"},{"location":"en/tutorials/14-testing/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand testing challenges with AI agents - Use AgentTestCase for agent testing - Write assertions for LLM behavior - Mock LLM responses for deterministic testing - Measure performance and cost</p>"},{"location":"en/tutorials/14-testing/#the-challenge-of-testing-ai-agents","title":"The Challenge of Testing AI Agents","text":"<p>Unlike traditional functions, AI agents are non-deterministic:</p> <pre><code># Traditional function - predictable\ndef add(a, b):\n    return a + b\n\nassert add(2, 3) == 5  # Always passes\n\n# AI agent - non-deterministic\n@agent\nasync def hello(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\nresult = await hello(\"Alice\")\n# Could be: \"Hello, Alice!\"\n# Could be: \"Hi Alice! How are you?\"\n# Could be: \"Hello there, Alice! Nice to meet you!\"\n</code></pre> <p>Solution: Test for patterns, not exact matches.</p>"},{"location":"en/tutorials/14-testing/#step-1-basic-test-setup","title":"Step 1: Basic Test Setup","text":"<p>Create a file called <code>test_agents.py</code>:</p> <pre><code>import pytest\nfrom kagura import agent\nfrom kagura.testing import AgentTestCase\n\n\n# Define agent to test\n@agent\nasync def greeter(name: str) -&gt; str:\n    '''Say hello to {{ name }}'''\n    pass\n\n\n# Create test class\nclass TestGreeter(AgentTestCase):\n    agent = greeter\n\n    @pytest.mark.asyncio\n    async def test_basic_greeting(self):\n        \"\"\"Test that agent produces a greeting.\"\"\"\n        result = await self.agent(\"Alice\")\n\n        # Assert response is not empty\n        self.assert_not_empty(result)\n\n        # Assert response contains the name\n        self.assert_contains(result, \"Alice\")\n</code></pre> <p>Run the test:</p> <pre><code>pytest test_agents.py -v\n</code></pre>"},{"location":"en/tutorials/14-testing/#step-2-content-assertions","title":"Step 2: Content Assertions","text":"<p>AgentTestCase provides many assertion methods:</p>"},{"location":"en/tutorials/14-testing/#assert_contains","title":"assert_contains","text":"<pre><code>@pytest.mark.asyncio\nasync def test_contains_name(self):\n    result = await self.agent(\"Bob\")\n    self.assert_contains(result, \"Bob\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#assert_contains_any","title":"assert_contains_any","text":"<pre><code>@pytest.mark.asyncio\nasync def test_greeting_style(self):\n    result = await self.agent(\"Charlie\")\n\n    # Accept any common greeting\n    self.assert_contains_any(result, [\n        \"Hello\",\n        \"Hi\",\n        \"Hey\",\n        \"Greetings\"\n    ])\n</code></pre>"},{"location":"en/tutorials/14-testing/#assert_not_contains","title":"assert_not_contains","text":"<pre><code>@pytest.mark.asyncio\nasync def test_no_profanity(self):\n    result = await self.agent(\"Test\")\n    self.assert_not_contains(result, \"bad_word\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#assert_matches_pattern","title":"assert_matches_pattern","text":"<pre><code>@pytest.mark.asyncio\nasync def test_email_format(self):\n    @agent\n    async def email_extractor(text: str) -&gt; str:\n        '''Extract email from: {{ text }}'''\n        pass\n\n    result = await email_extractor(\"Contact: alice@example.com\")\n\n    # Use regex pattern\n    self.assert_matches_pattern(result, r'\\w+@\\w+\\.\\w+')\n</code></pre>"},{"location":"en/tutorials/14-testing/#step-3-language-detection","title":"Step 3: Language Detection","text":"<p>Test multilingual agents:</p> <pre><code>@agent\nasync def translator(text: str, target_lang: str) -&gt; str:\n    '''Translate \"{{ text }}\" to {{ target_lang }}'''\n    pass\n\n\nclass TestTranslator(AgentTestCase):\n    agent = translator\n\n    @pytest.mark.asyncio\n    async def test_japanese_translation(self):\n        result = await self.agent(\"Hello\", target_lang=\"Japanese\")\n\n        # Requires: pip install langdetect\n        self.assert_language(result, \"ja\")\n\n    @pytest.mark.asyncio\n    async def test_french_translation(self):\n        result = await self.agent(\"Hello\", target_lang=\"French\")\n        self.assert_language(result, \"fr\")\n</code></pre> <p>Note: Requires <code>langdetect</code>: <pre><code>pip install langdetect\n</code></pre></p>"},{"location":"en/tutorials/14-testing/#step-4-llm-behavior-assertions","title":"Step 4: LLM Behavior Assertions","text":"<p>Test LLM call characteristics:</p>"},{"location":"en/tutorials/14-testing/#assert_llm_calls","title":"assert_llm_calls","text":"<pre><code>@pytest.mark.asyncio\nasync def test_single_llm_call(self):\n    with self.record_llm_calls():\n        result = await self.agent(\"Test\")\n\n    # Assert exactly one LLM call was made\n    self.assert_llm_calls(count=1)\n\n\n@pytest.mark.asyncio\nasync def test_correct_model(self):\n    with self.record_llm_calls():\n        result = await self.agent(\"Test\")\n\n    # Assert specific model was used\n    self.assert_llm_calls(model=\"gpt-4o-mini\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#assert_token_usage","title":"assert_token_usage","text":"<pre><code>@pytest.mark.asyncio\nasync def test_token_budget(self):\n    with self.record_llm_calls():\n        result = await self.agent(\"Test\")\n\n    # Assert token usage within limit\n    self.assert_token_usage(max_tokens=500)\n</code></pre>"},{"location":"en/tutorials/14-testing/#assert_tool_calls","title":"assert_tool_calls","text":"<pre><code>def search_web(query: str) -&gt; str:\n    return f\"Results for: {query}\"\n\n\n@agent(tools=[search_web])\nasync def researcher(query: str) -&gt; str:\n    '''Search for: {{ query }}'''\n    pass\n\n\nclass TestResearcher(AgentTestCase):\n    agent = researcher\n\n    @pytest.mark.asyncio\n    async def test_uses_search_tool(self):\n        result = await self.agent(\"Python tutorials\")\n\n        # Assert search tool was called\n        self.assert_tool_calls([\"search_web\"])\n</code></pre>"},{"location":"en/tutorials/14-testing/#step-5-performance-testing","title":"Step 5: Performance Testing","text":""},{"location":"en/tutorials/14-testing/#test-execution-duration","title":"Test Execution Duration","text":"<pre><code>@pytest.mark.asyncio\nasync def test_response_time(self):\n    with self.measure_time() as timer:\n        result = await self.agent(\"Test\")\n\n    # Assert response within 5 seconds\n    self.assert_duration(5.0)\n</code></pre>"},{"location":"en/tutorials/14-testing/#test-cost-budget","title":"Test Cost Budget","text":"<pre><code>@pytest.mark.asyncio\nasync def test_cost_budget(self):\n    with self.record_llm_calls():\n        result = await self.agent(\"Test\")\n\n    # Assert cost under $0.01\n    self.assert_cost(0.01)\n</code></pre>"},{"location":"en/tutorials/14-testing/#step-6-mocking-llm-responses","title":"Step 6: Mocking LLM Responses","text":"<p>For fast, deterministic testing, mock LLM responses:</p> <pre><code>@pytest.mark.asyncio\nasync def test_with_mock_llm(self):\n    with self.mock_llm(\"Mocked response\"):\n        result = await self.agent(\"Test\")\n\n    # Now we can assert exact match\n    assert result == \"Mocked response\"\n</code></pre>"},{"location":"en/tutorials/14-testing/#use-case-test-error-handling","title":"Use Case: Test Error Handling","text":"<pre><code>@agent\nasync def safe_agent(query: str) -&gt; str:\n    '''Process: {{ query }}'''\n    pass\n\n\nclass TestSafeAgent(AgentTestCase):\n    agent = safe_agent\n\n    @pytest.mark.asyncio\n    async def test_handles_empty_response(self):\n        with self.mock_llm(\"\"):\n            result = await self.agent(\"Test\")\n\n            # Agent should handle empty response gracefully\n            # (Implementation-dependent)\n</code></pre>"},{"location":"en/tutorials/14-testing/#step-7-structured-output-testing","title":"Step 7: Structured Output Testing","text":"<p>Test agents that return Pydantic models:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n\n@agent\nasync def extract_person(text: str) -&gt; Person:\n    '''Extract person info from: {{ text }}'''\n    pass\n\n\nclass TestPersonExtractor(AgentTestCase):\n    agent = extract_person\n\n    @pytest.mark.asyncio\n    async def test_extracts_person(self):\n        result = await self.agent(\n            \"Alice is 30 years old and works as a software engineer\"\n        )\n\n        # Assert result is valid Person model\n        self.assert_valid_model(result, Person)\n\n        # Assert specific field values\n        self.assert_field_value(result, \"name\", \"Alice\")\n        self.assert_field_value(result, \"age\", 30)\n        self.assert_field_value(result, \"occupation\", \"software engineer\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#step-8-mocking-tools","title":"Step 8: Mocking Tools","text":"<p>Test agents with tools without executing real tools:</p> <pre><code>def expensive_api_call(query: str) -&gt; dict:\n    \"\"\"Simulate expensive API call.\"\"\"\n    # Real implementation would call external API\n    pass\n\n\n@agent(tools=[expensive_api_call])\nasync def api_agent(query: str) -&gt; str:\n    '''Query API: {{ query }}'''\n    pass\n\n\nclass TestAPIAgent(AgentTestCase):\n    agent = api_agent\n\n    @pytest.mark.asyncio\n    async def test_with_mocked_tool(self):\n        mock_data = {\"result\": \"mocked data\"}\n\n        with self.mock_tool(\"expensive_api_call\", return_value=mock_data):\n            result = await self.agent(\"test query\")\n\n            # Agent receives mocked data instead of real API call\n            self.assert_not_empty(result)\n</code></pre>"},{"location":"en/tutorials/14-testing/#complete-example-comprehensive-test-suite","title":"Complete Example: Comprehensive Test Suite","text":"<pre><code>import pytest\nfrom pydantic import BaseModel\nfrom kagura import agent\nfrom kagura.testing import AgentTestCase\n\n\n# Agent definition\n@agent(model=\"gpt-4o-mini\", temperature=0.7)\nasync def sentiment_analyzer(text: str) -&gt; str:\n    '''Analyze sentiment (positive/negative/neutral) of: {{ text }}'''\n    pass\n\n\n# Test suite\nclass TestSentimentAnalyzer(AgentTestCase):\n    agent = sentiment_analyzer\n\n    @pytest.mark.asyncio\n    async def test_positive_sentiment(self):\n        \"\"\"Test positive sentiment detection.\"\"\"\n        result = await self.agent(\"I love this product!\")\n\n        self.assert_not_empty(result)\n        self.assert_contains_any(result, [\"positive\", \"Positive\"])\n\n    @pytest.mark.asyncio\n    async def test_negative_sentiment(self):\n        \"\"\"Test negative sentiment detection.\"\"\"\n        result = await self.agent(\"This is terrible.\")\n\n        self.assert_not_empty(result)\n        self.assert_contains_any(result, [\"negative\", \"Negative\"])\n\n    @pytest.mark.asyncio\n    async def test_neutral_sentiment(self):\n        \"\"\"Test neutral sentiment detection.\"\"\"\n        result = await self.agent(\"It's okay.\")\n\n        self.assert_not_empty(result)\n        self.assert_contains_any(result, [\"neutral\", \"Neutral\"])\n\n    @pytest.mark.asyncio\n    async def test_uses_correct_model(self):\n        \"\"\"Test correct model is used.\"\"\"\n        with self.record_llm_calls():\n            result = await self.agent(\"Test\")\n\n        self.assert_llm_calls(count=1, model=\"gpt-4o-mini\")\n\n    @pytest.mark.asyncio\n    async def test_performance(self):\n        \"\"\"Test response time.\"\"\"\n        with self.measure_time():\n            result = await self.agent(\"Test\")\n\n        self.assert_duration(5.0)\n\n    @pytest.mark.asyncio\n    async def test_token_efficiency(self):\n        \"\"\"Test token usage.\"\"\"\n        with self.record_llm_calls():\n            result = await self.agent(\"Test\")\n\n        self.assert_token_usage(max_tokens=200)\n\n    @pytest.mark.asyncio\n    async def test_deterministic_with_mock(self):\n        \"\"\"Test with mocked LLM response.\"\"\"\n        with self.mock_llm(\"Positive sentiment detected\"):\n            result = await self.agent(\"Test\")\n\n        assert result == \"Positive sentiment detected\"\n</code></pre> <p>Run the suite:</p> <pre><code>pytest test_agents.py -v\n</code></pre>"},{"location":"en/tutorials/14-testing/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/14-testing/#1-test-patterns-not-exact-text","title":"1. Test Patterns, Not Exact Text","text":"<pre><code># Good\nself.assert_contains_any(result, [\"hello\", \"hi\", \"greetings\"])\n\n# Bad\nassert result == \"Hello, World!\"  # Too brittle\n</code></pre>"},{"location":"en/tutorials/14-testing/#2-use-mocks-for-fast-tests","title":"2. Use Mocks for Fast Tests","text":"<pre><code># Fast (mocked)\nwith self.mock_llm(\"Mocked\"):\n    result = await self.agent(\"Test\")\n\n# Slow (real LLM call)\nresult = await self.agent(\"Test\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#3-test-edge-cases","title":"3. Test Edge Cases","text":"<pre><code>@pytest.mark.asyncio\nasync def test_empty_input(self):\n    result = await self.agent(\"\")\n    # Handle edge case\n\n@pytest.mark.asyncio\nasync def test_very_long_input(self):\n    long_text = \"word \" * 1000\n    result = await self.agent(long_text)\n    # Handle long input\n</code></pre>"},{"location":"en/tutorials/14-testing/#4-parametrize-tests","title":"4. Parametrize Tests","text":"<pre><code>@pytest.mark.asyncio\n@pytest.mark.parametrize(\"text,expected\", [\n    (\"I love it\", \"positive\"),\n    (\"I hate it\", \"negative\"),\n    (\"It's okay\", \"neutral\"),\n])\nasync def test_sentiment(self, text, expected):\n    result = await self.agent(text)\n    self.assert_contains(result.lower(), expected)\n</code></pre>"},{"location":"en/tutorials/14-testing/#common-testing-patterns","title":"Common Testing Patterns","text":""},{"location":"en/tutorials/14-testing/#pattern-1-golden-test","title":"Pattern 1: Golden Test","text":"<p>Store expected output and compare:</p> <pre><code>@pytest.mark.asyncio\nasync def test_golden_output(self):\n    with self.mock_llm(\"Expected output\"):\n        result = await self.agent(\"Test\")\n\n    # Load golden output from file\n    with open(\"golden_output.txt\") as f:\n        expected = f.read()\n\n    assert result == expected\n</code></pre>"},{"location":"en/tutorials/14-testing/#pattern-2-regression-test","title":"Pattern 2: Regression Test","text":"<p>Ensure behavior doesn't change:</p> <pre><code>@pytest.mark.asyncio\nasync def test_no_regression(self):\n    # Use fixed mock to ensure consistent behavior\n    with self.mock_llm(\"Previous version output\"):\n        result = await self.agent(\"Test\")\n\n    # Test should always pass\n    self.assert_not_empty(result)\n</code></pre>"},{"location":"en/tutorials/14-testing/#pattern-3-integration-test","title":"Pattern 3: Integration Test","text":"<p>Test multiple agents together:</p> <pre><code>@pytest.mark.asyncio\nasync def test_agent_pipeline(self):\n    @agent\n    async def analyzer(text: str) -&gt; str:\n        '''Analyze: {{ text }}'''\n        pass\n\n    @agent\n    async def summarizer(text: str) -&gt; str:\n        '''Summarize: {{ text }}'''\n        pass\n\n    # Test pipeline\n    analysis = await analyzer(\"Long text...\")\n    summary = await summarizer(analysis)\n\n    self.assert_not_empty(summary)\n</code></pre>"},{"location":"en/tutorials/14-testing/#common-mistakes","title":"Common Mistakes","text":""},{"location":"en/tutorials/14-testing/#1-testing-exact-llm-output","title":"1. Testing Exact LLM Output","text":"<pre><code># Wrong - LLM output varies\nassert result == \"Hello, World!\"\n\n# Correct - Test pattern\nself.assert_contains(result, \"World\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#2-not-using-mocks","title":"2. Not Using Mocks","text":"<pre><code># Slow - Real LLM calls in every test\nresult = await self.agent(\"Test\")\n\n# Fast - Mocked responses\nwith self.mock_llm(\"Mocked\"):\n    result = await self.agent(\"Test\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#3-missing-pytestmarkasyncio","title":"3. Missing @pytest.mark.asyncio","text":"<pre><code># Wrong - Async test without decorator\nasync def test_agent(self):\n    result = await self.agent(\"Test\")\n\n# Correct\n@pytest.mark.asyncio\nasync def test_agent(self):\n    result = await self.agent(\"Test\")\n</code></pre>"},{"location":"en/tutorials/14-testing/#practice-exercises","title":"Practice Exercises","text":""},{"location":"en/tutorials/14-testing/#exercise-1-test-translation-agent","title":"Exercise 1: Test Translation Agent","text":"<p>Create tests for a translation agent:</p> <pre><code>@agent\nasync def translator(text: str, target_lang: str) -&gt; str:\n    '''Translate to {{ target_lang }}: {{ text }}'''\n    pass\n\n# Your tests here:\nclass TestTranslator(AgentTestCase):\n    agent = translator\n\n    # TODO: Test Japanese translation\n    # TODO: Test French translation\n    # TODO: Test empty input\n    # TODO: Test performance\n</code></pre>"},{"location":"en/tutorials/14-testing/#exercise-2-test-with-multiple-assertions","title":"Exercise 2: Test with Multiple Assertions","text":"<p>Create a comprehensive test with multiple assertions:</p> <pre><code>@pytest.mark.asyncio\nasync def test_comprehensive(self):\n    with self.record_llm_calls():\n        with self.measure_time():\n            result = await self.agent(\"Test\")\n\n    # TODO: Add multiple assertions\n    # - Not empty\n    # - Contains specific text\n    # - LLM call count\n    # - Duration\n    # - Token usage\n</code></pre>"},{"location":"en/tutorials/14-testing/#exercise-3-mock-tool-testing","title":"Exercise 3: Mock Tool Testing","text":"<p>Test an agent with tools:</p> <pre><code>def calculator(expr: str) -&gt; float:\n    return eval(expr)\n\n@agent(tools=[calculator])\nasync def math_agent(question: str) -&gt; str:\n    '''Answer: {{ question }}'''\n    pass\n\n# TODO: Create tests with mocked calculator\n</code></pre>"},{"location":"en/tutorials/14-testing/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"en/tutorials/14-testing/#1-non-deterministic-testing","title":"1. Non-Deterministic Testing","text":"<p>Test patterns, not exact matches: <pre><code>self.assert_contains_any(result, [\"option1\", \"option2\"])\n</code></pre></p>"},{"location":"en/tutorials/14-testing/#2-llm-behavior-assertions","title":"2. LLM Behavior Assertions","text":"<p>Assert on LLM characteristics: <pre><code>self.assert_llm_calls(count=1, model=\"gpt-4o-mini\")\nself.assert_token_usage(max_tokens=500)\n</code></pre></p>"},{"location":"en/tutorials/14-testing/#3-mocking-for-determinism","title":"3. Mocking for Determinism","text":"<p>Use mocks for fast, predictable tests: <pre><code>with self.mock_llm(\"Fixed output\"):\n    result = await self.agent(\"Test\")\n</code></pre></p>"},{"location":"en/tutorials/14-testing/#4-performance-testing","title":"4. Performance Testing","text":"<p>Measure duration and cost: <pre><code>self.assert_duration(5.0)\nself.assert_cost(0.01)\n</code></pre></p>"},{"location":"en/tutorials/14-testing/#next-steps","title":"Next Steps","text":"<ul> <li>Tutorial 15: Observability - Monitor agent performance</li> <li>API Reference: Testing - Complete testing API</li> <li>Tutorial 13: Agent Builder - Build complex agents</li> </ul>"},{"location":"en/tutorials/14-testing/#summary","title":"Summary","text":"<p>You learned: - \u2713 How to test non-deterministic AI agents - \u2713 How to use AgentTestCase assertions - \u2713 How to mock LLM responses and tools - \u2713 How to test performance and cost - \u2713 How to test structured outputs</p> <p>Continue to Tutorial 15: Observability to learn agent monitoring!</p>"},{"location":"en/tutorials/15-observability/","title":"Tutorial 15: Observability &amp; Monitoring","text":"<p>Learn how to monitor agent execution telemetry, track performance, analyze costs, and debug issues using Kagura's observability tools.</p>"},{"location":"en/tutorials/15-observability/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Kagura AI installed (<code>pip install kagura-ai</code>)</li> <li>Completion of Tutorial 1: Basic Agent</li> <li>Rich library (included with Kagura)</li> </ul>"},{"location":"en/tutorials/15-observability/#goal","title":"Goal","text":"<p>By the end of this tutorial, you will: - Understand agent telemetry and observability - Use the monitor CLI for live tracking - Analyze execution history and traces - Track performance metrics and costs - Build custom monitoring dashboards</p>"},{"location":"en/tutorials/15-observability/#what-is-observability","title":"What is Observability?","text":"<p>Observability means understanding what your agents are doing: - When did they run? - How long did they take? - What did they call (LLM, tools)? - How much did they cost? - Did they succeed or fail?</p> <p>Kagura automatically tracks telemetry for all agent executions.</p>"},{"location":"en/tutorials/15-observability/#step-1-enable-telemetry","title":"Step 1: Enable Telemetry","text":"<p>Telemetry is enabled by default. All agent executions are automatically recorded to:</p> <pre><code>~/.kagura/telemetry.db\n</code></pre> <p>No configuration needed!</p>"},{"location":"en/tutorials/15-observability/#step-2-live-monitoring","title":"Step 2: Live Monitoring","text":"<p>The simplest way to monitor agents is the <code>kagura monitor</code> command:</p> <pre><code># Start live monitoring\nkagura monitor\n</code></pre> <p>Output: <pre><code>\ud83d\udcca Kagura Agent Monitor\nTotal: 42 | Completed: 40 | Failed: 2\n\n\u250c\u2500 Recent Activity \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Time     Agent         Status      Duration  Cost     \u2502\n\u2502 14:32:15 translator    \u2713 COMPLETED 0.52s    $0.0003  \u2502\n\u2502 14:31:58 chatbot       \u2713 COMPLETED 1.23s    $0.0012  \u2502\n\u2502 14:30:41 researcher    \u2717 FAILED    2.11s    $0.0008  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#monitor-specific-agent","title":"Monitor Specific Agent","text":"<pre><code># Monitor only \"translator\" agent\nkagura monitor --agent translator\n</code></pre>"},{"location":"en/tutorials/15-observability/#custom-refresh-rate","title":"Custom Refresh Rate","text":"<pre><code># Update every 2 seconds\nkagura monitor --refresh 2.0\n</code></pre>"},{"location":"en/tutorials/15-observability/#step-3-execution-history","title":"Step 3: Execution History","text":"<p>View past executions:</p> <pre><code># List recent executions\nkagura monitor list\n\n# Filter by agent\nkagura monitor list --agent my_agent\n\n# Filter by status (completed/failed)\nkagura monitor list --status failed\n\n# Limit results\nkagura monitor list --limit 50\n</code></pre> <p>Output: <pre><code>\u250c\u2500 Execution History \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Time     Agent         Status      Duration  Cost     \u2502\n\u2502 14:32:15 translator    \u2713 COMPLETED 0.52s    $0.0003  \u2502\n\u2502 14:31:58 chatbot       \u2713 COMPLETED 1.23s    $0.0012  \u2502\n\u2502 14:30:41 researcher    \u2717 FAILED    2.11s    $0.0008  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#step-4-statistics","title":"Step 4: Statistics","text":"<p>Get aggregate statistics:</p> <pre><code># Overall statistics\nkagura monitor stats\n\n# Agent-specific stats\nkagura monitor stats --agent translator\n</code></pre> <p>Output: <pre><code>\ud83d\udcca Summary Statistics\n\nTotal Executions: 42\n  \u2022 Completed: 40\n  \u2022 Failed: 2\nAvg Duration: 1.34s\nTotal Cost: $0.0512\nTotal Tokens: 12,450\nLLM Calls: 45\nTool Calls: 12\n\nSuccess Rate: 95.2%\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#step-5-detailed-traces","title":"Step 5: Detailed Traces","text":"<p>View detailed execution traces:</p> <pre><code># Get execution ID from list\nkagura monitor list\n\n# View detailed trace\nkagura monitor trace exec_abc123\n</code></pre> <p>Output: <pre><code>\ud83d\udccd Execution Trace: translator (exec_abc123)\n\nExecution Info\n\u251c\u2500\u2500 Started: 14:32:15\n\u251c\u2500\u2500 Status: \u2713 COMPLETED\n\u251c\u2500\u2500 Duration: 0.52s\n\nMetrics\n\u251c\u2500\u2500 total_cost: $0.0003\n\u251c\u2500\u2500 total_tokens: 85\n\u251c\u2500\u2500 llm_calls: 1\n\u2514\u2500\u2500 tool_calls: 0\n\nEvents Timeline (3 events)\n\u251c\u2500\u2500 [0.00s] LLM Call (gpt-4o-mini) - 85 tokens, $0.0003, 0.48s\n\u251c\u2500\u2500 [0.48s] Memory Op (store) - 0.02s\n\u2514\u2500\u2500 [0.50s] Completion\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#step-6-cost-analysis","title":"Step 6: Cost Analysis","text":"<p>Track costs across agents:</p> <pre><code># Cost by agent\nkagura monitor cost\n\n# Cost by date\nkagura monitor cost --group-by date\n</code></pre> <p>Output (by agent): <pre><code>\u250c\u2500 Cost by Agent \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Agent          Calls  Tokens    Cost     \u2502\n\u2502 translator     23     5,123     $0.0234  \u2502\n\u2502 chatbot        15     4,892     $0.0189  \u2502\n\u2502 researcher     4      2,435     $0.0089  \u2502\n\u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502 Total          42     12,450    $0.0512  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nEstimated monthly cost: $1.54\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#step-7-programmatic-access","title":"Step 7: Programmatic Access","text":"<p>Use EventStore and Dashboard in your Python code:</p> <pre><code>from pathlib import Path\nfrom kagura.observability import EventStore, Dashboard\n\n# Load event store\nstore = EventStore(Path.home() / \".kagura\" / \"telemetry.db\")\n\n# Get recent executions\nexecutions = store.get_executions(agent_name=\"translator\", limit=10)\n\nfor exec in executions:\n    print(f\"{exec['agent_name']}: {exec['status']} - {exec['duration']:.2f}s\")\n\n# Get statistics\nstats = store.get_summary_stats(agent_name=\"translator\")\nprint(f\"Total: {stats['total_executions']}\")\nprint(f\"Avg Duration: {stats['avg_duration']:.2f}s\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#step-8-custom-dashboard","title":"Step 8: Custom Dashboard","text":"<p>Create a custom monitoring dashboard:</p> <pre><code>from kagura.observability import EventStore, Dashboard\n\n# Initialize\nstore = EventStore()\ndashboard = Dashboard(store)\n\n# Show live dashboard (refreshes every 1 second)\ndashboard.show_live(agent_name=\"my_agent\", refresh_rate=1.0)\n\n# Show execution list\ndashboard.show_list(agent_name=\"my_agent\", limit=20)\n\n# Show statistics\ndashboard.show_stats(agent_name=\"my_agent\")\n\n# Show specific trace\ndashboard.show_trace(execution_id=\"exec_abc123\")\n\n# Show cost summary\ndashboard.show_cost_summary(group_by=\"agent\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#step-9-filtering-and-querying","title":"Step 9: Filtering and Querying","text":"<p>Filter executions programmatically:</p> <pre><code>import time\nfrom kagura.observability import EventStore\n\nstore = EventStore()\n\n# Get executions from last 24 hours\nsince = time.time() - 86400  # 24 hours ago\nrecent = store.get_executions(since=since)\n\n# Get failed executions only\nfailed = store.get_executions(status=\"failed\")\n\n# Get specific agent's executions\nagent_execs = store.get_executions(agent_name=\"translator\", limit=50)\n\n# Get single execution\nexecution = store.get_execution(\"exec_abc123\")\nif execution:\n    print(f\"Duration: {execution['duration']:.2f}s\")\n    print(f\"Status: {execution['status']}\")\n    print(f\"Error: {execution.get('error')}\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#step-10-cleanup-old-data","title":"Step 10: Cleanup Old Data","text":"<p>Manage telemetry database size:</p> <pre><code>import time\nfrom kagura.observability import EventStore\n\nstore = EventStore()\n\n# Delete executions older than 30 days\nthirty_days_ago = time.time() - (30 * 86400)\ndeleted = store.delete_old_executions(older_than=thirty_days_ago)\nprint(f\"Deleted {deleted} old executions\")\n\n# Clear all data (use with caution!)\n# store.clear_all()\n</code></pre>"},{"location":"en/tutorials/15-observability/#complete-example-monitoring-integration","title":"Complete Example: Monitoring Integration","text":"<pre><code>import asyncio\nfrom kagura import agent\nfrom kagura.observability import EventStore, Dashboard\n\n\n@agent(model=\"gpt-4o-mini\")\nasync def translator(text: str, target_lang: str) -&gt; str:\n    '''Translate \"{{ text }}\" to {{ target_lang }}'''\n    pass\n\n\nasync def main():\n    # Run agent multiple times\n    translations = [\n        (\"Hello\", \"French\"),\n        (\"Goodbye\", \"Japanese\"),\n        (\"Thank you\", \"Spanish\"),\n    ]\n\n    for text, lang in translations:\n        result = await translator(text, target_lang=lang)\n        print(f\"{text} \u2192 {lang}: {result}\")\n\n    # Analyze telemetry\n    store = EventStore()\n    dashboard = Dashboard(store)\n\n    print(\"\\n\" + \"=\" * 50)\n    print(\"TELEMETRY ANALYSIS\")\n    print(\"=\" * 50 + \"\\n\")\n\n    # Show statistics\n    dashboard.show_stats(agent_name=\"translator\")\n\n    # Show execution list\n    dashboard.show_list(agent_name=\"translator\", limit=10)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"en/tutorials/15-observability/#use-cases","title":"Use Cases","text":""},{"location":"en/tutorials/15-observability/#use-case-1-performance-monitoring","title":"Use Case 1: Performance Monitoring","text":"<p>Track agent performance over time:</p> <pre><code>store = EventStore()\n\n# Get last 100 executions\nexecutions = store.get_executions(limit=100)\n\n# Calculate average duration per agent\nfrom collections import defaultdict\n\nagent_durations = defaultdict(list)\nfor exec in executions:\n    agent_durations[exec['agent_name']].append(exec['duration'])\n\nfor agent, durations in agent_durations.items():\n    avg = sum(durations) / len(durations)\n    print(f\"{agent}: {avg:.2f}s average\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#use-case-2-cost-budget-alerts","title":"Use Case 2: Cost Budget Alerts","text":"<p>Monitor costs and alert when budget exceeded:</p> <pre><code>store = EventStore()\n\n# Get today's executions\nimport time\ntoday_start = time.time() - 86400\nexecutions = store.get_executions(since=today_start)\n\n# Calculate total cost\ntotal_cost = sum(\n    exec.get('metrics', {}).get('total_cost', 0.0)\n    for exec in executions\n)\n\n# Alert if over budget\nDAILY_BUDGET = 1.0  # $1.00\nif total_cost &gt; DAILY_BUDGET:\n    print(f\"\u26a0\ufe0f  ALERT: Daily cost ${total_cost:.2f} exceeds budget ${DAILY_BUDGET:.2f}\")\nelse:\n    print(f\"\u2713 Cost ${total_cost:.2f} within budget ${DAILY_BUDGET:.2f}\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#use-case-3-error-tracking","title":"Use Case 3: Error Tracking","text":"<p>Track and analyze failures:</p> <pre><code>store = EventStore()\n\n# Get all failed executions\nfailed = store.get_executions(status=\"failed\", limit=100)\n\n# Group by error type\nfrom collections import Counter\n\nerror_types = Counter(\n    exec.get('error', 'Unknown error')\n    for exec in failed\n)\n\nprint(\"Top 5 Error Types:\")\nfor error, count in error_types.most_common(5):\n    print(f\"  {count}x: {error}\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#use-case-4-custom-metrics-dashboard","title":"Use Case 4: Custom Metrics Dashboard","text":"<p>Build a real-time metrics dashboard:</p> <pre><code>import time\nfrom rich.console import Console\nfrom rich.table import Table\nfrom kagura.observability import EventStore\n\ndef show_realtime_metrics():\n    \"\"\"Display real-time metrics dashboard.\"\"\"\n    store = EventStore()\n    console = Console()\n\n    while True:\n        # Get recent executions\n        recent = store.get_executions(limit=50)\n\n        # Calculate metrics\n        total = len(recent)\n        completed = sum(1 for e in recent if e['status'] == 'completed')\n        failed = total - completed\n        avg_duration = sum(e['duration'] for e in recent) / total if total &gt; 0 else 0\n\n        # Create table\n        table = Table(title=\"Real-Time Metrics\")\n        table.add_column(\"Metric\", style=\"cyan\")\n        table.add_column(\"Value\", style=\"white\")\n\n        table.add_row(\"Total Executions\", str(total))\n        table.add_row(\"Completed\", str(completed))\n        table.add_row(\"Failed\", str(failed))\n        table.add_row(\"Avg Duration\", f\"{avg_duration:.2f}s\")\n\n        # Display\n        console.clear()\n        console.print(table)\n\n        time.sleep(2)  # Refresh every 2 seconds\n\n# show_realtime_metrics()\n</code></pre>"},{"location":"en/tutorials/15-observability/#best-practices","title":"Best Practices","text":""},{"location":"en/tutorials/15-observability/#1-regular-monitoring","title":"1. Regular Monitoring","text":"<p>Check your agents regularly:</p> <pre><code># Daily health check\nkagura monitor stats\n\n# Weekly cost review\nkagura monitor cost\n</code></pre>"},{"location":"en/tutorials/15-observability/#2-set-up-alerts","title":"2. Set Up Alerts","text":"<p>Create scripts to alert on issues:</p> <pre><code>#!/bin/bash\n# daily_check.sh\n\n# Check for failed executions\nfailed_count=$(kagura monitor stats | grep \"Failed:\" | awk '{print $3}')\n\nif [ \"$failed_count\" -gt 10 ]; then\n  echo \"\u26a0\ufe0f  Alert: $failed_count failed executions\"\n  # Send notification (email, Slack, etc.)\nfi\n</code></pre>"},{"location":"en/tutorials/15-observability/#3-cost-tracking","title":"3. Cost Tracking","text":"<p>Track costs by project:</p> <pre><code># Tag agents by project\n@agent(model=\"gpt-4o-mini\")\nasync def project_a_agent(query: str) -&gt; str:\n    '''...'''\n    pass\n\n# Query costs by agent name prefix\nproject_a_execs = store.get_executions(agent_name=\"project_a_\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#4-performance-baselines","title":"4. Performance Baselines","text":"<p>Establish performance baselines:</p> <pre><code># Record baseline\nbaseline_duration = 2.0  # seconds\n\n# Check if performance degraded\nrecent = store.get_executions(agent_name=\"my_agent\", limit=10)\navg_recent = sum(e['duration'] for e in recent) / len(recent)\n\nif avg_recent &gt; baseline_duration * 1.5:\n    print(f\"\u26a0\ufe0f  Performance degraded: {avg_recent:.2f}s (baseline: {baseline_duration:.2f}s)\")\n</code></pre>"},{"location":"en/tutorials/15-observability/#common-monitoring-patterns","title":"Common Monitoring Patterns","text":""},{"location":"en/tutorials/15-observability/#pattern-1-health-check","title":"Pattern 1: Health Check","text":"<pre><code>def health_check(agent_name: str) -&gt; dict:\n    \"\"\"Check agent health.\"\"\"\n    store = EventStore()\n    recent = store.get_executions(agent_name=agent_name, limit=20)\n\n    if not recent:\n        return {\"status\": \"unknown\", \"reason\": \"no executions\"}\n\n    failed = sum(1 for e in recent if e['status'] == 'failed')\n    failure_rate = failed / len(recent)\n\n    if failure_rate &gt; 0.5:\n        return {\"status\": \"unhealthy\", \"failure_rate\": failure_rate}\n    elif failure_rate &gt; 0.2:\n        return {\"status\": \"degraded\", \"failure_rate\": failure_rate}\n    else:\n        return {\"status\": \"healthy\", \"failure_rate\": failure_rate}\n</code></pre>"},{"location":"en/tutorials/15-observability/#pattern-2-performance-regression-detection","title":"Pattern 2: Performance Regression Detection","text":"<pre><code>def detect_regression(agent_name: str, threshold: float = 1.5) -&gt; bool:\n    \"\"\"Detect performance regression.\"\"\"\n    store = EventStore()\n\n    # Get baseline (last 100 executions)\n    baseline = store.get_executions(agent_name=agent_name, limit=100)\n    baseline_avg = sum(e['duration'] for e in baseline) / len(baseline)\n\n    # Get recent (last 10 executions)\n    recent = store.get_executions(agent_name=agent_name, limit=10)\n    recent_avg = sum(e['duration'] for e in recent) / len(recent)\n\n    # Check if recent is significantly slower\n    return recent_avg &gt; baseline_avg * threshold\n</code></pre>"},{"location":"en/tutorials/15-observability/#pattern-3-cost-tracking","title":"Pattern 3: Cost Tracking","text":"<pre><code>def get_cost_breakdown(since: float) -&gt; dict:\n    \"\"\"Get cost breakdown by agent.\"\"\"\n    store = EventStore()\n    executions = store.get_executions(since=since, limit=10000)\n\n    breakdown = {}\n    for exec in executions:\n        agent = exec['agent_name']\n        cost = exec.get('metrics', {}).get('total_cost', 0.0)\n\n        if agent not in breakdown:\n            breakdown[agent] = {\"cost\": 0.0, \"calls\": 0}\n\n        breakdown[agent][\"cost\"] += cost\n        breakdown[agent][\"calls\"] += 1\n\n    return breakdown\n</code></pre>"},{"location":"en/tutorials/15-observability/#troubleshooting","title":"Troubleshooting","text":""},{"location":"en/tutorials/15-observability/#issue-no-telemetry-data","title":"Issue: No telemetry data","text":"<p>Solution: Check database location: <pre><code>ls ~/.kagura/telemetry.db\n</code></pre></p> <p>If missing, run an agent to initialize it.</p>"},{"location":"en/tutorials/15-observability/#issue-old-data-filling-disk","title":"Issue: Old data filling disk","text":"<p>Solution: Regularly clean old data: <pre><code>import time\nfrom kagura.observability import EventStore\n\nstore = EventStore()\nthirty_days_ago = time.time() - (30 * 86400)\nstore.delete_old_executions(older_than=thirty_days_ago)\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#issue-slow-queries","title":"Issue: Slow queries","text":"<p>Solution: Use indexes and filters: <pre><code># Efficient - uses indexes\nstore.get_executions(agent_name=\"my_agent\", limit=100)\n\n# Less efficient - scans all data\nall_execs = store.get_executions(limit=100000)\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#key-concepts-learned","title":"Key Concepts Learned","text":""},{"location":"en/tutorials/15-observability/#1-automatic-telemetry","title":"1. Automatic Telemetry","text":"<p>All executions are tracked automatically: <pre><code># Just use agents - telemetry is automatic\nresult = await my_agent(\"query\")\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#2-cli-monitoring","title":"2. CLI Monitoring","text":"<p>Quick monitoring via CLI: <pre><code>kagura monitor        # Live view\nkagura monitor list   # History\nkagura monitor stats  # Statistics\nkagura monitor trace  # Detailed trace\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#3-programmatic-access","title":"3. Programmatic Access","text":"<p>Build custom monitoring: <pre><code>store = EventStore()\nexecutions = store.get_executions(...)\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#4-cost-tracking","title":"4. Cost Tracking","text":"<p>Monitor spending: <pre><code>kagura monitor cost\n</code></pre></p>"},{"location":"en/tutorials/15-observability/#next-steps","title":"Next Steps","text":"<ul> <li>API Reference: Observability - Complete observability API</li> <li>Tutorial 13: Agent Builder - Build advanced agents</li> <li>Tutorial 14: Testing - Test your agents</li> </ul>"},{"location":"en/tutorials/15-observability/#summary","title":"Summary","text":"<p>You learned: - \u2713 How to monitor agents with CLI commands - \u2713 How to access telemetry programmatically - \u2713 How to track performance and costs - \u2713 How to build custom dashboards - \u2713 Best practices for observability</p> <p>You now have the tools to monitor, debug, and optimize your AI agents!</p>"}]}